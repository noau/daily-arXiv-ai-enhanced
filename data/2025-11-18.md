<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 8]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Learning Conjugate Direction Fields for Planar Quadrilateral Mesh Generation](https://arxiv.org/abs/2511.11865)
*Jiong Tao,Yong-Liang Yang,Bailin Deng*

Main category: cs.GR

TL;DR: 提出了一种基于神经网络的平面四边形网格生成方法，通过数据驱动的共轭方向场生成，解决了传统方法计算复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的共轭方向场生成需要解决复杂的非线性优化问题，计算成本高，限制了交互式设计过程。因此，需要一种高效的方法来生成符合用户需求的共轭方向场。

Method: 采用基于神经网络的数据驱动方法，学习并融合自由曲面的特征和用户笔画，高效生成符合用户引导的高质量共轭方向场。

Result: 实验结果表明，该方法在各种测试数据、建筑曲面和一般3D形状上均表现出高效性和有效性。

Conclusion: 提出的数据驱动方法在平面四边形网格生成中表现出色，为交互式设计提供了可行的解决方案。

Abstract: Planar quadrilateral (PQ) mesh generation is a key process in computer-aided design, particularly for architectural applications where the goal is to discretize a freeform surface using planar quad faces. The conjugate direction field (CDF) defined on the freeform surface plays a significant role in generating a PQ mesh, as it largely determines the PQ mesh layout. Conventionally, a CDF is obtained by solving a complex non-linear optimization problem that incorporates user preferences, i.e., aligning the CDF with user-specified strokes on the surface. This often requires a large number of iterations that are computationally expensive, preventing the interactive CDF design process for a desirable PQ mesh. To address this challenge, we propose a data-driven approach based on neural networks for controlled CDF generation. Our approach can effectively learn and fuse features from the freeform surface and the user strokes, and efficiently generate quality CDF respecting user guidance. To enable training and testing, we also present a dataset composed of 50000+ freeform surfaces with ground-truth CDFs, as well as a set of metrics for quantitative evaluation. The effectiveness and efficiency of our work are demonstrated by extensive experiments using testing data, architectural surfaces, and general 3D shapes.

</details>


### [2] [Locomotion in CAVE: Enhancing Immersion through Full-Body Motion](https://arxiv.org/abs/2511.12251)
*Xiaohui Li,Xiaolong Liu,Zhongchen Shi,Wei Chen,Liang Xie,Meng Gai,Jun Cao,Suxia Zhang,Erwei Yin*

Main category: cs.GR

TL;DR: 提出了一种用于CAVE环境的运动框架，通过优化的人体运动识别技术提升沉浸感。


<details>
  <summary>Details</summary>
Motivation: CAVE中的运动方法受限于不自然的交互方式，影响了用户体验和沉浸感。

Method: 构建四面显示CAVE系统，通过动态方法校准摄像头，利用动作识别架构获取动作类别，并转换为图形工作站显示效果。

Result: 与传统方法相比，该方法在真实感和自我存在感上有显著提升，有效减少了运动不适。

Conclusion: 提出的运动框架显著改善了用户在CAVE环境中的沉浸体验，减少了不适感。

Abstract: Cave Automatic Virtual Environment (CAVE) is one of the virtual reality (VR) immersive devices currently used to present virtual environments. However, the locomotion methods in the CAVE are limited by unnatural interaction methods, severely hindering the user experience and immersion in the CAVE. We proposed a locomotion framework for CAVE environments aimed at enhancing the immersive locomotion experience through optimized human motion recognition technology. Firstly, we construct a four-sided display CAVE system, then through the dynamic method based on Perspective-n-Point to calibrate the camera, using the obtained camera intrinsics and extrinsic parameters, and an action recognition architecture to get the action category. At last, transform the action category to a graphical workstation that renders display effects on the screen. We designed a user study to validate the effectiveness of our method. Compared to the traditional methods, our method has significant improvements in realness and self-presence in the virtual environment, effectively reducing motion sickness.

</details>


### [3] [TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting](https://arxiv.org/abs/2511.13009)
*Yong Liu,Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.GR

TL;DR: TR-Gaussians是一种基于3D高斯的新型表示方法，用于高保真渲染室内场景中常见的平面透射和反射。


<details>
  <summary>Details</summary>
Motivation: 室内场景中平面透射和反射的普遍存在性促使研究者提出一种能够高保真渲染这些效果的方法。

Method: 该方法结合了3D高斯和可学习的反射平面，通过Fresnel-based的视点相关加权方案混合透射和反射组件。

Result: 实验表明，TR-Gaussians在不同数据集上实现了实时高保真的新视角合成，定量和定性上均优于现有方法。

Conclusion: TR-Gaussians能够有效建模复杂的外观效果，并在渲染质量和效率上取得了显著提升。

Abstract: We propose Transmission-Reflection Gaussians (TR-Gaussians), a novel 3D-Gaussian-based representation for high-fidelity rendering of planar transmission and reflection, which are ubiquitous in indoor scenes. Our method combines 3D Gaussians with learnable reflection planes that explicitly model the glass planes with view-dependent reflectance strengths. Real scenes and transmission components are modeled by 3D Gaussians and the reflection components are modeled by the mirrored Gaussians with respect to the reflection plane. The transmission and reflection components are blended according to a Fresnel-based, view-dependent weighting scheme, allowing for faithful synthesis of complex appearance effects under varying viewpoints. To effectively optimize TR-Gaussians, we develop a multi-stage optimization framework incorporating color and geometry constraints and an opacity perturbation mechanism. Experiments on different datasets demonstrate that TR-Gaussians achieve real-time, high-fidelity novel view synthesis in scenes with planar transmission and reflection, and outperform state-of-the-art approaches both quantitatively and qualitatively.

</details>


### [4] [Force-Aware 3D Contact Modeling for Stable Grasp Generation](https://arxiv.org/abs/2511.13247)
*Zhuo Chen,Zhongqun Zhang,Yihua Cheng,Ales Leonardis,Hyung Jin Chang*

Main category: cs.GR

TL;DR: 本文提出了一种基于显式接触力预测的稳定抓取生成方法，通过力感知的接触表示和稳定性约束，显著提高了抓取的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽略抓取的物理属性（如接触力），导致抓取稳定性不足。本文旨在通过显式预测接触力并引入力感知的稳定性约束来解决这一问题。

Method: 首先定义了一个力感知的接触表示方法，将法向力值离散化并用one-hot向量编码；随后引入了力感知的稳定性约束，将稳定性问题表述为加速度最小化任务；最后提出了一个姿态优化器，整合上述表示和约束以生成稳定抓取。

Result: 在两个公开基准上的实验表明，该方法使稳定性指标提升了约20%，并能很好地适应新物体。

Conclusion: 本文的方法通过力感知的接触表示和稳定性约束，显著提升了抓取的稳定性，并能有效指导优化过程。

Abstract: Contact-based grasp generation plays a crucial role in various applications. Recent methods typically focus on the geometric structure of objects, producing grasps with diverse hand poses and plausible contact points. However, these approaches often overlook the physical attributes of the grasp, specifically the contact force, leading to reduced stability of the grasp. In this paper, we focus on stable grasp generation using explicit contact force predictions. First, we define a force-aware contact representation by transforming the normal force value into discrete levels and encoding it using a one-hot vector. Next, we introduce force-aware stability constraints. We define the stability problem as an acceleration minimization task and explicitly relate stability with contact geometry by formulating the underlying physical constraints. Finally, we present a pose optimizer that systematically integrates our contact representation and stability constraints to enable stable grasp generation. We show that these constraints can help identify key contact points for stability which provide effective initialization and guidance for optimization towards a stable grasp. Experiments are carried out on two public benchmarks, showing that our method brings about 20% improvement in stability metrics and adapts well to novel objects.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Modular GPU Programming with Typed Perspectives](https://arxiv.org/abs/2511.11939)
*Manya Bansal,Daniel Sainati,Joseph W. Cutler,Saman Amarasinghe,Jonathan Ragan-Kelley*

Main category: cs.PL

TL;DR: Prism是一种新的GPU编程语言，通过类型化视角恢复模块化编程，同时保持对高性能集体操作的低级控制。


<details>
  <summary>Details</summary>
Motivation: 现代GPU编程需要在单个线程行为和线程集体操作之间平衡，这种冲突导致模块化编程容易出错。Prism旨在解决这一问题。

Method: Prism引入了类型化视角的概念，明确程序员控制线程行为的粒度。设计并实现了Prism编译器，并基于核心演算Bundl奠定理论基础。

Result: 在Prism中实现了先进的GPU内核，验证了其既能保证模块化代码的安全性，又不会牺牲性能。

Conclusion: Prism为程序员提供了编写模块化代码的安全保障，同时保持了高性能GPU操作的控制能力。

Abstract: To achieve peak performance on modern GPUs, one must balance two frames of mind: issuing instructions to individual threads to control their behavior, while simultaneously tracking the convergence of many threads acting in concert to perform collective operations like Tensor Core instructions. The tension between these two mindsets makes modular programming error prone. Functions that encapsulate collective operations, despite being called per-thread, must be executed cooperatively by groups of threads.
  In this work, we introduce Prism, a new GPU language that restores modularity while still giving programmers the low-level control over collective operations necessary for high performance. Our core idea is typed perspectives, which materialize, at the type level, the granularity at which the programmer is controlling the behavior of threads. We describe the design of Prism, implement a compiler for it, and lay its theoretical foundations in a core calculus called Bundl. We implement state-of-the-art GPU kernels in Prism and find that it offers programmers the safety guarantees needed to confidently write modular code without sacrificing performance.

</details>


### [6] [The Search for Constrained Random Generators](https://arxiv.org/abs/2511.12253)
*Harrison Goldstein,Hila Peleg,Cassia Torczon,Daniel Sainati,Leonidas Lampropoulos,Benjamin C. Pierce*

Main category: cs.PL

TL;DR: 提出了一种基于演绎程序合成的新方法，用于解决基于属性的测试中的约束随机生成问题，通过将递归谓词重写为范畴态射，简化了合成过程。


<details>
  <summary>Details</summary>
Motivation: 解决基于属性测试中约束随机生成问题的重要性，因为有效的输入值生成对满足稀疏分布的前置条件至关重要。

Method: 基于生成器的指称语义，提出了一组合成规则，通过将递归谓词重写为范畴态射并匹配适当的变形射，实现了生成器的自动合成。

Result: 实现了一个名为Palamedes的可扩展库，合成算法基于Lean定理证明器的标准证明搜索策略，减轻了实现负担。

Conclusion: 这一方法在理论上更简单且表达性强，为约束随机生成问题提供了高效解决方案。

Abstract: Among the biggest challenges in property-based testing (PBT) is the constrained random generation problem: given a predicate on program values, randomly sample from the set of all values satisfying that predicate, and only those values. Efficient solutions to this problem are critical, since the executable specifications used by PBT often have preconditions that input values must satisfy in order to be valid test cases, and satisfying values are often sparsely distributed.
  We propose a novel approach to this problem using ideas from deductive program synthesis. We present a set of synthesis rules, based on a denotational semantics of generators, that give rise to an automatic procedure for synthesizing correct generators. Our system handles recursive predicates by rewriting them as catamorphisms and then matching with appropriate anamorphisms; this is theoretically simpler than other approaches to synthesis for recursive functions, yet still extremely expressive.
  Our implementation, Palamedes, is an extensible library for the Lean theorem prover. The synthesis algorithm itself is built on standard proof-search tactics, reducing implementation burden and allowing the algorithm to benefit from further advances in Lean proof automation.

</details>


### [7] [Equivalence Checking of ML GPU Kernels](https://arxiv.org/abs/2511.12638)
*Kshitij Dubey,Benjamin Driscoll,Anjiang Wei,Neeraj Kayal,Rahul Sharma,Alex Aiken*

Main category: cs.PL

TL;DR: 本文提出了第一个用于GPU内核的等价检查器VOLTA，能够对通过人工、LLM和编译器优化的ML内核进行形式化验证，确保其正确性。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习和LLM的快速发展，GPU内核的优化成为重点，但现有方法缺乏形式化保证，亟需一种可靠的工具验证优化后的内核等价性。

Method: 设计并实现了一个GPU内核的等价检查器VOLTA，验证其在一类明确定义的GPU内核（包括ML计算任务）上的完备性和正确性。

Result: VOLTA能够验证卷积、矩阵乘法及多种注意力机制等ML计算任务，证明其在特定内核类别上是完备的。

Conclusion: VOLTA为GPU内核优化提供了形式化验证工具，填补了LLM和编译器生成内核缺乏形式化保证的空白。

Abstract: With the rapid progress of deep learning and large language models (LLMs), companies now spend enormous sums executing GPU kernels. These kernels have, therefore, become prime targets for aggressive optimization. Recent efforts increasingly leverage LLMs to generate GPU kernels, but make no formal guarantees about the generated kernels. We present the first equivalence checker for GPU kernels and use it to formally verify the correctness of machine learning (ML) kernels optimized by hand, by LLMs, and by compilers. We show that our equivalence checker is sound and, for a well-defined class of GPU kernels which includes the programs of interest, complete. Our implementation, VOLTA, can verify ML computations such as convolutions, matrix multiplications, and various attention mechanisms.

</details>


### [8] [Cost-Driven Synthesis of Sound Abstract Interpreters](https://arxiv.org/abs/2511.13663)
*Qiuhan Gu,Avaljot Singh,Gagandeep Singh*

Main category: cs.PL

TL;DR: 利用现代大语言模型（LLM）合成全局保真的抽象解释器，以减轻神经网络验证中抽象解释器的构建负担。


<details>
  <summary>Details</summary>
Motivation: 构建提供全局保真保证的抽象解释器仍是抽象解释领域的重大挑战，研究旨在探索现代LLM是否能通过合成保真且非平凡的抽象解释器来减轻这一负担。

Method: 将合成问题建模为约束优化问题，并提出一种基于数学的成本函数来衡量不保真程度；开发了一个统一框架，将LLM生成与语法和语义验证及成本反馈机制相结合。

Result: 实证结果表明，该框架不仅能媲美手工设计的转换器，还能发现复杂非线性算子的保真高精度转换器，填补了现有文献空白。

Conclusion: 研究表明，现代LLM可以有效合成高质量的抽象解释器，为神经网络验证领域提供了新的解决方案。

Abstract: Constructing abstract interpreters that provide global soundness guarantees remains a major obstacle in abstract interpretation. We investigate whether modern LLMs can reduce this burden by leveraging them to synthesize sound, non-trivial abstract interpreters across multiple abstract domains in the setting of neural network verification. We formulate synthesis as a constrained optimization problem and introduce a novel mathematically grounded cost function for measuring unsoundness under strict syntactic and semantic constraints. Based on this formulation, we develop a unified framework that unifies LLM-based generation with syntactic and semantic validation and a quantitative cost-guided feedback mechanism. Empirical results demonstrate that our framework not only matches the quality of handcrafted transformers, but more importantly, discovers sound, high-precision transformers for complex nonlinear operators that are absent from existing literature.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Collusion-proof Auction Design using Side Information](https://arxiv.org/abs/2511.12456)
*Sukanya Kudva,Anil Aswani*

Main category: cs.GT

TL;DR: 该论文研究拍卖设计中竞标者串谋的问题，提出了一种混合VCG机制（H-VCG），结合非串谋竞标者的VCG机制和串谋竞标者的固定价格机制，以提高福利和收益。


<details>
  <summary>Details</summary>
Motivation: 经典的VCG机制在面对竞标者串谋时表现脆弱，而完全防止串谋的机制又难以保证效率。论文旨在设计一种既能应付串谋又能保证良好福利和收益的拍卖机制。

Method: 论文首先分析了串谋竞标者在VCG机制下的策略行为，并提出了一种混合VCG机制（H-VCG），结合VCG机制和非串谋竞标者的固定价格机制。

Result: H-VCG机制在实验中表现优于仅针对非串谋竞标者的VCG机制，并在福利和收益方面接近理想状态下的VCG机制。

Conclusion: H-VCG机制为拍卖设计中检测和应对串谋提供了理论框架，朝着抗串谋拍卖迈出了一步。

Abstract: We study the problem of auction design in the presence of bidder collusion. Specifically, we consider a multi-unit auction of identical items with single-minded bidders, where a subset of bidders may collude by coordinating bids and transferring payments and items among themselves. While the classical Vickrey-Clarke-Groves (VCG) mechanism achieves efficient and truthful outcomes, it is highly vulnerable to collusion. In contrast, fully collusion-proof mechanisms are limited to posted-price formats, which fail to guarantee even approximate efficiency. This paper aims to bridge this gap by designing auctions that achieve good welfare and revenue guarantees even when some bidders collude. We first characterize the strategic behavior of colluding bidders under VCG and prove that such bidders optimally bid shade: they never overbid or take additional items, but instead reduce the auction price. This characterization enables a Bulow-Klemperer type result: adding colluding bidders can only improve welfare and revenue relative to running VCG on the non-colluding group alone. We then propose a Hybrid VCG (H-VCG) mechanism that combines VCG applied to non-colluding bidders with a posted-price mechanism for colluding bidders, assuming access to a black-box collusion detection algorithm. We show that H-VCG is ex-post dominant-strategy incentive compatible (DSIC) and derive probabilistic guarantees on expected welfare and revenue under both known and unknown valuation distributions. Numerical experiments across several distributions demonstrate that H-VCG consistently outperforms VCG restricted to non-colluding bidders and approaches the performance of the ideal VCG mechanism assuming universal truthfulness. Our results provide a principled framework for incorporating collusion detection into mechanism design, offering a step toward collusion-resistant auctions.

</details>


### [10] [Perturbing Best Responses in Zero-Sum Games](https://arxiv.org/abs/2511.12523)
*Adam Dziwoki,Rostislav Horcik*

Main category: cs.GT

TL;DR: 本文研究了扰动对基于最佳响应的零和博弈中纳什均衡近似算法（Double Oracle和Fictitious Play）的影响，发现扰动可以减少算法迭代次数，甚至在特定情况下使期望迭代次数对数化。


<details>
  <summary>Details</summary>
Motivation: 动机在于探索扰动如何影响零和博弈中最佳响应算法的性能，特别是迭代效率和计算复杂度。

Method: 方法是通过假设最佳响应计算器在选择最佳响应前对效用进行扰动，分析其对Double Oracle和Fictitious Play算法的影响。

Result: 结果显示，扰动可以显著减少算法迭代次数，某些情况下甚至可以实现对数级别的期望迭代次数。

Conclusion: 结论表明，尽管扰动计算开销较大，但在具有内部结构的博弈中可以实现高效扰动，从而提高算法性能。

Abstract: This paper investigates the impact of perturbations on the best-response-based algorithms approximating Nash equilibria in zero-sum games, namely Double Oracle and Fictitious Play. More precisely, we assume that the oracle computing the best responses perturbs the utilities before selecting the best response. We show that using such an oracle reduces the number of iterations for both algorithms. For some cases, suitable perturbations ensure the expected number of iterations is logarithmic. Although the utility perturbation is computationally demanding as it requires iterating through all pure strategies, we demonstrate that one can efficiently perturb the utilities in games where pure strategies have further inner structure.

</details>


### [11] [Bandit Learning in Housing Markets](https://arxiv.org/abs/2511.12629)
*Shiyun Lin*

Main category: cs.GT

TL;DR: 该论文提出了一种基于多玩家多臂老虎机框架的统计学习模型，用于在偏好未知的情况下学习住房市场中代理人的偏好，并引入了核心遗憾的概念作为市场目标。


<details>
  <summary>Details</summary>
Motivation: 住房市场作为经典的交换经济模型已有广泛研究，但在偏好未知且需要通过重复交互学习的场景中缺乏关注。本文旨在填补这一空白。

Method: 论文采用了多玩家多臂老虎机框架，代理人在随机奖励的基础上学习对商品的偏好，并提出了核心遗憾的概念。研究了集中式和分散式两种方法。

Result: 证明了在集中式和分散式设置下，遗憾的上界为$O(N \log T / \Delta^2)$，并在分散式设置中建立了匹配的下界，表明算法是顺序最优的。

Conclusion: 本文的创新在于将统计学习引入住房市场偏好学习问题，并通过理论分析证明了算法的性能最优性。

Abstract: The housing market, also known as one-sided matching market, is a classic exchange economy model where each agent on the demand side initially owns an indivisible good (a house) and has a personal preference over all goods. The goal is to find a core-stable allocation that exhausts all mutually beneficial exchanges among subgroups of agents. While this model has been extensively studied in economics and computer science due to its broad applications, little attention has been paid to settings where preferences are unknown and must be learned through repeated interactions. In this paper, we propose a statistical learning model within the multi-player multi-armed bandit framework, where players (agents) learn their preferences over arms (goods) from stochastic rewards. We introduce the notion of core regret for each player as the market objective. We study both centralized and decentralized approaches, proving $O(N \log T / Δ^2)$ upper bounds on regret, where $N$ is the number of players, $T$ is the time horizon and $Δ$ is the minimum preference gap among players. For the decentralized setting, we also establish a matching lower bound, demonstrating that our algorithm is order-optimal.

</details>


### [12] [Rethinking Data Value: Asymmetric Data Shapley for Structure-Aware Valuation in Data Markets and Machine Learning Pipelines](https://arxiv.org/abs/2511.12863)
*Xi Zheng,Yinghui Huang,Xiangyu Chang,Ruoxi Jia,Yong Tan*

Main category: cs.GT

TL;DR: 论文提出了非对称数据Shapley（ADS）框架，用于现代ML/AI工作流程中的数据估值，解决了传统数据Shapley（DS）在对称性假设上的限制。


<details>
  <summary>Details</summary>
Motivation: 现行数据Shapley（DS）方法的对称性假设无法捕捉现代ML/AI工作流中的方向性和时间依赖性，例如数据增强或多阶段训练中的顺序贡献。

Method: 引入非对称数据Shapley（ADS），放松对称性假设，通过只在符合应用特定数据组顺序的排列上平均边际贡献来估值。提出了两种计算ADS的方法：蒙特卡洛估计器（MC-ADS）和KNN代理（KNN-ADS）。

Result: 在具有方向性和时间依赖性的代表性场景中，ADS持续优于基准方法，能够区分新颖和冗余贡献，并尊重训练的顺序性。

Conclusion: ADS为数据市场和复杂ML/AI流水线中的公平数据估值提供了原则性和实用的解决方案。

Abstract: Rigorous valuation of individual data sources is critical for fair compensation in data markets, informed data acquisition, and transparent development of ML/AI models. Classical Data Shapley (DS) provides a essential axiomatic framework for data valuation but is constrained by its symmetry axiom that assumes interchangeability of data sources. This assumption fails to capture the directional and temporal dependencies prevalent in modern ML/AI workflows, including the reliance of duplicated or augmented data on original sources and the order-specific contributions in sequential pipelines such as federated learning and multi-stage LLM fine tuning. To address these limitations, we introduce Asymmetric Data Shapley (ADS), a structure-aware data valuation framework for modern ML/AI pipelines. ADS relaxes symmetry by averaging marginal contributions only over permutations consistent with an application-specific ordering of data groups. It preserves efficiency and linearity, maintains within group symmetry and directional precedence across groups, and reduces to DS when the ordering collapses to a single group. We develop two complementary computational procedures for ADS: (i) a Monte Carlo estimator (MC-ADS) with finite-sample accuracy guarantees, and (ii) a k-nearest neighbor surrogate (KNN-ADS) that is exact and efficient for KNN predictors. Across representative settings with directional and temporal dependence, ADS consistently outperforms benchmark methods by distinguishing novel from redundant contributions and respecting the sequential nature of training. These results establish ADS as a principled and practical approach to equitable data valuation in data markets and complex ML/AI pipelines.

</details>


### [13] [Resilient and Efficient Allocation for Large-Scale Autonomous Fleets via Decentralized Coordination](https://arxiv.org/abs/2511.12879)
*Ashish Kumar Perukari,Polina Khoroshevskaya*

Main category: cs.GT

TL;DR: 该论文提出了一种结合分布预测与分散协调的资源分配方法，用于大规模自主车队中的稀缺资源管理，显著降低了故障率。


<details>
  <summary>Details</summary>
Motivation: 大规模自主车队需要快速、弹性地分配稀缺资源（如能源、充电器访问等），以适应不确定性。现有方法难以兼顾效率与鲁棒性。

Method: 提出了一种基于局部侧信息的资源分配方法，结合分布预测和分散协调。通过轻量级的共识-ADMM算法在稀疏通信图上协调代理。

Result: 在真实城市路网和卫星星座上的验证表明，该方法将故障率降低30-55%，且能扩展到数千个代理。

Conclusion: 该方法在保持高概率可行性的同时，实现了与集中式方法相近的性能，且避免了单点故障。

Abstract: Operating large autonomous fleets demands fast, resilient allocation of scarce resources (such as energy and fuel, charger access and maintenance slots, time windows, and communication bandwidth) under uncertainty. We propose a side-information-aware approach for resource allocation at scale that combines distributional predictions with decentralized coordination. Local side information shapes per-agent risk models for consumption, which are coupled through chance constraints on failures. A lightweight consensus-ADMM routine coordinates agents over a sparse communication graph, enabling near-centralized performance while avoiding single points of failure. We validate the framework on real urban road networks with autonomous vehicles and on a representative satellite constellation, comparing against greedy, no-side-information, and oracle central baselines. Our method reduces failure rates by 30-55% at matched cost and scales to thousands of agents with near-linear runtime, while preserving feasibility with high probability.

</details>


### [14] [An FPTAS for 7/9-Approximation to Maximin Share Allocations](https://arxiv.org/abs/2511.13056)
*Xin Huang,Shengwei Zhou*

Main category: cs.GT

TL;DR: 提出了一种新算法，在加法估值下，将不可分割物品的最大最小份额（MMS）分配提升至$\frac{7}{9}$近似比，优于当前的$\frac{10}{13}$，算法更简单并提供了FPTAS。


<details>
  <summary>Details</summary>
Motivation: 当前的最大最小份额分配算法的近似比为$\frac{10}{13}$，存在改进空间且复杂度较高，目标是提出更高效和简单的算法。

Method: 基于新的分析框架，提出了一个$\frac{7}{9}$近似比的算法，并进一步设计了FPTAS，实现$\frac{7}{9}-\varepsilon$近似且时间复杂度为$\tfrac{1}{\varepsilon} \cdot \mathrm{poly}(n,m)$。

Result: 新算法在MMS分配问题上达到$\frac{7}{9}$近似比，高于现有的$\frac{10}{13}$，并且算法复杂度更低。

Conclusion: 研究不仅提高了MMS分配的近似比，还简化了算法，证明了新框架的有效性。

Abstract: We present a new algorithm that achieves a $\frac{7}{9}$-approximation for the maximin share (MMS) allocation of indivisible goods under additive valuations, improving the current best ratio of $\frac{10}{13}$ (Heidari et al., SODA 2026). Building on a new analytical framework, we further obtain an FPTAS that achieves a $\frac{7}{9}-\varepsilon$ approximation in $\tfrac{1}{\varepsilon} \cdot \mathrm{poly}(n,m)$ time. Compared with prior work (Heidari et al., SODA 2026), our algorithm is substantially simpler.

</details>


### [15] [MEV in Multiple Concurrent Proposer Blockchains](https://arxiv.org/abs/2511.13080)
*Steven Landers,Benjamin Marsh*

Main category: cs.GT

TL;DR: 该论文研究了多并发提议者区块链中的最大可提取价值（MEV），分析了并发性导致的MEV新渠道，并提出了一种延迟和包含的模型以及游戏均衡解。


<details>
  <summary>Details</summary>
Motivation: 在多并发提议者区块链中，多个块在最终执行顺序确定之前变为数据可用，这种并发性打破了顺序链的单一构建者假设，引入了新的MEV渠道，从而需要研究其影响和解决方案。

Method: 论文开发了一个延迟和包含的标准化模型，推导出封闭形式的延迟包络M(τ)，并描述了审查、复制和拍卖游戏的均衡解。

Result: 研究表明，确定性优先级DAG调度和重复感知支付可以消除同tick MEV，同时保持吞吐量，并提出简单的协议配置无需集中构建者即可缓解MCP特定提取。

Conclusion: 论文得出结论，通过确定性优先级DAG调度和重复感知支付可以有效解决多并发提议者区块链中的MEV问题，同时维持系统性能。

Abstract: We analyze maximal extractable value in multiple concurrent proposer blockchains, where multiple blocks become data available before their final execution order is determined. This concurrency breaks the single builder assumption of sequential chains and introduces new MEV channels, including same tick duplicate steals, proposer to proposer auctions, and timing races driven by proof of availability latency. We develop a hazard normalized model of delay and inclusion, derive a closed form delay envelope \(M(τ)\), and characterize equilibria for censorship, duplication, and auction games. We show how deterministic priority DAG scheduling and duplicate aware payouts neutralize same tick MEV while preserving throughput, identifying simple protocol configurations to mitigate MCP specific extraction without centralized builders.

</details>


### [16] [The Publication Choice Problem](https://arxiv.org/abs/2511.13678)
*Haichuan Wang,Yifan Wu,Haifeng Xu*

Main category: cs.GT

TL;DR: 研究者通过博弈论框架分析发表选择与期刊影响力的双向关系，发现均衡存在性及标注‘spotlight’对期刊影响力的影响。


<details>
  <summary>Details</summary>
Motivation: 研究者需要最大化其工作的影响力，而发表选择又决定期刊的影响因子，因此需分析这种双向关系。

Method: 引入‘Publication Choice Problem’的博弈论框架，分析纯策略均衡及其在二元研究者类型下的唯一性。

Result: 研究发现标注‘spotlight’的竞争性期刊可能降低其他期刊的整体影响力，而非竞争性期刊则相反。

Conclusion: 研究揭示了发表行为如何反映研究者影响力水平，以及期刊标注策略对社区影响力的复杂影响。

Abstract: Researchers strategically choose where to submit their work in order to maximize its impact, and these publication decisions in turn determine venues' impact factors. To analyze how individual publication choices both respond to and shape venue impact, we introduce a game-theoretic framework, coined the Publication Choice Problem, that captures this two-way interplay. We show the existence of a pure-strategy equilibrium in the Publication Choice Problem and its uniqueness under binary researcher types. Our characterizations of the equilibrium properties offer insights about what publication behaviors better indicate a researcher's impact level. Through equilibrium analysis, we further investigate how labeling papers with ``spotlight'' affects the impact factor of venues in the research community. Our analysis shows that competitive venue labeling top papers with ``spotlight'' may decrease the overall impact of other venues in the community, while less competitive venues with ``spotlight'' labeling have the opposite impact.

</details>
