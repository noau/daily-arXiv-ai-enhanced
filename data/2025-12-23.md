<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 13]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs](https://arxiv.org/abs/2512.18134)
*Rupanshu Soi,Rohan Yadav,Fredrik Kjolstad,Alex Aiken,Maryam Mehri Dehnavi,Michael Garland,Michael Bauer*

Main category: cs.PL

TL;DR: Twill是一个新型系统，通过联合优化软件流水线（SWP）和线程束专业化（WS），自动生成最优的GPU调度方案，无需依赖启发式方法或人工直觉。


<details>
  <summary>Details</summary>
Motivation: 随着GPU架构的日益复杂，如何充分利用其固定功能单元和高并行核心资源成为挑战。现有的SWP和WS组合使用缺乏系统化方法，依赖启发式或人工直觉。

Method: Twill将SWP和WS建模为一个联合优化问题，利用现成的约束求解器进行整体求解。

Result: Twill能够自动生成最优调度方案，并成功复现专家手动为NVIDIA Hopper和Blackwell GPU开发的Flash Attention调度。

Conclusion: Twill提供了一种无需启发式、可扩展且保证最优的系统化方法，为复杂GPU程序的调度优化提供了新思路。

Abstract: GPU architectures have continued to grow in complexity, with recent incarnations introducing increasingly powerful fixed-function units for matrix multiplication and data movement to accompany highly parallel general-purpose cores. To fully leverage these machines, software must use sophisticated schedules that maximally utilize all hardware resources. Since realizing such schedules is complex, both programmers and compilers routinely employ program transformations, such as software pipelining (SWP) and warp specialization (WS), to do so in practice. However, determining how best to use SWP and WS in combination is a challenging problem that is currently handled through a mix of brittle compilation heuristics and fallible human intuition, with little insight into the space of solutions. To remedy this situation, we introduce a novel formulation of SWP and WS as a joint optimization problem that can be solved holistically by off-the-shelf constraint solvers. We reify our approach in Twill, the first system that automatically derives optimal SWP and WS schedules for a large class of iterative programs. Twill is heuristic-free, easily extensible to new GPU architectures, and guaranteed to produce optimal schedules. We show that Twill can rediscover, and thereby prove optimal, the SWP and WS schedules manually developed by experts for Flash Attention on both the NVIDIA Hopper and Blackwell GPU architectures.

</details>


### [2] [DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs](https://arxiv.org/abs/2512.18842)
*Aleksandr Fedchin,Antero Mejr,Hari Sundar,Jeffrey S. Foster*

Main category: cs.PL

TL;DR: DafnyMPI是一种新颖的可扩展方法，用于形式化验证MPI软件，能够证明死锁自由、终止和功能等价性，简化并行编程的验证过程。


<details>
  <summary>Details</summary>
Motivation: MPI广泛应用于高性能并行编程，但编写无错误的MPI软件仍然困难。DafnyMPI旨在通过形式化验证解决这一问题，提升并行软件的可靠性。

Method: DafnyMPI基于Dafny编程语言，扩展其并发推理能力，要求用户预先指定通信拓扑并验证通信原语的前提条件，确保程序的安全性。

Result: DafnyMPI成功验证了数值解算三个典型偏微分方程的应用，证明了其可行性和有效性，可用于更广泛的程序验证。

Conclusion: DafnyMPI为并行和并发系统的形式化验证提供了新工具，展示了如何扩大形式化验证的适用范围，提升软件验证效率。

Abstract: The Message Passing Interface (MPI) is widely used in parallel, high-performance programming, yet writing bug-free software that uses MPI remains difficult. We introduce DafnyMPI, a novel, scalable approach to formally verifying MPI software. DafnyMPI allows proving deadlock freedom, termination, and functional equivalence with simpler sequential implementations. In contrast to existing specialized frameworks, DafnyMPI avoids custom concurrency logics and instead relies on Dafny, a verification-ready programming language used for sequential programs, extending it with concurrent reasoning abilities. DafnyMPI is implemented as a library that enables safe MPI programming by requiring users to specify the communication topology upfront and to verify that calls to communication primitives such as MPI_ISEND and MPI_WAIT meet their preconditions. We formalize DafnyMPI using a core calculus and prove that the preconditions suffice to guarantee deadlock freedom. Functional equivalence is proved via rely-guarantee reasoning over message payloads and a system that guarantees safe use of read and write buffers. Termination and the absence of runtime errors are proved using standard Dafny techniques. To further demonstrate the applicability of DafnyMPI, we verify numerical solutions to three canonical partial differential equations. We believe DafnyMPI demonstrates how to make formal verification viable for a broader class of programs and provides proof engineers with additional tools for software verification of parallel and concurrent systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [3] [Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy](https://arxiv.org/abs/2512.17950)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.GT

TL;DR: 研究提出了一种作者提名审稿人的策略，以减少因提名不负责任的审稿人而导致论文被拒的风险。通过贪婪算法和优化框架解决了这一问题。


<details>
  <summary>Details</summary>
Motivation: AI会议提交量快速增长，审稿负担过重。为解决这一问题，ICLR 2026等新政策要求每篇论文提名一位作者作为审稿人，若提名不负责任的审稿人则论文将被拒。本研究旨在从作者福利的角度分析这一政策，探讨如何最小化提名风险。

Method: 研究提出了三种降低被拒风险的提名问题变体，并分别通过贪婪算法、最小成本流和线性规划等优化框架进行解决。

Result: 研究表明，基本问题可通过贪婪算法最优解决；引入硬性和软性提名限制后，可用最小成本流和线性规划设计高效的提名策略。

Conclusion: 本研究为首个理论分析审稿人提名政策的成果，为作者明智选择提名审稿人提供了理论和实践指导。

Abstract: The rapid growth of AI conference submissions has created an overwhelming reviewing burden. To alleviate this, recent venues such as ICLR 2026 introduced a reviewer nomination policy: each submission must nominate one of its authors as a reviewer, and any paper nominating an irresponsible reviewer is desk-rejected. We study this new policy from the perspective of author welfare. Assuming each author carries a probability of being irresponsible, we ask: how can authors (or automated systems) nominate reviewers to minimize the risk of desk rejections? We formalize and analyze three variants of the desk-rejection risk minimization problem. The basic problem, which minimizes expected desk rejections, is solved optimally by a simple greedy algorithm. We then introduce hard and soft nomination limit variants that constrain how many papers may nominate the same author, preventing widespread failures if one author is irresponsible. These formulations connect to classical optimization frameworks, including minimum-cost flow and linear programming, allowing us to design efficient, principled nomination strategies. Our results provide the first theoretical study for reviewer nomination policies, offering both conceptual insights and practical directions for authors to wisely choose which co-author should serve as the nominated reciprocal reviewer.

</details>


### [4] [Will AI Trade? A Computational Inversion of the No-Trade Theorem](https://arxiv.org/abs/2512.17952)
*Hanyu Li,Xiaotie Deng*

Main category: cs.GT

TL;DR: 研究探讨AI代理的计算局限性是否会在共同信念下引发交易，发现计算能力相似的代理无法达成均衡，导致持续的策略调整和交易行为。


<details>
  <summary>Details</summary>
Motivation: 传统无交易定理将交易归因于异质信念，本研究重新审视这一结论，探讨在共同信念下，AI代理的计算局限性是否会导致交易行为。

Method: 采用展开博弈框架建模代理的计算有限理性，计算能力决定策略的复杂度。

Result: 研究发现，当计算能力略有差异时，代理才能达成稳定的无交易均衡；反之，相同计算能力的代理无法收敛到均衡，导致持续的策略调整和交易行为。

Conclusion: 结果表明，AI代理的计算局限性可能导致无法达到均衡，从而创造比传统模型更活跃和不可预测的交易环境。

Abstract: Classic no-trade theorems attribute trade to heterogeneous beliefs. We re-examine this conclusion for AI agents, asking if trade can arise from computational limitations, under common beliefs. We model agents' bounded computational rationality within an unfolding game framework, where computational power determines the complexity of its strategy. Our central finding inverts the classic paradigm: a stable no-trade outcome (Nash equilibrium) is reached only when "almost rational" agents have slightly different computational power. Paradoxically, when agents possess identical power, they may fail to converge to equilibrium, resulting in persistent strategic adjustments that constitute a form of trade. This instability is exacerbated if agents can strategically under-utilize their computational resources, which eliminates any chance of equilibrium in Matching Pennies scenarios. Our results suggest that the inherent computational limitations of AI agents can lead to situations where equilibrium is not reached, creating a more lively and unpredictable trade environment than traditional models would predict.

</details>


### [5] [Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis](https://arxiv.org/abs/2512.17979)
*Matthieu Mastio,Paul Saves,Benoit Gaudou,Nicolas Verstaevel*

Main category: cs.GT

TL;DR: 该论文通过基于代理的模型研究了工业共生中分散交易的稳定性和效率，揭示了空间结构和市场参数如何共同影响循环经济。


<details>
  <summary>Details</summary>
Motivation: 工业共生通过利用残余资源促进循环经济，但其发展受限于社会空间摩擦，现有模型往往忽略了空间结构、市场设计和自适应企业行为之间的相互作用。

Method: 研究开发了一个基于代理的模型，异质企业通过空间嵌入的双重拍卖市场交易副产品，利用强化学习优化报价策略，考虑了运输成本、处置惩罚和资源稀缺性。

Result: 模拟实验揭示了分散交易在哪些经济与空间条件下能够趋于稳定和高效。反事实遗憾分析显示卖方策略接近纳什均衡，敏感性分析则强调了空间结构和市场参数对循环经济的共同影响。

Conclusion: 该模型为探索政策干预提供了基础，以协调企业激励与可持续发展目标，并更广泛地展示了在空间受限市场中自适应代理如何实现分散协调。

Abstract: Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behavior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local interactions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation experiments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient outcomes. Counterfactual regret analysis shows that sellers' strategies approach a near Nash equilibrium, while sensitivity analysis highlights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy interventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.

</details>


### [6] [Privacy Data Pricing: A Stackelberg Game Approach](https://arxiv.org/abs/2512.18296)
*Lijun Bo,Weiqiang Chang*

Main category: cs.GT

TL;DR: 本文提出了一种基于Stackelberg博弈的差分隐私数据定价框架，研究了市场定价者与数据买家之间的策略互动，并在平衡定价函数下推导了双方的最优策略。


<details>
  <summary>Details</summary>
Motivation: 传统的数据定价模型主要关注价格一致性和利润最大化，而忽略了隐私约束和战略互动。随着差分隐私（DP）的广泛应用，隐私与效用之间的权衡成为关键问题。本文旨在填补这一研究空白。

Method: 采用Stackelberg博弈框架，市场定价者（领导者）设定价格函数，数据买家（追随者）在DP约束下选择最优查询精度。研究平衡定价函数下的均衡策略，并扩展到非线性幂定价函数的情况。

Result: 推导了最优方差和定价水平的闭式解，确定了市场参与的边界条件，为激励兼容和隐私保护的数据定价提供了统一理论基础。

Conclusion: 该模型将差分隐私与经济机制设计相结合，为数据市场中的隐私保护与激励兼容定价提供了新方法。

Abstract: Data markets are emerging as key mechanisms for trading personal and organizational data. Traditional data pricing studies -- such as query-based or arbitrage-free pricing models -- mainly emphasize price consistency and profit maximization but often neglect privacy constraints and strategic interactions. The widespread adoption of differential privacy (DP) introduces a fundamental privacy-utility trade-off: noise protects individuals' privacy but reduces data accuracy and market value. This paper develops a Stackelberg game framework for pricing DP data, where the market maker (leader) sets the price function and the data buyer (follower) selects the optimal query precision under DP constraints. We derive the equilibrium strategies for both parties under a balanced pricing function where the pricing decision variable enters linearly into the original pricing model. We obtain closed-form solutions for the optimal variance and pricing level, and determine the boundary conditions for market participation. Furthermore, we extend the analysis to Stackelberg games involving nonlinear power pricing functions. The model bridges DP and economic mechanism design, offering a unified foundation for incentive-compatible and privacy-conscious data pricing in data markets.

</details>


### [7] [Snowveil: A Framework for Decentralised Preference Discovery](https://arxiv.org/abs/2512.18444)
*Grammateia Kotsialou*

Main category: cs.GT

TL;DR: 该论文提出了一个名为Snowveil的新框架，用于解决去中心化环境下大规模选民的主观偏好聚合问题。通过迭代的基于八卦的协议和潜在函数分析，Snowveil能够在有限时间内几乎确定地收敛到一个稳定的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的偏好聚合方法依赖中心化机构，存在局限性。论文旨在解决这些问题，特别是在抗审查、部分信息和异步通信的约束下，如何确定选民的集体意愿。

Method: 论文提出Snowveil框架，使用基于八卦的迭代协议，选民反复随机抽样其他选民偏好，逐步收敛到集体结果。设计了Constrained Hybrid Borda（CHB）聚合规则，并通过潜在函数和亚鞅理论分析了其收敛性。

Result: Snowveil展示了在有限时间内几乎确定地收敛到一个稳定结果的能力，并通过广泛的仿真验证了其O(n)的可扩展性。CHB规则在广泛共识和强多元支持之间取得了平衡。

Conclusion: Snowveil为去中心化系统中大规模选民的复杂偏好聚合提供了一种可行方法，推动了在这一领域的理解。其框架和工具可以扩展到更广泛的DPD协议类别。

Abstract: Aggregating subjective preferences of a large group is a fundamental challenge in computational social choice, traditionally reliant on central authorities. To address the limitations of this model, this paper introduces Decentralised Preference Discovery (DPD), the problem of determining the collective will of an electorate under constraints of censorship resistance, partial information, and asynchronous communication. We propose Snowveil, a novel framework for this task. Snowveil uses an iterative, gossip-based protocol where voters repeatedly sample the preferences of a small, random subset of the electorate to progressively converge on a collective outcome. We demonstrate the framework's modularity by designing the Constrained Hybrid Borda (CHB), a novel aggregation rule engineered to balance broad consensus with strong plurality support, and provide a rigorous axiomatic analysis of its properties. By applying a potential function and submartingale theory, we develop a multi-level analytical method to show that the system almost surely converges to a stable, single-winner in finite time, a process that can then be iterated to construct a set of winning candidates for multi-winner scenarios. This technique is largely agnostic to the specific aggregation rule, requiring only that it satisfies core social choice axioms like Positive Responsiveness, thus offering a formal toolkit for a wider class of DPD protocols. Furthermore, we present a comprehensive empirical analysis through extensive simulation, validating Snowveil's $O(n)$ scalability. Overall, this work advances the understanding of how a stable consensus can emerge from subjective, complex, and diverse preferences in decentralised systems for large electorates.

</details>


### [8] [Obnoxious Facility Location Problems: Strategyproof Mechanisms Optimizing $L_p$-Aggregated Utilities and Costs](https://arxiv.org/abs/2512.18620)
*Hau Chan,Jianan Lin,Chenhao Wang*

Main category: cs.GT

TL;DR: 研究在归一化线段[0,1]上定位单个厌恶设施的策略问题，设计策略证明机制以最大化L_p聚合效用或最小化L_p聚合成本。


<details>
  <summary>Details</summary>
Motivation: 厌恶设施的选址问题中，设施对代理是不受欢迎的，代理希望设施远离自己。研究目的是设计机制以真实反映代理位置并近似优化L_p聚合目标。

Method: 通过机制设计，研究了确定性及随机策略证明机制，建立L_p聚合效用和成本的近似比上下界。对于确定性机制，边界是紧的。

Result: 确定了确定性机制的最优近似比，随机机制的上下界存在差距。

Conclusion: 研究为厌恶设施选址问题提供了L_p目标下的机制设计理论框架，确定性机制的性能边界严格。

Abstract: We study the problem of locating a single obnoxious facility on the normalized line segment $[0,1]$ with strategic agents from a mechanism design perspective. Each agent has a preference for the undesirable location of the facility and would prefer the facility to be far away from their location. We consider the utility of the agent, defined as the distance between the agent's location and the facility location, and the cost of each agent, equal to one minus the utility. Given this standard setting of obnoxious facility location problems, our goal is to design (group) strategyproof mechanisms to elicit agent locations truthfully and determine facility location approximately optimizing the $L_p$-aggregated utility and cost objectives, which generalizes the $L_p$-norm ($p\ge 1$) of the agents' utilities and agents' costs to any $p \in [-\infty, \infty]$, respectively. We establish upper and lower bounds on the approximation ratios of deterministic and randomized (group) strategyproof mechanisms for maximizing the $L_p$-aggregated utilities or minimizing the $L_p$-aggregated costs across the range of \(p\)-values. While there are gaps between upper and lower bounds for randomized mechanisms, our bounds for deterministic mechanisms are tight.

</details>


### [9] [Adapting Skill Ratings to Luck-Based Hidden-Information Games](https://arxiv.org/abs/2512.18858)
*Avirup Chakraborty,Shirsa Maitra,Tathagata Banerjee,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.GT

TL;DR: 本文探讨了传统Elo评分系统在运气驱动环境中的局限性，并提出了一种专门为Rummy游戏设计的改进Elo框架，该框架通过积分性能指标和初始手牌质量模型分离技能与运气。


<details>
  <summary>Details</summary>
Motivation: 传统的Elo评分系统仅考虑游戏结果且假设玩家初始状态一致，这在Rummy等部分随机不完全信息游戏中存在方法学上的挑战。本文旨在解决这一问题。

Method: 提出了一种改进的Elo框架，结合积分性能指标并明确建模初始手牌质量的影响，以分离技能与运气的影响。

Result: 通过27万场游戏的模拟实验，证明了该系统在稳定性、区分力和预测准确性上优于传统Elo评分系统。

Conclusion: 改进后的框架在计算简单的同时，有效捕捉了技能、策略和随机性的相互作用，适用于其他随机竞争环境。

Abstract: Rating systems play a crucial role in evaluating player skill across competitive environments. The Elo rating system, originally designed for deterministic and information-complete games such as chess, has been widely adopted and modified in various domains. However, the traditional Elo rating system only considers game outcomes for rating calculation and assumes uniform initial states across players. This raises important methodological challenges in skill modelling for popular partially randomized incomplete-information games such as Rummy. In this paper, we examine the limitations of conventional Elo ratings when applied to luck-driven environments and propose a modified Elo framework specifically tailored for Rummy. Our approach incorporates score-based performance metrics and explicitly models the influence of initial hand quality to disentangle skill from luck. Through extensive simulations involving 270,000 games across six strategies of varying sophistication, we demonstrate that our proposed system achieves stable convergence, superior discriminative power, and enhanced predictive accuracy compared to traditional Elo formulations. The framework maintains computational simplicity while effectively capturing the interplay of skill, strategy, and randomness, with broad applicability to other stochastic competitive environments.

</details>


### [10] [Considering the Difference in Utility Functions of Team Players in Adversarial Team Games](https://arxiv.org/abs/2512.18989)
*Youzhi Zhang*

Main category: cs.GT

TL;DR: 本文提出了一种新的解决方案概念——合作竞争均衡（CoE），用于对抗性团队游戏中，团队成员具有不同效用函数的情况，解决了忽略效用差异导致的不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 联合国2030年可持续发展议程要求各国合作对抗不利因素，但现有对抗性团队游戏的理论假设团队成员效用函数相同，忽略了现实中国家的效用差异。本文旨在填补这一研究空白。

Method: 提出了合作竞争均衡（CoE）和团队最大化CoE，通过团队成员不同效用函数的协同行动对抗对手，避免因忽略效用差异而产生的均衡不稳定问题。

Result: 研究表明，CoE和团队最大化CoE能够解决团队成员效用差异导致的问题，并为理论和算法研究提供了新的机遇。

Conclusion: 本文强调了对抗性团队游戏中考虑团队成员效用差异的重要性，提出的CoE概念为解决这一问题提供了理论支持，并为未来研究指明了方向。

Abstract: The United Nations' 2030 Agenda for Sustainable Development requires that all countries collaborate to fight adversarial factors to achieve peace and prosperity for humans and the planet. This scenario can be formulated as an adversarial team game in AI literature, where a team of players play against an adversary. However, previous solution concepts for this game assume that team players have the same utility functions, which cannot cover the real-world case that countries do not always have the same utility function. This paper argues that studying adversarial team games should not ignore the difference in utility functions of team players. We show that ignoring the difference in utility functions of team players could cause the computed equilibrium to be unstable. To show the benefit of considering the difference in utility functions of team players, we introduce a novel solution concept called Co-opetition Equilibrium (CoE) for the adversarial team game. In this game, team players with different utility functions (i.e., cooperation between team players) correlate their actions to play against the adversary (i.e., competition between the team and the adversary). We further introduce the team-maximizing CoE, which is a CoE but maximizes the team's utility among all CoEs. Both equilibria can overcome the issue caused by ignoring the difference in utility functions of team players. We further show the opportunities for theoretical and algorithmic contributions based on our position of considering the difference in utility functions of team players.

</details>


### [11] [A Unified Framework and Comparative Study of Decentralized Finance Derivatives Protocols](https://arxiv.org/abs/2512.19113)
*Luca Pennella,Pietro Saggese,Fabio Pinelli,Letterio Galletta*

Main category: cs.GT

TL;DR: 本文系统分析了DeFi衍生品协议的三种类型（永续、期权和合成资产），提出了一个统一的概念框架，并通过数值模拟评估了不同经济条件下的协议动态。


<details>
  <summary>Details</summary>
Motivation: 尽管DeFi衍生品协议的重要性日益增长，但与借贷协议和自动化做市商等DeFi工具相比，它们的研究相对较少。本文旨在填补这一研究空白。

Method: 研究通过分类（永续、期权和合成资产）系统分析了DeFi衍生品协议，并提出了一个统一的概念框架。还通过数值模拟评估了不同经济条件下的协议动态。

Result: 研究发现并总结了DeFi衍生品协议的相似性、差异性和动态特征，并通过模拟评估了资产价格、波动性、协议费用和杠杆等因素对清算和盈利能力的影响。

Conclusion: 本文为DeFi衍生品协议提供了形式化的描述和统一的概念框架，并通过模拟验证了设计原则和核心架构的有效性。

Abstract: Decentralized Finance (DeFi) applications introduce novel financial instruments replicating and extending traditional ones through blockchain-based smart contracts. Among these, derivatives protocols enable the decentralized trading of cryptoassets that are the counterpart of derivative products available in traditional finance. Despite their growing significance, DeFi derivatives protocols remain relatively understudied compared to other DeFi instruments, such as lending protocols and decentralized exchanges with automated market makers. This paper systematically analyzes DeFi derivatives protocols - categorized into perpetual, options, and synthetics - in the field, highlighting similarities, differences, dynamics, and actors. As a result of our study, we provide a formal characterization of decentralized derivative products and introduce a unifying conceptual framework that captures the design principles and core architecture of such protocols. We complement our theoretical analysis with numerical simulations: we evaluate protocol dynamics under various economic conditions, including changes in underlying asset prices, volatility, protocol-specific fees, leverage, and their impact on liquidation and profitability.

</details>


### [12] [LOCO: A Low-Cost SNU-Self-Resilient Latch Using an Output-Split C-Element](https://arxiv.org/abs/2512.19292)
*Ruijun Ma,Xin Chen,Xiaoqing Wen,Hui Xu,Shengnan Ye,Chuanjian Zhang,Senling Wang*

Main category: cs.GT

TL;DR: 本文提出了一种新型的输出分裂C元件（OSC）和低成本单节点翻转自恢复锁存器（LOCO），显著降低了软错误防护的开销。


<details>
  <summary>Details</summary>
Motivation: 随着CMOS技术进入纳米尺度，集成电路对辐射引起的软错误越来越敏感，现有防护设计仅保护输入节点，导致额外开销。

Method: 研究提出OSC保护输入输出节点，并设计LOCO锁存器结合OSC，利用时钟门控和高速路径降低功耗和延迟。

Result: 与现有设计相比，LOCO锁存器晶体管数量减少19%，功耗降低63.58%，延迟减少74%，功耗延迟积降低92%。

Conclusion: LOCO锁存器在PVT变化下表现出更好稳定性，显著提升了集成电路的可靠性并降低了开销。

Abstract: As the CMOS technology enters nanometer scales, integrated circuits (ICs) become increasingly sensitive to radiation-induced soft errors, which can corrupt the state of storage elements and cause severe reliability issues. Many hardened designs have been proposed to mitigate soft errors by using filtering elements. However, existing filtering elements only protect their inputs against soft errors and leave their outputs unprotected. Therefore, additional filtering elements must be added to protect outputs, resulting in extra overhead. In this paper, we first propose a novel Output-Split C-element (OSC) to protect both its input and output nodes, and then a novel LOw-COst single-node-upset (SNU) self-resilient latch (LOCO) to use OSCs to achieve both soft error resilience and low overhead. The usage of OSCs effectively reduce the short-circuit current of the LOCO latch during switching activities. Furthermore, the usage of clock gating and high-speed path reduces power consumption and delay, respectively. Compared with state-of-the-art SNU-resilient hardened designs, the LOCO latch achieves 19% fewer transistors, 63.58% lower power, 74% less delay, and 92% lower power-delay-product (PDP) on average. In addition, the LOCO latch exhibits better stability under variations in PVT (Process, Voltage, and Temperature).

</details>


### [13] [Stochastic assignment games for Mobility-as-a-Service markets](https://arxiv.org/abs/2512.19328)
*Bingqing Liu,David Watling,Joseph Y. J. Chow*

Main category: cs.GT

TL;DR: 该论文研究了随机分配博弈，并将其扩展到多模式移动市场中，引入了MaaS平台的领导者角色，提出了一种双层问题的解决框架。


<details>
  <summary>Details</summary>
Motivation: 探讨多模式移动市场中平台和用户之间的动态博弈关系，设计最优票价策略以最大化平台收益。

Method: 扩展随机多对多分配博弈为Stackelberg博弈，提出迭代平衡算法解决双层问题。

Result: 模型成功应用于MaaS票价设计，并能用于公共机构管理多模式交通系统。

Conclusion: 模型在MaaS票价设计和多模式交通管理中具有实际应用价值，同时考虑了用户和运营商的异质性。

Abstract: We study the stochastic assignment game and extend it to model multimodal mobility markets with a regulator or a Mobility-as-a-Service (MaaS) platform. We start by presenting general forms of one-to-one and many-to-many stochastic assignment games. Optimality conditions are discussed. The core of stochastic assignment games is defined, with expected payoffs of sellers and buyers in stochastic assignment games as payoffs from a hypothetical "ideal matching" that represent sellers' and buyers' expectations under imperfect information. To apply stochastic assignment games to the urban mobility markets, we extend the general stochastic many-to-many assignment game into a stochastic Stackelberg game to model MaaS systems, where the platform is the leader, and users and operators are the followers. The platform sets fares to maximize revenue. Users and operator react to the fare settings to form a stochastic many-to-many assignment game considering both fixed-route services and Mobility-on-Demand (MOD). The Stackelberg game is formulated as a bilevel problem. The lower level is the stochastic many-to-many assignment game between users and operators, shown to yield a coalitional logit model. The upper-level problem is a fare adjustment problem maximizing revenue. An iterative balancing algorithm is proposed to solve the lower-level problem exactly. The bilevel problem is solved through an iterative fare adjusting heuristic, whose solution is shown to be equivalent to the bilevel problem with an additional condition when it converges. Two case studies are conducted. The model can be applied to design MaaS fares maximizing income of the platform while anticipating the selfish behavior and heterogeneity of users and operators. Public agencies can also use the model to manage multimodal transportation systems.

</details>


### [14] [Fair Team Contracts](https://arxiv.org/abs/2512.19388)
*Matteo Castiglioni,Junjie Chen,Yingkai Li*

Main category: cs.GT

TL;DR: 论文研究团队合作中的最优公平合同设计，确保每个代理人获得不低于最低份额的线性合同，并展示了其在高收益和非歧视性合同中的优势。


<details>
  <summary>Details</summary>
Motivation: 研究团队合作中如何设计最优公平合同，以激励代理人付出努力并满足公平性约束。

Method: 设计了确保最低份额的线性合同，并提出FPTAS和常数近似算法以处理不同类型的成功函数。

Result: 最优公平合同能使收益增加25%，优于非歧视性合同，尤其适用于加法成功函数和子模成功函数。

Conclusion: 采用最优公平合同不仅能激励代理人努力，还能显著提高团队合作的收益。

Abstract: A principal selects a team of agents for collaborating on a joint project. The principal aims to design a revenue-optimal contract that incentivize the team of agents to exert costly effort while satisfying fairness constraints. We show that the optimal fair contract ensures that there is a minimum share, and every agent receives a linear contract weakly higher than the minimum share that is sufficient to incentivize them to exert costly effort. We utilize this structure to design an FPTAS for additive success functions and a constant approximation algorithm for submodular success functions. Moreover, we show that adopting optimal fair contracts can lead to a 25% revenue increase compared to the optimal non-discriminatory contracts even for additive success functions.

</details>


### [15] [Three Tiers and Thresholds: Incentives in Private Market Investing](https://arxiv.org/abs/2512.19405)
*Jussi Keppo,Yingkai Li*

Main category: cs.GT

TL;DR: 本文研究了私募市场投资中的最优合同设计，重点关注风险投资和私募股权公司内部的决策制定。委托人依赖代理人进行高成本的尽职调查并提出投资建议，事后结果可观察，允许补偿与成功投资和谨慎不投资决策挂钩。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决私募市场中委托人如何设计合同以激励代理人进行尽职调查并真实报告投资建议的问题，同时防止过度风险行为。

Method: 通过模型分析最优合同设计，研究了代理人的努力成本和事后结果的可观测性，并提出了三种层级的合同形式，其中支付与代理人的建议和实际回报挂钩。

Result: 研究结果表明，在对称环境下，满足单调似然比性质时，最优合同简化为阈值合同，仅在建议与实际极端回报一致时支付。

Conclusion: 结论指出，这种基于绩效的补偿机制能有效促进审慎筛选并限制过度风险行为，为私募市场合同设计提供了指导。

Abstract: This paper studies optimal contract design in private market investing, focusing on internal decision making in venture capital and private equity firms. A principal relies on an agent who privately exerts costly due diligence effort and then recommends whether to invest. Outcomes are observable ex post even when an opportunity is declined, allowing compensation to reward both successful investments and prudent decisions to pass. We characterize profit maximizing contracts that induce information acquisition and truthful reporting. We show that three tier contracts are sufficient, with payments contingent on the agent's recommendation and the realized return. In symmetric environments satisfying the monotone likelihood ratio property, the optimal contract further simplifies to a threshold contract that pays only when the recommendation is aligned with an extreme realized return. These results provide guidance for performance based compensation that promotes diligent screening while limiting excessive risk taking.

</details>
