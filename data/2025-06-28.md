<div id=toc></div>

# Table of Contents

- [cs.DM](#cs.DM) [Total: 2]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.LO](#cs.LO) [Total: 2]
- [math.LO](#math.LO) [Total: 3]
- [math.RT](#math.RT) [Total: 4]


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [1] [Making Graphs Irregular through Irregularising Walks](https://arxiv.org/abs/2506.21254)
*Julien Bensmail,Romain Bourneuf,Paul Colinot,Samuel Humeau,Timothée Martinod*

Main category: cs.DM

TL;DR: 1-2-3猜想由Karoński等人提出，近期被Keusch解决。本文在原有问题基础上引入额外约束，研究如何通过最短的路径将图转化为局部不规则多重图。


<details>
  <summary>Details</summary>
Motivation: 基于1-2-3猜想的最新解决，研究在额外约束条件下（即添加的边必须形成路径）如何将图转化为局部不规则多重图。

Method: 引入路径约束条件，研究不同类别图中最短不规则化路径的性质，包括结构、组合和算法方面的分析。

Result: 提供了关于最短不规则化路径长度的多种结果，包括一般图和特定受限图类的分析。

Conclusion: 研究表明，在路径约束条件下，存在可行的方法将图转化为局部不规则多重图，且路径长度受限于图的类型。

Abstract: The 1-2-3 Conjecture, introduced by Karo\'nski, {\L}uczak, and Thomason in
2004, was recently solved by Keusch. This implies that, for any connected graph
$G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph
$M(G)$, i.e., in which no two adjacent vertices have the same degree, by
replacing some of its edges with at most three parallel edges. In this work, we
introduce and study a restriction of this problem under the additional
constraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a
path with possibly repeated edges and vertices) of $G$. We investigate the
general consequences of having this additional constraint, and provide several
results of different natures (structural, combinatorial, algorithmic) on the
length of the shortest irregularising walks, for general graphs and more
restricted classes.

</details>


### [2] [Playing Snake on a Graph](https://arxiv.org/abs/2506.21281)
*Denise Graafsma,Bodo Manthey,Alexander Skopalik*

Main category: cs.DM

TL;DR: 研究了在任意无向图上的蛇游戏，证明了判断图是否蛇可赢是NP困难的，并对某些特定图类进行了完全表征。


<details>
  <summary>Details</summary>
Motivation: 基于经典的蛇游戏，研究其在任意无向图上的扩展，探索蛇游戏在图论中的复杂性和特性。

Method: 通过分析蛇在无向图中的移动策略，研究了蛇可赢图的判定问题，并针对特定图类（如奇二分图和顶点连通度为1的图）进行详细分析。

Result: 证明了蛇可赢图的判定问题对网格图是NP困难的，完全表征了奇二分图和顶点连通度为1的蛇可赢图，并展示了非哈密顿蛇可赢图的围长不超过6且此界紧。

Conclusion: 蛇可赢图的判定问题具有复杂性，且特定图类的蛇可赢性可以通过结构特性完全表征，非哈密顿蛇可赢图的围长受限。

Abstract: Snake is a classic computer game, which has been around for decades. Based on
this game, we study the game of Snake on arbitrary undirected graphs. A snake
forms a simple path that has to move to an apple while avoiding colliding with
itself. When the snake reaches the apple, it grows longer, and a new apple
appears. A graph on which the snake has a strategy to keep eating apples until
it covers all the vertices of the graph is called snake-winnable. We prove that
determining whether a graph is snake-winnable is NP-hard, even when restricted
to grid graphs. We fully characterize snake-winnable graphs for odd-sized
bipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian
graphs are always snake-winnable, we show that non-Hamiltonian snake-winnable
graphs have a girth of at most 6 and that this bound is tight.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [3] [Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions](https://arxiv.org/abs/2506.20677)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.DS

TL;DR: 提出了一种自适应混合排序范式，通过实时监测输入数据模式自动选择最优排序算法（Counting Sort、Radix Sort或QuickSort），显著提升执行时间、灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 排序是计算机科学中的核心操作，直接影响大规模数据系统、实时系统和嵌入式计算的性能。然而，没有任何一种排序算法在所有数据分布下都是最优的。

Method: 该方法通过特征提取模块计算数据量、值范围和熵等关键参数，使用有限状态机和XGBoost分类器构成的决策引擎选择最优排序策略：在小的键范围上采用Counting Sort，在低熵结构输入上采用Radix Sort，通用排序则使用QuickSort。

Result: 实验结果表明，该自适应排序框架在合成和真实数据集上的执行时间、灵活性和效率均显著优于传统静态排序算法。

Conclusion: 提出的框架具有可扩展性和高效性，适用于大数据分析、边缘计算和硬件受限系统等多种数据操作场景。

Abstract: Sorting is an essential operation in computer science with direct
consequences on the performance of large scale data systems, real-time systems,
and embedded computation. However, no sorting algorithm is optimal under all
distributions of data. The new adaptive hybrid sorting paradigm proposed in
this paper is the paradigm that automatically selects the most effective
sorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time
monitoring of patterns in input data. The architecture begins by having a
feature extraction module to compute significant parameters such as data
volume, value range and entropy. These parameters are sent to a decision engine
involving Finite State Machine and XGBoost classifier to aid smart and
effective in choosing the optimal sorting strategy. It implements Counting Sort
on small key ranges, Radix Sort on large range structured input with
low-entropy keys and QuickSort on general purpose sorting. The experimental
findings of both synthetic and real life dataset confirm that the proposed
solution is actually inclined to excel significantly by comparison in execution
time, flexibility and the efficiency of conventional static sorting algorithms.
The proposed framework provides a scalable, high perhaps and applicable to a
wide range of data processing operations like big data analytics, edge
computing, and systems with hardware limitations.

</details>


### [4] [Review of Three Variants of the k-d Tree](https://arxiv.org/abs/2506.20687)
*Russell A. Brown*

Main category: cs.DS

TL;DR: 本文介绍了三种不同的 k-d 树变体，比较了它们在构建过程中的分区技术及其性能，并分析了其中一种变体的双线程执行效果。


<details>
  <summary>Details</summary>
Motivation: 传统平衡技术（如 AVL 树或红黑树）不适用于 k-d 树，因此需要找到适合 k-d 树的平衡构建方法，以优化计算复杂度。

Method: 通过对比三种不同的分区技术来构建平衡的 k-d 树，并对其中一种变体提出了双线程执行方案。

Result: 研究表明，不同的分区技术对 k-d 树的构建复杂度有显著影响，双线程执行在某些情况下能提高性能。

Conclusion: 选择合适的 k-d 树构建技术和并行化方法可以有效优化其性能，尤其是在处理大数据集时。

Abstract: The original description of the k-d tree recognized that rebalancing
techniques, such as used to build an AVL tree or a red-black tree, are not
applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is
necessary to find the median of a set of data for each recursive subdivision of
that set. The sort or selection used to find the median, and the technique used
to partition the set about that median, strongly influence the computational
complexity of building a k-d tree. This article describes and contrasts three
variants of the k-d tree that differ in their technique used to partition the
set, and compares the performance of those variants. In addition, dual-threaded
execution is proposed and analyzed for one of the three variants.

</details>


### [5] [A Framework for Building Data Structures from Communication Protocols](https://arxiv.org/abs/2506.20761)
*Alexandr Andoni,Shunhua Jiang,Omri Weinstein*

Main category: cs.DS

TL;DR: 提出了一个高效高维模式匹配数据结构设计的通用框架，通过通信模型降低数据结构问题复杂度，应用于部分匹配问题，显著提升查询时间和空间效率。


<details>
  <summary>Details</summary>
Motivation: 解决高维模式匹配问题中数据结构查询效率低下的问题，尤其是部分匹配问题中的查询时间和空间瓶颈。

Method: 将数据结构问题转化为无歧义Arthur-Merlin（UAM）通信复杂度问题，开发了一种单边误差的通信协议改进经典结果。

Result: 新框架在查询时间上达到$n^{1-1/(c \log^2 c)}$，空间接近线性，优于现有最佳线性空间数据结构。

Conclusion: 该框架为高维模式匹配提供了高效解决方案，展示了数据依赖型数据结构在降低问题复杂度方面的潜力。

Abstract: We present a general framework for designing efficient data structures for
high-dimensional pattern-matching problems ($\exists \;? i\in[n], f(x_i,y)=1$)
through communication models in which $f(x,y)$ admits sublinear communication
protocols with exponentially-small error. Specifically, we reduce the data
structure problem to the Unambiguous Arthur-Merlin (UAM) communication
complexity of $f(x,y)$ under product distributions.
  We apply our framework to the Partial Match problem (a.k.a, matching with
wildcards), whose underlying communication problem is sparse set-disjointness.
When the database consists of $n$ points in dimension $d$, and the number of
$\star$'s in the query is at most $w = c\log n \;(\ll d)$, the fastest known
linear-space data structure (Cole, Gottlieb and Lewenstein, STOC'04) had query
time $t \approx 2^w = n^c$, which is nontrivial only when $c<1$. By contrast,
our framework produces a data structure with query time $n^{1-1/(c \log^2 c)}$
and space close to linear.
  To achieve this, we develop a one-sided $\epsilon$-error communication
protocol for Set-Disjointness under product distributions with
$\tilde{\Theta}(\sqrt{d\log(1/\epsilon)})$ complexity, improving on the
classical result of Babai, Frankl and Simon (FOCS'86). Building on this
protocol, we show that the Unambiguous AM communication complexity of
$w$-Sparse Set-Disjointness with $\epsilon$-error under product distributions
is $\tilde{O}(\sqrt{w \log(1/\epsilon)})$, independent of the ambient dimension
$d$, which is crucial for the Partial Match result. Our framework sheds further
light on the power of data-dependent data structures, which is instrumental for
reducing to the (much easier) case of product distributions.

</details>


### [6] [Edge Clique Partition and Cover Beyond Independence](https://arxiv.org/abs/2506.21216)
*Fedor V. Fomin,Petr A. Golovach,Danil Sagunov,Kirill Simonov*

Main category: cs.DS

TL;DR: 论文研究了基于独立集的边团覆盖和分区问题，发现ECC/α在k≥2时是NP完全的，而ECP/α则是固定参数可解的。


<details>
  <summary>Details</summary>
Motivation: 由于传统参数化方法在稀疏图上的局限性，研究提出了基于独立集α(G)的参数化方法，以更有效地解决边团覆盖和分区问题。

Method: 引入ECC/α和ECP/α问题，分别研究在α(G) + k团下的边覆盖和分割问题，并通过固定参数和复杂度分析进行比较。

Result: ECP/α是固定参数可解的，而ECC/α在k≥2时是NP完全的。另外，当参数化为k + ω(G)时，ECC/α成为固定参数可解。

Conclusion: 研究揭示了ECC/α和ECP/α在参数化问题上的复杂性差异，并为稀疏图提供了高效的算法解决方案。

Abstract: Covering and partitioning the edges of a graph into cliques are classical
problems at the intersection of combinatorial optimization and graph theory,
having been studied through a range of algorithmic and complexity-theoretic
lenses. Despite the well-known fixed-parameter tractability of these problems
when parameterized by the total number of cliques, such a parameterization
often fails to be meaningful for sparse graphs. In many real-world instances,
on the other hand, the minimum number of cliques in an edge cover or partition
can be very close to the size of a maximum independent set \alpha(G).
  Motivated by this observation, we investigate above \alpha parameterizations
of the edge clique cover and partition problems. Concretely, we introduce and
study Edge Clique Cover Above Independent Set (ECC/\alpha) and Edge Clique
Partition Above Independent Set (ECP/\alpha), where the goal is to cover or
partition all edges of a graph using at most \alpha(G) + k cliques, and k is
the parameter. Our main results reveal a distinct complexity landscape for the
two variants. We show that ECP/\alpha is fixed-parameter tractable, whereas
ECC/\alpha is NP-complete for all k \geq 2, yet can be solved in polynomial
time for k \in {0,1}. These findings highlight intriguing differences between
the two problems when viewed through the lens of parameterization above a
natural lower bound.
  Finally, we demonstrate that ECC/\alpha becomes fixed-parameter tractable
when parameterized by k + \omega(G), where \omega(G) is the size of a maximum
clique of the graph G. This result is particularly relevant for sparse graphs,
in which \omega is typically small. For H-minor free graphs, we design a
subexponential algorithm of running time f(H)^{\sqrt{k}}n^{O(1)}.

</details>


### [7] [Practical and Accurate Local Edge Differentially Private Graph Algorithms](https://arxiv.org/abs/2506.20828)
*Pranay Mundra,Charalampos Papamanthou,Julian Shun,Quanquan C. Liu*

Main category: cs.DS

TL;DR: 该论文提出了基于本地差分隐私（LDP）的新算法，用于解决大规模网络分析中的隐私问题，并显著提升了k-core分解和三角形计数的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模网络数据的普及，如何在保护敏感数据隐私的同时进行高效的图分析成为一个重要挑战。本地差分隐私（LDP）因其在个体层面的隐私保护能力而成为解决方案。

Method: 论文提出了针对k-core分解和三角形计数的LDP算法，利用图的退化性和最大度数等输入依赖的私有图属性来提升理论效用。算法包括私有的出度定向和改进的随机响应技术。

Result: 实验表明，新算法在真实图数据上表现优异：k-core分解的误差仅为基线方法的3倍，而三角形计数的近似误差减少了多达六个数量级，同时保持了较低的运行时间。

Conclusion: 该研究不仅通过LDP提升了图统计任务的隐私保护性能，还展示了在分布式模拟环境下的实际应用潜力，为未来隐私保护图分析提供了新思路。

Abstract: The rise of massive networks across diverse domains necessitates
sophisticated graph analytics, often involving sensitive data and raising
privacy concerns. This paper addresses these challenges using local
differential privacy (LDP), which enforces privacy at the individual level,
where no third-party entity is trusted, unlike centralized models that assume a
trusted curator. We introduce novel LDP algorithms for two fundamental graph
statistics: k-core decomposition and triangle counting. Our approach leverages
input-dependent private graph properties, specifically the degeneracy and
maximum degree of the graph, to improve theoretical utility. Unlike prior
methods, our error bounds are determined by the maximum degree rather than the
total number of edges, resulting in significantly tighter guarantees. For
triangle counting, we improve upon the work of Imola, Murakami, and
Chaudhury~\cite{IMC21locally, IMC21communication}, which bounds error in terms
of edge count. Instead, our algorithm achieves bounds based on graph degeneracy
by leveraging a private out-degree orientation, a refined variant of Eden et
al.'s randomized response technique~\cite{ELRS23, and a novel analysis,
yielding stronger guarantees than prior work. Beyond theoretical gains, we are
the first to evaluate local DP algorithms in a distributed simulation, unlike
prior work tested on a single processor. Experiments on real-world graphs show
substantial accuracy gains: our k-core decomposition achieves errors within 3x
of exact values, far outperforming the 131x error in the baseline of Dhulipala
et al.~\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative
approximation errors by up to six orders of magnitude, while maintaining
competitive runtime.

</details>


### [8] [Almost Tight Additive Guarantees for \boldmath $k$-Edge-Connectivity](https://arxiv.org/abs/2506.20906)
*Nikhil Kumar,Chaitanya Swamy*

Main category: cs.DS

TL;DR: 本文提出了针对k-边连通支撑子图（kECSS）问题的近似算法，针对偶数k和奇数k分别给出了不同的连通性保证和成本上限，且在APX-hard条件下接近最优。方法改进并简化了现有工作，并扩展到度约束版本。


<details>
  <summary>Details</summary>
Motivation: k-边连通支撑子图问题在实际网络设计中具有重要意义，但因其APX-hard性质，难以精确求解。本文旨在提供高效的近似算法，以在保证一定连通性的同时最小化成本。

Method: 为偶数k设计了多项式时间算法，得到成本不超过LP最优解的(k-2)-边连通子图；为奇数k得到(k-3)-边连通子图。还提供了1.5倍LP最优解成本的(k-1)-边连通子图。

Result: 所提算法在APX-hard条件下接近最优，显著改进了现有成果，且方法更简单。扩展到度约束版本时，对度约束的违反仅约2。

Conclusion: 本文提供了高效的近似算法，解决了kECSS及其变种问题，为网络设计中的k-边连通问题提供了实用且理论保证的解决方案。

Abstract: We consider the \emph{$k$-edge connected spanning subgraph} (kECSS) problem,
where we are given an undirected graph $G = (V, E)$ with nonnegative edge costs
$\{c_e\}_{e\in E}$, and we seek a minimum-cost \emph{$k$-edge connected}
subgraph $H$ of $G$. For even $k$, we present a polytime algorithm that
computes a $(k-2)$-edge connected subgraph of cost at most the optimal value
$LP^*$ of the natural LP-relaxation for kECSS; for odd $k$, we obtain a
$(k-3)$-edge connected subgraph of cost at most $LP^*$. Since kECSS is APX-hard
for all $k\geq 2$, our results are nearly optimal. They also significantly
improve upon the recent work of Hershkowitz et al., both in terms of solution
quality and the simplicity of algorithm and its analysis. Our techniques also
yield an alternate guarantee, where we obtain a $(k-1)$-edge connected subgraph
of cost at most $1.5\cdot LP^*$; with unit edge costs, the cost guarantee
improves to $(1+\frac{4}{3k})\cdot LP^*$, which improves upon the
state-of-the-art approximation for unit edge costs, but with a unit loss in
edge connectivity.
  Our kECSS-result also yields results for the \emph{$k$-edge connected
spanning multigraph} (kECSM) problem, where multiple copies of an edge can be
selected: we obtain a $(1+2/k)$-approximation algorithm for even $k$, and a
$(1+3/k)$-approximation algorithm for odd $k$.
  Our techniques extend to the degree-bounded versions of kECSS and kECSM,
wherein we also impose degree lower- and upper- bounds on the nodes. We obtain
the same cost and connectivity guarantees for these degree-bounded versions
with an additive violation of (roughly) $2$ for the degree bounds. These are
the first results for degree-bounded \{kECSS,kECSM\} of the form where the cost
of the solution obtained is at most the optimum, and the connectivity
constraints are violated by an additive constant.

</details>


### [9] [Courcelle's Theorem for Lipschitz Continuity](https://arxiv.org/abs/2506.21118)
*Tatsuya Gima,Soh Kumabe,Yuichi Yoshida*

Main category: cs.DS

TL;DR: 本文提出了Lipschitz连续算法的首个元定理，类似于Courcelle定理，为有界树宽图上的问题提供高效Lipschitz连续算法，提升了近似性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的Lipschitz连续算法多为问题特定设计，缺乏通用性，本文旨在通过元定理解决这一问题。

Method: 利用有界树宽图和有界团宽图上的单子二阶逻辑（MSO_2和MSO_1）约束，设计(1±ε)-近似算法，并应用Baker分解。

Result: 展示了对有界树宽图问题的近似算法，具有多项式对数级Lipschitz常数，同时在有界团宽图上取得类似结果。

Conclusion: 本文提出的元定理为Lipschitz连续算法提供了通用框架，显著提升了算法的适用范围和性能。

Abstract: Lipschitz continuity of algorithms, introduced by Kumabe and Yoshida
(FOCS'23), measures the stability of an algorithm against small input
perturbations. Algorithms with small Lipschitz continuity are desirable, as
they ensure reliable decision-making and reproducible scientific research.
Several studies have proposed Lipschitz continuous algorithms for various
combinatorial optimization problems, but these algorithms are problem-specific,
requiring a separate design for each problem.
  To address this issue, we provide the first algorithmic meta-theorem in the
field of Lipschitz continuous algorithms. Our result can be seen as a Lipschitz
continuous analogue of Courcelle's theorem, which offers Lipschitz continuous
algorithms for problems on bounded-treewidth graphs. Specifically, we consider
the problem of finding a vertex set in a graph that maximizes or minimizes the
total weight, subject to constraints expressed in monadic second-order logic
(MSO_2). We show that for any $\varepsilon>0$, there exists a $(1\pm
\varepsilon)$-approximation algorithm for the problem with a polylogarithmic
Lipschitz constant on bounded treewidth graphs. On such graphs, our result
outperforms most existing Lipschitz continuous algorithms in terms of
approximability and/or Lipschitz continuity. Further, we provide similar
results for problems on bounded-clique-width graphs subject to constraints
expressed in MSO_1. Additionally, we construct a Lipschitz continuous version
of Baker's decomposition using our meta-theorem as a subroutine.

</details>


### [10] [On Minimizing Wiggle in Stacked Area Charts](https://arxiv.org/abs/2506.21175)
*Alexander Dobler,Martin Nöllenburg*

Main category: cs.DS

TL;DR: 堆叠面积图的优化问题中，最小化边界垂直变化（wiggle）的计算复杂度被证明是NP难的且难以近似求解。本文还提出了一种精确的混合整数线性规划方法，并与启发式算法进行了性能比较。


<details>
  <summary>Details</summary>
Motivation: 堆叠面积图是一种广泛使用的时间序列可视化技术，优化其可读性的关键是减少边界垂直变化（wiggle）。尽管已有许多启发式算法，但其计算复杂度尚未被正式分析。

Method: 本文通过数学证明展示了wiggle最小化问题的NP难性，并提出了一种精确的混合整数线性规划方法。同时，还与现有的启发式算法进行了实验对比。

Result: 研究表明，wiggle最小化问题不仅是NP难的，而且难以近似求解。混合整数线性规划方法在某些情况下优于启发式算法。

Conclusion: 本文为堆叠面积图优化问题提供了理论复杂度分析，并提出了一种新的解决方案，为后续研究奠定了基础。

Abstract: Stacked area charts are a widely used visualization technique for numerical
time series. The x-axis represents time, and the time series are displayed as
horizontal, variable-height layers stacked on top of each other. The height of
each layer corresponds to the time series values at each time point. The main
aesthetic criterion for optimizing the readability of stacked area charts is
the amount of vertical change of the borders between the time series in the
visualization, called wiggle. While many heuristic algorithms have been
developed to minimize wiggle, the computational complexity of minimizing wiggle
has not been formally analyzed. In this paper, we show that different variants
of wiggle minimization are NP-hard and even hard to approximate. We also
present an exact mixed-integer linear programming formulation and compare its
performance with a state-of-the-art heuristic in an experimental evaluation.
Lastly, we consider a special case of wiggle minimization that corresponds to
the fundamentally interesting and natural problem of ordering a set of numbers
as to minimize their sum of absolute prefix sums. We show several complexity
results for this problem that imply some of the mentioned hardness results for
wiggle minimization.

</details>


### [11] [Vantage Point Selection Algorithms for Bottleneck Capacity Estimation](https://arxiv.org/abs/2506.21418)
*Vikrant Ashvinkumar,Rezaul Chowdhury,Jie Gao,Mayank Goswami,Joseph S. B. Mitchell,Valentin Polishchuk*

Main category: cs.DS

TL;DR: 研究在网络中选择最佳观测点以揭示最大瓶颈边容量的问题，提出了非自适应和自适应两种设置下的近似算法和上下界分析。


<details>
  <summary>Details</summary>
Motivation: 解决在互联网中估计瓶颈容量的问题，需要选择最佳的观测点以揭示最多的瓶颈边容量。

Method: 在非自适应设置中，使用随机排列模型并提出一个1-1/e的近似算法；在自适应设置中，针对固定但未知的边容量，分析实例最优近似算法的下界和树及平面图的上界。

Result: 在非自适应设置中成功提出了近似算法；在自适应设置中，提供了针对特定输入实例的最优解和下界及上界分析。

Conclusion: 论文通过非自适应和自适应两种设置，为选择最优观测点问题提供了理论支持和实用算法。

Abstract: Motivated by the problem of estimating bottleneck capacities on the Internet,
we formulate and study the problem of vantage point selection. We are given a
graph $G=(V, E)$ whose edges $E$ have unknown capacity values that are to be
discovered. Probes from a vantage point, i.e, a vertex $v \in V$, along
shortest paths from $v$ to all other vertices, reveal bottleneck edge
capacities along each path. Our goal is to select $k$ vantage points from $V$
that reveal the maximum number of bottleneck edge capacities.
  We consider both a non-adaptive setting where all $k$ vantage points are
selected before any bottleneck capacity is revealed, and an adaptive setting
where each vantage point selection instantly reveals bottleneck capacities
along all shortest paths starting from that point. In the non-adaptive setting,
by considering a relaxed model where edge capacities are drawn from a random
permutation (which still leaves the problem of maximizing the expected number
of revealed edges NP-hard), we are able to give a $1-1/e$ approximate
algorithm. In the adaptive setting we work with the least permissive model
where edge capacities are arbitrarily fixed but unknown. We compare with the
best solution for the particular input instance (i.e. by enumerating all
choices of $k$ tuples), and provide both lower bounds on instance optimal
approximation algorithms and upper bounds for trees and planar graphs.

</details>


### [12] [Succinct Preferential Attachment Graphs](https://arxiv.org/abs/2506.21436)
*Ziad Ismaili Alaoui,Namrata,Sebastian Wild*

Main category: cs.DS

TL;DR: 该论文设计了一种能够在图数据压缩时动态优化空间使用的数据结构，支持高效的导航操作，尤其在Barabási-Albert模型中接近实例最优空间使用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决图数据压缩领域的局限性，即现有方法对特定图类别的限制以及空间使用的最坏情况假设。

Method: 设计了一种数据结构，其空间使用随图的压缩性自动优化，并能高效支持导航操作。关键技术贡献是对实例最优空间使用的分析。

Result: 数据结构在Barabási-Albert模型中接近实例最优空间使用，并对任意图保证空间不大于熵压缩的边列表。

Conclusion: 该研究为图数据的压缩计算提供了灵活高效的解决方案，具有广泛的应用潜力。

Abstract: Computing over compressed data combines the space saving of data compression
with efficient support for queries directly on the compressed representation.
Such data structures are widely applied in text indexing and have been
successfully generalised to trees. For graphs, support for computing over
compressed data remains patchy; typical results in the area of succinct data
structures are restricted to a specific class of graphs and use the same,
worst-case amount of space for any graph from this class.
  In this work, we design a data structure whose space usage automatically
improves with the compressibility of the graph at hand, while efficiently
supporting navigational operations (simulating adjacency-list access).
Specifically, we show that the space usage approaches the instance-optimal
space when the graph is drawn according to the classic Barab\'asi-Albert model
of preferential-attachment graphs. Our data-structure techniques also work for
arbitrary graphs, guaranteeing a size asymptotically no larger than an
entropy-compressed edge list. A key technical contribution is the careful
analysis of the instance-optimal space usage.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [13] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

Main category: cs.GR

TL;DR: Generative Blocks World 提出了一种通过操作简单几何抽象来生成和编辑图像的方法，通过3D原语的组合表示场景，并利用基于流的方法生成图像，实现了更高的视觉保真度和编辑灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有技术在图像生成和编辑中缺乏对几何和纹理一致性的有效处理，特别是在3D场景的表示和编辑上表现不足。该研究旨在通过几何抽象和纹理提示技术解决这些问题。

Method: 方法使用凸3D原语的组合表示场景，支持不同数量的原语表示同一场景，便于编辑。通过基于流的方法生成图像，利用深度和纹理提示确保几何和纹理一致性。纹理提示技术考虑了修改后的3D原语，提高了编辑的准确性。

Result: 定量和定性实验表明，该方法在视觉保真度、编辑能力和构图泛化性方面优于现有技术，能够更准确地处理对象和相机的移动，并保持对象的身份特征。

Conclusion: 该方法通过几何抽象和纹理提示技术，实现了高效且准确的图像生成和编辑，为3D场景的表示和操作提供了新的解决方案。

Abstract: We describe Generative Blocks World to interact with the scene of a generated
image by manipulating simple geometric abstractions. Our method represents
scenes as assemblies of convex 3D primitives, and the same scene can be
represented by different numbers of primitives, allowing an editor to move
either whole structures or small details. Once the scene geometry has been
edited, the image is generated by a flow-based method which is conditioned on
depth and a texture hint. Our texture hint takes into account the modified 3D
primitives, exceeding texture-consistency provided by existing key-value
caching techniques. These texture hints (a) allow accurate object and camera
moves and (b) largely preserve the identity of objects depicted. Quantitative
and qualitative experiments demonstrate that our approach outperforms prior
works in visual fidelity, editability, and compositional generalization.

</details>


### [14] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

Main category: cs.GR

TL;DR: 3DGH是一个无条件生成3D人头的模型，通过分离头发和面部的建模，并使用基于模板的3D高斯溅射数据表示，实现了可组合的头发和面部组件。


<details>
  <summary>Details</summary>
Motivation: 以往的研究在建模头发和面部时存在纠缠问题，3DGH旨在通过分离两者并引入可变形的头发几何结构来解决这一问题。

Method: 采用基于3D GAN的双生成器架构，利用交叉注意力机制建模头发与面部的关联，并使用合成渲染数据进行训练。

Result: 实验表明，3DGH在无条件全头图像合成和可组合3D发型编辑方面表现优异，优于多种先进的3D GAN方法。

Conclusion: 3DGH通过创新的数据表示和架构设计，成功实现了头发和面部的分离建模，为3D人头生成和编辑提供了有效的解决方案。

Abstract: We present 3DGH, an unconditional generative model for 3D human heads with
composable hair and face components. Unlike previous work that entangles the
modeling of hair and face, we propose to separate them using a novel data
representation with template-based 3D Gaussian Splatting, in which deformable
hair geometry is introduced to capture the geometric variations across
different hairstyles. Based on this data representation, we design a 3D
GAN-based architecture with dual generators and employ a cross-attention
mechanism to model the inherent correlation between hair and face. The model is
trained on synthetic renderings using carefully designed objectives to
stabilize training and facilitate hair-face separation. We conduct extensive
experiments to validate the design choice of 3DGH, and evaluate it both
qualitatively and quantitatively by comparing with several state-of-the-art 3D
GAN methods, demonstrating its effectiveness in unconditional full-head image
synthesis and composable 3D hairstyle editing. More details will be available
on our project page: https://c-he.github.io/projects/3dgh/.

</details>


### [15] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
*Meng Du,Robert Amor,Kwan-Liu Ma,Burkhard C. Wünsche*

Main category: cs.GR

TL;DR: 数据可视化和视觉分析在金融教育和素养提升中的应用系统性综述，分析了37篇研究论文，涵盖五大关键领域，并提出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 提高金融素养对个人财务健康至关重要，但许多人对此感到困惑。数据可视化可以简化金融概念，使其更易于理解和吸引人。

Method: 系统综述了37篇研究论文，将其分类为五个关键领域，包括可视化工具的动机、金融主题和教学方法、工具与技术类型以及教学干预效果的评估。

Result: 研究提供了金融素养教育中可视化应用的全面视角，并指出了研究空白和未来发展方向。

Conclusion: 研究结果为教育者和专业人士提供了实用见解，帮助他们有效利用或设计视觉工具以提升金融素养。

Abstract: Financial literacy empowers individuals to make informed and effective
financial decisions, improving their overall financial well-being and security.
However, for many people understanding financial concepts can be daunting and
only half of US adults are considered financially literate. Data visualization
simplifies these concepts, making them accessible and engaging for learners of
all ages. This systematic review analyzes 37 research papers exploring the use
of data visualization and visual analytics in financial education and literacy
enhancement. We classify these studies into five key areas: (1) the evolution
of visualization use across time and space, (2) motivations for using
visualization tools, (3) the financial topics addressed and instructional
approaches used, (4) the types of tools and technologies applied, and (5) how
the effectiveness of teaching interventions was evaluated. Furthermore, we
identify research gaps and highlight opportunities for advancing financial
literacy. Our findings offer practical insights for educators and professionals
to effectively utilize or design visual tools for financial literacy.

</details>


### [16] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

Main category: cs.GR

TL;DR: VideoTex是一个利用视频生成模型解决3D纹理合成中空间和时间不一致性的新框架，通过几何感知条件和结构UV扩散策略实现高质量纹理。


<details>
  <summary>Details</summary>
Motivation: 当前纹理合成方法因缺乏全局上下文和几何理解，导致固定视角下纹理不一致。视频生成模型的成功启发我们开发一种既能解决空间不一致又能保证时间一致性的方法。

Method: VideoTex结合了几何感知条件以精确利用3D网格结构，并提出结构UV扩散策略，通过保留语义信息增强遮挡区域纹理生成，实现更平滑和连贯的纹理。

Result: 实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法，能够生成高质量且时间稳定的纹理。

Conclusion: VideoTex通过视频生成模型和创新的UV扩散策略，为动态实时应用提供了兼具视觉质量和时间一致性的解决方案。

Abstract: Current texture synthesis methods, which generate textures from fixed
viewpoints, suffer from inconsistencies due to the lack of global context and
geometric understanding. Meanwhile, recent advancements in video generation
models have demonstrated remarkable success in achieving temporally consistent
videos. In this paper, we introduce VideoTex, a novel framework for seamless
texture synthesis that leverages video generation models to address both
spatial and temporal inconsistencies in 3D textures. Our approach incorporates
geometry-aware conditions, enabling precise utilization of 3D mesh structures.
Additionally, we propose a structure-wise UV diffusion strategy, which enhances
the generation of occluded areas by preserving semantic information, resulting
in smoother and more coherent textures. VideoTex not only achieves smoother
transitions across UV boundaries but also ensures high-quality, temporally
stable textures across video frames. Extensive experiments demonstrate that
VideoTex outperforms existing methods in texture fidelity, seam blending, and
stability, paving the way for dynamic real-time applications that demand both
visual quality and temporal coherence.

</details>


### [17] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
*Jiayi Zheng,Xiaodong Cun*

Main category: cs.GR

TL;DR: FairyGen是一个自动系统，可从儿童的单幅绘画生成具有故事性的卡通视频，同时保留其独特的艺术风格。


<details>
  <summary>Details</summary>
Motivation: 现有的故事生成方法主要关注角色一致性和基本动作，FairyGen旨在通过分离角色建模与风格化背景生成，并结合电影镜头设计，实现更具表现力和连贯性的故事讲述。

Method: FairyGen使用MLLM生成结构化故事板，引入风格传播适配器确保视觉一致性，并通过镜头设计模块增强视觉多样性和电影质感。动画通过3D代理角色生成物理上合理的运动序列，并结合两阶段运动定制适配器优化视频生成。

Result: 实验表明，FairyGen生成的动画在风格上忠实原画，叙事结构自然，运动合理，适合个性化和引人入胜的故事动画。

Conclusion: FairyGen通过结合多种技术实现了风格一致且叙事连贯的动画生成，展现了其在个性化故事动画中的潜力。

Abstract: We propose FairyGen, an automatic system for generating story-driven cartoon
videos from a single child's drawing, while faithfully preserving its unique
artistic style. Unlike previous storytelling methods that primarily focus on
character consistency and basic motion, FairyGen explicitly disentangles
character modeling from stylized background generation and incorporates
cinematic shot design to support expressive and coherent storytelling. Given a
single character sketch, we first employ an MLLM to generate a structured
storyboard with shot-level descriptions that specify environment settings,
character actions, and camera perspectives. To ensure visual consistency, we
introduce a style propagation adapter that captures the character's visual
style and applies it to the background, faithfully retaining the character's
full visual identity while synthesizing style-consistent scenes. A shot design
module further enhances visual diversity and cinematic quality through frame
cropping and multi-view synthesis based on the storyboard. To animate the
story, we reconstruct a 3D proxy of the character to derive physically
plausible motion sequences, which are then used to fine-tune an MMDiT-based
image-to-video diffusion model. We further propose a two-stage motion
customization adapter: the first stage learns appearance features from
temporally unordered frames, disentangling identity from motion; the second
stage models temporal dynamics using a timestep-shift strategy with frozen
identity weights. Once trained, FairyGen directly renders diverse and coherent
video scenes aligned with the storyboard. Extensive experiments demonstrate
that our system produces animations that are stylistically faithful,
narratively structured natural motion, highlighting its potential for
personalized and engaging story animation. The code will be available at
https://github.com/GVCLab/FairyGen

</details>


### [18] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
*Pin Ren,Yan Gao,Zhichun Li,Yan Chen,Benjamin Watson*

Main category: cs.GR

TL;DR: IDGraphs是一个用于入侵检测的交互式可视化系统，能够高效检测和分析网络中的攻击和异常。


<details>
  <summary>Details</summary>
Motivation: 当前网络中的流量异常和攻击频发，现有入侵检测系统在交互式检查、分析蠕虫传播模式和发现相关攻击方面支持有限。

Method: IDGraphs采用流级跟踪的可视化方法，通过时间轴和连接失败次数的聚合展示数据，并使用Histographs技术汇总数据频率。用户可以通过交互式查询进行分析。

Result: IDGraphs成功应用于一个包含1.79亿条流级记录的真实网络数据集，检测到包括端口扫描、蠕虫爆发和分布式攻击在内的多种攻击和异常。

Conclusion: IDGraphs提供了一种高效且交互式的入侵检测方法，能够解决现有系统在检测和分析上的局限性。

Abstract: Traffic anomalies and attacks are commonplace in today's networks and
identifying them rapidly and accurately is critical for large network
operators. For a statistical intrusion detection system (IDS), it is crucial to
detect at the flow-level for accurate detection and mitigation. However,
existing IDS systems offer only limited support for 1) interactively examining
detected intrusions and anomalies, 2) analyzing worm propagation patterns, 3)
and discovering correlated attacks. These problems are becoming even more acute
as the traffic on today's high-speed routers continues to grow.
  IDGraphs is an interactive visualization system for intrusion detection that
addresses these challenges. The central visualization in the system is a
flow-level trace plotted with time on the horizontal axis and aggregated number
of unsuccessful connections on the vertical axis. We then summarize a stack of
tens or hundreds of thousands of these traces using the Histographs [RW05]
technique, which maps data frequency at each pixel to brightness. Users may
then interactively query the summary view, performing analysis by highlighting
subsets of the traces. For example, brushing a linked correlation matrix view
highlights traces with similar patterns, revealing distributed attacks that are
difficult to detect using standard statistical analysis.
  We apply IDGraphs system to a real network router data-set with 179M
flow-level records representing a total traffic of 1.16TB. The system
successfully detects and analyzes a variety of attacks and anomalies, including
port scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed
attacks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [19] [Smoothness Meets Autobidding: Tight Price of Anarchy Bounds for Simultaneous First-Price Auctions](https://arxiv.org/abs/2506.20908)
*Riccardo Colini-Baldeschi,Sophie Klumper,Twan Kroll,Stefano Leonardi,Guido Schäfer,Artem Tsikiridis*

Main category: cs.GT

TL;DR: 本文扩展了Syrgkanis和Tardos的平滑框架，用于自动竞价系统，提出了一种平衡异构代理类型平滑参数的技术，并在多种模型中获得了紧的价格无政府状态（POA）界限。


<details>
  <summary>Details</summary>
Motivation: 随着在线广告系统转向自动竞价，研究不同代理行为下的价格无政府状态（POA）界限变得尤为重要。本文旨在扩展现有框架，以更简单、可扩展和通用的方式分析自动竞价系统中的POA。

Method: 本文扩展了Syrgkanis和Tardos的平滑框架，提出了一种平衡异构代理类型平滑参数的技术，并通过解决数学程序找到最佳的POA界限。方法还适用于多物品拍卖和混合代理行为。

Result: 通过在单物品一价拍卖（FPA）中证明平滑性，本文获得了混合自动竞价代理行为的紧POA界限（2.18）。此外，框架还适用于带保留价的FPA和异构代理行为，并首次为多种模型提供了紧POA界限。

Conclusion: 本文提出的框架不仅在分析自动竞价系统中的POA时表现出简洁性、可扩展性和通用性，还为未来研究提供了理论基础。此外，通过分析粗相关均衡（CCE），框架进一步证明了其在复杂代理行为下的适用性。

Abstract: Online advertising systems have recently transitioned to autobidding,
enabling advertisers to delegate bidding decisions to automated agents. Each
advertiser directs their agent to optimize a valuation-dependent objective
subject to return-on-investment (ROI) or budget constraints. Given their
relevance, there has been a surge in literature studying the liquid welfare
price of anarchy (POA) of core auction formats in autobidding, among which
simultaneous first-price auctions (FPA). These models capture a large range of
heterogeneous agent behaviors, requiring advanced proofs to derive tight POA
bounds. Recently, Deng et al. (NeurIPS 2024) showed that the POA of FPA for
mixed autobidders (i.e., value and utility maximizers) under ROI is 2.18 for
additive valuations.
  We extend the smoothness framework of Syrgkanis and Tardos (STOC 2013) to
autobidding. A key contribution is a technique to balance smoothness parameters
across heterogeneous agent types. Finding the best POA bound reduces to solving
a POA-revealing mathematical program. Our approach has three strengths: (1)
Simplicity: We prove smoothness for single-item FPA. Results for simultaneous
FPA follow via our theorem. For example, by showing smoothness for value and
utility maximizers, we obtain the tight POA of 2.18 for mixed autobidding. (2)
Extendibility: Our Extension Theorem adapts to simultaneous FPA with reserve
prices and agents with fractionally subadditive valuations and heterogeneous
payment sensitivities and target ROI parameters. We establish the first
(mostly) tight POA bounds for several models beyond the autobidding state of
the art. (3) Generality: Our framework bounds the POA of coarse correlated
equilibria (CCE), which arise when hybrid agents employ regret-minimizing
algorithms. Building on Kolumbus and Nisan (WWW 2022), we show that CCE from
such agents have properties that keep their POA low.

</details>


### [20] [From multi-allocations to allocations, with subadditive valuations](https://arxiv.org/abs/2506.21493)
*Uriel Feige*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the problem of fair allocation of $m$ indivisible items to $n$
agents with monotone subadditive valuations. For integer $d \ge 2$, a
$d$-multi-allocation is an allocation in which each item is allocated to at
most $d$ different agents. We show that $d$-multi-allocations can be
transformed into allocations, while not losing much more than a factor of $d$
in the value that each agent receives. One consequence of this result is that
for allocation instances with equal entitlements and subadditive valuations, if
$\rho$-MMS $d$-multi-allocations exist, then so do $\frac{\rho}{4d}$-MMS
allocations. Combined with recent results of Seddighin and Seddighin [EC 2025],
this implies the existence of $\Omega(\frac{1}{\log\log n})$-MMS allocations.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [21] [Pebble Games and Algebraic Proof Systems](https://arxiv.org/abs/2506.21149)
*Lisa-Marie Jaser,Jacobo Toran*

Main category: cs.LO

TL;DR: 论文通过研究Peb$(G)$公式的反驳，揭示了pebbling游戏与代数证明系统之间的强联系，并展示了它们在空间和时间上的对应关系。


<details>
  <summary>Details</summary>
Motivation: 探讨pebbling游戏与代数证明系统之间的联系，以更深入地理解两者之间的相似性和对应关系。

Method: 通过分析Peb$(G)$公式的反驳，研究了可逆、黑色和黑白pebbling游戏与Nullstellensatz、Monomial Calculus和Polynomial Calculus三种代数证明系统之间的对应关系。

Result: 证明了对于任何单汇点DAG $G$，Monomial Calculus（MC）反驳的空间和时间与黑色pebbling策略的空间和时间之间存在对应关系。同时，发现了pebbling游戏空间与代数证明系统中变量空间复杂度的精确匹配。

Conclusion: 研究揭示了pebbling游戏与代数证明系统之间的深刻联系，为进一步研究两者之间的分离和权衡提供了理论基础。

Abstract: Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove
some new strong connections between pebble games and algebraic proof system,
showing that there is a parallelism between the reversible, black and
black-white pebbling games on one side, and the three algebraic proof systems
Nullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.
In particular we prove that for any DAG $G$ with a single sink, if there is a
Monomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and
size $t$ then there is a black pebbling strategy on $G$ with space $s$ and time
$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and
time $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having
simultaneously degree $s$ and size $ts$. These results are analogous to those
proven in {deRezende et al.21} for the case of reversible pebbling and
Nullstellensatz. Using them we prove degree separations between NS, MC and PC,
as well as strong degree-size tradeoffs for MC.
  We also notice that for any directed acyclic graph $G$ the space needed in a
pebbling strategy on $G$, for the three versions of the game, reversible, black
and black-white, exactly matches the variable space complexity of a refutation
of the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof
systems NS, MC and PC. Using known pebbling bounds on graphs, this connection
implies separations between the corresponding variable space measures.

</details>


### [22] [Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space](https://arxiv.org/abs/2506.21481)
*Eike Neumann*

Main category: cs.LO

TL;DR: 论文研究了在实数计算的比特模型中，连续映射下点是否逃离封闭子集的问题，提出了一个部分决策方法，并证明了其鲁棒性和普遍适用性。


<details>
  <summary>Details</summary>
Motivation: 研究在连续映射下点是否逃离封闭子集的决策问题，旨在提供一种鲁棒且通用的决策方法。

Method: 采用部分决策方法，证明其终止性和鲁棒性，并适用于一般连续函数、仿射线性系统和二次复多项式。

Result: 该方法在鲁棒问题实例上终止且完备，并且在所有问题实例集合中密集，特别适用于复杂动态中的双曲密度猜想。

Conclusion: 该方法不仅提供了通用的决策框架，还为复杂动态中的开放问题提供了新的证明思路，如Mandelbrot集的可计算性问题。

Abstract: We study the problem of deciding whether a point escapes a closed subset of
$\mathbb{R}^d$ under the iteration of a continuous map $f \colon \mathbb{R}^d
\to \mathbb{R}^d$ in the bit-model of real computation. We give a sound partial
decision method for this problem which is complete in the sense that its
halting set contains the halting set of all sound partial decision methods for
the problem. Equivalently, our decision method terminates on all problem
instances whose answer is robust under all sufficiently small perturbations of
the function. We further show that the halting set of our algorithm is dense in
the set of all problem instances. While our algorithm applies to general
continuous functions, we demonstrate that it also yields complete decision
methods for much more rigid function families: affine linear systems and
quadratic complex polynomials. In the latter case, completeness is subject to
the density of hyperbolicity conjecture in complex dynamics. This in particular
yields an alternative proof of Hertling's (2004) conditional answer to a
question raised by Penrose (1989) regarding the computability of the Mandelbrot
set.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [23] [On pre-local tabularity above $\mathrm{S4}\times \mathrm{S4}$](https://arxiv.org/abs/2506.20874)
*Ilya B. Shapirovsky,Vladislav V. Sliusarev*

Main category: math.LO

TL;DR: 研究在$	ext{S4} \times 	ext{S4}$的正规扩展中的预局部表格性，发现有四种预局部表格逻辑，并给出了局部表格性的公理标准。


<details>
  <summary>Details</summary>
Motivation: 探讨模态逻辑中$	ext{S4} \times 	ext{S4}$的正规扩展的预局部表格性，以填补该领域的知识空白。

Method: 通过分析正规扩展中的预局部表格性，识别四种特定的逻辑，并构造包含逆和通用模态的预局部表格扩展。

Result: 确定了四种预局部表格逻辑，并提供了关于局部表格性的公理标准，构造了不在这些类中的扩展示例。

Conclusion: 研究发现$	ext{S4} \times 	ext{S4}$的正规扩展中存在四种预局部表格逻辑，并有工具识别局部表格性。

Abstract: We investigate pre-local tabularity in normal extensions of the logic
$\mathrm{S4}\times \mathrm{S4}$. We show that there are exactly four
pre-locally tabular logics in normal extensions of products of finite height,
and that every non-locally tabular logic in this family is contained in one of
them. We also give an axiomatic criterion of local tabularity above the logic
of products with Noetherian skeletons. Then we construct examples of
pre-locally tabular extensions of $\mathrm{S4}\times \mathrm{S4}$ outside this
class. In particular, we describe pre-locally tabular bimodal logics with the
converse and universal modalities.

</details>


### [24] [Splitting Families, Reaping Families, and Families of Permutations Associated with Asymptotic Density](https://arxiv.org/abs/2506.21059)
*David Valderrama*

Main category: math.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We investigate several relations between cardinal characteristics of the
continuum related with the asymptotic density of the natural numbers and some
known cardinal invariants. Specifically, we study the cardinals of the form
$\mathfrak{s}_X$, $\mathfrak{r}_X$ and $\mathfrak{dd}_{X,Y}$ introduced in
arXiv:2304.09698 and arXiv:2410.21102, answering some questions raised in these
papers. In particular, we prove that $\mathfrak{s}_0=$ cov$(\mathcal{M})$ and
$\mathfrak{r}_0=$ non$(\mathcal{M})$. We also show that $\mathfrak{dd}_{\{r\},
\textsf{all}}=\mathfrak{dd}_{\{1/2\}, \textsf{all}}$ for all $r\in (0,1)$, and
we provide a proof of Con($\mathfrak{dd}_{(0,1),\{0,1\}}^{\textsf{rel}}<$
non$(\mathcal{N})$) and
Con($\mathfrak{dd}_{\textsf{all},\textsf{all}}^{\textsf{rel}}<$
non$(\mathcal{N})$).

</details>


### [25] [Polynomial fingerprinting for trees and formulas](https://arxiv.org/abs/2506.21114)
*Mihai Prunescu*

Main category: math.LO

TL;DR: 该论文提出了一种将形式化句子转换为2x2矩阵的方法，以支持零知识证明中的数学证明需求，通过多项式评估和随机场元素替换实现高效的证明步骤。


<details>
  <summary>Details</summary>
Motivation: 为了满足零知识证明中对数学证明的需求，特别是在形式化句子和证明步骤的高效计算上，论文探索了一种新的方法。

Method: 论文提出了一种将形式化句子转换为2x2矩阵的方法，矩阵包含多元多项式及其整数系数，通过随机有限域元素评估多项式，将证明转换为数值序列。

Result: 通过这种方法，证明步骤（如modus-ponens和替换）可以高效计算，且仅需从公理开始重新计算，派生公式的值可通过同态性质从祖先值推导。

Conclusion: 该方法为形式化句子和证明步骤的高效计算提供了一种可行方案，适用于零知识证明中的数学证明需求。

Abstract: To cater to the needs of (Zero Knowledge) proofs for (mathematical) proofs,
we describe a method to transform formal sentences in 2x2 - matrices over
multivariate polynomials with integer coefficients, such that usual proof-steps
like modus-ponens or the substitution are easy to compute from the matrices
corresponding to the terms or formulas used as arguments. By evaluating the
polynomial variables in random elements of a suitably chosen finite field, the
proof is replaced by a numeric sequence. Only the values corresponding to the
axioms have to be computed from scratch. The values corresponding to derived
formulas are computed from the values corresponding to their ancestors by
applying the homomorphic properties. On such sequences, various Zero Knowledge
methods can be applied.

</details>


<div id='math.RT'></div>

# math.RT [[Back]](#toc)

### [26] [On preservation of relative resolutions for poset representations](https://arxiv.org/abs/2506.21227)
*Toshitaka Aoki,Shunsuke Tada*

Main category: math.RT

TL;DR: 本文研究了Galois连接的一类特殊情况，即左伴随为全子偏序集的规范包含函数的情形，并探讨了其在多参数持久同调中的应用。


<details>
  <summary>Details</summary>
Motivation: Galois连接在数学中广泛存在，而在表示理论中，它通过Kan扩展自然地在偏序集的持久模块（表示）类别中诱导出四重伴随关系。本文旨在研究一类特殊的Galois连接及其在持久模块结构分析中的应用。

Method: 本文主要研究一类Galois连接，其左伴随为全子偏序集的规范包含函数，并引入“内系统”的概念及其对应的右伴随“地板函数”。通过构造，研究了“收缩函子”及其与“归纳函子”的伴随关系。

Result: 证明了这种伴随关系在有限可表示持久模块中也成立，并引入对齐内系统证明其归纳和收缩函子保持模块的区间可分解性。进一步分析了区间覆盖和分辨率，并计算了某些有限偏序集的区间分辨率全局维数。

Conclusion: 本研究揭示了Galois连接在多参数持久同调分析中的重要作用，特别是通过内系统和地板函数对模块结构的理解和计算提供了新的工具和视角。

Abstract: The concept of Galois connections (i.e., adjoint pairs between posets) is
ubiquitous in mathematics. In representation theory, it is interesting because
it naturally induces the adjoint quadruple between the categories of
persistence modules (representations) of the posets via Kan extensions. One of
central subjects in multiparameter persistent homology analysis is to
understand structures of persistence modules. In this paper, we mainly study a
class of Galois connections whose left adjoint is the canonical inclusion of a
full subposet. We refer to such a subposet as an interior system, with its
corresponding right adjoint given by the floor function. In the induced adjoint
quadruple, we call the left Kan extension along its floor function the
contraction functor. From its construction, it is left adjoint to the induction
functor. Under this setting, we firstly prove that this adjoint pair gives an
adjoint pair between finitely presentable persistence modules. Moreover, we
introduce a special class of interior systems called aligned interior systems,
and prove that both induction and contraction functors over them preserve
interval-decomposability of modules. Then, we use them to analyze interval
covers and resolutions. We also compute interval resolution global dimensions
for certain classes of finite posets.

</details>


### [27] [The spectrum of global representations for families of bounded rank and VI-modules](https://arxiv.org/abs/2506.21525)
*Miguel Barrero,Tobias Barthel,Luca Pol,Neil Strickland,Jordan Williamson*

Main category: math.RT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A global representation is a compatible collection of representations of the
outer automorphism groups of the finite groups belonging to a family
$\mathscr{U}$. These arise in classical representation theory, in the study of
representation stability, as well as in global homotopy theory. In this paper
we begin a systematic study of the derived category $\mathsf{D}(\mathscr{U};k)$
of global representations over fields $k$ of characteristic zero, from the
point-of-view of tensor-triangular geometry. We calculate its Balmer spectrum
for various infinite families of finite groups including elementary abelian
$p$-groups, cyclic groups, and finite abelian $p$-groups of bounded rank. We
then deduce that the Balmer spectrum associated to the family of finite abelian
$p$-groups has infinite Krull dimension and infinite Cantor--Bendixson rank,
illustrating the complex phenomena we encounter. As a concrete application, we
provide a complete tt-theoretic classification of finitely generated derived
VI-modules. Our proofs rely on subtle information about the growth behaviour of
global representations studied in a companion paper, as well as novel methods
from non-rigid tt-geometry.

</details>


### [28] [On some results of Harish-Chandra for representations of p-adic groups, extended to their central extensions](https://arxiv.org/abs/2506.21334)
*Volker Heiermann*

Main category: math.RT

TL;DR: 本文旨在完整证明Harish-Chandra关于p-adic群超尖表示抛物归纳不可约性与Harish-Chandra mu-函数解析行为之间联系的结果，并证明该证明在中心扩张情况下依然有效。


<details>
  <summary>Details</summary>
Motivation: 研究Harish-Chandra关于p-adic群超尖表示抛物归纳不可约性与mu-函数解析行为之间联系的未完全证明结果，并扩展到中心扩张的情境。

Method: 通过完整的证明过程，验证Harish-Chandra的结果，并扩展到中心扩展的情况。

Result: 证明了Harish-Chandra的结果在中心扩展情况下依然成立，为该理论提供了更广泛的适用性。

Conclusion: 本文不仅完成了Harish-Chandra结果的证明，还将其推广到中心扩张的情境，为相关领域的研究提供了新的工具和视角。

Abstract: The aim of this article is to give a complete proof of results of
Harish-Chandra linking the irreducibility of parabolic induction of a
supercuspidal representation of a p-adic group to the analytic behavior of the
mu-function of Harish-Chandra and to show that the proof remains valid in the
case of a central extension.

</details>


### [29] [Transitivity of mutation of $τ$-exceptional sequences in the $τ$-tilting finite case](https://arxiv.org/abs/2506.21372)
*Aslak B. Buan,Eric J. Hanson,Bethany R. Marsh*

Main category: math.RT

TL;DR: 证明了对于τ-倾斜有限代数，完全τ-例外序列的突变是传递的。


<details>
  <summary>Details</summary>
Motivation: 研究τ-例外序列在τ-倾斜有限代数中的传递性，以拓展对代数结构的理解。

Method: 通过数学证明，探讨了完全τ-例外序列在τ-倾斜有限代数中的突变传递性。

Result: 证明了完全τ-例外序列的突变在τ-倾斜有限代数中具有传递性。

Conclusion: 该研究为τ-倾斜有限代数的结构性质提供了新的理论支持。

Abstract: We prove that mutation of complete $\tau$-exceptional sequences is transitive
for $\tau$-tilting finite algebras.

</details>
