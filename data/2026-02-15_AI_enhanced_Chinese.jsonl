{"id": "2602.11315", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11315", "abs": "https://arxiv.org/abs/2602.11315", "authors": ["Oliver Biggar", "Christos Papadimitriou"], "title": "Computing stable limit cycles of learning in games", "comment": null, "summary": "Many well-studied learning dynamics, such as fictitious play and the replicator, are known to not converge in general $N$-player games. The simplest mode of non-convergence is cyclical or periodic behavior. Such cycles are fundamental objects, and have inspired a number of significant insights in the field, beginning with the pioneering work of Shapley (1964). However a central question remains unanswered: which cycles are stable under game dynamics? In this paper we give a complete and computational answer to this question for the two best-studied dynamics, fictitious play/best-response dynamics and the replicator dynamic. We show (1) that a periodic sequence of profiles is stable under one of these dynamics if and only it is stable under the other, and (2) we provide a polynomial-time spectral stability test to determine whether a given periodic sequence is stable under either dynamic. Finally, we give an entirely `structural' sufficient condition for stability: every cycle that is a sink equilibrium of the preference graph of the game is stable, and moreover it is an attractor of the replicator dynamic. This result generalizes the famous theorems of Shapley (1964) and Jordan (1993), and extends the frontier of recent work relating the preference graph to the replicator attractors.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86N\u4eba\u6e38\u620f\u4e2d\u5faa\u73af\u884c\u4e3a\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u865a\u6784\u535a\u5f08\u548c\u590d\u5236\u52a8\u6001\u7684\u7a33\u5b9a\u6027\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u7ed3\u6784\u5316\u7684\u5145\u5206\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u6e38\u620f\u52a8\u6001\u4e2d\u5faa\u73af\u884c\u4e3a\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u586b\u8865\u4e86\u6b64\u524dShapley\u548cJordan\u7814\u7a76\u4e2d\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf9\u865a\u6784\u535a\u5f08\u548c\u590d\u5236\u52a8\u6001\u7684\u5206\u6790\uff0c\u63d0\u4f9b\u591a\u9879\u5f0f\u65f6\u95f4\u7684\u8c31\u7a33\u5b9a\u6027\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u504f\u597d\u56fe\u7684\u7ed3\u6784\u5316\u6761\u4ef6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5468\u671f\u6027\u5e8f\u5217\u5728\u4e24\u79cd\u52a8\u6001\u4e0b\u7684\u7a33\u5b9a\u6027\u4e00\u81f4\uff0c\u4e14\u6240\u6709\u4f5c\u4e3a\u504f\u597d\u56fe\u6c47\u5e73\u8861\u7684\u5faa\u73af\u5747\u662f\u7a33\u5b9a\u7684\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6269\u5c55\u4e86Shapley\u548cJordan\u7684\u7ecf\u5178\u7406\u8bba\uff0c\u5e76\u4e3a\u6e38\u620f\u52a8\u6001\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u7ed3\u6784\u5316\u6761\u4ef6\u3002"}}
{"id": "2602.11330", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.11330", "abs": "https://arxiv.org/abs/2602.11330", "authors": ["Sushmita Gupta", "Pallavi Jain", "Sanjay Seetharaman", "Meirav Zehavi"], "title": "When agents choose bundles autonomously: guarantees beyond discrepancy", "comment": "40 pages; abstract shortened due to arXiv requirements", "summary": "We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent.\n  We prove that partitions where \\emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $\u0398(\\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time.\n  Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\\mathsf{PROP} - \\mathcal{O}{(\\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \\emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u65e8\u5728\u514b\u670d\u6e10\u8fdb\u9650\u5236\u7684$\u0398(\\sqrt{n})$\u5dee\u5f02\u969c\u788d\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u9879\u6539\u8fdb\u65b9\u6cd5\uff0c\u5305\u62ec\u5728\u7ebf\u5206\u914d\u548c\u7279\u5b9a\u4f30\u503c\u7c7b\u7684\u66f4\u5f3a\u4fdd\u8bc1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5728\u591a\u4e2a\u4ee3\u7406\u95f4\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u786e\u4fdd\u6bcf\u4e2a\u4ee3\u7406\u83b7\u5f97\u63a5\u8fd1\u5176\u6bd4\u4f8b\u4efd\u989d\u7684\u9ad8\u4ef7\u503c\u4fdd\u8bc1\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5728\u7ebf\u5206\u914d\u548c\u7279\u5b9a\u4f30\u503c\u7c7b\u7684\u9650\u5236\uff08\u5982\u516c\u5171\u7269\u54c1\u987a\u5e8f\u3001\u4ef7\u503c\u591a\u6837\u6027\u9650\u5236\u548c\u8d85\u56fe\u7ed3\u6784\uff09\uff0c\u8bbe\u8ba1\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u4ee5\u514b\u670d\u6e10\u8fdb\u9650\u5236\u7684\u5dee\u5f02\u969c\u788d\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7ebf\u5206\u914d\u65b9\u6cd5\u53ef\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u63d0\u4f9b\u81f3\u5c11$\\mathsf{PROP} - \\mathcal{O}{(\\log n)}$\u7684\u4ef7\u503c\u4fdd\u8bc1\uff0c\u5e76\u5728\u4e09\u79cd\u53d7\u9650\u4f30\u503c\u7c7b\u4e2d\u5b9e\u73b0\u66f4\u5f3a\u7684\u4e2a\u4f53\u4fdd\u8bc1\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u7279\u5b9a\u65b9\u6cd5\u548c\u9650\u5236\u6761\u4ef6\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u516c\u5e73\u5206\u914d\u4e2d\u7684\u4e2a\u4f53\u4ef7\u503c\u4fdd\u8bc1\uff0c\u6253\u7834\u4e86\u6e10\u8fdb\u5dee\u5f02\u969c\u788d\u7684\u9650\u5236\u3002"}}
{"id": "2602.11400", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11400", "abs": "https://arxiv.org/abs/2602.11400", "authors": ["Paula B\u00f6hm", "Robert Bredereck", "Till Fluschnik"], "title": "Maximizing Index Diversity in Committee Elections", "comment": "A short version was published in the proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "We introduce two models of multiwinner elections with approval preferences and labelled candidates that take the committee's diversity into account. One model aims to find a committee with maximal diversity given a scoring function (e.g. of a scoring-based voting rule) and a lower bound for the score to be respected. The second model seeks to maximize the diversity given a minimal satisfaction for each agent to be respected. To measure the diversity of a committee, we use multiple diversity indices used in ecology and introduce one new index. We define (desirable) properties of diversity indices, test the indices considered against these properties, and characterize the new index. We analyze the computational complexity of computing a committee for both models and scoring functions of well-known voting rules, and investigate the influence of weakening the score or satisfaction constraints on the diversity empirically.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e24\u79cd\u8003\u8651\u591a\u6837\u6027\u7684\u591a\u8d62\u9009\u4e3e\u6a21\u578b\uff0c\u5206\u522b\u901a\u8fc7\u6700\u5927\u5316\u591a\u6837\u6027\u548c\u6ee1\u8db3\u6700\u5c0f\u6ee1\u610f\u5ea6\u6765\u89e3\u51b3\u9009\u4e3e\u4e2d\u7684\u591a\u6837\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6837\u6027\u6307\u6570\u3002", "motivation": "\u89e3\u51b3\u591a\u8d62\u9009\u4e3e\u4e2d\u5bf9\u5019\u9009\u4eba\u591a\u6837\u6027\u7684\u9700\u6c42\uff0c\u7ed3\u5408\u751f\u6001\u5b66\u4e2d\u7684\u591a\u6837\u6027\u6307\u6570\u6765\u8861\u91cf\u59d4\u5458\u4f1a\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6a21\u578b\uff0c\u4e00\u79cd\u57fa\u4e8e\u8bc4\u5206\u51fd\u6570\u548c\u5206\u6570\u4e0b\u9650\u6700\u5927\u5316\u591a\u6837\u6027\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8e\u6700\u5c0f\u6ee1\u610f\u5ea6\u6700\u5927\u5316\u591a\u6837\u6027\uff1b\u540c\u65f6\u5f15\u5165\u65b0\u7684\u591a\u6837\u6027\u6307\u6570\u5e76\u5206\u6790\u5176\u6027\u8d28\u3002", "result": "\u5206\u6790\u4e86\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u524a\u5f31\u8bc4\u5206\u6216\u6ee1\u610f\u5ea6\u7ea6\u675f\u5bf9\u591a\u6837\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u548c\u591a\u6837\u6027\u6307\u6570\u6709\u6548\u89e3\u51b3\u4e86\u9009\u4e3e\u4e2d\u7684\u591a\u6837\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u91cf\u5316\u591a\u6837\u6027\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.11481", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11481", "abs": "https://arxiv.org/abs/2602.11481", "authors": ["Minda Li", "Bhaskar Krishnamachari"], "title": "Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris", "comment": null, "summary": "GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86GPT-5\u5728\u4f4e\u8d44\u6e90\u6216\u5c0f\u4f17\u8bed\u8a00\uff08\u5982Idris\uff09\u4e2d\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u63d0\u793a\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u5176\u8868\u73b0\u3002", "motivation": "GPT-5\u5728\u4e3b\u6d41\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\u3001C++\u3001Java\uff09\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5c0f\u4f17\u6216\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1GPT-5\u80fd\u5426\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u63d0\u793a\u7b56\u7565\u5728\u5c0f\u4f17\u8bed\u8a00Idris\u4e2d\u53d6\u5f97\u7c7b\u4f3c\u6548\u679c\u3002", "method": "\u7814\u7a76\u9996\u5148\u901a\u8fc7\u96f6\u6837\u672c\u63d0\u793a\u6d4b\u8bd5GPT-5\u5728Idris\u8bed\u8a00\u4e2d\u7684\u521d\u59cb\u8868\u73b0\uff0c\u968f\u540e\u8bc4\u4f30\u4e86\u591a\u79cd\u6539\u8fdb\u7b56\u7565\uff0c\u5305\u62ec\u57fa\u4e8e\u5e73\u53f0\u53cd\u9988\u7684\u8fed\u4ee3\u63d0\u793a\u3001\u589e\u52a0\u6587\u6863\u548c\u9519\u8bef\u5206\u7c7b\u6307\u5357\u7684\u63d0\u793a\uff0c\u4ee5\u53ca\u5229\u7528\u672c\u5730\u7f16\u8bd1\u9519\u8bef\u548c\u5931\u8d25\u6d4b\u8bd5\u6848\u4f8b\u7684\u8fed\u4ee3\u63d0\u793a\u3002", "result": "\u6700\u521d\u7684\u96f6\u6837\u672c\u63d0\u793a\u4e0b\uff0cGPT-5\u4ec5\u89e3\u51b3\u4e8656\u4e2aIdris\u7ec3\u4e60\u4e2d\u768422\u4e2a\uff1b\u800c\u901a\u8fc7\u5f15\u5165\u672c\u5730\u7f16\u8bd1\u9519\u8bef\u7684\u53cd\u9988\u5faa\u73af\uff0c\u5176\u8868\u73b0\u663e\u8457\u63d0\u5347\u81f354\u4e2a\u7ec3\u4e60\u7684\u6210\u529f\u89e3\u51b3\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u7ed3\u6784\u5316\u7684\u7f16\u8bd1\u5668\u7ea7\u522b\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u91ca\u653e\u5176\u6f5c\u529b\u3002"}}
{"id": "2602.11404", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.11404", "abs": "https://arxiv.org/abs/2602.11404", "authors": ["Ioannis Caragiannis", "Vasilis Gkatzelis", "Sebastian Homrighausen"], "title": "The Distortion of Prior-Independent b-Matching Mechanisms", "comment": null, "summary": "In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \\emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \\emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \\emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7269\u54c1\u5206\u914d\u95ee\u9898\u4e2d\u57fa\u4e8e\u4ee3\u7406\u5e8f\u6570\u504f\u597d\u7684\u673a\u5236\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u6700\u4f18\u5931\u771f\u5ea6\u548c\u5931\u771f\u5dee\u8ddd\u7684\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u6700\u574f\u60c5\u51b5\u5206\u6790\u5bfc\u81f4\u4e86\u5bf9\u5e8f\u6570\u673a\u5236\u6027\u80fd\u7684\u60b2\u89c2\u7ed3\u8bba\uff0c\u672c\u6587\u901a\u8fc7\u968f\u673a\u751f\u6210\u4ee3\u7406\u504f\u597d\u7684\u65b9\u5f0f\u8bc4\u4f30\u673a\u5236\u7684\u9884\u671f\u6027\u80fd\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u73b0\u5b9e\u7684\u6027\u80fd\u6307\u6807\u3002", "method": "\u672c\u6587\u9996\u5148\u8bc1\u660e\u4e86\u5e8f\u6570\u673a\u5236\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u6700\u4f18\u5931\u771f\u5ea6\u4e0b\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u8fbe\u5230\u6700\u4f18\u5931\u771f\u5ea6\u7684\u5e8f\u6570\u673a\u5236\uff0c\u5373\u4f7f\u4ee3\u7406\u7684\u504f\u597d\u5206\u5e03\u672a\u77e5\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u5177\u6709\u8fd1\u6700\u4f18\u5931\u771f\u5dee\u8ddd\u7684\u673a\u5236\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6700\u4f18\u5931\u771f\u5ea6\u4e3a$e/(e-1)\\approx 1.582$\uff0c\u63d0\u51fa\u7684\u673a\u5236\u80fd\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u4e14\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u5931\u771f\u5dee\u8ddd\u53ef\u4f18\u5316\u81f31.076\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u968f\u673a\u504f\u597d\u751f\u6210\u4e0b\u5e8f\u6570\u673a\u5236\u7684\u6027\u80fd\u6781\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u7684\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.11433", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.11433", "abs": "https://arxiv.org/abs/2602.11433", "authors": ["Pengfei Wang", "Jian Liu", "Qiujie Dong", "Shiqing Xin", "Yuanfeng Zhou", "Changhe Tu", "Caiming Zhang", "Wenping Wang"], "title": "Filmsticking++: Rapid Film Sticking for Explicit Surface Reconstruction", "comment": "15 pages, 15 figures", "summary": "Explicit surface reconstruction aims to generate a surface mesh that exactly interpolates a given point cloud. This requirement is crucial when the point cloud must lie non-negotiably on the final surface to preserve sharp features and fine geometric details. However, the task becomes substantially challenging with low-quality point clouds, due to inherent reconstruction ambiguities compounded by combinatorial complexity. A previous method using filmsticking technique by iteratively compute restricted Voronoi diagram to address these issues, ensures to produce a watertight manifold, setting a new benchmark as the state-of-the-art (SOTA) technique. Unfortunately, RVD-based filmsticking is inability to interpolate all points in the case of deep internal cavities, resulting in very likely is the generation of faulty topology. The cause of this issue is that RVD-based filmsticking has inherent limitations due to Euclidean distance metrics. In this paper, we extend the filmsticking technique, named Filmsticking++. Filmsticking++ reconstructing an explicit surface from points without normals. On one hand, Filmsticking++ break through the inherent limitations of Euclidean distance by employing a weighted-distance-based Restricted Power Diagram, which guarantees that all points are interpolated. On the other hand, we observe that as the guiding surface increasingly approximates the target shape, the external medial axis is gradually expelled outside the guiding surface. Building on this observation, we propose placing virtual sites inside the guiding surface to accelerate the expulsion of the external medial axis from its interior. To summarize, contrary to the SOTA method, Filmsticking++ demonstrates multiple benefits, including decreases computational cost, improved robustness and scalability.", "AI": {"tldr": "Filmsticking++\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u663e\u5f0f\u8868\u9762\u91cd\u5efa\u6280\u672f\uff0c\u901a\u8fc7\u52a0\u6743\u8ddd\u79bb\u9650\u5236\u529f\u7387\u56fe\u89e3\u51b3\u4e86\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u5185\u5728\u9650\u5236\uff0c\u786e\u4fdd\u6240\u6709\u70b9\u90fd\u80fd\u63d2\u503c\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u663e\u5f0f\u8868\u9762\u91cd\u5efa\u9700\u8981\u786e\u4fdd\u7ed9\u5b9a\u70b9\u4e91\u5b8c\u5168\u63d2\u503c\u5230\u6700\u7ec8\u8868\u9762\u4e0a\uff0c\u4f46\u5728\u4f4e\u8d28\u91cf\u70b9\u4e91\u60c5\u51b5\u4e0b\uff0c\u4efb\u52a1\u53d8\u5f97\u6781\u5177\u6311\u6218\u6027\u3002\u4f20\u7edfRVD-based filmsticking\u65b9\u6cd5\u5b58\u5728\u65e0\u6cd5\u63d2\u503c\u6240\u6709\u70b9\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u6df1\u5185\u90e8\u7a7a\u6d1e\u7684\u60c5\u51b5\u3002", "method": "Filmsticking++\u91c7\u7528\u4e86\u52a0\u6743\u8ddd\u79bb\u9650\u5236\u529f\u7387\u56fe\uff0c\u7a81\u7834\u4e86\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u9650\u5236\uff0c\u5e76\u901a\u8fc7\u5728\u5f15\u5bfc\u8868\u9762\u5185\u90e8\u653e\u7f6e\u865a\u62df\u7ad9\u70b9\u6765\u52a0\u901f\u5916\u90e8\u4e2d\u8f74\u7684\u6392\u51fa\u3002", "result": "Filmsticking++\u4e0d\u4ec5\u63d2\u503c\u4e86\u6240\u6709\u70b9\uff0c\u8fd8\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u7684SOTA\u65b9\u6cd5\u3002", "conclusion": "Filmsticking++\u901a\u8fc7\u521b\u65b0\u7684\u52a0\u6743\u8ddd\u79bb\u9650\u5236\u529f\u7387\u56fe\u548c\u865a\u62df\u7ad9\u70b9\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u663e\u5f0f\u8868\u9762\u91cd\u5efa\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11417", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11417", "abs": "https://arxiv.org/abs/2602.11417", "authors": ["Rashida Hakim", "Christos Papadimitriou", "Mihalis Yannakakis"], "title": "Fair Data-Exchange Mechanisms", "comment": "29 pages, 2 figures", "summary": "We study data exchange among strategic agents without monetary transfers, motivated by domains such as research consortia and healthcare collaborations where payments are infeasible or restricted. The central challenge is to reap the benefits of data-sharing while preventing free-riding that would otherwise lead agents to under invest in data collection. We introduce a simple fair-exchange contract in which, for every pair of agents, each agent receives exactly as many data points as it provides, equal to the minimum of their two collection levels. We show that the game induced by this contract is supermodular under a transformation of the strategy space. This results in a clean structure: pure Nash equilibria exist, they form a lattice, and can be computed in time quadratic in the number of agents. In addition, the maximal equilibrium is truthfully implementable under natural enforcement assumptions and is globally Pareto-optimal across all strategy profiles. In a graph-restricted variant of the model supermodularity fails, but an adaptation of the construction still yields efficiently computable pure Nash equilibria and Pareto-optimal outcomes. Overall, fair exchange provides a tractable and incentive-aligned mechanism for data exchange in the absence of payments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u8d27\u5e01\u8f6c\u79fb\u7684\u6218\u7565\u4ee3\u7406\u6570\u636e\u4ea4\u6362\u673a\u5236\uff0c\u901a\u8fc7\u516c\u5e73\u4ea4\u6362\u5408\u7ea6\u9632\u6b62\u642d\u4fbf\u8f66\u884c\u4e3a\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u6fc0\u52b1\u76f8\u5bb9\u7684\u6570\u636e\u5171\u4eab\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u7814\u7a76\u8054\u76df\u548c\u533b\u7597\u5408\u4f5c\u7b49\u9886\u57df\uff0c\u8fd9\u4e9b\u9886\u57df\u56e0\u652f\u4ed8\u4e0d\u53ef\u884c\u6216\u53d7\u9650\uff0c\u9700\u8981\u5728\u4e0d\u4f7f\u7528\u8d27\u5e01\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6570\u636e\u5171\u4eab\uff0c\u540c\u65f6\u907f\u514d\u4ee3\u7406\u7684\u642d\u4fbf\u8f66\u884c\u4e3a\u3002", "method": "\u65b9\u6cd5\u662f\u901a\u8fc7\u5f15\u5165\u516c\u5e73\u4ea4\u6362\u5408\u7ea6\uff0c\u8981\u6c42\u6bcf\u5bf9\u4ee3\u7406\u4ea4\u6362\u7684\u6570\u636e\u70b9\u6570\u91cf\u7b49\u4e8e\u4e24\u8005\u6536\u96c6\u6c34\u5e73\u7684\u6700\u5c0f\u503c\uff0c\u4ece\u800c\u8bf1\u5bfc\u6e38\u620f\u6210\u4e3a\u8d85\u6a21\u6e38\u620f\uff0c\u786e\u4fdd\u7eaf\u7eb3\u4ec0\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u53ef\u8ba1\u7b97\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u5408\u7ea6\u5728\u6e38\u620f\u7ed3\u6784\u4e0a\u5177\u6709\u8d85\u6a21\u6027\uff0c\u7eaf\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\u4e14\u6784\u6210\u683c\u7ed3\u6784\uff0c\u6700\u5927\u5747\u8861\u5728\u81ea\u7136\u6267\u884c\u5047\u8bbe\u4e0b\u53ef\u771f\u5b9e\u5b9e\u65bd\u4e14\u5168\u5c40\u5e15\u7d2f\u6258\u6700\u4f18\u3002\u5728\u56fe\u7684\u53d7\u9650\u6a21\u578b\u4e2d\uff0c\u867d\u7136\u8d85\u6a21\u6027\u5931\u6548\uff0c\u4f46\u8c03\u6574\u540e\u7684\u7ed3\u6784\u4ecd\u80fd\u9ad8\u6548\u8ba1\u7b97\u5747\u8861\u548c\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u3002", "conclusion": "\u7ed3\u8bba\u662f\u516c\u5e73\u4ea4\u6362\u5408\u7ea6\u5728\u65e0\u652f\u4ed8\u73af\u5883\u4e0b\u63d0\u4f9b\u4e86\u53ef\u8ba1\u7b97\u4e14\u6fc0\u52b1\u76f8\u5bb9\u7684\u6570\u636e\u5171\u4eab\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5171\u4eab\u7684\u6311\u6218\u3002"}}
{"id": "2602.11577", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.11577", "abs": "https://arxiv.org/abs/2602.11577", "authors": ["Chang Luo", "Nobuyuki Umetani"], "title": "LeafFit: Plant Assets Creation from 3D Gaussian Splatting", "comment": "Our source code is publicly available at https://github.com/netbeifeng/leaf_fit", "summary": "We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing.", "AI": {"tldr": "LeafFit\u662f\u4e00\u79cd\u5c063D\u9ad8\u65af\u55b7\u6d12\uff083DGS\uff09\u690d\u7269\u6a21\u578b\u8f6c\u6362\u4e3a\u53ef\u7f16\u8f91\u3001\u5b9e\u4f8b\u5316\u7f51\u683c\u8d44\u4ea7\u7684\u6d41\u6c34\u7ebf\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u6e38\u620f\u751f\u4ea7\u4e2d\u7684\u517c\u5bb9\u6027\u3002", "motivation": "3DGS\u867d\u7136\u80fd\u7cbe\u786e\u6355\u6349\u590d\u6742\u690d\u7269\u53f6\u7247\u7ed3\u6784\uff0c\u4f46\u5176\u9ad8\u5185\u5b58\u5360\u7528\u548c\u7f3a\u4e4f\u7f51\u683c\u62d3\u6251\u4f7f\u5176\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u4f20\u7edf\u6e38\u620f\u751f\u4ea7\u6d41\u7a0b\u3002LeafFit\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4ece\u65e0\u7ed3\u6784\u76843DGS\u4e2d\u5206\u5272\u53f6\u7247\uff0c\u9009\u62e9\u4ee3\u8868\u6027\u53f6\u7247\u7ec4\u4f5c\u4e3a\u6a21\u677f\uff0c\u5e76\u901a\u8fc7\u53ef\u5fae\u5206Moving Least Squares\uff08MLS\uff09\u53d8\u5f62\u5c06\u6a21\u677f\u62df\u5408\u5230\u5176\u4ed6\u53f6\u7247\u4e0a\u3002\u8fd0\u884c\u65f6\u901a\u8fc7\u9876\u70b9\u7740\u8272\u5668\u9ad8\u6548\u8ba1\u7b97\u53d8\u5f62\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLeafFit\u5728\u5206\u5272\u8d28\u91cf\u548c\u53d8\u5f62\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6570\u636e\u5927\u5c0f\u5e76\u652f\u6301\u53c2\u6570\u7ea7\u7f16\u8f91\u3002", "conclusion": "LeafFit\u6210\u529f\u5730\u5c063DGS\u8f6c\u6362\u4e3a\u9002\u5408\u6e38\u620f\u751f\u4ea7\u7684\u7f51\u683c\u8d44\u4ea7\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u7f16\u8f91\u7075\u6d3b\u6027\u3002"}}
{"id": "2602.11486", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11486", "abs": "https://arxiv.org/abs/2602.11486", "authors": ["Simina Br\u00e2nzei", "Reed Phillips"], "title": "Dueling over Multiple Pieces of Dessert", "comment": "52 pages, 6 figures", "summary": "We study the dynamics of repeated fair division between two players, Alice and Bob, where Alice partitions a cake into two subsets and Bob chooses his preferred one over $T$ rounds. Alice aims to minimize her regret relative to the Stackelberg value -- the maximum utility she could achieve if she knew Bob's private valuation.\n  We show that if Alice uses arbitrary measurable partitions, achieving strongly sublinear regret is impossible; she suffers a regret of $\u03a9\\Bigl(\\frac{T}{\\log^2 T}\\Bigr)$ regret even against a myopic Bob. However, when Alice uses at most $k$ cuts, the learning landscape becomes tractable. We analyze Alice's performance based on her knowledge of Bob's strategic sophistication (his regret budget). When Bob's learning rate is public, we establish a hierarchy of polynomial regret bounds determined by $k$ and Bob's regret budget. In contrast, when this learning rate is private, Alice can universally guarantee $O\\Bigl(\\frac{T}{\\log T}\\Bigr)$ regret, but any attempt to secure a polynomial rate $O(T^\u03b2)$ (for $\u03b2< 1$) leaves her vulnerable to incurring strictly linear regret against some Bob.\n  Finally, as a corollary of our online learning dynamics, we characterize the randomized query complexity of finding approximate Stackelberg allocations with a constant number of cuts in the Robertson-Webb model.", "AI": {"tldr": "\u7814\u7a76\u4e86Alice\u548cBob\u4e4b\u95f4\u5728\u591a\u8f6e\u516c\u5e73\u5206\u5272\u95ee\u9898\u4e2d\u7684\u52a8\u6001\u535a\u5f08\uff0c\u63a2\u8ba8\u4e86Alice\u5728\u6700\u5c0f\u5316\u540e\u6094\u503c\u548cBob\u7684\u7b56\u7565\u590d\u6742\u6027\u4e4b\u95f4\u5bfb\u627e\u5e73\u8861\u7684\u65b9\u6cd5\u53ca\u5176\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u7d22\u5728\u91cd\u590d\u516c\u5e73\u5206\u5272\u95ee\u9898\u4e2d\uff0cAlice\u5982\u4f55\u901a\u8fc7\u7b56\u7565\u6027\u5730\u5206\u5272\u8d44\u6e90\u548c\u5e94\u5bf9Bob\u7684\u4e0d\u540c\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u6700\u5c0f\u5316\u81ea\u5df1\u7684\u540e\u6094\u503c\uff0c\u5c24\u5176\u662f\u5728Bob\u7684\u4f30\u503c\u548c\u5b66\u4e60\u901f\u7387\u4e0d\u540c\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u5206\u6790Alice\u4f7f\u7528\u4e0d\u540c\u5206\u5272\u7b56\u7565\uff08\u5982\u4efb\u610f\u53ef\u6d4b\u5206\u5272\u6216\u6709\u9650\u5206\u5272\uff09\u65f6\u7684\u540e\u6094\u503c\uff0c\u4ee5\u53caBob\u7684\u5b66\u4e60\u901f\u7387\uff08\u516c\u5f00\u6216\u79c1\u6709\uff09\u5bf9Alice\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f53Alice\u4f7f\u7528\u4efb\u610f\u53ef\u6d4b\u5206\u5272\u65f6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5f3a\u6b21\u7ebf\u6027\u540e\u6094\u503c\uff1b\u800c\u5f53\u4f7f\u7528\u6709\u9650\u5206\u5272\u65f6\uff0c\u540e\u6094\u503c\u754c\u53ef\u7531Bob\u7684\u5b66\u4e60\u901f\u7387\u548c\u5206\u5272\u65b9\u5f0f\u51b3\u5b9a\u3002\u6b64\u5916\uff0c\u5f53Bob\u7684\u5b66\u4e60\u901f\u7387\u79c1\u6709\u65f6\uff0cAlice\u53ea\u80fd\u4fdd\u8bc1\u67d0\u79cd\u5f62\u5f0f\u7684\u540e\u6094\u503c\u754c\u9650\u3002", "conclusion": "\u7ed3\u8bba\u662fAlice\u7684\u7b56\u7565\u548c\u5b66\u4e60\u9c8d\u52c3\u7684\u52a8\u6001\u884c\u4e3a\u5bc6\u5207\u76f8\u5173\uff0c\u4e14\u5206\u5272\u65b9\u5f0f\u548cBob\u7684\u79c1\u6709\u4fe1\u606f\u5bf9\u540e\u6094\u503c\u7684\u754c\u9650\u6709\u663e\u8457\u5f71\u54cd\u3002\u540c\u65f6\uff0c\u8be5\u7814\u7a76\u8fd8\u4e3a\u8fd1\u4f3cStackelberg\u5206\u914d\u7684\u968f\u673a\u67e5\u8be2\u590d\u6742\u5ea6\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.11638", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11638", "abs": "https://arxiv.org/abs/2602.11638", "authors": ["Hao Qin", "Yukai Sun", "Meng Wang", "Ming Kong", "Mengxu Lu", "Qiang Zhu"], "title": "Variation-aware Flexible 3D Gaussian Editing", "comment": null, "summary": "Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.", "AI": {"tldr": "VF-Editor\u901a\u8fc7\u524d\u9988\u65b9\u5f0f\u9884\u6d4b\u9ad8\u65af\u57fa\u5143\u7684\u5c5e\u6027\u53d8\u5316\uff0c\u5b9e\u73b0\u4e863D\u9ad8\u65af\u55b7\u7ed8\u7684\u76f4\u63a5\u7f16\u8f91\uff0c\u89e3\u51b3\u4e86\u95f4\u63a5\u7f16\u8f91\u65b9\u6cd5\u7684\u89c6\u56fe\u4e0d\u4e00\u81f4\u6027\u548c\u7075\u6d3b\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u76843D\u9ad8\u65af\u55b7\u7ed8\u95f4\u63a5\u7f16\u8f91\u65b9\u6cd5\u57282D\u6e32\u67d3\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7f16\u8f91\u540e\u518d\u6295\u5f71\u56de3D\uff0c\u5bfc\u81f4\u89c6\u56fe\u4e0d\u4e00\u81f4\u6027\u548c\u7f16\u8f91\u7075\u6d3b\u6027\u53d7\u9650\u3002VF-Editor\u65e8\u5728\u901a\u8fc7\u76f4\u63a5\u7f16\u8f91\u9ad8\u65af\u57fa\u5143\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "VF-Editor\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u578b\u7684\u53d8\u5316\u9884\u6d4b\u5668\uff0c\u901a\u8fc7\u4ece2D\u7f16\u8f91\u77e5\u8bc6\u4e2d\u63d0\u70bc\u4fe1\u606f\uff0c\u751f\u6210\u53d8\u5316\u573a\uff0c\u5e76\u4f7f\u7528\u4e24\u4e2a\u53ef\u5b66\u4e60\u7684\u5e76\u884c\u89e3\u7801\u51fd\u6570\u8fed\u4ee3\u63a8\u65ad3D\u9ad8\u65af\u7684\u5c5e\u6027\u53d8\u5316\u3002", "result": "\u5728\u516c\u5171\u548c\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u514b\u670d\u4e86\u95f4\u63a5\u7f16\u8f91\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "VF-Editor\u901a\u8fc7\u7edf\u4e00\u7684\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u4ece\u591a\u68372D\u7f16\u8f91\u5668\u548c\u7b56\u7565\u52303D\u9886\u57df\u7684\u7075\u6d3b\u77e5\u8bc6\u8f6c\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8f91\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2602.11691", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11691", "abs": "https://arxiv.org/abs/2602.11691", "authors": ["Yiding Feng", "Mengfan Ma", "Bo Peng", "Zongqi Wan"], "title": "Searching for Optimal Prices in Two-Sided Markets", "comment": null, "summary": "We investigate online pricing in two-sided markets where a platform repeatedly posts prices based on binary accept/reject feedback to maximize gains-from-trade (GFT) or profit. We characterize the regret achievable across three mechanism classes: Single-Price, Two-Price, and Segmented-Price.\n  For profit maximization, we design an algorithm using Two-Price Mechanisms that achieves $O(n^2 \\log\\log T)$ regret, where $n$ is the number of traders.\n  For GFT maximization, the optimal regret depends critically on both market size and mechanism expressiveness. Constant regret is achievable in bilateral trade, but this guarantee breaks down as the market grows: even in a one-seller, two-buyer market, any algorithm using Single-Price Mechanisms suffers regret at least $\u03a9\\!\\big(\\frac{\\log\\log T}{\\log\\log\\log\\log T}\\big)$, and we provide a nearly matching $O(\\log\\log T)$ upper bound for general one-to-many markets. In full many-to-many markets, we prove that Two-Price Mechanisms inevitably incur linear regret $\u03a9(T)$ due to a \\emph{mismatch phenomenon}, wherein inefficient pairings prevent near-optimal trade. To overcome this barrier, we introduce \\emph{Segmented-Price Mechanisms}, which partition traders into groups and assign distinct prices per group. Using this richer mechanism, we design an algorithm achieving $O(n^2 \\log\\log T + n^3)$ regret for GFT maximization.\n  Finally, we extend our results to the contextual setting, where traders' costs and values depend linearly on observed $d$-dimensional features that vary across rounds, obtaining regret bounds of $O(n^2 d \\log\\log T + n^2 d \\log d)$ for profit and $O(n^2 d^2 \\log T)$ for GFT. Our work delineates sharp boundaries between learnable and unlearnable regimes in two-sided dynamic pricing and demonstrates how modest increases in pricing expressiveness can circumvent fundamental hardness barriers.", "AI": {"tldr": "\u7814\u7a76\u4e86\u53cc\u8fb9\u5e02\u573a\u4e2d\u5728\u7ebf\u5b9a\u4ef7\u95ee\u9898\uff0c\u901a\u8fc7\u4e8c\u5143\u53cd\u9988\u4f18\u5316\u6536\u76ca\u6216\u5229\u6da6\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u5b9a\u4ef7\u673a\u5236\u7684\u540e\u6094\u8fb9\u754c\uff0c\u5e76\u8bc1\u660e\u5206\u6bb5\u5b9a\u4ef7\u673a\u5236\u53ef\u7a81\u7834\u5b66\u4e60\u56f0\u96be\u3002", "motivation": "\u53cc\u8fb9\u5e02\u573a\u7684\u52a8\u6001\u5b9a\u4ef7\u5bf9\u5e73\u53f0\u6536\u76ca\u548c\u4ea4\u6613\u589e\u76ca\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u673a\u5236\u8868\u8fbe\u6027\u548c\u5e02\u573a\u6269\u5c55\u6027\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u4e9f\u9700\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u53cc\u4ef7\u673a\u5236\u548c\u5206\u6bb5\u5b9a\u4ef7\u673a\u5236\u7684\u7b97\u6cd5\uff0c\u5206\u522b\u4f18\u5316\u5229\u6da6\u548c\u4ea4\u6613\u589e\u76ca\uff0c\u5e76\u5728\u4e0d\u540c\u5e02\u573a\u89c4\u6a21\u548c\u60c5\u5883\u4e0b\u5206\u6790\u5176\u6709\u6548\u6027\u3002", "result": "\u5728\u5229\u6da6\u6700\u5927\u5316\u4e0a\u5b9e\u73b0\u4e86$O(n^2 \\log\\log T)$\u540e\u6094\u8fb9\u754c\uff1b\u4ea4\u6613\u589e\u76ca\u4f18\u5316\u4e2d\uff0c\u5206\u6bb5\u5b9a\u4ef7\u673a\u5236\u7a81\u7834\u4e86\u7ebf\u6027\u540e\u6094\u7684\u9650\u5236\uff0c\u8fbe\u5230\u4e86$O(n^2 \\log\\log T + n^3)$\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5b9a\u4ef7\u673a\u5236\u7684\u9002\u5ea6\u6269\u5c55\u53ef\u7a81\u7834\u5b66\u4e60\u56f0\u96be\uff0c\u4e3a\u53cc\u8fb9\u5e02\u573a\u52a8\u6001\u5b9a\u4ef7\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u7b97\u6cd5\u57fa\u7840\u3002"}}
{"id": "2602.11693", "categories": ["cs.GR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11693", "abs": "https://arxiv.org/abs/2602.11693", "authors": ["Zehao Xia", "Yiqun Wang", "Zhengda Lu", "Kai Liu", "Jun Xiao", "Peter Wonka"], "title": "OMEGA-Avatar: One-shot Modeling of 360\u00b0 Gaussian Avatars", "comment": "Project page: https://omega-avatar.github.io/OMEGA-Avatar/", "summary": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360\u00b0 full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360\u00b0-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360\u00b0 full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360\u00b0 consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360\u00b0 full-head completeness while robustly preserving identity across different viewpoints.", "AI": {"tldr": "OMEGA-Avatar\u662f\u4e00\u79cd\u524d\u9988\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u4ece\u5355\u5f20\u56fe\u50cf\u540c\u65f6\u751f\u6210\u53ef\u6cdb\u5316\u3001360\u00b0\u5b8c\u6574\u4e14\u53ef\u52a8\u753b\u76843D\u9ad8\u65af\u5934\u90e8\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u540c\u65f6\u6ee1\u8db3360\u00b0\u5168\u5934\u548c\u53ef\u52a8\u753b\u6027\u4e2d\u7684\u4e24\u70b9\uff0c\u800c\u65e0\u6cd5\u517c\u987e\u4e09\u70b9\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u4e86OMEGA-Avatar\u6765\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7f51\u683c\u53d8\u5f62\u6a21\u5757\u4f18\u5316\u5e26\u5934\u53d1\u7684FLAME\u5934\u90e8\uff0c\u5e76\u7ed3\u5408\u591a\u89c6\u89d2\u7279\u5f81\u55b7\u6e85\u6a21\u5757\u6784\u5efa\u5171\u4eab\u7684UV\u8868\u793a\uff0c\u786e\u4fdd360\u00b0\u4e00\u81f4\u6027\u548c\u9ad8\u9891\u7ec6\u8282\u3002", "result": "OMEGA-Avatar\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e0d\u4ec5\u5728360\u00b0\u5168\u5934\u5b8c\u6574\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8fd8\u80fd\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u4fdd\u6301\u8eab\u4efd\u4e00\u81f4\u6027\u3002", "conclusion": "OMEGA-Avatar\u662f\u9996\u4e2a\u540c\u65f6\u6ee1\u8db3\u524d\u9988\u6027\u3001360\u00b0\u5b8c\u6574\u6027\u548c\u53ef\u52a8\u753b\u6027\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u56fe\u50cf\u751f\u62103D\u5934\u50cf\u7684\u903c\u771f\u5ea6\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.11732", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11732", "abs": "https://arxiv.org/abs/2602.11732", "authors": ["Hannaneh Akrami", "Ryoga Mahara", "Kurt Mehlhorn", "Nidhi Rathi"], "title": "Achieving EF1 and Epistemic EFX Guarantees Simultaneously", "comment": null, "summary": "We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved.\n  In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5206\u914d\u4e2d\uff0c\u5982\u4f55\u540c\u65f6\u6ee1\u8db3EF1\u548cEEFX\u4e24\u79cd\u516c\u5e73\u6027\u6982\u5ff5\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u65b0\u6982\u5ff5\u2018strong EEFX share\u2019\uff0c\u8bc1\u660e\u4e86\u5728\u52a0\u6cd5\u4f30\u503c\u4e0b\u5b58\u5728\u540c\u65f6\u6ee1\u8db3\u4e24\u8005\u7684\u5206\u914d\u65b9\u6848\u3002", "motivation": "EFX\u7684\u5b58\u5728\u6027\u662f\u8be5\u9886\u57df\u6700\u91cd\u8981\u7684\u5f00\u653e\u95ee\u9898\u4e4b\u4e00\uff0c\u5c3d\u7ba1EF1\u548cEEFX\u5404\u81ea\u5df2\u88ab\u8bc1\u660e\u5b58\u5728\uff0c\u4f46\u80fd\u5426\u540c\u65f6\u6ee1\u8db3\u4e24\u8005\u4ecd\u672a\u89e3\u51b3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u516c\u5e73\u6027\u6982\u5ff5\u2018strong EEFX share\u2019\uff0c\u5b83\u9690\u542b\u4e86EEFX\u7684\u53ef\u884c\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e00\u6982\u5ff5\u4e0eEF1\u517c\u5bb9\u3002", "result": "\u8bba\u6587\u8bc1\u660e\u4e86\u5728\u52a0\u6cd5\u4f30\u503c\u4e0b\uff0c\u5b58\u5728\u4e00\u4e2a\u5206\u914d\u65b9\u6848\u540c\u65f6\u6ee1\u8db3EF1\uff08\u66f4\u4e25\u683c\u7684EFL\uff09\u548cEEFX\uff0c\u89e3\u51b3\u4e86Akrami\u548cRathi\u63d0\u51fa\u7684\u4e3b\u8981\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "\u8fd9\u4e00\u7814\u7a76\u4e0d\u4ec5\u89e3\u51b3\u4e86EF1\u548cEEFX\u7684\u540c\u65f6\u5b58\u5728\u6027\u95ee\u9898\uff0c\u8fd8\u5f15\u5165\u4e86\u65b0\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u4e3a\u6700\u7ec8\u89e3\u51b3EFX\u95ee\u9898\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2602.12105", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12105", "abs": "https://arxiv.org/abs/2602.12105", "authors": ["Ana Dodik", "Ahmed H. Mahmoud", "Justin Solomon"], "title": "Iskra: A System for Inverse Geometry Processing", "comment": null, "summary": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u51e0\u4f55\u5904\u7406\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u5fae\u5206\u7684\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u79cd\u51e0\u4f55\u7b97\u6cd5\uff0c\u5e76\u4e0e\u673a\u5668\u5b66\u4e60\u6846\u67b6\u517c\u5bb9\uff0c\u4e3a\u9006\u51e0\u4f55\u5904\u7406\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u51e0\u4f55\u5904\u7406\u7b97\u6cd5\u7684\u5fae\u5206\u5bf9\u4e8e\u9006\u51e0\u4f55\u5904\u7406\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u589e\u52a0\u4e86\u5b9e\u73b0\u96be\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u7ed3\u5408\u6563\u70b9-\u805a\u96c6\u65b9\u6cd5\u548c\u57fa\u4e8e\u5f20\u91cf\u7684\u5de5\u4f5c\u6d41\uff0c\u5229\u7528\u4f34\u968f\u65b9\u6cd5\u5bf9\u7528\u6237\u6307\u5b9a\u7684\u547d\u4ee4\u5f0f\u4ee3\u7801\u8fdb\u884c\u9ad8\u6548\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u901a\u8fc7\u5e73\u5747\u66f2\u7387\u6d41\u3001\u5149\u8c31\u5171\u5f62\u53c2\u6570\u5316\u7b49\u5e94\u7528\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6613\u7528\u6027\u548c\u9ad8\u6548\u6027\uff0c\u76f8\u8f83\u4e8e\u975e\u5b9a\u5236\u5316\u7684\u5fae\u5206\u4f18\u5316\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u5b9e\u73b0\u6210\u672c\u548c\u5185\u5b58\u9700\u6c42\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u51e0\u4f55\u5904\u7406\u7b97\u6cd5\u7684\u5fae\u5206\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b9e\u73b0\u96be\u5ea6\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2602.11835", "categories": ["cs.GT", "cs.MA", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.11835", "abs": "https://arxiv.org/abs/2602.11835", "authors": ["Yutong Chao", "Jalal Etesami"], "title": "Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition", "comment": "24 pages", "summary": "We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\\in\\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-\u0141ojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u4e00\u822c\u548c\u535a\u5f08\u4e2d\u5bfb\u627e\u7eb3\u4ec0\u5747\u8861\uff08NE\uff09\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6761\u4ef6\uff08n-sided PL\u6761\u4ef6\uff09\u4ee5\u5206\u6790\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u6807\u51c6\u65b9\u6cd5\u5931\u6548\u65f6\u7684\u6539\u8fdb\u7b97\u6cd5\u3002", "motivation": "\u5728\u4e00\u822c\u548c\u535a\u5f08\u4e2d\uff0c\u4f20\u7edf\u7684\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u6761\u4ef6\u548c\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165n-sided PL\u6761\u4ef6\uff0c\u6269\u5c55\u68af\u5ea6\u4f18\u52bf\u6761\u4ef6\uff08PL\u6761\u4ef6\uff09\u548c\u591a\u51f8\u6027\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u7684\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff08\u5982BCD\uff09\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6ee1\u8db3n-sided PL\u6761\u4ef6\u7684\u975e\u51f8\u51fd\u6570\u7c7b\u53ef\u4ee5\u88ab\u6709\u6548\u5206\u6790\uff0c\u4e14\u6539\u8fdb\u7b97\u6cd5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684n-sided PL\u6761\u4ef6\u548c\u6539\u8fdb\u7b97\u6cd5\u4e3a\u5206\u6790\u975e\u51f8\u51fd\u6570\u53ca\u5176\u6536\u655b\u6027\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.11857", "categories": ["cs.GT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.11857", "abs": "https://arxiv.org/abs/2602.11857", "authors": ["Taira Tsuchiya", "Haipeng Luo", "Shinji Ito"], "title": "Scale-Invariant Fast Convergence in Games", "comment": "44 pages", "summary": "Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\\tilde{O}(A_{\\mathrm{diff}})$, where $A_{\\mathrm{diff}}$ is the payoff range, which implies an $\\tilde{O}(A_{\\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\\mathrm{max}} \\log T)$, where $U_{\\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\\mathrm{max}} \\log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65e0\u9700\u6548\u7528\u5c3a\u5ea6\u5148\u9a8c\u77e5\u8bc6\u7684\u5c3a\u5ea6\u65e0\u5173\u4e14\u5c3a\u5ea6\u4e0d\u53d8\u7684\u52a8\u6001\u5b66\u4e60\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u4e8c\u4eba\u96f6\u548c\u535a\u5f08\u548c\u591a\u73a9\u5bb6\u4e00\u822c\u548c\u535a\u5f08\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\u6216\u76f8\u5173\u5747\u8861\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5b66\u4e60\u7b97\u6cd5\u5728\u535a\u5f08\u4e2d\u9700\u8981\u5148\u9a8c\u6548\u7528\u5c3a\u5ea6\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u5c3a\u5ea6\u65e0\u5173\u4e14\u5c3a\u5ea6\u4e0d\u53d8\u7684\u5b66\u4e60\u52a8\u6001\u3002", "method": "\u57fa\u4e8e\u4e50\u89c2\u8ddf\u968f\u6b63\u5219\u5316\u9886\u5bfc\u8005\uff08OFTRL\uff09\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u65b9\u6cd5\uff0c\u7ed3\u5408\u5bf9\u624b\u68af\u5ea6\u5411\u91cf\u7684\u5e73\u65b9\u8def\u5f84\u957f\u5ea6\uff0c\u4ee5\u53ca\u65b0\u7684\u505c\u6b62\u65f6\u95f4\u5206\u6790\u6280\u672f\u3002", "result": "\u5728\u4e8c\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u5b9e\u73b0\u4e86$\\tilde{O}(A_{\\mathrm{diff}} / T)$\u7684\u6536\u655b\u901f\u7387\uff1b\u5728\u591a\u73a9\u5bb6\u4e00\u822c\u548c\u535a\u5f08\u4e2d\u5b9e\u73b0\u4e86$O(U_{\\mathrm{max}} \\log T / T)$\u7684\u6536\u655b\u901f\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u5c3a\u5ea6\u65e0\u5173\u548c\u5c3a\u5ea6\u4e0d\u53d8\u7b97\u6cd5\u5728\u591a\u79cd\u535a\u5f08\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u655b\uff0c\u65e0\u9700\u5148\u9a8c\u6548\u7528\u4fe1\u606f\u3002"}}
{"id": "2602.11914", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11914", "abs": "https://arxiv.org/abs/2602.11914", "authors": ["Hanbing Liu", "Ningyuan Li", "Weian Li", "Qi Qi", "Changyuan Yu"], "title": "Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection", "comment": null, "summary": "Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5e26\u6709\u77ed\u540d\u5355\u548c\u622a\u6b62\u5206\u6570\u62ab\u9732\u7684\u6392\u540d\u7ade\u8d5b\uff0c\u5206\u6790\u4e86\u77ed\u540d\u5355\u53c2\u8d5b\u8005\u7684\u5747\u8861\u884c\u4e3a\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e24\u79cd\u76ee\u6807\u51fd\u6570\u4e0b\u7684\u6700\u4f18\u7ade\u8d5b\u5f62\u5f0f\u3002", "motivation": "\u77ed\u540d\u5355\u662f\u7ade\u8d5b\u4e2d\u5e38\u89c1\u7684\u9884\u9009\u65b9\u6cd5\uff0c\u4f46\u5982\u4f55\u786e\u4fdd\u516c\u5e73\u6027\u548c\u6700\u4f18\u8868\u73b0\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u672c\u6587\u63a2\u8ba8\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5efa\u6a21\u548c\u5206\u6790\uff0c\u7814\u7a76\u4e86\u77ed\u540d\u5355\u7ade\u8d5b\u4e2d\u7684\u5747\u8861\u884c\u4e3a\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e24\u79cd\u76ee\u6807\u51fd\u6570\uff08\u6700\u9ad8\u4e2a\u4f53\u8868\u73b0\u548c\u603b\u8868\u73b0\uff09\u4e0b\u7684\u6700\u4f18\u7ade\u8d5b\u5f62\u5f0f\u3002", "result": "\u5bf9\u4e8e\u6700\u9ad8\u4e2a\u4f53\u8868\u73b0\uff0c\u6700\u4f18\u77ed\u540d\u5355\u5927\u5c0f\u4e3a\u4e24\u4eba\uff1b\u800c\u5bf9\u4e8e\u603b\u8868\u73b0\uff0c\u77ed\u540d\u5355\u5927\u5c0f\u4e0d\u5f71\u54cd\u7ed3\u679c\u3002\u4e0e\u65e0\u77ed\u540d\u5355\u76f8\u6bd4\uff0c\u6700\u9ad8\u4e2a\u4f53\u8868\u73b0\u63d0\u9ad8\u4e864/3\u500d\u3002", "conclusion": "\u77ed\u540d\u5355\u7ade\u8d5b\u7684\u6700\u4f18\u5f62\u5f0f\u53d6\u51b3\u4e8e\u76ee\u6807\u51fd\u6570\uff0c\u6700\u9ad8\u4e2a\u4f53\u8868\u73b0\u7684\u6700\u4f18\u77ed\u540d\u5355\u5927\u5c0f\u4e3a\u4e24\u4eba\uff0c\u800c\u603b\u8868\u73b0\u4e0d\u53d7\u77ed\u540d\u5355\u5927\u5c0f\u5f71\u54cd\u3002"}}
{"id": "2602.11959", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11959", "abs": "https://arxiv.org/abs/2602.11959", "authors": ["Moshe Babaioff", "Yiding Feng", "Zihan Luo"], "title": "Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions", "comment": null, "summary": "The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the \"competition complexity\" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions.\n  First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \\approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\\leq n$, and any target fraction of the optimal revenue.\n  Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers.\n  Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.", "AI": {"tldr": "\u5728\u591a\u5355\u4f4d\u62cd\u5356\u4e2d\uff0c\u901a\u8fc7\u66f4\u5f3a\u7684\u5206\u5e03\u5047\u8bbe\u6216\u6539\u826f\u7684VCG\u62cd\u5356\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u4e3a\u5b9e\u73b0\uff08\u63a5\u8fd1\uff09\u6700\u4f18\u6536\u5165\u6240\u9700\u7684\u989d\u5916\u4e70\u5bb6\u6570\u91cf\u3002", "motivation": "Bulow\u548cKlemperer\uff081996\uff09\u7684\u7ecf\u5178\u7ed3\u679c\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\uff0cVCG\u62cd\u5356\u9700\u8981\u589e\u52a0m\u4e2a\u989d\u5916\u4e70\u5bb6\u624d\u80fd\u8fbe\u5230\u6700\u4f18\u6536\u5165\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u66f4\u5f3a\u7684\u5206\u5e03\u5047\u8bbe\u6216\u6539\u826f\u7684\u62cd\u5356\u673a\u5236\u4e0b\uff0c\u662f\u5426\u80fd\u51cf\u5c11\u8fd9\u4e00\u7ade\u4e89\u590d\u6742\u5ea6\u3002", "method": "\u9996\u5148\uff0c\u5728\u66f4\u5f3a\u7684\u5206\u5e03\u5047\u8bbe\uff08\u5982MHR\u5206\u5e03\uff09\u4e0b\uff0c\u8bc1\u660e\u4e86VCG\u62cd\u5356\u7684\u7ade\u4e89\u590d\u6742\u5ea6\u663e\u8457\u4e0b\u964d\uff1b\u5176\u6b21\uff0c\u5206\u6790\u4e86\u4e00\u79cd\u4f9b\u5e94\u9650\u5236\u7684VCG\u62cd\u5356\u53d8\u4f53\uff0c\u8be5\u53d8\u4f53\u901a\u8fc7\u9650\u5236\u552e\u5356\u5355\u4f4d\u6570\u91cf\u6765\u51cf\u5c11\u6240\u9700\u989d\u5916\u4e70\u5bb6\u3002", "result": "\u5728MHR\u5206\u5e03\u4e0b\uff0c\u989d\u5916\u4e70\u5bb6\u6570\u91cf\u53ef\u4ee5\u964d\u81f30.4447n\uff1b\u4f9b\u5e94\u9650\u5236\u7684VCG\u62cd\u5356\u53d8\u4f53\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u6240\u9700\u989d\u5916\u4e70\u5bb6\u6570\u91cf\u3002\u4e24\u79cd\u65b9\u6cd5\u5747\u663e\u8457\u964d\u4f4e\u4e86\u7ade\u4e89\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u66f4\u5f3a\u7684\u5206\u5e03\u5047\u8bbe\u548c\u6539\u826f\u7684\u62cd\u5356\u673a\u5236\uff0c\u6210\u529f\u964d\u4f4e\u4e86VCG\u62cd\u5356\u7684\u7ade\u4e89\u590d\u6742\u5ea6\uff0c\u4e3a\u5b9e\u73b0\u6700\u4f18\u6536\u5165\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.11967", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.11967", "abs": "https://arxiv.org/abs/2602.11967", "authors": ["Moshe Babaioff", "Sijin Chen", "Zhaohua Chen", "Yiding Feng"], "title": "Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare", "comment": null, "summary": "A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve.\n  Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.", "AI": {"tldr": "\u7814\u7a76\u4e86\u8d1d\u53f6\u65af\u5355\u7269\u54c1\u62cd\u5356\u4e2d\u771f\u5b9e\u673a\u5236\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63ed\u793a\u4e86\u5728\u72ec\u7acb\u540c\u5206\u5e03\u4e70\u5bb6\u4f30\u503c\u4e0b\u5e15\u7d2f\u6258\u6700\u4f18\u673a\u5236\u7684\u7ed3\u6784\uff0c\u5e76\u5206\u6790\u4e86\u4e24\u7c7b\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u63a2\u7a76\u8d1d\u53f6\u65af\u5355\u7269\u54c1\u62cd\u5356\u4e2d\u771f\u5b9e\u673a\u5236\u5982\u4f55\u5f71\u54cd\u5356\u5bb6\u548c\u4e70\u5bb6\u7684\u6548\u7528\u524d\u6cbf\uff0c\u7279\u522b\u662f\u5728\u72ec\u7acb\u540c\u5206\u5e03\u4f30\u503c\u5047\u8bbe\u4e0b\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5206\u6790\u548c\u5bf9\u5e15\u7d2f\u6258\u524d\u6cbf\u7684\u5b8c\u6574\u63cf\u8ff0\uff0c\u7814\u7a76\u4e86Kalai-Smorodinsky\u548cNash\u4e24\u7c7b\u89e3\u7684\u6027\u80fd\u3002", "result": "\u5728\u6b63\u5219\u548c\u53cdMHR\u5206\u5e03\u4e0b\uff0c\u4e24\u79cd\u89e3\u5728\u5927\u5e02\u573a\u4e2d\u8868\u73b0\u63a5\u8fd1\u6700\u4f18\uff1b\u4f46\u5728\u6700\u574fMHR\u5206\u5e03\u4e0b\uff0cKS\u89e3\u8868\u73b0\u7a33\u5065\uff0c\u800cNash\u89e3\u53ef\u80fd\u8868\u73b0\u6781\u5dee\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u516c\u5e73\u4e0e\u6548\u7387\u6743\u8861\u5bf9\u5206\u5e03\u7ed3\u6784\u7684\u654f\u611f\u6027\uff0c\u8bc1\u5b9eKS\u89e3\u5728\u975e\u5bf9\u79f0\u53cc\u8fb9\u5e02\u573a\u4e2d\u66f4\u5177\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.12089", "categories": ["cs.GT", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.12089", "abs": "https://arxiv.org/abs/2602.12089", "authors": ["Kehang Zhu", "Lithium Thain", "Vivian Tsai", "James Wexler", "Crystal Qian"], "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation", "comment": null, "summary": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5728\u7ebf\u884c\u4e3a\u5b9e\u9a8c\uff08N = 243\uff09\u63a2\u7d22AI\u4ee3\u7406\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u4ea4\u4e92\u6548\u679c\uff0c\u53d1\u73b0\u5c3d\u7ba1\u7528\u6237\u504f\u597d\u63a8\u8350\u578b\u5e2e\u52a9\uff0c\u4f46\u59d4\u6258\u578b\u4ee3\u7406\u80fd\u4e3a\u4e2a\u4f53\u548c\u7fa4\u4f53\u5e26\u6765\u66f4\u9ad8\u7684\u6548\u76ca\u3002", "motivation": "\u968f\u7740AI\u5728\u793e\u4ea4\u573a\u666f\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u7406\u89e3\u4ee3\u7406\u4e0e\u7528\u6237\u7684\u4ea4\u4e92\u5bf9\u8bbe\u8ba1\u63d0\u5347\u4e2a\u4f53\u548c\u7fa4\u4f53\u6548\u679c\u7684\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u53c2\u4e0e\u8005\u4ee5\u4e09\u4eba\u4e00\u7ec4\u7684\u5f62\u5f0f\u53c2\u4e0e\u591a\u8f6e\u8c08\u5224\u6e38\u620f\uff0c\u968f\u673a\u63a5\u89e6\u4e09\u79cdLLM\u534f\u52a9\u6a21\u5f0f\uff1a\u4e3b\u52a8\u63a8\u8350\u7684\u987e\u95ee\u3001\u88ab\u52a8\u53cd\u9988\u7684\u6559\u7ec3\u6216\u81ea\u4e3b\u6267\u884c\u7684\u59d4\u6258\u4ee3\u7406\u3002", "result": "\u5c3d\u7ba1\u7528\u6237\u66f4\u504f\u597d\u987e\u95ee\u6a21\u5f0f\uff0c\u4f46\u59d4\u6258\u4ee3\u7406\u5e26\u6765\u6700\u9ad8\u7684\u4e2a\u4f53\u6536\u76ca\uff0c\u5e76\u4ea7\u751f\u6b63\u5411\u5916\u90e8\u6548\u5e94\uff0c\u63d0\u5347\u975e\u4f7f\u7528\u8005\u7684\u4ea4\u6613\u8d28\u91cf\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4ee3\u7406\u80fd\u529b\u4e0e\u5b9e\u9645\u7fa4\u4f53\u6548\u76ca\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u8bbe\u8ba1\u517c\u5bb9\u7528\u6237\u91c7\u7eb3\u7684\u4ea4\u4e92\u673a\u5236\u662f\u63d0\u5347\u4eba\u7c7b\u798f\u7949\u7684\u5173\u952e\u3002"}}
{"id": "2602.12118", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.12118", "abs": "https://arxiv.org/abs/2602.12118", "authors": ["Johannes Brustle", "Paul Duetting", "Stefano Leonardi", "Tomasz Ponitka", "Matteo Russo"], "title": "Anonymous Contracts", "comment": "37 pages, 2 figures", "summary": "We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents.\n  We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees.\n  In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u5408\u540c\u95ee\u9898\uff0c\u5f15\u5165\u533f\u540d\u5408\u540c\u4ee5\u907f\u514d\u4e0d\u516c\u5e73\u611f\u77e5\uff0c\u5206\u6790\u4e86\u5176\u5747\u8861\u6027\u548c\u6548\u7387\u9650\u5236\u3002", "motivation": "\u5728\u591a\u4ee3\u7406\u5408\u540c\u4e2d\uff0c\u7406\u8bba\u4e0a\u7684\u6b67\u89c6\u6027\u5408\u540c\u53ef\u4ee5\u63d0\u53d6\u5168\u90e8\u793e\u4f1a\u798f\u5229\uff0c\u4f46\u53ef\u80fd\u88ab\u89c6\u4e3a\u4e0d\u516c\u5e73\uff0c\u56e0\u6b64\u63a2\u7d22\u533f\u540d\u5408\u540c\u7684\u53ef\u884c\u6027\u3002", "method": "\u5f15\u5165\u533f\u540d\u5408\u540c\uff0c\u652f\u4ed8\u4ec5\u53d6\u51b3\u4e8e\u603b\u6210\u529f\u6570\uff0c\u786e\u4fdd\u4ee3\u7406\u4eba\u7684\u516c\u5e73\u5f85\u9047\uff0c\u5e76\u5206\u6790\u5176\u5747\u8861\u6027\u548c\u6548\u7387\u9650\u5236\u3002", "result": "\u533f\u540d\u5408\u540c\u5b58\u5728\u7eaf\u7eb3\u4ec0\u5747\u8861\uff0c\u4f46\u53ef\u80fd\u6709\u591a\u91cd\u5747\u8861\uff1b\u7edf\u4e00\u533f\u540d\u5408\u540c\u4fdd\u8bc1\u552f\u4e00\u5747\u8861\u3002\u6548\u7387\u4e0a\uff0c\u533f\u540d\u5408\u540c\u5728\u6709\u9650\u8d23\u4efb\u4e0b\u65e0\u6cd5\u8fd1\u4f3c\u793e\u4f1a\u798f\u5229\u3002", "conclusion": "\u533f\u540d\u5408\u540c\u5728\u516c\u5e73\u6027\u4e0a\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u6548\u7387\u4e0a\u53d7\u9650\u4e8e\u6709\u9650\u8d23\u4efb\uff1b\u53d6\u6d88\u6709\u9650\u8d23\u4efb\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2602.12181", "categories": ["cs.GT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.12181", "abs": "https://arxiv.org/abs/2602.12181", "authors": ["Anas Barakat", "Ioannis Panageas", "Antonios Varvitsiotis"], "title": "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria", "comment": "AISTATS 2026", "summary": "Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5e7f\u4e49\u6548\u7528\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff08GUMGs\uff09\uff0c\u6269\u5c55\u4e86\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff08cMGs\uff09\u7684\u7406\u8bba\u6846\u67b6\uff0c\u586b\u8865\u4e86\u5176\u5728\u7eb3\u4ec0\u5747\u8861\u7ed3\u6784\u548c\u5b66\u4e60\u7b97\u6cd5\u4fdd\u8bc1\u65b9\u9762\u7684\u7a7a\u767d\u3002", "motivation": "\u51f8\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff08cMGs\uff09\u867d\u7136\u6269\u5c55\u4e86\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u5efa\u6a21\u8303\u56f4\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\uff0c\u5c24\u5176\u662f\u7eb3\u4ec0\u5747\u8861\u7ed3\u6784\u548c\u5b66\u4e60\u7b97\u6cd5\u7684\u4fdd\u8bc1\u5c1a\u672a\u5145\u5206\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u5e7f\u4e49\u6548\u7528\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff08GUMGs\uff09\uff0c\u5206\u6790\u4e86\u7eb3\u4ec0\u5747\u8861\u4e0e\u6295\u5f71\u4f2a\u68af\u5ea6\u52a8\u6001\u56fa\u5b9a\u70b9\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65e0\u6a21\u578b\u7684\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86GUMGs\u4e2d\u7eb3\u4ec0\u5747\u8861\u7684\u5b58\u5728\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7cbe\u786e\u68af\u5ea6\u548c\u751f\u6210\u6a21\u578b\u4e0b\u7684\u8fed\u4ee3\u590d\u6742\u5ea6\u548c\u6837\u672c\u590d\u6742\u5ea6\u8fb9\u754c\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u4e4b\u524d\u5c40\u9650\u4e8e\u96f6\u548ccMGs\u7684\u7814\u7a76\uff0c\u9996\u6b21\u5bf9\u5171\u540c\u5229\u76cacMGs\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2602.12224", "categories": ["cs.GT", "cs.AI", "econ.TH"], "pdf": "https://arxiv.org/pdf/2602.12224", "abs": "https://arxiv.org/abs/2602.12224", "authors": ["Amirmahdi Mirfakhar", "Xuchuang Wang", "Mengfan Xu", "Hedyeh Beyhaghi", "Mohammad Hajiesmaili"], "title": "Bandit Learning in Matching Markets with Interviews", "comment": null, "summary": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5e26\u6709\u9762\u8bd5\u7684\u5339\u914d\u5e02\u573a\u4e2d\u7684\u591a\u81c2\u8001\u864e\u673a\u5b66\u4e60\uff0c\u9762\u8bd5\u88ab\u89c6\u4e3a\u4f4e\u6210\u672c\u63d0\u793a\uff0c\u5e2e\u52a9\u53cc\u65b9\u83b7\u53d6\u90e8\u5206\u504f\u597d\u4fe1\u606f\uff0c\u5e76\u5141\u8bb8\u4f01\u4e1a\u6218\u7565\u6027\u5730\u5ef6\u8fdf\u62db\u8058\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u53cc\u8fb9\u5339\u914d\u5e02\u573a\u901a\u5e38\u9700\u8981\u53cc\u65b9\u5b8c\u5168\u660e\u786e\u7684\u504f\u597d\uff0c\u4f46\u5b9e\u8df5\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002\u901a\u8fc7\u9762\u8bd5\u83b7\u53d6\u65e9\u671f\u566a\u97f3\u4fe1\u606f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5728\u53cc\u65b9\u4e0d\u786e\u5b9a\u6027\u4e0b\u4f18\u5316\u5339\u914d\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5141\u8bb8\u4f01\u4e1a\u5728\u62db\u8058\u8fc7\u7a0b\u4e2d\u6218\u7565\u6027\u5ef6\u8fdf\uff0c\u4ee5\u7ea0\u6b63\u65e9\u671f\u9519\u8bef\uff1b\u8bbe\u8ba1\u4e86\u96c6\u4e2d\u5f0f\u548c\u5206\u6563\u5f0f\u7b97\u6cd5\uff0c\u5206\u522b\u8003\u8651\u4e86\u5168\u77e5\u9762\u8bd5\u5206\u914d\u5668\u548c\u4f01\u4e1a\u4fa7\u53cd\u9988\u3002", "result": "\u7b97\u6cd5\u5b9e\u73b0\u4e86\u65f6\u95f4\u65e0\u5173\u7684\u9057\u61be\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5339\u914d\u5b66\u4e60\u4e2d\u7684$O(\\log T)$\u9057\u61be\u754c\u9650\uff1b\u5728\u7ed3\u6784\u5316\u5e02\u573a\u4e2d\uff0c\u5206\u6563\u5f0f\u7b97\u6cd5\u6027\u80fd\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6218\u7565\u6027\u5ef6\u8fdf\u548c\u9762\u8bd5\u4fe1\u606f\u53ef\u4ee5\u6709\u6548\u652f\u6301\u5206\u6563\u5f0f\u5b66\u4e60\uff0c\u63d0\u5347\u5339\u914d\u5e02\u573a\u7684\u51b3\u7b56\u6548\u7387\uff0c\u5c24\u5176\u5728\u504f\u597d\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2602.12231", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.12231", "abs": "https://arxiv.org/abs/2602.12231", "authors": ["Robert Bredereck", "Bin Sun", "Eyal Briman", "Nimrod Talmon"], "title": "Adjusted Winner: from Splitting to Selling", "comment": null, "summary": "The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684Adjusted Winner\u65b9\u6cd5\uff0c\u901a\u8fc7\u5141\u8bb8\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u51fa\u552e\u9009\u5b9a\u8d44\u6e90\u5e76\u91cd\u65b0\u5206\u914d\u6536\u76ca\uff0c\u4ee5\u89e3\u51b3\u539f\u6709\u65b9\u6cd5\u4e2d\u8d44\u6e90\u5206\u5272\u5e26\u6765\u7684\u95ee\u9898\uff0c\u65e8\u5728\u5b9e\u73b0\u5c3d\u53ef\u80fd\u516c\u5e73\u7684\u5206\u914d\u3002", "motivation": "\u539f\u6709\u7684Adjusted Winner\u65b9\u6cd5\u5728\u5206\u914d\u4e0d\u53ef\u5206\u5272\u8d44\u6e90\u65f6\u4f9d\u8d56\u8d44\u6e90\u5206\u5272\uff0c\u53ef\u80fd\u5bfc\u81f4\u5b9e\u9645\u64cd\u4f5c\u4e2d\u7684\u56f0\u96be\u3002\u4e3a\u6b64\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u6269\u5c55\u4e86Adjusted Winner\u65b9\u6cd5\uff0c\u5f15\u5165\u8d44\u6e90\u51fa\u552e\u548c\u6536\u76ca\u518d\u5206\u914d\u7684\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u516c\u7406\u5316\u5206\u6790\u7814\u7a76\u516c\u5e73\u6027\u548c\u65e0\u5ac9\u5992\u6027\u7684\u53d8\u5316\u3002\u540c\u65f6\uff0c\u5b9a\u4e49\u4e86\u7ec4\u5408\u95ee\u9898\u5e76\u8bbe\u8ba1\u4e86FPTAS\u4ee5\u5e94\u5bf9\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u8bba\u6587\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u6269\u5c55\u65b9\u6cd5\u53ef\u4ee5\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u5206\u914d\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u673a\u6a21\u62df\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55Adjusted Winner\u65b9\u6cd5\u5e76\u5f15\u5165\u8d44\u6e90\u51fa\u552e\u673a\u5236\uff0c\u8bba\u6587\u89e3\u51b3\u4e86\u539f\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8df5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.12253", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.12253", "abs": "https://arxiv.org/abs/2602.12253", "authors": ["Yang Cai", "Haipeng Luo", "Chen-Yu Wei", "Weiqiang Zheng"], "title": "Is Online Linear Optimization Sufficient for Strategic Robustness?", "comment": "26 pages", "summary": "We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.\n  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\\sqrt{T \\log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\\sqrt{T (\\log K+\\log(T/\u03b4)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u91cd\u590d\u8d1d\u53f6\u65af\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u4e2d\u7684\u6295\u6807\u7b97\u6cd5\uff0c\u63d0\u51fa\u901a\u8fc7\u7b80\u5355\u7684\u5728\u7ebf\u7ebf\u6027\u4f18\u5316\uff08OLO\uff09\u7b97\u6cd5\u5b9e\u73b0\u7b56\u7565\u7a33\u5065\u6027\u548c\u65e0\u9057\u61be\u6295\u6807\u3002", "motivation": "\u73b0\u6709\u6700\u4f18\u9057\u61be\u6295\u6807\u7b97\u6cd5\u5bf9\u5356\u65b9\u7684\u7b56\u7565\u64cd\u7eb5\u7f3a\u4e4f\u8db3\u591f\u7a33\u5065\u6027\uff0c\u800c\u57fa\u4e8e\u65e0\u4ea4\u6362\u9057\u61be\u7684\u7b97\u6cd5\u867d\u80fd\u517c\u987e\u7a33\u5065\u6027\uff0c\u4f46\u5728\u7edf\u8ba1\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u7b80\u5355\u7684\u9ed1\u76d2\u5f52\u7ea6\u65b9\u6cd5\uff0c\u5c06\u4efb\u4f55OLO\u7b97\u6cd5\u8f6c\u5316\u4e3a\u7b56\u7565\u7a33\u5065\u7684\u65e0\u9057\u61be\u6295\u6807\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5df2\u77e5\u548c\u672a\u77e5\u4ef7\u503c\u5206\u5e03\u7684\u573a\u666f\u3002", "result": "\u5728\u5df2\u77e5\u4ef7\u503c\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u5b9e\u73b0\u4e86$O(\\sqrt{T \\log K})$\u7684\u9057\u61be\u548c\u7b56\u7565\u7a33\u5065\u6027\uff1b\u5728\u672a\u77e5\u5206\u5e03\u4e0b\uff0c\u53bb\u9664\u4e86\u5bc6\u5ea6\u6709\u754c\u5047\u8bbe\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6982\u7387\u7684$O(\\sqrt{T (\\log K+\\log(T/\\delta)})$\u9057\u61be\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u7684\u5728\u7ebf\u7ebf\u6027\u4f18\u5316\u7b97\u6cd5\u8db3\u4ee5\u5b9e\u73b0\u7b56\u7565\u7a33\u5065\u7684\u65e0\u9057\u61be\u6295\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7b97\u6cd5\u5728\u7a33\u5065\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u8868\u73b0\u3002"}}
