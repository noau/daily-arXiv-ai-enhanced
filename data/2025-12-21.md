<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [A Fast Volumetric Capture and Reconstruction Pipeline for Dynamic Point Clouds and Gaussian Splats](https://arxiv.org/abs/2512.15719)
*Athanasios Charisoudis,Simone Croci,Lam Kit Yung,Pascal Frossard,Aljosa Smolic*

Main category: cs.GR

TL;DR: 提出了一个快速高效的体积捕获与重建系统，支持RGB-D或RGB输入，生成点云和高斯溅射的3D表示，具有易部署和开源特点。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在非控制照明和任意背景下工作的体积捕获系统，支持灵活相机配置，以实现高质量3D重建。

Method: 采用改进的GPS-Gaussian回归器生成高斯溅射重建，支持RGB-D或RGB输入，系统设计易于部署并支持多种输出格式。

Result: 系统能以5-10 FPS实时预览输入和重建结果，支持标准格式导出，并通过定性和目标性消融研究验证其有效性。

Conclusion: 该系统提供了一个高效、易部署和开源的解决方案，适用于实际应用和进一步研究。

Abstract: We present a fast and efficient volumetric capture and reconstruction system that processes either RGB-D or RGB-only input to generate 3D representations in the form of point clouds and Gaussian splats. For Gaussian splat reconstructions, we took the GPS-Gaussian regressor and improved it, enabling high-quality reconstructions with minimal overhead. The system is designed for easy setup and deployment, supporting in-the-wild operation under uncontrolled illumination and arbitrary backgrounds, as well as flexible camera configurations, including sparse setups, arbitrary camera numbers and baselines. Captured data can be exported in standard formats such as PLY, MPEG V-PCC, and SPLAT, and visualized through a web-based viewer or Unity/Unreal plugins. A live on-location preview of both input and reconstruction is available at 5-10 FPS. We present qualitative findings focused on deployability and targeted ablations. The complete framework is open-source, facilitating reproducibility and further research.

</details>


### [2] [Enhancing Line Density Plots with Outlier Control and Bin-based Illumination](https://arxiv.org/abs/2512.16017)
*Yumeng Xue,Bin Chen,Patrick Paetzold,Yunhai Wang,Christophe Hurter,Oliver Deussen*

Main category: cs.GR

TL;DR: 提出了一种基于分箱的照明模型，用于处理线型数据集的密度图问题，通过解耦结构与密度，增强流线可视化和揭示稀疏异常值。


<details>
  <summary>Details</summary>
Motivation: 解决传统密度图在线型数据集（如轨迹或时间序列）中破坏路径连续性和掩盖平滑趋势及罕见异常值的问题。

Method: 引入基于分箱的异常度量方法，构建结构法线图，并在亮度通道中应用局部自适应照明，以突出主导趋势或异常路径。

Result: 在多个真实数据集上验证了该方法能够揭示简单方法遗漏的细节，颜色失真显著低于标准着色，并支持高达10,000条线的交互更新。

Conclusion: 该方法有效平衡了对主导趋势和异常值的可视化需求，提供了一种交互性强且颜色失真低的解决方案。

Abstract: Density plots effectively summarize large numbers of points, which would otherwise lead to severe overplotting in, for example, a scatter plot. However, when applied to line-based datasets, such as trajectories or time series, density plots alone are insufficient, as they disrupt path continuity, obscuring smooth trends and rare anomalies. We propose a bin-based illumination model that decouples structure from density to enhance flow and reveal sparse outliers while preserving the original colormap. We introduce a bin-based outlierness metric to rank trajectories. Guided by this ranking, we construct a structural normal map and apply locally-adaptive lighting in the luminance channel to highlight chosen patterns -- from dominant trends to atypical paths -- with acceptable color distortion. Our interactive method enables analysts to prioritize main trends, focus on outliers, or strike a balance between the two. We demonstrate our method on several real-world datasets, showing it reveals details missed by simpler alternatives, achieves significantly lower CIEDE2000 color distortion than standard shading, and supports interactive updates for up to 10,000 lines.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2512.15766)
*Yijie Zhi,Yayu Cao,Jianhua Dai,Xiaoyang Han,Jingwen Pu,Qingran Wu,Sheng Cheng,Ming Cai*

Main category: cs.PL

TL;DR: LOOPRAG是一个新颖的检索增强生成框架，旨在通过循环感知算法和反馈迭代机制指导LLMs在静态控制部分进行高效的循环优化。


<details>
  <summary>Details</summary>
Motivation: LLMs在循环变换优化中常出现错误或次优结果，导致性能改进机会的丧失。LOOPRAG旨在弥补这一差距。

Method: 提出了一种参数驱动的方法，结合循环特性触发变换，并通过基于反馈的迭代机制优化代码生成。

Result: 在PolyBench、TSVC和LORE基准测试中，LOOPRAG相比基础编译器和LLMs实现了显著的性能提升。

Conclusion: LOOPRAG通过创新的框架设计解决了LLMs在循环优化中的局限性，显著提升了性能。

Abstract: Loop transformations are semantics-preserving optimization techniques, widely used to maximize objectives such as parallelism. Despite decades of research, applying the optimal composition of loop transformations remains challenging due to inherent complexities, including cost modeling for optimization objectives. Recent studies have explored the potential of Large Language Models (LLMs) for code optimization. However, our key observation is that LLMs often struggle with effective loop transformation optimization, frequently leading to errors or suboptimal optimization, thereby missing opportunities for performance improvements. To bridge this gap, we propose LOOPRAG, a novel retrieval-augmented generation framework designed to guide LLMs in performing effective loop optimization on Static Control Part. We introduce a parameter-driven method to harness loop properties, which trigger various loop transformations, and generate diverse yet legal example codes serving as a demonstration source. To effectively obtain the most informative demonstrations, we propose a loop-aware algorithm based on loop features, which balances similarity and diversity for code retrieval. To enhance correct and efficient code generation, we introduce a feedback-based iterative mechanism that incorporates compilation, testing and performance results as feedback to guide LLMs. Each optimized code undergoes mutation, coverage and differential testing for equivalence checking. We evaluate LOOPRAG on PolyBench, TSVC and LORE benchmark suites, and compare it against compilers (GCC-Graphite, Clang-Polly, Perspective and ICX) and representative LLMs (DeepSeek and GPT-4). The results demonstrate average speedups over base compilers of up to 11.20$\times$, 14.34$\times$, and 9.29$\times$ for PolyBench, TSVC, and LORE, respectively, and speedups over base LLMs of up to 11.97$\times$, 5.61$\times$, and 11.59$\times$.

</details>


### [4] [Automated Formalization of Probabilistic Requirements from Structured Natural Language](https://arxiv.org/abs/2512.15788)
*Anastasia Mavridou,Marie Farrell,Gricel Vázquez,Tom Pressburger,Timothy E. Wang,Radu Calinescu,Michael Fisher*

Main category: cs.PL

TL;DR: NASA的FRET工具扩展支持结构化自然语言描述概率需求，并将其自动转换为概率时序逻辑公式，使自主和自适应系统的形式化分析更实用且低错误率。


<details>
  <summary>Details</summary>
Motivation: 在软件密集型系统中集成自主和自适应行为面临不确定性需求描述的挑战，尤其是在安全和关键任务系统中，需要严谨的需求捕获和分析。

Method: 扩展NASA的FRET工具，支持结构化自然语言描述概率需求，并开发自动化方法将其转换为概率时序逻辑公式，同时提供验证框架和形式化证明确保语义正确性。

Result: 开发了一个自动化工具，能够将结构化自然语言描述的概率需求转换为概率时序逻辑公式，并通过验证和证明确保其正确性。

Conclusion: 扩展后的FRET工具显著提升了概率需求的形式化分析能力，使其更实用且降低了错误率，适用于自主和自适应系统的开发。

Abstract: Integrating autonomous and adaptive behavior into software-intensive systems presents significant challenges for software development, as uncertainties in the environment or decision-making processes must be explicitly captured. These challenges are amplified in safety- and mission-critical systems, which must undergo rigorous scrutiny during design and development. Key among these challenges is the difficulty of specifying requirements that use probabilistic constructs to capture the uncertainty affecting these systems. To enable formal analysis, such requirements must be expressed in precise mathematical notations such as probabilistic logics. However, expecting developers to write requirements directly in complex formalisms is unrealistic and highly error-prone. We extend the structured natural language used by NASA's Formal Requirement Elicitation Tool (FRET) with support for the specification of unambiguous and correct probabilistic requirements, and develop an automated approach for translating these requirements into logical formulas. We propose and develop a formal, compositional, and automated approach for translating structured natural-language requirements into formulas in probabilistic temporal logic. To increase trust in our formalizations, we provide assurance that the generated formulas are well-formed and conform to the intended semantics through an automated validation framework and a formal proof. The extended FRET tool enables developers to specify probabilistic requirements in structured natural language, and to automatically translate them into probabilistic temporal logic, making the formal analysis of autonomous and adaptive systems more practical and less error-prone.

</details>


### [5] [A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning](https://arxiv.org/abs/2512.15816)
*Daragh King,Vasileios Koutavas,Laura Kovacs*

Main category: cs.PL

TL;DR: 论文提出了NeuroInv，一种结合神经符号方法生成循环不变量的新方法，使用LLM和Hoare逻辑，并通过符号验证模块修复不变量，在150个Java程序上达到99.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在生成循环不变量时缺乏可靠和结构化的方法，且忽略现有的程序验证理论。因此，论文提出NeuroInv以解决这一问题。

Method: NeuroInv包含两个模块：(1)神经推理模块，利用LLM和Hoare逻辑通过反向链式最弱前置条件推理生成和优化候选不变量；(2)符号验证模块，使用OpenJML的反例迭代修复不变量。

Result: 在150个Java程序的综合基准测试中，NeuroInv达到了99.5%的成功率，显著优于其他方法；在10个更大的多循环程序上也表现出色，展示了其可扩展性。

Conclusion: NeuroInv通过结合神经符号方法，成功解决了循环不变量生成的瓶颈问题，并在复杂验证场景中表现出强大的可扩展性。

Abstract: Loop invariant generation remains a critical bottleneck in automated program verification. Recent work has begun to explore the use of Large Language Models (LLMs) in this area, yet these approaches tend to lack a reliable and structured methodology, with little reference to existing program verification theory. This paper presents NeuroInv, a neurosymbolic approach to loop invariant generation. NeuroInv comprises two key modules: (1) a neural reasoning module that leverages LLMs and Hoare logic to derive and refine candidate invariants via backward-chaining weakest precondition reasoning, and (2) a verification-guided symbolic module that iteratively repairs invariants using counterexamples from OpenJML. We evaluate NeuroInv on a comprehensive benchmark of 150 Java programs, encompassing single and multiple (sequential) loops, multiple arrays, random branching, and noisy code segments. NeuroInv achieves a $99.5\%$ success rate, substantially outperforming the other evaluated approaches. Additionally, we introduce a hard benchmark of $10$ larger multi-loop programs (with an average of $7$ loops each); NeuroInv's performance in this setting demonstrates that it can scale to more complex verification scenarios.

</details>


### [6] [Optimizing Agentic Language Model Inference via Speculative Tool Calls](https://arxiv.org/abs/2512.15834)
*Daniel Nichols,Prajwal Singhania,Charles Jekel,Abhinav Bhatele,Harshitha Menon*

Main category: cs.PL

TL;DR: 提出了一种通过推测工具调用和优化推理引擎中的序列驻留来减少大型语言模型（LM）在推理过程中性能瓶颈的新系统优化方法，显著提升了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型（LMs）越来越依赖外部工具（如文件搜索、代码运行、API调用等），但这些工具也带来了推理过程中的性能瓶颈，亟需优化以提高效率。

Method: 通过推测工具调用并强制序列驻留在推理引擎中，以减少开销，并提出了一种新的“工具缓存”API端点以便于LM提供者采用这些优化。

Result: 优化后的系统实现了每秒数百令牌的吞吐量提升，并通过理论分析提供了最佳性能的推测配置建议。

Conclusion: 所提出的优化方法有效减少了LM推理过程中的性能瓶颈，显著提升了吞吐量，为LM提供者提供了易于采用的优化方案。

Abstract: Language models (LMs) are becoming increasingly dependent on external tools. LM-based agentic frameworks frequently interact with their environment via such tools to search files, run code, call APIs, etc. Further, modern reasoning-based LMs use tools such as web search and Python code execution to enhance their reasoning capabilities. While tools greatly improve the capabilities of LMs, they also introduce performance bottlenecks during the inference process. In this paper, we introduce novel systems optimizations to address such performance bottlenecks by speculating tool calls and forcing sequences to remain resident in the inference engine to minimize overheads. Our optimizations lead to throughput improvements of several hundred tokens per second when hosting inference for LM agents. We provide a theoretical analysis of our algorithms to provide insights into speculation configurations that will yield the best performance. Further, we recommend a new "tool cache" API endpoint to enable LM providers to easily adopt these optimizations.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Algorithmic Monetary Policies for Blockchain Participation Games](https://arxiv.org/abs/2512.16514)
*Diodato Ferraioli,Paolo Penna,Manvir Schneider,Carmine Ventre*

Main category: cs.GT

TL;DR: 论文提出了一种算法货币政策框架，用于在区块链通证经济中平衡短期性能激励与长期去中心化目标，分析了短期和长期视角下代理行为的均衡，并探讨了虚拟权益的作用。


<details>
  <summary>Details</summary>
Motivation: 区块链通证经济中的一个核心挑战是如何在短期性能激励和长期去中心化目标之间取得平衡。论文旨在通过算法货币政策框架解决这一问题。

Method: 设计了一个参与游戏的重复框架，代理根据类型和权益选择参与或放弃，政策（概率性）选择高类型代理执行任务以最大化吞吐量，同时分配奖励以维持去中心化。分析了短期和长期视角下代理行为的均衡。

Result: 研究发现，针对短期视角的代理，性能中心的政策可能导致中心化；而具有远见的代理行为可以实现稳定的去中心化，但伴随代币价值的波动。虚拟权益的初始分配对长期结果有重要影响。

Conclusion: 论文表明，政策需要间接管理去中心化，而虚拟权益作为一种混合方法，其初始分配对长期结果至关重要。

Abstract: A central challenge in blockchain tokenomics is aligning short-term performance incentives with long-term decentralization goals. We propose a framework for algorithmic monetary policies that navigates this tradeoff in repeated participation games. Agents, characterized by type (capability) and stake, choose to participate or abstain at each round; the policy (probabilistically) selects high-type agents for task execution (maximizing throughput) while distributing rewards to sustain decentralization. We analyze equilibria under two agent behaviors: myopic (short-term utility maximization) and foresighted (multi-round planning). For myopic agents, performance-centric policies risk centralization, but foresight enables stable decentralization with some volatility to the token value. We further discuss virtual stake--a hybrid of type and stake--as an alternative approach. We show that the initial virtual stake distribution critically impacts long-term outcomes, suggesting that policies must indirectly manage decentralization.

</details>


### [8] [Online Resource Allocation via Static Bundle Pricing](https://arxiv.org/abs/2512.16570)
*Dimitris Fotakis,Charalampos Platanos,Thanos Tolias*

Main category: cs.GT

TL;DR: 该论文研究了在线资源分配问题，提出了一种统一的静态捆绑定价机制，适用于三种互补性估值场景，并在性能和理论下限上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 在互补性估值环境中，现有的单件定价机制无法有效利用物品的多重性，而静态捆绑定价机制又依赖特定问题的参数，缺乏通用性。因此，需要开发一种通用的在线资源分配技术。

Method: 提出了一种统一的静态匿名捆绑定价机制，适用于三种场景：(i) 最大捆绑大小为$d$的单目标组合拍卖，(ii) 一般单目标组合拍卖，(iii) 基于图的路由模型。该机制的竞争性能随物品容量的增加呈指数级提升。

Result: 在$d$-单目标场景下，获得了$O(d^{1/B})$-竞争性能的机制；在一般单目标组合拍卖和图路由模型中，实现了$O(m^{1/(B+1)})$-竞争性能。同时，通过信息论下限证明了这些结果的紧性。

Conclusion: 论文提出的机制在互补性估值环境中表现出色，揭示了与极端组合问题之间的深刻联系，为在线资源分配领域提供了新的理论和技术支持。

Abstract: Online Resource Allocation addresses the problem of efficiently allocating limited resources to buyers with incomplete knowledge of future requests. In our setting, buyers arrive sequentially demanding a set of items, each with a value drawn from a known distribution. We study environments where buyers' valuations exhibit complementarities. In such settings, standard item-pricing mechanisms fail to leverage item multiplicities, while existing static bundle-pricing mechanisms rely on problem-specific arguments that do not generalize.
  We develop a unified technique for online resource allocation with complementarities for three domains: (i) single-minded combinatorial auctions with maximum bundle size $d$, (ii) general single-minded combinatorial auctions, and (iii) a graph-based routing model in which buyers request to route a unit of flow from a source node $s$ to a target node $t$ in a capacitated graph. Our approach yields static and anonymous bundle-pricing mechanisms whose performance improves exponentially with item capacities. For the $d$-single-minded setting with minimum item capacity $B$, we obtain an $O(d^{1/B})$-competitive mechanism, recovering the known $O(d)$ bound for unit capacities ($B=1$) and achieving exponentially better guarantees as capacities grow. For general single-minded combinatorial auctions and the graph-routing model, we obtain $O(m^{1/(B+1)})$-competitive mechanisms, where $m$ is the number of items.
  We complement these results with information-theoretic lower bounds. We show that no online algorithm can achieve a competitive ratio better than $Ω((m/\ln m)^{1/(B+2)})$ in the general single-minded setting and $Ω((d/\ln d)^{1/(B+1)})$ in the $d$-single-minded setting. In doing so, we reveal a deep connection to the extremal combinatorics problem of determining the maximum number of qualitatively independent partitions of a ground set.

</details>


### [9] [On the Edge of Core (Non-)Emptiness: An Automated Reasoning Approach to Approval-Based Multi-Winner Voting](https://arxiv.org/abs/2512.16895)
*Ratip Emin Berker,Emanuel Tewolde,Vincent Conitzer,Mingyu Guo,Marijn Heule,Lirong Xia*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Core stability is a natural and well-studied notion for group fairness in multi-winner voting, where the task is to select a committee from a pool of candidates. We study the setting where voters either approve or disapprove of each candidate; here, it remains a major open problem whether a core-stable committee always exists. In this work, we develop an approach based on mixed-integer linear programming for deciding whether and when core-stable committees are guaranteed to exist. In contrast to SAT-based approaches popular in computational social choice, our method can produce proofs for a specific number of candidates independent of the number of voters. In addition to these computational gains, our program lends itself to a novel duality-based reformulation of the core stability problem, from which we obtain new existence results in special cases. Further, we use our framework to reveal previously unknown relationships between core stability and other desirable properties, such as notions of priceability.

</details>
