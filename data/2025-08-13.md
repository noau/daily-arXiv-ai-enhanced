<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 11]
- [cs.GT](#cs.GT) [Total: 4]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Spatiotemporally Consistent Indoor Lighting Estimation with Diffusion Priors](https://arxiv.org/abs/2508.08384)
*Mutian Tong,Rundi Wu,Changxi Zheng*

Main category: cs.GR

TL;DR: 本文提出了一种从单张图像或视频中估计室内光照条件的方法，通过利用2D扩散先验优化MLP表示的光场，实现在真实场景中的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 室内光照估计因其高度不适定性而具有挑战性，尤其是在光照条件在空间和时间上变化的情况下。本文旨在解决这一问题。

Method: 利用2D扩散先验优化MLP表示的光场，并通过调整预训练的扩散模型在多位置预测光照，以联合修复多个镀铬球作为光探头。

Result: 在单张图像或视频的室内光照估计任务上表现优于基线方法，尤其是在真实视频中实现了时空一致的光照估计。

Conclusion: 本文方法在室内光照估计任务中表现出色，特别在真实视频中展现了时空一致性，超越了先前的工作。

Abstract: Indoor lighting estimation from a single image or video remains a challenge
due to its highly ill-posed nature, especially when the lighting condition of
the scene varies spatially and temporally. We propose a method that estimates
from an input video a continuous light field describing the spatiotemporally
varying lighting of the scene. We leverage 2D diffusion priors for optimizing
such light field represented as a MLP. To enable zero-shot generalization to
in-the-wild scenes, we fine-tune a pre-trained image diffusion model to predict
lighting at multiple locations by jointly inpainting multiple chrome balls as
light probes. We evaluate our method on indoor lighting estimation from a
single image or video and show superior performance over compared baselines.
Most importantly, we highlight results on spatiotemporally consistent lighting
estimation from in-the-wild videos, which is rarely demonstrated in previous
works.

</details>


### [2] [Improving Facial Rig Semantics for Tracking and Retargeting](https://arxiv.org/abs/2508.08429)
*Dalton Omens,Allise Thurman,Jihun Yu,Ronald Fedkiw*

Main category: cs.GR

TL;DR: 本文提出了一种通过使用相同的面部建模框架（如3DMM、FLAME等）来简化面部动作重定向的方法，并通过Simon-Says表达式校准和细调技术提高重定向效果。


<details>
  <summary>Details</summary>
Motivation: 解决面部动作重定向中因使用不同面部建模框架而导致的语义识别和重定向困难问题，并优化从真实人物到虚拟角色的面部动画控制。

Method: 采用相同的面部建模框架进行重定向，使用体积变形技术拟合面部模型，并通过Simon-Says表达式校准每个模型；提出基于隐式微分的方法细调跟踪器以生成更具语义意义的动画控制。

Result: 校准后的模型能够生成预期的表情动画，但在跟踪性能时仍可能出现不良控制；提出的细调方法显著提升了重定向的语义效果和实用性。

Conclusion: 通过标准化框架和细调技术，本研究实现了更高效的面部动作重定向，适用于从人物到人物的重定向以及人物到虚拟角色的场景。

Abstract: In this paper, we consider retargeting a tracked facial performance to either
another person or to a virtual character in a game or virtual reality (VR)
environment. We remove the difficulties associated with identifying and
retargeting the semantics of one rig framework to another by utilizing the same
framework (3DMM, FLAME, MetaHuman, etc.) for both subjects. Although this does
not constrain the choice of framework when retargeting from one person to
another, it does force the tracker to use the game/VR character rig when
retargeting to a game/VR character. We utilize volumetric morphing in order to
fit facial rigs to both performers and targets; in addition, a carefully chosen
set of Simon-Says expressions is used to calibrate each rig to the motion
signatures of the relevant performer or target. Although a uniform set of
Simon-Says expressions can likely be used for all person to person retargeting,
we argue that person to game/VR character retargeting benefits from Simon-Says
expressions that capture the distinct motion signature of the game/VR character
rig. The Simon-Says calibrated rigs tend to produce the desired expressions
when exercising animation controls (as expected). Unfortunately, these
well-calibrated rigs still lead to undesirable controls when tracking a
performance (a well-behaved function can have an arbitrarily ill-conditioned
inverse), even though they typically produce acceptable geometry
reconstructions. Thus, we propose a fine-tuning approach that modifies the rig
used by the tracker in order to promote the output of more semantically
meaningful animation controls, facilitating high efficacy retargeting. In order
to better address real-world scenarios, the fine-tuning relies on implicit
differentiation so that the tracker can be treated as a (potentially
non-differentiable) black box.

</details>


### [3] [Hybrid Long and Short Range Flows for Point Cloud Filtering](https://arxiv.org/abs/2508.08542)
*Dasith de Silva Edirimuni,Xuequan Lu,Ajmal Saeed Mian,Lei Wei,Gang Li,Scott Schaefer,Ying He*

Main category: cs.GR

TL;DR: 本文提出了一种混合点云滤波方法（HybridPF），结合短程和远程滤波轨迹，通过并行模块和动态图卷积解码器，有效去除噪声并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有点云滤波方法常存在点聚类或噪声残留问题，本文旨在通过结合短程和远程信息，提出一种更有效的点云去噪方法。

Method: 设计了并行模块ShortModule和LongModule，分别处理短程评分和远程流速信息，并通过联合损失函数进行端到端训练，同时引入动态图卷积解码器优化推理过程。

Result: 实验表明，HybridPF在点云去噪任务中实现了最先进的性能，同时提升了推理速度。

Conclusion: 结合短程和远程信息的混合滤波方法能够显著提升点云去噪效果，动态图卷积解码器进一步优化了推理效率。

Abstract: Point cloud capture processes are error-prone and introduce noisy artifacts
that necessitate filtering/denoising. Recent filtering methods often suffer
from point clustering or noise retaining issues. In this paper, we propose
Hybrid Point Cloud Filtering ($\textbf{HybridPF}$) that considers both
short-range and long-range filtering trajectories when removing noise. It is
well established that short range scores, given by $\nabla_{x}\log p(x_t)$, may
provide the necessary displacements to move noisy points to the underlying
clean surface. By contrast, long range velocity flows approximate constant
displacements directed from a high noise variant patch $x_0$ towards the
corresponding clean surface $x_1$. Here, noisy patches $x_t$ are viewed as
intermediate states between the high noise variant and the clean patches. Our
intuition is that long range information from velocity flow models can guide
the short range scores to align more closely with the clean points. In turn,
score models generally provide a quicker convergence to the clean surface.
Specifically, we devise two parallel modules, the ShortModule and LongModule,
each consisting of an Encoder-Decoder pair to respectively account for
short-range scores and long-range flows. We find that short-range scores,
guided by long-range features, yield filtered point clouds with good point
distributions and convergence near the clean surface. We design a joint loss
function to simultaneously train the ShortModule and LongModule, in an
end-to-end manner. Finally, we identify a key weakness in current displacement
based methods, limitations on the decoder architecture, and propose a dynamic
graph convolutional decoder to improve the inference process. Comprehensive
experiments demonstrate that our HybridPF achieves state-of-the-art results
while enabling faster inference speed.

</details>


### [4] [Revisiting the City Tower Project: Geometric Principles and Structural Morphology in the Works of Louis I. Kahn and Anne Tyng](https://arxiv.org/abs/2508.08561)
*Aysan Mokhtarimousavi,Michael Kleiss,Mostafa Alani,Sida Dai*

Main category: cs.GR

TL;DR: 本文研究了Louis Kahn City Tower项目的计算与形态学，分析了其基于四面体和八面体空间框架的几何结构，并探讨了其在模块化和适应性建筑设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于分析Louis Kahn和Anne Tyng未建成的City Tower项目的几何框架，揭示了其对空间框架结构设计的预见性，并探讨了其在现代建筑中的潜在应用。

Method: 研究采用了形状语法分析方法，首先重建了City Tower的原始结构，随后基于其几何形态生成了新的结构配置。

Result: 研究结果表明，四面体和八面体几何可以作为模块化和可扩展设计的基础，为建筑设计提供了新的可能性。

Conclusion: 结论指出，City Tower的几何框架及其衍生配置展示了适应性建筑设计的潜力，为未来的建筑创新提供了启示。

Abstract: This paper presents a study of computation and morphology of Louis Kahn City
Tower project. The City Tower is an unbuilt design by Louis I. Kahn and Anne
Tyng that integrates form and structure using 3D space triangular geometries.
Although never built, the City Tower geometrical framework anticipated later
developments in design of space-frame structures. Initially envisioned in the
1950s, the City Tower project is a skyscraper structure based on a tetrahedral
and octahedral space frame called Octet-Truss. The aim of this study is to
analyze the geometry of the City Tower structure and how it can be used to
develop modular and adaptable architectural forms. The study is based on an
analytical shape grammar that is used to recreate the original structure, and
later to generate new structural configurations based on the City Tower's
morphology. This study also investigates the potential applications of these
findings in architecture and reveals the possibilities of using tetrahedrons
and octahedrons as fundamental geometries for creating scalable and modular
designs and presents initial findings.

</details>


### [5] [Bio-Generative Design Morphology with Radiolaria: An application of a Nature-Based Generative Shape Grammar for Geometrical Design of Space Frames](https://arxiv.org/abs/2508.08572)
*Michael Kleiss,Seyedehaysan Mokhtarimousavi,Sida Dai,Mostafa Alani*

Main category: cs.GR

TL;DR: 该研究探讨了利用放射虫（Radiolaria）的几何结构作为基础，通过形状语法生成空间结构设计的方法，并展示了其潜在应用。


<details>
  <summary>Details</summary>
Motivation: 放射虫因其复杂的结构和几何图案在建筑设计中具有启发意义，研究旨在探索如何将其几何特征转化为空间结构设计的计算系统。

Method: 研究首先分析了放射虫的几何结构，并将其简化为四面体结构，结合八面体生成3D空间结构框架，进而开发生成形状语法。

Result: 研究成功开发了基于放射虫几何的形状语法，并生成了一系列空间结构配置，展示了在空间框架结构中的潜在应用。

Conclusion: 该研究通过放射虫的几何分析和形状语法开发，为3D空间结构设计提供了新的方法和潜在应用方向。

Abstract: This paper presents a study on using Radiolaria as a basis for generation of
space-based geometry for structural design with shape grammars. Radiolaria has
been a source of inspiration for architectural design with its intricate
structural features and geometric patterns (Lim, 2012). We use the basis of the
Radiolaria geometry to create a generative shape grammar as a computational
system; then use the shape grammar to create spatial configurations for
potential applications in design of 3D space structural frames. This study
begins with the geometric analysis of Radiolaria and the dissection of its
structure and geometry into a simplified morphological source, in this case a
tetrahedral structure. Tetrahedrons are used in combination with octahedrons to
generate spatial configurations to generate 3D spatial structural frames. The
paper presents the Radiolaria spatial analysis, the shape grammar, the
collection of generated designs, and possible applications in space frame
structures.

</details>


### [6] [Exploring Palette based Color Guidance in Diffusion Models](https://arxiv.org/abs/2508.08754)
*Qianru Qiu,Jiafeng Mao,Xueting Wang*

Main category: cs.GR

TL;DR: 本文提出了一种通过在扩散模型框架中引入调色板引导机制的新方法，以增强文本到图像生成中对整体色彩方案的控制。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在控制图像的整体色彩方案，尤其是背景元素和未明确提及对象的色彩时表现不佳，缺乏对色彩组合的全面控制。

Method: 提出了一种将调色板作为独立引导机制的方法，结合提示指令，探索了多种调色板表示方法，并构建了专门的调色板-文本-图像数据集进行实验。

Result: 实验表明，调色板引导显著提升了模型生成具有所需色彩方案图像的能力，实现了更可控和精细的色彩化过程。

Conclusion: 通过引入调色板引导机制，本文有效改进了文本到图像生成中对整体色彩方案的控制能力，为更精细的图像生成提供了新思路。

Abstract: With the advent of diffusion models, Text-to-Image (T2I) generation has seen
substantial advancements. Current T2I models allow users to specify object
colors using linguistic color names, and some methods aim to personalize
color-object association through prompt learning. However, existing models
struggle to provide comprehensive control over the color schemes of an entire
image, especially for background elements and less prominent objects not
explicitly mentioned in prompts. This paper proposes a novel approach to
enhance color scheme control by integrating color palettes as a separate
guidance mechanism alongside prompt instructions. We investigate the
effectiveness of palette guidance by exploring various palette representation
methods within a diffusion-based image colorization framework. To facilitate
this exploration, we construct specialized palette-text-image datasets and
conduct extensive quantitative and qualitative analyses. Our results
demonstrate that incorporating palette guidance significantly improves the
model's ability to generate images with desired color schemes, enabling a more
controlled and refined colorization process.

</details>


### [7] [Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination](https://arxiv.org/abs/2508.08826)
*Meng Gai,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 该论文提出了一种基于学习的屏幕空间漫反射间接光照预测方法，通过结合直接光照合成高动态范围结果，以解决神经网络处理长距离间接光照的挑战。


<details>
  <summary>Details</summary>
Motivation: 实时全局光照渲染对于虚拟环境中的用户体验至关重要，但神经网络在捕捉长距离间接光照方面存在挑战。论文旨在通过学习方法提供一种高效的解决方案。

Method: 提出了一种新型网络架构，采用改进的注意力机制聚合全局信息，并通过单色设计独立编码每个颜色通道，从而预测间接光照。

Result: 实验结果表明，该方法在处理复杂光照（如多色光照和环境光照）和捕捉远距离间接光照方面优于现有学习技术，并能有效处理训练数据中未出现过的新场景。

Conclusion: 该方法成功解决了长距离间接光照捕捉的难题，并在复杂光照和场景中展现出优越性能，为实时全局光照渲染提供了新的解决方案。

Abstract: Real-time rendering with global illumination is crucial to afford the user
realistic experience in virtual environments. We present a learning-based
estimator to predict diffuse indirect illumination in screen space, which then
is combined with direct illumination to synthesize globally-illuminated high
dynamic range (HDR) results. Our approach tackles the challenges of capturing
long-range/long-distance indirect illumination when employing neural networks
and is generalized to handle complex lighting and scenarios.
  From the neural network thinking of the solver to the rendering equation, we
present a novel network architecture to predict indirect illumination. Our
network is equipped with a modified attention mechanism that aggregates global
information guided by spacial geometry features, as well as a monochromatic
design that encodes each color channel individually.
  We conducted extensive evaluations, and the experimental results demonstrate
our superiority over previous learning-based techniques. Our approach excels at
handling complex lighting such as varying-colored lighting and environment
lighting. It can successfully capture distant indirect illumination and
simulates the interreflections between textured surfaces well (i.e., color
bleeding effects); it can also effectively handle new scenes that are not
present in the training dataset.

</details>


### [8] [DiffPhysCam: Differentiable Physics-Based Camera Simulation for Inverse Rendering and Embodied AI](https://arxiv.org/abs/2508.08831)
*Bo-Hsun Chen,Nevindu M. Batagoda,Dan Negrut*

Main category: cs.GR

TL;DR: DiffPhysCam是一种可微分的相机模拟器，旨在通过支持梯度优化来提升机器人和AI的视觉感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有的虚拟相机在控制内在设置、光学效果模拟和校准参数方面存在局限，影响了从模拟到现实的转换效果。DiffPhysCam旨在克服这些限制。

Method: DiffPhysCam采用多阶段流程，提供对相机设置的精细控制，模拟光学效果（如散焦模糊），并支持基于真实数据的校准。同时支持正向渲染和逆向渲染。

Result: 实验表明，DiffPhysCam提升了机器人感知性能，并在逆向渲染中成功创建了真实场景的数字孪生，模拟了多物理环境中的自主地面车辆导航。

Conclusion: DiffPhysCam通过提供全面的相机模拟和优化功能，为机器人和AI视觉任务提供了高效的工具。

Abstract: We introduce DiffPhysCam, a differentiable camera simulator designed to
support robotics and embodied AI applications by enabling gradient-based
optimization in visual perception pipelines. Generating synthetic images that
closely mimic those from real cameras is essential for training visual models
and enabling end-to-end visuomotor learning. Moreover, differentiable rendering
allows inverse reconstruction of real-world scenes as digital twins,
facilitating simulation-based robotics training. However, existing virtual
cameras offer limited control over intrinsic settings, poorly capture optical
artifacts, and lack tunable calibration parameters -- hindering sim-to-real
transfer. DiffPhysCam addresses these limitations through a multi-stage
pipeline that provides fine-grained control over camera settings, models key
optical effects such as defocus blur, and supports calibration with real-world
data. It enables both forward rendering for image synthesis and inverse
rendering for 3D scene reconstruction, including mesh and material texture
optimization. We show that DiffPhysCam enhances robotic perception performance
in synthetic image tasks. As an illustrative example, we create a digital twin
of a real-world scene using inverse rendering, simulate it in a multi-physics
environment, and demonstrate navigation of an autonomous ground vehicle using
images generated by DiffPhysCam.

</details>


### [9] [How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation](https://arxiv.org/abs/2508.08930)
*Juyeong Hwang,Seong-Eun Hon,JaeYoung Seon,Hyeongyeop Kang*

Main category: cs.GR

TL;DR: 论文介绍了一种名为SCORE的符号认知推理框架，用于生成虚拟代理的自然头部旋转行为，通过分析人类头部运动的五种动机驱动因素，并结合视觉语言模型和大语言模型，实现了上下文感知的头部运动。


<details>
  <summary>Details</summary>
Motivation: 当前头部旋转预测算法主要关注视觉显着刺激，忽略了认知动机，导致虚拟代理行为不真实。为了解决这一问题，论文提出了一种能模拟人类头部运动动机的框架。

Method: SCORE框架通过视觉语言模型感知场景，并结合大语言模型规划头部姿态。采用离线推理和在线验证的混合工作流，确保生成的头部运动既符合上下文又保持实时响应。

Result: 通过虚拟现实实验验证，SCORE能够模拟五种动机驱动的头部运动（兴趣、信息寻求、安全、社会习惯和习惯），并在未见过的新场景和多代理群体中保持行为合理性。

Conclusion: SCORE框架为虚拟代理的头部运动提供了一种无需任务特定训练或手动调整的解决方案，显著提升了虚拟环境中的行为和交互的真实性。

Abstract: Natural head rotation is critical for believable embodied virtual agents, yet
this micro-level behavior remains largely underexplored. While head-rotation
prediction algorithms could, in principle, reproduce this behavior, they
typically focus on visually salient stimuli and overlook the cognitive motives
that guide head rotation. This yields agents that look at conspicuous objects
while overlooking obstacles or task-relevant cues, diminishing realism in a
virtual environment. We introduce SCORE, a Symbolic Cognitive Reasoning
framework for Embodied Head Rotation, a data-agnostic framework that produces
context-aware head movements without task-specific training or hand-tuned
heuristics. A controlled VR study (N=20) identifies five motivational drivers
of human head movements: Interest, Information Seeking, Safety, Social Schema,
and Habit. SCORE encodes these drivers as symbolic predicates, perceives the
scene with a Vision-Language Model (VLM), and plans head poses with a Large
Language Model (LLM). The framework employs a hybrid workflow: the VLM-LLM
reasoning is executed offline, after which a lightweight FastVLM performs
online validation to suppress hallucinations while maintaining responsiveness
to scene dynamics. The result is an agent that predicts not only where to look
but also why, generalizing to unseen scenes and multi-agent crowds while
retaining behavioral plausibility.

</details>


### [10] [VertexRegen: Mesh Generation with Continuous Level of Detail](https://arxiv.org/abs/2508.09062)
*Xiang Zhang,Yawar Siddiqui,Armen Avetisyan,Chris Xie,Jakob Engel,Henry Howard-Jenkins*

Main category: cs.GR

TL;DR: VertexRegen是一种新型的网格生成框架，支持连续细节级别的生成，通过逆向边缘折叠（顶点分裂）学习生成模型，实现随时停止生成并输出有效网格。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归方法以部分到完整的方式生成网格，中间步骤代表不完整结构，无法灵活控制细节级别。VertexRegen的目标是克服这一限制。

Method: VertexRegen受渐进网格启发，将生成过程重新定义为通过生成模型学习的逆向边缘折叠（顶点分裂）。

Result: 实验结果表明，VertexRegen生成的网格质量与最先进方法相当，同时具有随时生成和灵活停止的优势。

Conclusion: VertexRegen通过顶点分裂实现了连续细节级别的网格生成，为网格生成提供了更高的灵活性和实用性。

Abstract: We introduce VertexRegen, a novel mesh generation framework that enables
generation at a continuous level of detail. Existing autoregressive methods
generate meshes in a partial-to-complete manner and thus intermediate steps of
generation represent incomplete structures. VertexRegen takes inspiration from
progressive meshes and reformulates the process as the reversal of edge
collapse, i.e. vertex split, learned through a generative model. Experimental
results demonstrate that VertexRegen produces meshes of comparable quality to
state-of-the-art methods while uniquely offering anytime generation with the
flexibility to halt at any step to yield valid meshes with varying levels of
detail.

</details>


### [11] [Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer](https://arxiv.org/abs/2508.09131)
*Zixin Yin,Xili Dai,Ling-Hao Chen,Deyu Zhou,Jianan Wang,Duomin Wang,Gang Yu,Lionel M. Ni,Heung-Yeung Shum*

Main category: cs.GR

TL;DR: ColorCtrl是一种无需训练的颜色编辑方法，利用多模态扩散变换器的注意力机制，实现了对图像和视频中颜色的精确编辑，同时保持物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的无需训练的颜色编辑方法在精确控制颜色和保持视觉一致性方面表现不佳，尤其是在编辑和非编辑区域之间容易产生不一致。

Method: ColorCtrl通过解构结构和颜色，并定向操作注意力图和值标记，利用多模态扩散变换器的注意力机制，实现了准确的区域化颜色编辑。

Result: ColorCtrl在SD3和FLUX.1-dev上的实验表明其优于现有方法，并在编辑质量和一致性方面达到最新水平，甚至超过了FLUX.1 Kontext Max和GPT-4o等商业模型。

Conclusion: ColorCtrl不仅在图像和视频编辑中表现出色，还能扩展到基于指令的编辑扩散模型，展现了其广泛的适用性和优势。

Abstract: Text-guided color editing in images and videos is a fundamental yet unsolved
problem, requiring fine-grained manipulation of color attributes, including
albedo, light source color, and ambient lighting, while preserving physical
consistency in geometry, material properties, and light-matter interactions.
Existing training-free methods offer broad applicability across editing tasks
but struggle with precise color control and often introduce visual
inconsistency in both edited and non-edited regions. In this work, we present
ColorCtrl, a training-free color editing method that leverages the attention
mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By
disentangling structure and color through targeted manipulation of attention
maps and value tokens, our method enables accurate and consistent color
editing, along with word-level control of attribute intensity. Our method
modifies only the intended regions specified by the prompt, leaving unrelated
areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate
that ColorCtrl outperforms existing training-free approaches and achieves
state-of-the-art performances in both edit quality and consistency.
Furthermore, our method surpasses strong commercial models such as FLUX.1
Kontext Max and GPT-4o Image Generation in terms of consistency. When extended
to video models like CogVideoX, our approach exhibits greater advantages,
particularly in maintaining temporal coherence and editing stability. Finally,
our method also generalizes to instruction-based editing diffusion models such
as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [12] [Convergent Q-Learning for Infinite-Horizon General-Sum Markov Games through Behavioral Economics](https://arxiv.org/abs/2508.08669)
*Yizhou Zhang,Eric Mazumdar*

Main category: cs.GT

TL;DR: 该论文研究了风险规避量化响应均衡（RQE）在两人一般形式博弈和无限视界马尔可夫博弈中的计算问题，提出了一种基于单调性的方法，并在无限视界马尔可夫博弈中定义了风险规避量化响应Bellman算子，证明了其收敛性。


<details>
  <summary>Details</summary>
Motivation: 风险规避和有限理性是人类决策的两个关键特征，RQE作为一种解决方案概念，比纳什均衡更能真实地反映人类在各种战略环境中的决策行为。论文旨在扩展对RQE的研究，并分析其在不同博弈模型中的计算问题。

Method: 在一般形式博弈中，采用基于单调性的方法；在无限视界马尔可夫博弈中，定义了风险规避量化响应Bellman算子，并在特定条件下证明其收敛性。

Result: 证明了一般形式博弈中RQE的唯一性和Lipschitz连续性；在无限视界马尔可夫博弈中，证明了风险规避量化响应Bellman算子的收敛性，并提出了一种具有收敛保证的Q学习算法。

Conclusion: 该研究扩展了对RQE的理解，并提供了在多种博弈模型中计算RQE的有效方法，尤其在无限视界马尔可夫博弈中提出的算法具有重要的理论和实践意义。

Abstract: Risk-aversion and bounded rationality are two key characteristics of human
decision-making. Risk-averse quantal-response equilibrium (RQE) is a solution
concept that incorporates these features, providing a more realistic depiction
of human decision making in various strategic environments compared to a Nash
equilibrium. Furthermore a class of RQE has recently been shown in
arXiv:2406.14156 to be universally computationally tractable in all
finite-horizon Markov games, allowing for the development of multi-agent
reinforcement learning algorithms with convergence guarantees. In this paper,
we expand upon the study of RQE and analyze their computation in both
two-player normal form games and discounted infinite-horizon Markov games. For
normal form games we adopt a monotonicity-based approach allowing us to
generalize previous results. We first show uniqueness and Lipschitz continuity
of RQE with respect to player's payoff matrices under monotonicity assumptions,
and then provide conditions on the players' degrees of risk aversion and
bounded rationality that ensure monotonicity. We then focus on discounted
infinite-horizon Markov games. We define the risk-averse quantal-response
Bellman operator and prove its contraction under further conditions on the
players' risk-aversion, bounded rationality, and temporal discounting. This
yields a Q-learning based algorithm with convergence guarantees for all
infinite-horizon general-sum Markov games.

</details>


### [13] [How to Resolve Envy by Adding Goods](https://arxiv.org/abs/2508.08682)
*Matthias Bentert,Robert Bredereck,Eva Deltl,Pallavi Jain,Leon Kellerhals*

Main category: cs.GT

TL;DR: 论文研究了通过从物品池中添加物品来解决初始分配中的嫉妒问题，提供了在物品池中添加任意数量副本时可解决嫉妒的实例的特征，并推导了多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过添加物品来解决分配中的嫉妒问题，探讨在物品池中无限或有限添加物品时的计算复杂性和可行性。

Method: 通过特征化实例，推导出多项式时间算法，并在参数化复杂度分析中关注代理数量和物品池大小作为参数。

Result: 在物品池中无限添加物品时，存在多项式时间算法解决问题；但在副本数量或添加物品总数有限时，问题计算困难。

Conclusion: 尽管并非所有实例都能无嫉妒解决，但论文提出的方法能高效判断解的存在性，具有理论和实际意义。

Abstract: We consider the problem of resolving the envy of a given initial allocation
by adding elements from a pool of goods. We give a characterization of the
instances where envy can be resolved by adding an arbitrary number of copies of
the items in the pool. From this characterization, we derive a polynomial-time
algorithm returning a respective solution if it exists. If the number of copies
or the total number of added items are bounded, the problem becomes
computationally intractable even in various restricted cases. We perform a
parameterized complexity analysis, focusing on the number of agents and the
pool size as parameters. Notably, although not every instance admits an
envy-free solution, our approach allows us to efficiently determine, in
polynomial time, whether a solution exists-an aspect that is both theoretically
interesting and far from trivial.

</details>


### [14] [Optimal Boost Design for Auto-bidding Mechanism with Publisher Quality Constraints](https://arxiv.org/abs/2508.08772)
*Huanyu Yan,Yu Huo,Min Lu,Weitong Ou,Xingyan Shi,Ruihe Shi,Xiaoying Tang*

Main category: cs.GT

TL;DR: 本文研究了在线竞价中结合质量价值的优化提升因素设计，提出了质量参与的提升算法（q-Boost），实验证明其在实际环境中能提高2%-6%的福利。


<details>
  <summary>Details</summary>
Motivation: 提升广告分配效率是长期的研究问题，因为它直接影响广告平台中所有参与者的经济成果。本文旨在设计在线竞价中的最优提升因素，同时纳入质量价值（展示广告对发布者长期利益的影响）。

Method: 通过建立一个三方拍卖框架，统一了广告主和发布者的福利指标，并在第二价格单插槽拍卖中推导了理论效率下界。随后设计了一种新颖的质量参与提升算法（q-Boost）来计算最优提升因素。

Result: 在阿里巴巴的公开数据集（AuctionNet）上的实验验证显示，该方法比传统方法提高了2%-6%的福利。

Conclusion: 研究证明了质量参与的提升算法在实际应用中的有效性，能够显著提升广告平台的经济效益。

Abstract: Online bidding is crucial in mobile ecosystems, enabling real-time ad
allocation across billions of devices to optimize performance and user
experience. Improving ad allocation efficiency is a long-standing research
problem, as it directly enhances the economic outcomes for all participants in
advertising platforms. This paper investigates the design of optimal boost
factors in online bidding while incorporating quality value (the impact of
displayed ads on publishers' long-term benefits). To address the divergent
interests on quality, we establish a three-party auction framework with a
unified welfare metric of advertiser and publisher. Within this framework, we
derive the theoretical efficiency lower bound for C-competitive boost in
second-price single-slot auctions, then design a novel quality-involved
Boosting (q-Boost) algorithm for computing the optimal boost factor.
Experimental validation on Alibaba's public dataset (AuctionNet) demonstrates
2%-6% welfare improvements over conventional approaches, proving our method's
effectiveness in real-world settings.

</details>


### [15] [Not in My Backyard! Temporal Voting Over Public Chores](https://arxiv.org/abs/2508.08810)
*Edith Elkind,Tzeh Yuan Neoh,Nicholas Teh*

Main category: cs.GT

TL;DR: 研究了一个时间投票模型，分析了优化功利主义和平均主义福利的计算复杂性，发现前者简单而后者困难，但某些情况下可有效解决。探讨了时间公平性和策略行为的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动态偏好下公共任务分配的投票模型，以理解社会福利优化的计算复杂性和公平性问题。

Method: 通过计算复杂性分析和近似算法，研究了功利主义和平均主义福利的优化，并探讨了时间公平性和策略行为。

Result: 优化功利主义福利计算简单，而优化平均主义福利在受限情况下仍困难，但某些场景可高效解决。时间公平性影响社会福利，策略行为可能导致决策环境中的不当行为。

Conclusion: 研究揭示了动态偏好下社会福利优化的复杂性，并提供了公平性度量和策略行为的深入分析。

Abstract: We study a temporal voting model where voters have dynamic preferences over a
set of public chores -- projects that benefit society, but impose individual
costs on those affected by their implementation. We investigate the
computational complexity of optimizing utilitarian and egalitarian welfare. Our
results show that while optimizing the former is computationally
straightforward, minimizing the latter is computationally intractable, even in
very restricted cases. Nevertheless, we identify several settings where this
problem can be solved efficiently, either exactly or by an approximation
algorithm. We also examine the effects of enforcing temporal fairness and its
impact on social welfare, and analyze the competitive ratio of online
algorithms. We then explore the strategic behavior of agents, providing
insights into potential malfeasance in such decision-making environments.
Finally, we discuss a range of fairness measures and their suitability for our
setting.

</details>
