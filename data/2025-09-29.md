<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering](https://arxiv.org/abs/2509.21541)
*Weikai Lin,Haoxiang Li,Yuhao Zhu*

Main category: cs.GR

TL;DR: ControlHair是一个混合框架，结合物理模拟器和条件视频扩散模型，实现了可控的动态头发渲染。


<details>
  <summary>Details</summary>
Motivation: 由于头发模拟和渲染的复杂性，现有的视频扩散模型缺乏对头发动态的精细控制。

Method: ControlHair采用三阶段流程：首先通过物理模拟器将物理参数编码为每帧几何，然后提取每帧控制信号，并将其输入视频扩散模型以生成动态头发视频。

Result: ControlHair在10K视频数据集上训练，优于基于文本和姿势的基线模型，能够精确控制头发动态。

Conclusion: ControlHair首次提出了基于物理的视频扩散框架，支持动态发型试戴、子弹时间效果和电影图形等多种应用场景。

Abstract: Hair simulation and rendering are challenging due to complex strand dynamics,
diverse material properties, and intricate light-hair interactions. Recent
video diffusion models can generate high-quality videos, but they lack
fine-grained control over hair dynamics. We present ControlHair, a hybrid
framework that integrates a physics simulator with conditional video diffusion
to enable controllable dynamic hair rendering. ControlHair adopts a three-stage
pipeline: it first encodes physics parameters (e.g., hair stiffness, wind) into
per-frame geometry using a simulator, then extracts per-frame control signals,
and finally feeds control signals into a video diffusion model to generate
videos with desired hair dynamics. This cascaded design decouples physics
reasoning from video generation, supports diverse physics, and makes training
the video diffusion model easy. Trained on a curated 10K video dataset,
ControlHair outperforms text- and pose-conditioned baselines, delivering
precisely controlled hair dynamics. We further demonstrate three use cases of
ControlHair: dynamic hairstyle try-on, bullet-time effects, and cinemagraphic.
ControlHair introduces the first physics-informed video diffusion framework for
controllable dynamics. We provide a teaser video and experimental results on
our website.

</details>


### [2] [PowerGS: Display-Rendering Power Co-Optimization for Neural Rendering in Power-Constrained XR Systems](https://arxiv.org/abs/2509.21702)
*Weikai Lin,Sushant Kondguli,Carl Marshall,Yuhao Zhu*

Main category: cs.GR

TL;DR: PowerGS是一个旨在在3D高斯泼溅（3DGS）技术中联合最小化渲染和显示功耗的框架，特别适用于功耗受限的扩展现实（XR）设备。


<details>
  <summary>Details</summary>
Motivation: 传统的3DGS模型在功耗受限的XR设备上效率低下，这些设备需要在瓦特级别运行。PowerGS致力于在质量约束下优化功耗。

Method: PowerGS通过识别显示和渲染功耗的等质量曲线，并在给定曲线上找到功耗最小的点，支持进一步的注视点渲染以节省功耗。

Result: 实验和用户研究表明，PowerGS相比最先进的3DGS模型可实现高达86%的总功耗降低，同时保持主观和客观质量的最小损失。

Conclusion: PowerGS提供了一种高效的功耗优化方法，适用于XR设备，并能显著降低功耗而不显著影响质量。

Abstract: 3D Gaussian Splatting (3DGS) combines classic image-based rendering,
pointbased graphics, and modern differentiable techniques, and offers an
interesting alternative to traditional physically-based rendering. 3DGS-family
models are far from efficient for power-constrained Extended Reality (XR)
devices, which need to operate at a Watt-level. This paper introduces PowerGS,
the first framework to jointly minimize the rendering and display power in 3DGS
under a quality constraint. We present a general problem formulation and show
that solving the problem amounts to 1) identifying the iso-quality curve(s) in
the landscape subtended by the display and rendering power and 2) identifying
the power-minimal point on a given curve, which has a closed-form solution
given a proper parameterization of the curves. PowerGS also readily supports
foveated rendering for further power savings. Extensive experiments and user
studies show that PowerGS achieves up to 86% total power reduction compared to
state-of-the-art 3DGS models, with minimal loss in both subjective and
objective quality. Code is available at
https://github.com/horizon-research/PowerGS.

</details>


### [3] [Rigidity-Aware 3D Gaussian Deformation from a Single Image](https://arxiv.org/abs/2509.22222)
*Jinhyeok Kim,Jaehun Bang,Seunghyun Seo,Kyungdon Joo*

Main category: cs.GR

TL;DR: DeformSplat 是一种新框架，通过单张图像指导 3D 高斯形变，解决了现有方法依赖多视角视频的限制。


<details>
  <summary>Details</summary>
Motivation: 单张图像重建物体形变是计算机视觉和图形学中的挑战，现有方法通常依赖多视角视频，适用性受限。

Method: DeformSplat 提出了高斯到像素匹配和刚性部分分割两项技术，分别解决 3D 高斯与 2D 像素的域间隙问题和几何一致性维护问题。

Result: 实验表明，该方法显著优于现有方法，并能自然扩展到帧插值和交互式物体操纵等应用中。

Conclusion: DeformSplat 通过两项技术实现了单张图像下的形变重建，具有广泛的应用潜力。

Abstract: Reconstructing object deformation from a single image remains a significant
challenge in computer vision and graphics. Existing methods typically rely on
multi-view video to recover deformation, limiting their applicability under
constrained scenarios. To address this, we propose DeformSplat, a novel
framework that effectively guides 3D Gaussian deformation from only a single
image. Our method introduces two main technical contributions. First, we
present Gaussian-to-Pixel Matching which bridges the domain gap between 3D
Gaussian representations and 2D pixel observations. This enables robust
deformation guidance from sparse visual cues. Second, we propose Rigid Part
Segmentation consisting of initialization and refinement. This segmentation
explicitly identifies rigid regions, crucial for maintaining geometric
coherence during deformation. By combining these two techniques, our approach
can reconstruct consistent deformations from a single image. Extensive
experiments demonstrate that our approach significantly outperforms existing
methods and naturally extends to various applications,such as frame
interpolation and interactive object manipulation.

</details>


### [4] [Aerial Path Planning for Urban Geometry and Texture Co-Capture](https://arxiv.org/abs/2509.22227)
*Weidan Xiong,Bochuan Zeng,Ziyu Hu,Jianwei Guo,Ke Xie,Hui Huang*

Main category: cs.GR

TL;DR: 论文提出了一种创新的空中路径规划框架，用于在有限先验知识条件下共同捕获城市几何结构和高质量纹理，通过多目标优化和顺序路径规划算法实现低成本的现实场景重建。


<details>
  <summary>Details</summary>
Motivation: 目前城市场景重建技术忽视了纹理质量的重要性，导致纹理模型存在明显的视觉缺陷。论文旨在解决在有限先验知识条件下的城市几何结构和纹理共同捕获问题。

Method: 提出了一种空中路径规划框架，包括生成高质量垂直和水平视角、多目标优化策略以及顺序路径规划算法，以联合最大化纹理保真度和几何精度。

Result: 在大规模合成和真实城市数据集上的实验表明，该方法能够有效生成适用于几何和纹理重建的图像集，实现低成本的现实场景代理生成。

Conclusion: 该方法通过创新的路径规划和纹理质量评估系统，解决了城市几何与纹理共同捕获的问题，为低成本高质量场景重建提供了有效解决方案。

Abstract: Recent advances in image acquisition and scene reconstruction have enabled
the generation of high-quality structural urban scene geometry, given
sufficient site information. However, current capture techniques often overlook
the crucial importance of texture quality, resulting in noticeable visual
artifacts in the textured models. In this work, we introduce the urban geometry
and texture co-capture problem under limited prior knowledge before a site
visit. The only inputs are a 2D building contour map of the target area and a
safe flying altitude above the buildings. We propose an innovative aerial path
planning framework designed to co-capture images for reconstructing both
structured geometry and high-fidelity textures. To evaluate and guide view
planning, we introduce a comprehensive texture quality assessment system,
including two novel metrics tailored for building facades. Firstly, our method
generates high-quality vertical dipping views and horizontal planar views to
effectively capture both geometric and textural details. A multi-objective
optimization strategy is then proposed to jointly maximize texture fidelity,
improve geometric accuracy, and minimize the cost associated with aerial views.
Furthermore, we present a sequential path planning algorithm that accounts for
texture consistency during image capture. Extensive experiments on large-scale
synthetic and real-world urban datasets demonstrate that our approach
effectively produces image sets suitable for concurrent geometric and texture
reconstruction, enabling the creation of realistic, textured scene proxies at
low operational cost.

</details>


### [5] [Learning to Ball: Composing Policies for Long-Horizon Basketball Moves](https://arxiv.org/abs/2509.22442)
*Pei Xu,Zhen Wu,Ruocheng Wang,Vishnu Sarukkai,Kayvon Fatahalian,Ioannis Karamouzas,Victor Zordan,C. Karen Liu*

Main category: cs.GR

TL;DR: 本文提出了一种新的策略集成框架，用于在多阶段长程任务中组合截然不同的运动技能，并通过高级软路由实现子任务之间的无缝过渡。该方法在篮球技能和复杂任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 多阶段长程任务（如篮球动作）需要无缝的策略组合和过渡，现有方法在处理缺乏共同探索状态或明确初始/终止状态的任务时表现不佳。

Method: 提出了一种新的策略集成框架，支持在多阶段长程任务中组合不同技能，并通过高级软路由实现子任务间的无缝过渡。

Result: 在篮球技能和复杂任务上的实验表明，训练的策略能有效控制模拟角色完成任务，无需依赖球轨迹参考。

Conclusion: 该框架在多阶段长程任务中展现出强大的策略组合能力和过渡鲁棒性，为复杂任务的控制提供了新思路。

Abstract: Learning a control policy for a multi-phase, long-horizon task, such as
basketball maneuvers, remains challenging for reinforcement learning approaches
due to the need for seamless policy composition and transitions between skills.
A long-horizon task typically consists of distinct subtasks with well-defined
goals, separated by transitional subtasks with unclear goals but critical to
the success of the entire task. Existing methods like the mixture of experts
and skill chaining struggle with tasks where individual policies do not share
significant commonly explored states or lack well-defined initial and terminal
states between different phases. In this paper, we introduce a novel policy
integration framework to enable the composition of drastically different motor
skills in multi-phase long-horizon tasks with ill-defined intermediate states.
Based on that, we further introduce a high-level soft router to enable seamless
and robust transitions between the subtasks. We evaluate our framework on a set
of fundamental basketball skills and challenging transitions. Policies trained
by our approach can effectively control the simulated character to interact
with the ball and accomplish the long-horizon task specified by real-time user
commands, without relying on ball trajectory references.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?](https://arxiv.org/abs/2509.21629)
*Anjiang Wei,Tarun Suresh,Tianran Sun,Haoze Wu,Ke Wang,Alex Aiken*

Main category: cs.PL

TL;DR: 该论文提出了一种评估LLMs在循环不变量合成上的框架，发现当前LLM基于的验证器相比传统求解器UAutomizer优势不大，但监督微调和Best-of-N采样能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决程序验证中自动发现强不变量这一长期挑战，评估LLMs在不变量合成上的潜力。

Method: 采用基于验证器的决策过程，结合形式化保证，评估12种LLMs的正确性和验证速度提升。

Result: LLM验证器尚未显著优于UAutomizer，但监督微调和Best-of-N采样能大幅提升性能指标，如Qwen3-Coder-480B的速度提升比例从8%增至29.2%。

Conclusion: LLM在不变量合成上潜力大但仍需提升，监督微调和采样技术是关键手段，当前基准对LLMs仍具挑战性。

Abstract: Program verification relies on loop invariants, yet automatically discovering
strong invariants remains a long-standing challenge. We introduce a principled
framework for evaluating LLMs on invariant synthesis. Our approach uses a
verifier-based decision procedure with a formal soundness guarantee and
assesses not only correctness but also the speedup that invariants provide in
verification. We evaluate 7 state-of-the-art LLMs, and existing LLM-based
verifiers against the traditional solver UAutomizer. While LLM-based verifiers
represent a promising direction, they do not yet offer a significant advantage
over UAutomizer. Model capability also proves critical, as shown by sharp
differences in speedups across models, and our benchmark remains an open
challenge for current LLMs. Finally, we show that supervised fine-tuning and
Best-of-N sampling can improve performance: fine-tuning on 3589 instances
raises the percentage of speedup cases for Qwen3-Coder-480B from 8% to 29.2%,
and Best-of-N sampling with N=16 improves Claude-sonnet-4 from 8.8% to 22.1%.

</details>


### [7] [Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics](https://arxiv.org/abs/2509.21793)
*Jianhong Zhao,Everett Hildenbrandt,Juan Conejero,Yongwang Zhao*

Main category: cs.PL

TL;DR: 提出了一种通过证明编译的范式，将验证证明转化为优化的执行规则，实现了性能的大幅提升。


<details>
  <summary>Details</summary>
Motivation: 传统验证证明被检查正确性后即被丢弃，未能充分利用其潜在价值。

Method: 采用符号执行构建全路径可达性证明，并通过编译其图结构将多次语义重写合并为单条规则。

Result: 评估显示，在指令级优化和全程序编译中均实现了显著的性能提升。

Conclusion: 通过证明编译的范式在保留正确性的同时，显著提升了执行效率。

Abstract: Verification proofs encode complete program behavior, yet we discard them
after checking correctness. We present compiling by proving, a paradigm that
transforms these proofs into optimized execution rules. By constructing
All-Path Reachability Proofs through symbolic execution and compiling their
graph structure, we consolidate many semantic rewrites into single rules while
preserving correctness by construction. We implement this as a
language-agnostic extension to the K framework. Evaluation demonstrates
performance improvements across different compilation scopes: opcode-level
optimizations show consistent speedups, while whole-program compilation
achieves orders of magnitude greater performance gains.

</details>


### [8] [Committing to the bit: Relational programming with semiring arrays and SAT solving](https://arxiv.org/abs/2509.22614)
*Dmitri Volkov,Yafei Yang,Chung-chieh Shan*

Main category: cs.PL

TL;DR: 论文提出了semiringKanren，一种关系型编程语言，其中关系表达式表示半环数组，并通过SAT求解器实现高效执行，实验表明其在解决数独问题时比miniKanren更高效。


<details>
  <summary>Details</summary>
Motivation: 为了解决关系型编程语言的效率和灵活性需求，作者提出了一种基于半环数组的新语言semiringKanren。

Method: 论文通过形式化类型系统限制数组大小，并为数组元素定义参数化语义，同时将类型编译为位串表示，支持使用SAT求解器高效执行。

Result: 实验表明，semiringKanren在解决数独问题时比miniKanren更具效率优势。

Conclusion: semiringKanren是一种高效的关系型编程语言变体，特别适合需要高效求解的问题场景。

Abstract: We propose semiringKanren, a relational programming language where each
relation expression denotes a semiring array. We formalize a type system that
restricts the arrays to finite size. We then define a semantics that is
parameterized by the semiring that the arrays draw their elements from. We
compile semiringKanren types to bitstring representations. For the Boolean
semiring, this compilation enables us to use an SAT solver to run
semiringKanren programs efficiently. We compare the performance of
semiringKanren and faster miniKanren for solving Sudoku puzzles. Our experiment
shows that semiringKanren can be a more efficient variant of miniKanren.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Breaking $1/ε$ Barrier in Quantum Zero-Sum Games: Generalizing Metric Subregularity for Spectraplexes](https://arxiv.org/abs/2509.21570)
*Yiheng Su,Emmanouil-Vasileios Vlatakis-Gkaragkounis,Pucheng Xiong*

Main category: cs.GT

TL;DR: 量子零和游戏中，矩阵变体的Nesterov迭代平滑和乐观梯度下降上升算法实现了线性最后迭代收敛，与经典多面体情况匹配。


<details>
  <summary>Details</summary>
Motivation: 研究量子零和游戏作为非局部游戏、量子交互证明和量子机器学习等现代领域的典型模型。

Method: 采用矩阵变体的Nesterov迭代平滑和乐观梯度下降上升算法，并结合半定规划几何的新推广误差界分析。

Result: 证明了在量子零和游戏中，算法的最后迭代收敛速率为线性，超越了传统多面体域的性能差距猜想。

Conclusion: 通过新的几何分析方法，解决了量子可行集与经典多面体集之间的性能差距问题，并为严格正半定规划的并行近似提供了指数级加速。

Abstract: Long studied as a toy model, quantum zero-sum games have recently resurfaced
as a canonical playground for modern areas such as non-local games, quantum
interactive proofs, and quantum machine learning. In this simple yet
fundamental setting, two competing quantum players send iteratively mixed
quantum states to a referee, who performs a joint measurement to determine
their payoffs. In 2025, Vasconcelos et al. [arXiv:2311.10859] connected quantum
communication channels with a hierarchy of quantum optimization algorithms that
generalize Matrix Multiplicative Weights Update ($\texttt{MMWU}$) through
extra-gradient mechanisms, establishing an average-iterate convergence rate of
$\mathcal{O}(1/\epsilon)$ iterations to $\epsilon$-Nash equilibria. While a
long line of work has shown that bilinear games over polyhedral domains admit
gradient methods with linear last-iterate convergence rates of
$\mathcal{O}(\log(1/\epsilon))$, it has been conjectured that a fundamental
performance gap must persist between quantum feasible sets (spectraplexes) and
classical polyhedral sets (simplices). We resolve this conjecture in the
negative. We prove that matrix variants of $\textit{Nesterov's iterative
smoothing}$ ($\texttt{IterSmooth}$) and $\textit{Optimistic Gradient
Descent-Ascent}$ ($\texttt{OGDA}$) achieve last-iterate convergence at a linear
rate in quantum zero-sum games, thereby matching the classical polyhedral case.
Our analysis relies on a new generalization of error bounds in semidefinite
programming geometry, establishing that (SP-MS) holds for monotone operators
over spectrahedra, despite their uncountably many extreme points. Finally, as a
byproduct, we obtain an exponential speed-up over the classical Jain-Watrous
[arXiv:0808.2775] method for parallel approximation of strictly positive
semidefinite programs.

</details>


### [10] [Incentives in Federated Learning with Heterogeneous Agents](https://arxiv.org/abs/2509.21612)
*Ariel D. Procaccia,Han Shao,Itai Shapira*

Main category: cs.GT

TL;DR: 联邦学习通过多智能体数据共享提升效率，但激励不一致导致合作困难。本文提出基于博弈论的框架，分析数据异质性，并用线性规划近似求解最小成本分配方案。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，每个智能体的更新成本高但收益共享，导致激励不一致。如何协调多智能体合作以最小化个人成本并满足精度要求是研究动机。

Method: 采用博弈论框架分析数据异质性，引入线性规划近似求解最小成本贡献分配问题，并设计基于贡献的支付机制。

Result: 研究发现非协调博弈可能导致均衡不存在或成本远高于合作；提出的线性规划方法能对数近似最优解，且支付机制具有策略证明性和唯一性。

Conclusion: 通过博弈论和线性规划方法，本研究为联邦学习的多智能体合作提供了成本优化和激励兼容的解决方案。

Abstract: Federated learning promises significant sample-efficiency gains by pooling
data across multiple agents, yet incentive misalignment is an obstacle: each
update is costly to the contributor but boosts every participant. We introduce
a game-theoretic framework that captures heterogeneous data: an agent's utility
depends on who supplies each sample, not just how many. Agents aim to meet a
PAC-style accuracy threshold at minimal personal cost. We show that
uncoordinated play yields pathologies: pure equilibria may not exist, and the
best equilibrium can be arbitrarily more costly than cooperation. To steer
collaboration, we analyze the cost-minimizing contribution vector, prove that
computing it is NP-hard, and derive a polynomial-time linear program that
achieves a logarithmic approximation. Finally, pairing the LP with a simple
pay-what-you-contribute rule - each agent receives a payment equal to its
sample cost - yields a mechanism that is strategyproof and, within the class of
contribution-based transfers, is unique.

</details>


### [11] [Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade](https://arxiv.org/abs/2509.22563)
*Simone Di Gregorio,Paul Dütting,Federico Fusco,Chris Schwiegelshohn*

Main category: cs.GT

TL;DR: 本文研究了双边贸易问题，提出了一种学习算法，在随机设定下实现了近乎最优的后悔界，并证明了在非稳态场景中无法实现亚线性后悔。


<details>
  <summary>Details</summary>
Motivation: 研究双边贸易问题，旨在从经纪人的角度，通过后悔最小化框架提出激励机制，最大化利润。

Method: 提出了一种学习算法，保证在随机设定下，当买卖双方估值从固定且可能相关的未知分布中独立同分布抽取时，实现近乎最优的后悔界。

Result: 在随机设定下，算法实现了近乎最优的后悔界；在非稳态场景中，无法实现亚线性后悔。

Conclusion: 通过细致的链式分析，证明了在近乎最优的机制中，利润收敛以最优速率实现，展示了技术的广泛适用性。

Abstract: Bilateral trade models the task of intermediating between two strategic
agents, a seller and a buyer, willing to trade a good for which they hold
private valuations. We study this problem from the perspective of a broker, in
a regret minimization framework. At each time step, a new seller and buyer
arrive, and the broker has to propose a mechanism that is incentive-compatible
and individually rational, with the goal of maximizing profit.
  We propose a learning algorithm that guarantees a nearly tight
$\tilde{O}(\sqrt{T})$ regret in the stochastic setting when seller and buyer
valuations are drawn i.i.d. from a fixed and possibly correlated unknown
distribution. We further show that it is impossible to achieve sublinear regret
in the non-stationary scenario where valuations are generated upfront by an
adversary. Our ambitious benchmark for these results is the best
incentive-compatible and individually rational mechanism. This separates us
from previous works on efficiency maximization in bilateral trade, where the
benchmark is a single number: the best fixed price in hindsight.
  A particular challenge we face is that uniform convergence for all
mechanisms' profits is impossible. We overcome this difficulty via a careful
chaining analysis that proves convergence for a provably near-optimal mechanism
at (essentially) optimal rate. We further showcase the broader applicability of
our techniques by providing nearly optimal results for the joint ads problem.

</details>
