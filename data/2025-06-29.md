<div id=toc></div>

# Table of Contents

- [cs.DM](#cs.DM) [Total: 2]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.LO](#cs.LO) [Total: 2]
- [math.LO](#math.LO) [Total: 3]
- [math.RT](#math.RT) [Total: 4]


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [1] [Making Graphs Irregular through Irregularising Walks](https://arxiv.org/abs/2506.21254)
*Julien Bensmail,Romain Bourneuf,Paul Colinot,Samuel Humeau,Timothée Martinod*

Main category: cs.DM

TL;DR: 本文研究了1-2-3猜想的一个限制版本，即在将图转化为局部不规则多重图时，额外要求添加的边必须形成图的路径。


<details>
  <summary>Details</summary>
Motivation: 1-2-3猜想最近被证明成立，但研究中引入了额外的路径约束条件，以探索该猜想在更严格条件下的表现和应用。

Method: 研究者在满足路径约束的条件下，分析如何通过最短路径将图转化为局部不规则多重图，并探讨了这一限制对图的结构和算法的影响。

Result: 研究得出了关于最短不规则化路径长度的多种结果，包括一般图和特定图类的结构性和组合性结论。

Conclusion: 在路径约束条件下，1-2-3猜想的应用表现出独特的性质和挑战，为图的局部不规则性研究提供了新的视角。

Abstract: The 1-2-3 Conjecture, introduced by Karo\'nski, {\L}uczak, and Thomason in
2004, was recently solved by Keusch. This implies that, for any connected graph
$G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph
$M(G)$, i.e., in which no two adjacent vertices have the same degree, by
replacing some of its edges with at most three parallel edges. In this work, we
introduce and study a restriction of this problem under the additional
constraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a
path with possibly repeated edges and vertices) of $G$. We investigate the
general consequences of having this additional constraint, and provide several
results of different natures (structural, combinatorial, algorithmic) on the
length of the shortest irregularising walks, for general graphs and more
restricted classes.

</details>


### [2] [Playing Snake on a Graph](https://arxiv.org/abs/2506.21281)
*Denise Graafsma,Bodo Manthey,Alexander Skopalik*

Main category: cs.DM

TL;DR: 研究了在任意无向图上玩蛇游戏的问题，证明了判断一个图是否“蛇可胜”是NP难的，并完全描述了奇偶数二分图和顶点连通度为1的图的特性。


<details>
  <summary>Details</summary>
Motivation: 探索蛇游戏在更一般图上的表现，研究其复杂度和特性，以扩展经典游戏的理论基础。

Method: 基于蛇游戏的规则，定义“蛇可胜”图，并利用图论和复杂性理论分析其特性，包括对哈密顿图和非哈密顿图的研究。

Result: 证明了“蛇可胜”问题的NP难性，完全描述了奇偶数二分图和顶点连通度为1的图的蛇可胜性，并确定了非哈密顿图的周长上限为6且该上限是紧的。

Conclusion: 蛇游戏在不同类型图上的可胜性具有复杂性和多样性，为非哈密顿图的特性提供了新的见解。

Abstract: Snake is a classic computer game, which has been around for decades. Based on
this game, we study the game of Snake on arbitrary undirected graphs. A snake
forms a simple path that has to move to an apple while avoiding colliding with
itself. When the snake reaches the apple, it grows longer, and a new apple
appears. A graph on which the snake has a strategy to keep eating apples until
it covers all the vertices of the graph is called snake-winnable. We prove that
determining whether a graph is snake-winnable is NP-hard, even when restricted
to grid graphs. We fully characterize snake-winnable graphs for odd-sized
bipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian
graphs are always snake-winnable, we show that non-Hamiltonian snake-winnable
graphs have a girth of at most 6 and that this bound is tight.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [3] [Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions](https://arxiv.org/abs/2506.20677)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.DS

TL;DR: 本文提出了一种新的自适应混合排序范式，能够根据输入数据的实时监控动态选择最优的排序算法（计数排序、基数排序或快速排序），显著提升了执行时间、灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 排序是计算机科学中的核心操作，对大规模数据系统、实时系统和嵌入式计算的性能有直接影响，但目前没有一种排序算法在所有数据分布下都是最优的。

Method: 通过特征提取模块计算数据量、值范围和熵等参数，使用有限状态机和XGBoost分类器的决策引擎动态选择最优排序算法，针对不同场景分别采用计数排序、基数排序或快速排序。

Result: 实验结果表明，该框架在合成和真实数据集上的执行时间、灵活性和效率均显著优于传统的静态排序算法。

Conclusion: 该框架具有可扩展性和广泛适用性，适用于大数据分析、边缘计算和硬件受限系统等多种数据处理场景。

Abstract: Sorting is an essential operation in computer science with direct
consequences on the performance of large scale data systems, real-time systems,
and embedded computation. However, no sorting algorithm is optimal under all
distributions of data. The new adaptive hybrid sorting paradigm proposed in
this paper is the paradigm that automatically selects the most effective
sorting algorithm Counting Sort, Radix Sort, or QuickSort based on real-time
monitoring of patterns in input data. The architecture begins by having a
feature extraction module to compute significant parameters such as data
volume, value range and entropy. These parameters are sent to a decision engine
involving Finite State Machine and XGBoost classifier to aid smart and
effective in choosing the optimal sorting strategy. It implements Counting Sort
on small key ranges, Radix Sort on large range structured input with
low-entropy keys and QuickSort on general purpose sorting. The experimental
findings of both synthetic and real life dataset confirm that the proposed
solution is actually inclined to excel significantly by comparison in execution
time, flexibility and the efficiency of conventional static sorting algorithms.
The proposed framework provides a scalable, high perhaps and applicable to a
wide range of data processing operations like big data analytics, edge
computing, and systems with hardware limitations.

</details>


### [4] [Review of Three Variants of the k-d Tree](https://arxiv.org/abs/2506.20687)
*Russell A. Brown*

Main category: cs.DS

TL;DR: 本文探讨了构建平衡k-d树的三种变体及其分割技术对计算复杂度的影响，并分析了其中一种变体的双线程执行性能。


<details>
  <summary>Details</summary>
Motivation: 由于传统的重新平衡技术（如AVL树或红黑树）不适用于k-d树，构建平衡的k-d树需要高效的找中位数和分割技术，本文旨在研究这些技术对计算复杂度的影响。

Method: 文章描述了三种k-d树变体，每种变体使用不同的分割技术，并在其中一种变体中提出并分析了双线程执行方法。

Result: 研究比较了三种k-d树变体的性能表现，并展示了双线程执行对其中一种变体的性能影响。

Conclusion: 不同的分割技术显著影响k-d树的构建复杂度，双线程执行在特定变体中表现出潜在的性能优势。

Abstract: The original description of the k-d tree recognized that rebalancing
techniques, such as used to build an AVL tree or a red-black tree, are not
applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is
necessary to find the median of a set of data for each recursive subdivision of
that set. The sort or selection used to find the median, and the technique used
to partition the set about that median, strongly influence the computational
complexity of building a k-d tree. This article describes and contrasts three
variants of the k-d tree that differ in their technique used to partition the
set, and compares the performance of those variants. In addition, dual-threaded
execution is proposed and analyzed for one of the three variants.

</details>


### [5] [A Framework for Building Data Structures from Communication Protocols](https://arxiv.org/abs/2506.20761)
*Alexandr Andoni,Shunhua Jiang,Omri Weinstein*

Main category: cs.DS

TL;DR: 提出一个通用框架，通过通信模型设计高效的高维模式匹配数据结构的，应用于部分匹配问题，显著提高了查询时间和空间效率。


<details>
  <summary>Details</summary>
Motivation: 高维模式匹配问题的数据结构的效率提升需求，特别是部分匹配问题的现有解决方案在查询时间和空间效率上的不足。

Method: 通过通信复杂度模型将数据结构问题转化为Unambiguous Arthur-Merlin (UAM)通信问题，并开发了一种改进的Set-Disjointness通信协议。

Result: 提出的框架显著降低了查询时间，从现有的指数级降低到多项式级，同时保持了接近线性的空间复杂度。

Conclusion: 该框架展示了数据依赖型数据结构的潜力，为高维模式匹配问题提供了更高效的解决方案。

Abstract: We present a general framework for designing efficient data structures for
high-dimensional pattern-matching problems ($\exists \;? i\in[n], f(x_i,y)=1$)
through communication models in which $f(x,y)$ admits sublinear communication
protocols with exponentially-small error. Specifically, we reduce the data
structure problem to the Unambiguous Arthur-Merlin (UAM) communication
complexity of $f(x,y)$ under product distributions.
  We apply our framework to the Partial Match problem (a.k.a, matching with
wildcards), whose underlying communication problem is sparse set-disjointness.
When the database consists of $n$ points in dimension $d$, and the number of
$\star$'s in the query is at most $w = c\log n \;(\ll d)$, the fastest known
linear-space data structure (Cole, Gottlieb and Lewenstein, STOC'04) had query
time $t \approx 2^w = n^c$, which is nontrivial only when $c<1$. By contrast,
our framework produces a data structure with query time $n^{1-1/(c \log^2 c)}$
and space close to linear.
  To achieve this, we develop a one-sided $\epsilon$-error communication
protocol for Set-Disjointness under product distributions with
$\tilde{\Theta}(\sqrt{d\log(1/\epsilon)})$ complexity, improving on the
classical result of Babai, Frankl and Simon (FOCS'86). Building on this
protocol, we show that the Unambiguous AM communication complexity of
$w$-Sparse Set-Disjointness with $\epsilon$-error under product distributions
is $\tilde{O}(\sqrt{w \log(1/\epsilon)})$, independent of the ambient dimension
$d$, which is crucial for the Partial Match result. Our framework sheds further
light on the power of data-dependent data structures, which is instrumental for
reducing to the (much easier) case of product distributions.

</details>


### [6] [Practical and Accurate Local Edge Differentially Private Graph Algorithms](https://arxiv.org/abs/2506.20828)
*Pranay Mundra,Charalampos Papamanthou,Julian Shun,Quanquan C. Liu*

Main category: cs.DS

TL;DR: 本文针对大规模网络中的隐私问题，提出了基于本地差分隐私（LDP）的新算法，用于k-core分解和三角形计数，显著提升了理论效用和实际准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模网络在各个领域的广泛应用，涉及敏感数据的图分析引发了隐私保护的迫切需求。传统的集中式差分隐私模型需要信任第三方，而本地差分隐私（LDP）能在不信任第三方的情况下，在个体层面保护隐私。

Method: 本文提出了两种基于LDP的新算法：一种改进k-core分解，另一种用于三角形计数。算法利用图的退化和最大度等特性，优化理论效用，并通过改进的随机响应技术和私有出度定向方法，提供更严格的误差边界。

Result: 实验表明，本文的k-core分解算法误差仅为精确值的3倍，远优于基线方法的131倍误差。三角形计数算法则将乘法近似误差降低了多达六个数量级，同时保持了高效的运行时间。

Conclusion: 本文提出的LDP算法在理论和实验验证中表现出色，为保护隐私的图分析提供了高效且准确的解决方案，填补了分布式仿真中本地DP算法评估的空白。

Abstract: The rise of massive networks across diverse domains necessitates
sophisticated graph analytics, often involving sensitive data and raising
privacy concerns. This paper addresses these challenges using local
differential privacy (LDP), which enforces privacy at the individual level,
where no third-party entity is trusted, unlike centralized models that assume a
trusted curator. We introduce novel LDP algorithms for two fundamental graph
statistics: k-core decomposition and triangle counting. Our approach leverages
input-dependent private graph properties, specifically the degeneracy and
maximum degree of the graph, to improve theoretical utility. Unlike prior
methods, our error bounds are determined by the maximum degree rather than the
total number of edges, resulting in significantly tighter guarantees. For
triangle counting, we improve upon the work of Imola, Murakami, and
Chaudhury~\cite{IMC21locally, IMC21communication}, which bounds error in terms
of edge count. Instead, our algorithm achieves bounds based on graph degeneracy
by leveraging a private out-degree orientation, a refined variant of Eden et
al.'s randomized response technique~\cite{ELRS23, and a novel analysis,
yielding stronger guarantees than prior work. Beyond theoretical gains, we are
the first to evaluate local DP algorithms in a distributed simulation, unlike
prior work tested on a single processor. Experiments on real-world graphs show
substantial accuracy gains: our k-core decomposition achieves errors within 3x
of exact values, far outperforming the 131x error in the baseline of Dhulipala
et al.~\cite{DLRSSY22}. Our triangle counting algorithm reduces multiplicative
approximation errors by up to six orders of magnitude, while maintaining
competitive runtime.

</details>


### [7] [Almost Tight Additive Guarantees for \boldmath $k$-Edge-Connectivity](https://arxiv.org/abs/2506.20906)
*Nikhil Kumar,Chaitanya Swamy*

Main category: cs.DS

TL;DR: 该论文针对k边连通生成子图问题（kECSS），提出了几乎最优的多项式时间算法，对于偶数k和奇数k分别实现了不同的连通性保证，并显著改进了已有成果。


<details>
  <summary>Details</summary>
Motivation: 研究kECSS问题在APX困难情况下，如何设计高效算法以实现近乎最优的解决方案，同时改进现有方法的复杂性和解的质量。

Method: 通过线性规划松弛（LP-relaxation）技术，针对偶数k和奇数k分别设计了不同的算法，确保子图的连通性和成本最优。

Result: 对于偶数k，算法生成(k-2)边连通子图且成本不超过LP^*；对于奇数k，生成(k-3)边连通子图且成本不超过LP^*。此外，对于单位边成本问题，实现了更优的近似比。

Conclusion: 论文提出的算法在kECSS和kECSM问题上取得了近乎最优的结果，且在度约束版本中也表现优异，为相关领域提供了新的解决方案。

Abstract: We consider the \emph{$k$-edge connected spanning subgraph} (kECSS) problem,
where we are given an undirected graph $G = (V, E)$ with nonnegative edge costs
$\{c_e\}_{e\in E}$, and we seek a minimum-cost \emph{$k$-edge connected}
subgraph $H$ of $G$. For even $k$, we present a polytime algorithm that
computes a $(k-2)$-edge connected subgraph of cost at most the optimal value
$LP^*$ of the natural LP-relaxation for kECSS; for odd $k$, we obtain a
$(k-3)$-edge connected subgraph of cost at most $LP^*$. Since kECSS is APX-hard
for all $k\geq 2$, our results are nearly optimal. They also significantly
improve upon the recent work of Hershkowitz et al., both in terms of solution
quality and the simplicity of algorithm and its analysis. Our techniques also
yield an alternate guarantee, where we obtain a $(k-1)$-edge connected subgraph
of cost at most $1.5\cdot LP^*$; with unit edge costs, the cost guarantee
improves to $(1+\frac{4}{3k})\cdot LP^*$, which improves upon the
state-of-the-art approximation for unit edge costs, but with a unit loss in
edge connectivity.
  Our kECSS-result also yields results for the \emph{$k$-edge connected
spanning multigraph} (kECSM) problem, where multiple copies of an edge can be
selected: we obtain a $(1+2/k)$-approximation algorithm for even $k$, and a
$(1+3/k)$-approximation algorithm for odd $k$.
  Our techniques extend to the degree-bounded versions of kECSS and kECSM,
wherein we also impose degree lower- and upper- bounds on the nodes. We obtain
the same cost and connectivity guarantees for these degree-bounded versions
with an additive violation of (roughly) $2$ for the degree bounds. These are
the first results for degree-bounded \{kECSS,kECSM\} of the form where the cost
of the solution obtained is at most the optimum, and the connectivity
constraints are violated by an additive constant.

</details>


### [8] [Courcelle's Theorem for Lipschitz Continuity](https://arxiv.org/abs/2506.21118)
*Tatsuya Gima,Soh Kumabe,Yuichi Yoshida*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Lipschitz continuity of algorithms, introduced by Kumabe and Yoshida
(FOCS'23), measures the stability of an algorithm against small input
perturbations. Algorithms with small Lipschitz continuity are desirable, as
they ensure reliable decision-making and reproducible scientific research.
Several studies have proposed Lipschitz continuous algorithms for various
combinatorial optimization problems, but these algorithms are problem-specific,
requiring a separate design for each problem.
  To address this issue, we provide the first algorithmic meta-theorem in the
field of Lipschitz continuous algorithms. Our result can be seen as a Lipschitz
continuous analogue of Courcelle's theorem, which offers Lipschitz continuous
algorithms for problems on bounded-treewidth graphs. Specifically, we consider
the problem of finding a vertex set in a graph that maximizes or minimizes the
total weight, subject to constraints expressed in monadic second-order logic
(MSO_2). We show that for any $\varepsilon>0$, there exists a $(1\pm
\varepsilon)$-approximation algorithm for the problem with a polylogarithmic
Lipschitz constant on bounded treewidth graphs. On such graphs, our result
outperforms most existing Lipschitz continuous algorithms in terms of
approximability and/or Lipschitz continuity. Further, we provide similar
results for problems on bounded-clique-width graphs subject to constraints
expressed in MSO_1. Additionally, we construct a Lipschitz continuous version
of Baker's decomposition using our meta-theorem as a subroutine.

</details>


### [9] [Edge Clique Partition and Cover Beyond Independence](https://arxiv.org/abs/2506.21216)
*Fedor V. Fomin,Petr A. Golovach,Danil Sagunov,Kirill Simonov*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Covering and partitioning the edges of a graph into cliques are classical
problems at the intersection of combinatorial optimization and graph theory,
having been studied through a range of algorithmic and complexity-theoretic
lenses. Despite the well-known fixed-parameter tractability of these problems
when parameterized by the total number of cliques, such a parameterization
often fails to be meaningful for sparse graphs. In many real-world instances,
on the other hand, the minimum number of cliques in an edge cover or partition
can be very close to the size of a maximum independent set \alpha(G).
  Motivated by this observation, we investigate above \alpha parameterizations
of the edge clique cover and partition problems. Concretely, we introduce and
study Edge Clique Cover Above Independent Set (ECC/\alpha) and Edge Clique
Partition Above Independent Set (ECP/\alpha), where the goal is to cover or
partition all edges of a graph using at most \alpha(G) + k cliques, and k is
the parameter. Our main results reveal a distinct complexity landscape for the
two variants. We show that ECP/\alpha is fixed-parameter tractable, whereas
ECC/\alpha is NP-complete for all k \geq 2, yet can be solved in polynomial
time for k \in {0,1}. These findings highlight intriguing differences between
the two problems when viewed through the lens of parameterization above a
natural lower bound.
  Finally, we demonstrate that ECC/\alpha becomes fixed-parameter tractable
when parameterized by k + \omega(G), where \omega(G) is the size of a maximum
clique of the graph G. This result is particularly relevant for sparse graphs,
in which \omega is typically small. For H-minor free graphs, we design a
subexponential algorithm of running time f(H)^{\sqrt{k}}n^{O(1)}.

</details>


### [10] [On Minimizing Wiggle in Stacked Area Charts](https://arxiv.org/abs/2506.21175)
*Alexander Dobler,Martin Nöllenburg*

Main category: cs.DS

TL;DR: 该论文研究了堆叠面积图中最小化边界波动（wiggle）的复杂性，证明了其NP-hard性，并提出了一种精确的混合整数线性规划方法。


<details>
  <summary>Details</summary>
Motivation: 堆叠面积图是一种广泛使用的时间序列可视化技术，但其边界波动的优化问题尚未从计算复杂性角度进行正式分析。

Method: 论文通过形式化分析证明了不同变体的wiggle最小化问题是NP-hard且难以逼近的，并提出了一种精确的混合整数线性编程方法。

Result: 实验结果表明，提出的精确方法在性能上与最先进的启发式算法相当，同时解决了wiggle最小化的复杂性。

Conclusion: 论文不仅为wiggle最小化问题提供了理论复杂性分析，还提出了一种可行的精确解法，为未来研究奠定了基础。

Abstract: Stacked area charts are a widely used visualization technique for numerical
time series. The x-axis represents time, and the time series are displayed as
horizontal, variable-height layers stacked on top of each other. The height of
each layer corresponds to the time series values at each time point. The main
aesthetic criterion for optimizing the readability of stacked area charts is
the amount of vertical change of the borders between the time series in the
visualization, called wiggle. While many heuristic algorithms have been
developed to minimize wiggle, the computational complexity of minimizing wiggle
has not been formally analyzed. In this paper, we show that different variants
of wiggle minimization are NP-hard and even hard to approximate. We also
present an exact mixed-integer linear programming formulation and compare its
performance with a state-of-the-art heuristic in an experimental evaluation.
Lastly, we consider a special case of wiggle minimization that corresponds to
the fundamentally interesting and natural problem of ordering a set of numbers
as to minimize their sum of absolute prefix sums. We show several complexity
results for this problem that imply some of the mentioned hardness results for
wiggle minimization.

</details>


### [11] [Vantage Point Selection Algorithms for Bottleneck Capacity Estimation](https://arxiv.org/abs/2506.21418)
*Vikrant Ashvinkumar,Rezaul Chowdhury,Jie Gao,Mayank Goswami,Joseph S. B. Mitchell,Valentin Polishchuk*

Main category: cs.DS

TL;DR: 研究了在图中选择最佳观测点以最大化揭示瓶颈边容量的问题，提出了非自适应和自适应两种设置下的近似算法和界限。


<details>
  <summary>Details</summary>
Motivation: 互联网中估计瓶颈容量的问题推动了观测点选择的研究，目的是通过最短路径揭示边的瓶颈容量。

Method: 在非自适应设置中，使用随机排列模型的1-1/e近似算法；在自适应设置中，研究固定但未知的容量模型，并对比最优解。

Result: 非自适应设置下提出近似算法；自适应设置下给出了实例最优近似算法的下界和树及平面图的上界。

Conclusion: 研究为图论中观测点选择问题提供了理论支持，展示了非自适应和自适应设置下的可行解决方案。

Abstract: Motivated by the problem of estimating bottleneck capacities on the Internet,
we formulate and study the problem of vantage point selection. We are given a
graph $G=(V, E)$ whose edges $E$ have unknown capacity values that are to be
discovered. Probes from a vantage point, i.e, a vertex $v \in V$, along
shortest paths from $v$ to all other vertices, reveal bottleneck edge
capacities along each path. Our goal is to select $k$ vantage points from $V$
that reveal the maximum number of bottleneck edge capacities.
  We consider both a non-adaptive setting where all $k$ vantage points are
selected before any bottleneck capacity is revealed, and an adaptive setting
where each vantage point selection instantly reveals bottleneck capacities
along all shortest paths starting from that point. In the non-adaptive setting,
by considering a relaxed model where edge capacities are drawn from a random
permutation (which still leaves the problem of maximizing the expected number
of revealed edges NP-hard), we are able to give a $1-1/e$ approximate
algorithm. In the adaptive setting we work with the least permissive model
where edge capacities are arbitrarily fixed but unknown. We compare with the
best solution for the particular input instance (i.e. by enumerating all
choices of $k$ tuples), and provide both lower bounds on instance optimal
approximation algorithms and upper bounds for trees and planar graphs.

</details>


### [12] [Succinct Preferential Attachment Graphs](https://arxiv.org/abs/2506.21436)
*Ziad Ismaili Alaoui,Namrata,Sebastian Wild*

Main category: cs.DS

TL;DR: 论文提出了一种基于图压缩的数据结构，该结构空间利用率随图的压缩性自动优化，并高效支持导航操作。


<details>
  <summary>Details</summary>
Motivation: 现有图压缩数据结构在空间利用率和通用性上存在局限，无法根据图的压缩性动态调整空间需求。

Method: 设计了一种自适应空间利用率的数据结构，通过分析实例最优空间使用，支持任意图的导航操作。

Result: 结构在Barabási-Albert模型下接近实例最优空间利用，并在通用图中保证不大于熵压缩边列表的大小。

Conclusion: 该数据结构在空间效率和导航操作支持上取得了显著改进，适用于多种图模型。

Abstract: Computing over compressed data combines the space saving of data compression
with efficient support for queries directly on the compressed representation.
Such data structures are widely applied in text indexing and have been
successfully generalised to trees. For graphs, support for computing over
compressed data remains patchy; typical results in the area of succinct data
structures are restricted to a specific class of graphs and use the same,
worst-case amount of space for any graph from this class.
  In this work, we design a data structure whose space usage automatically
improves with the compressibility of the graph at hand, while efficiently
supporting navigational operations (simulating adjacency-list access).
Specifically, we show that the space usage approaches the instance-optimal
space when the graph is drawn according to the classic Barab\'asi-Albert model
of preferential-attachment graphs. Our data-structure techniques also work for
arbitrary graphs, guaranteeing a size asymptotically no larger than an
entropy-compressed edge list. A key technical contribution is the careful
analysis of the instance-optimal space usage.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [13] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

Main category: cs.GR

TL;DR: 本文提出了一种通过操纵简单几何抽象来交互生成图像场景的方法，实现了高保真度、可编辑性和组合泛化能力的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成和编辑技术在场景的可编辑性和纹理一致性方面存在局限性，因此需要一个能够同时支持几何编辑和高质量图像生成的解决方案。

Method: 该方法通过将场景表示为凸3D基元的组合，并使用基于流的生成方法，结合深度和纹理提示来生成编辑后的图像。纹理提示考虑了修改后的3D基元，超越了现有的键值缓存技术。

Result: 定量和定性实验表明，该方法在视觉保真度、可编辑性和组合泛化能力方面优于先前的工作。

Conclusion: 本文的方法在生成和编辑场景图像方面表现出色，特别是在几何编辑和纹理一致性方面，提供了更高的灵活性和质量。

Abstract: We describe Generative Blocks World to interact with the scene of a generated
image by manipulating simple geometric abstractions. Our method represents
scenes as assemblies of convex 3D primitives, and the same scene can be
represented by different numbers of primitives, allowing an editor to move
either whole structures or small details. Once the scene geometry has been
edited, the image is generated by a flow-based method which is conditioned on
depth and a texture hint. Our texture hint takes into account the modified 3D
primitives, exceeding texture-consistency provided by existing key-value
caching techniques. These texture hints (a) allow accurate object and camera
moves and (b) largely preserve the identity of objects depicted. Quantitative
and qualitative experiments demonstrate that our approach outperforms prior
works in visual fidelity, editability, and compositional generalization.

</details>


### [14] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

Main category: cs.GR

TL;DR: 论文介绍了3DGH，一种无条件生成3D人头的模型，具有可组合的头发和面部组件，并通过新颖的数据表示和双生成器架构实现头发与面部的分离建模。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在建模头发和面部时存在纠缠问题，无法有效地分离二者的几何变化。3DGH旨在通过分离建模头发和面部，提供更灵活的3D人头生成和编辑能力。

Method: 提出了一种基于模板的3D高斯散射数据表示方法，并设计了双生成器架构和交叉注意力机制，以分离和建模头发与面部的相关性。

Result: 实验表明，3DGH在无条件全头图像合成和可组合3D发型编辑方面表现优异，优于多种现有的3D GAN方法。

Conclusion: 3DGH提供了一种有效的解决方案，能够分离建模头发和面部，为3D人头生成和编辑任务提供了新的方法。

Abstract: We present 3DGH, an unconditional generative model for 3D human heads with
composable hair and face components. Unlike previous work that entangles the
modeling of hair and face, we propose to separate them using a novel data
representation with template-based 3D Gaussian Splatting, in which deformable
hair geometry is introduced to capture the geometric variations across
different hairstyles. Based on this data representation, we design a 3D
GAN-based architecture with dual generators and employ a cross-attention
mechanism to model the inherent correlation between hair and face. The model is
trained on synthetic renderings using carefully designed objectives to
stabilize training and facilitate hair-face separation. We conduct extensive
experiments to validate the design choice of 3DGH, and evaluate it both
qualitatively and quantitatively by comparing with several state-of-the-art 3D
GAN methods, demonstrating its effectiveness in unconditional full-head image
synthesis and composable 3D hairstyle editing. More details will be available
on our project page: https://c-he.github.io/projects/3dgh/.

</details>


### [15] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
*Meng Du,Robert Amor,Kwan-Liu Ma,Burkhard C. Wünsche*

Main category: cs.GR

TL;DR: 系统综述分析了37篇研究论文，探讨了数据可视化和视觉分析在金融教育与素养提升中的应用，并分为五个关键领域进行分类和研究，为进一步提升金融素养提供了实践见解。


<details>
  <summary>Details</summary>
Motivation: 金融素养对个人做出明智的财务决策至关重要，但理解金融概念对许多人来说具有挑战性。数据可视化可以简化这些概念，使其更易于理解和吸引学习者。

Method: 通过系统综述37篇研究论文，分析数据可视化和视觉分析在金融教育中的应用，并将其分类为五个关键领域进行研究。

Result: 研究发现可视化工具在金融教育中的应用广泛，并指出研究空白和推进金融素养的机会，为教育者和专业人士提供了实践建议。

Conclusion: 数据可视化是提升金融素养的有效工具，研究为未来设计和利用可视化工具提供了重要指导，填补了研究空白。

Abstract: Financial literacy empowers individuals to make informed and effective
financial decisions, improving their overall financial well-being and security.
However, for many people understanding financial concepts can be daunting and
only half of US adults are considered financially literate. Data visualization
simplifies these concepts, making them accessible and engaging for learners of
all ages. This systematic review analyzes 37 research papers exploring the use
of data visualization and visual analytics in financial education and literacy
enhancement. We classify these studies into five key areas: (1) the evolution
of visualization use across time and space, (2) motivations for using
visualization tools, (3) the financial topics addressed and instructional
approaches used, (4) the types of tools and technologies applied, and (5) how
the effectiveness of teaching interventions was evaluated. Furthermore, we
identify research gaps and highlight opportunities for advancing financial
literacy. Our findings offer practical insights for educators and professionals
to effectively utilize or design visual tools for financial literacy.

</details>


### [16] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

Main category: cs.GR

TL;DR: VideoTex 是一个新颖的纹理合成框架，利用视频生成模型解决 3D 纹理中的空间和时间不一致问题，通过几何感知条件和结构化 UV 扩散策略，生成更一致、高质量的纹理。


<details>
  <summary>Details</summary>
Motivation: 当前的纹理合成方法由于缺乏全局上下文和几何理解，导致纹理在固定视角下不一致。视频生成模型在时间一致性上表现出色，因此被用于解决这一问题。

Method: VideoTex 结合几何感知条件和结构化 UV 扩散策略，利用 3D 网格结构精确生成纹理，并通过保留语义信息提升遮挡区域的生成质量。

Result: 实验表明，VideoTex 在纹理保真度、接缝融合和稳定性上优于现有方法，能够生成更平滑、时间稳定的纹理。

Conclusion: VideoTex 为需要高质量和时间一致性动态实时应用提供了有效解决方案，推动了纹理合成技术的进一步发展。

Abstract: Current texture synthesis methods, which generate textures from fixed
viewpoints, suffer from inconsistencies due to the lack of global context and
geometric understanding. Meanwhile, recent advancements in video generation
models have demonstrated remarkable success in achieving temporally consistent
videos. In this paper, we introduce VideoTex, a novel framework for seamless
texture synthesis that leverages video generation models to address both
spatial and temporal inconsistencies in 3D textures. Our approach incorporates
geometry-aware conditions, enabling precise utilization of 3D mesh structures.
Additionally, we propose a structure-wise UV diffusion strategy, which enhances
the generation of occluded areas by preserving semantic information, resulting
in smoother and more coherent textures. VideoTex not only achieves smoother
transitions across UV boundaries but also ensures high-quality, temporally
stable textures across video frames. Extensive experiments demonstrate that
VideoTex outperforms existing methods in texture fidelity, seam blending, and
stability, paving the way for dynamic real-time applications that demand both
visual quality and temporal coherence.

</details>


### [17] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
*Jiayi Zheng,Xiaodong Cun*

Main category: cs.GR

TL;DR: FairyGen是一种自动系统，能够从单张儿童绘画生成故事驱动的卡通视频，同时忠实保留其独特的艺术风格。


<details>
  <summary>Details</summary>
Motivation: 现有的故事生成方法主要集中在角色一致性和基本动作上，缺乏对艺术风格保留和电影级镜头设计的支持。FairyGen旨在解决这一问题，提供更具表现力和故事性的视频生成。

Method: 系统通过多模块协作实现这一目标：首先使用MLLM生成结构化故事板，再由风格传播适配器确保视觉一致性，并通过镜头设计模块提升视觉多样性和电影感。最后通过3D代理角色和图像到视频扩散模型完成动画生成。

Result: 实验结果表明，FairyGen生成的动画在艺术风格保留、叙事结构和自然动作方面表现出色，能够为用户提供个性化和引人入胜的故事动画。

Conclusion: FairyGen在保留儿童绘画独特风格的同时，成功生成了叙事连贯且视觉多样化的卡通视频，展示了其在个性化故事动画领域的潜力。

Abstract: We propose FairyGen, an automatic system for generating story-driven cartoon
videos from a single child's drawing, while faithfully preserving its unique
artistic style. Unlike previous storytelling methods that primarily focus on
character consistency and basic motion, FairyGen explicitly disentangles
character modeling from stylized background generation and incorporates
cinematic shot design to support expressive and coherent storytelling. Given a
single character sketch, we first employ an MLLM to generate a structured
storyboard with shot-level descriptions that specify environment settings,
character actions, and camera perspectives. To ensure visual consistency, we
introduce a style propagation adapter that captures the character's visual
style and applies it to the background, faithfully retaining the character's
full visual identity while synthesizing style-consistent scenes. A shot design
module further enhances visual diversity and cinematic quality through frame
cropping and multi-view synthesis based on the storyboard. To animate the
story, we reconstruct a 3D proxy of the character to derive physically
plausible motion sequences, which are then used to fine-tune an MMDiT-based
image-to-video diffusion model. We further propose a two-stage motion
customization adapter: the first stage learns appearance features from
temporally unordered frames, disentangling identity from motion; the second
stage models temporal dynamics using a timestep-shift strategy with frozen
identity weights. Once trained, FairyGen directly renders diverse and coherent
video scenes aligned with the storyboard. Extensive experiments demonstrate
that our system produces animations that are stylistically faithful,
narratively structured natural motion, highlighting its potential for
personalized and engaging story animation. The code will be available at
https://github.com/GVCLab/FairyGen

</details>


### [18] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
*Pin Ren,Yan Gao,Zhichun Li,Yan Chen,Benjamin Watson*

Main category: cs.GR

TL;DR: IDGraphs是一个交互式可视化系统，用于检测和分析网络中的流量异常和攻击，解决了现有入侵检测系统在交互性、攻击分析和相关性发现方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 网络流量异常和攻击日益普遍，现有入侵检测系统在交互性、蠕虫传播模式分析和相关性攻击发现方面支持有限，亟需改进。

Method: IDGraphs通过流级追踪的可视化，结合Histographs技术，将数据频率映射为亮度，用户可交互查询和分析数据。

Result: 在包含1.79亿条流级记录的真实网络数据集上，IDGraphs成功检测并分析了端口扫描、蠕虫爆发、TCP SYN洪泛等多种攻击和异常。

Conclusion: IDGraphs作为一种交互式可视化工具，能够有效支持快速准确的流量异常和攻击检测，尤其在分析和发现复杂攻击模式时表现出色。

Abstract: Traffic anomalies and attacks are commonplace in today's networks and
identifying them rapidly and accurately is critical for large network
operators. For a statistical intrusion detection system (IDS), it is crucial to
detect at the flow-level for accurate detection and mitigation. However,
existing IDS systems offer only limited support for 1) interactively examining
detected intrusions and anomalies, 2) analyzing worm propagation patterns, 3)
and discovering correlated attacks. These problems are becoming even more acute
as the traffic on today's high-speed routers continues to grow.
  IDGraphs is an interactive visualization system for intrusion detection that
addresses these challenges. The central visualization in the system is a
flow-level trace plotted with time on the horizontal axis and aggregated number
of unsuccessful connections on the vertical axis. We then summarize a stack of
tens or hundreds of thousands of these traces using the Histographs [RW05]
technique, which maps data frequency at each pixel to brightness. Users may
then interactively query the summary view, performing analysis by highlighting
subsets of the traces. For example, brushing a linked correlation matrix view
highlights traces with similar patterns, revealing distributed attacks that are
difficult to detect using standard statistical analysis.
  We apply IDGraphs system to a real network router data-set with 179M
flow-level records representing a total traffic of 1.16TB. The system
successfully detects and analyzes a variety of attacks and anomalies, including
port scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed
attacks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [19] [Smoothness Meets Autobidding: Tight Price of Anarchy Bounds for Simultaneous First-Price Auctions](https://arxiv.org/abs/2506.20908)
*Riccardo Colini-Baldeschi,Sophie Klumper,Twan Kroll,Stefano Leonardi,Guido Schäfer,Artem Tsikiridis*

Main category: cs.GT

TL;DR: 本文扩展了Syrgkanis和Tardos的平滑框架，用于自动竞价，提出了一种平衡异构代理类型平滑参数的技术，并证明了单物品首次价格拍卖的平滑性。


<details>
  <summary>Details</summary>
Motivation: 研究自动竞价系统中的价格无政府主义（POA）问题，尤其是异构代理行为下的边界，扩展现有平滑框架以简化分析。

Method: 通过扩展Syrgkanis和Tardos的平滑框架，提出一种平衡异构代理类型平滑参数的技术，并通过数学程序求解最佳POA边界。

Result: 证明了单物品首次价格拍卖的平滑性，并获得混合自动竞价下的紧POA边界2.18，同时扩展了多种模型的POA边界。

Conclusion: 提出的框架不仅简化了POA分析，还扩展了应用范围，为异构代理行为下的自动竞价系统提供了新的理论支持。

Abstract: Online advertising systems have recently transitioned to autobidding,
enabling advertisers to delegate bidding decisions to automated agents. Each
advertiser directs their agent to optimize a valuation-dependent objective
subject to return-on-investment (ROI) or budget constraints. Given their
relevance, there has been a surge in literature studying the liquid welfare
price of anarchy (POA) of core auction formats in autobidding, among which
simultaneous first-price auctions (FPA). These models capture a large range of
heterogeneous agent behaviors, requiring advanced proofs to derive tight POA
bounds. Recently, Deng et al. (NeurIPS 2024) showed that the POA of FPA for
mixed autobidders (i.e., value and utility maximizers) under ROI is 2.18 for
additive valuations.
  We extend the smoothness framework of Syrgkanis and Tardos (STOC 2013) to
autobidding. A key contribution is a technique to balance smoothness parameters
across heterogeneous agent types. Finding the best POA bound reduces to solving
a POA-revealing mathematical program. Our approach has three strengths: (1)
Simplicity: We prove smoothness for single-item FPA. Results for simultaneous
FPA follow via our theorem. For example, by showing smoothness for value and
utility maximizers, we obtain the tight POA of 2.18 for mixed autobidding. (2)
Extendibility: Our Extension Theorem adapts to simultaneous FPA with reserve
prices and agents with fractionally subadditive valuations and heterogeneous
payment sensitivities and target ROI parameters. We establish the first
(mostly) tight POA bounds for several models beyond the autobidding state of
the art. (3) Generality: Our framework bounds the POA of coarse correlated
equilibria (CCE), which arise when hybrid agents employ regret-minimizing
algorithms. Building on Kolumbus and Nisan (WWW 2022), we show that CCE from
such agents have properties that keep their POA low.

</details>


### [20] [From multi-allocations to allocations, with subadditive valuations](https://arxiv.org/abs/2506.21493)
*Uriel Feige*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We consider the problem of fair allocation of $m$ indivisible items to $n$
agents with monotone subadditive valuations. For integer $d \ge 2$, a
$d$-multi-allocation is an allocation in which each item is allocated to at
most $d$ different agents. We show that $d$-multi-allocations can be
transformed into allocations, while not losing much more than a factor of $d$
in the value that each agent receives. One consequence of this result is that
for allocation instances with equal entitlements and subadditive valuations, if
$\rho$-MMS $d$-multi-allocations exist, then so do $\frac{\rho}{4d}$-MMS
allocations. Combined with recent results of Seddighin and Seddighin [EC 2025],
this implies the existence of $\Omega(\frac{1}{\log\log n})$-MMS allocations.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [21] [Pebble Games and Algebraic Proof Systems](https://arxiv.org/abs/2506.21149)
*Lisa-Marie Jaser,Jacobo Toran*

Main category: cs.LO

TL;DR: 论文通过分析著名的0pebbling公式Peb$(G)$的反驳，证明了pebble游戏与代数证明系统之间的强连接，揭示了它们之间的平行关系，并展示了在特定条件下如何从pebbling策略中提取MC反驳。


<details>
  <summary>Details</summary>
Motivation: 研究pebble游戏与代数证明系统之间的连接，有助于深入理解两者的性质及其在计算复杂性中的应用。

Method: 通过分析DAG $G$上的pebbling策略与Monomial Calculus（MC）反驳之间的关系，提出了从pebbling策略提取MC反驳的方法，并对其他代数证明系统（如Nullstellensatz和Polynomial Calculus）进行了类似分析。

Result: 证明了在DAG $G$上，如果存在空间为$s$、时间为$t$的pebbling策略，则可以提取出具有相同空间和时间复杂度的MC反驳。同时，揭示了pebbling空间与代数证明系统中变量空间复杂度的对应关系。

Conclusion: 论文通过建立pebble游戏与代数证明系统之间的连接，为计算复杂性领域提供了新的见解，并证明了不同代数证明系统之间的分离和复杂性权衡。

Abstract: Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove
some new strong connections between pebble games and algebraic proof system,
showing that there is a parallelism between the reversible, black and
black-white pebbling games on one side, and the three algebraic proof systems
Nullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.
In particular we prove that for any DAG $G$ with a single sink, if there is a
Monomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and
size $t$ then there is a black pebbling strategy on $G$ with space $s$ and time
$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and
time $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having
simultaneously degree $s$ and size $ts$. These results are analogous to those
proven in {deRezende et al.21} for the case of reversible pebbling and
Nullstellensatz. Using them we prove degree separations between NS, MC and PC,
as well as strong degree-size tradeoffs for MC.
  We also notice that for any directed acyclic graph $G$ the space needed in a
pebbling strategy on $G$, for the three versions of the game, reversible, black
and black-white, exactly matches the variable space complexity of a refutation
of the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof
systems NS, MC and PC. Using known pebbling bounds on graphs, this connection
implies separations between the corresponding variable space measures.

</details>


### [22] [Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space](https://arxiv.org/abs/2506.21481)
*Eike Neumann*

Main category: cs.LO

TL;DR: 论文研究了在实数计算的比特模型中，点是否在连续映射迭代下逃离闭子集的问题，提出了一种部分决策方法，并在特定函数族中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在连续映射迭代下点逃离闭子集的可判定性问题，特别是在实数计算的比特模型中的复杂性和鲁棒性。

Method: 提出一种部分决策方法，确保其终止集包含所有针对该问题的部分决策方法的终止集，并在通用连续函数和特定刚性函数族（如仿射线性系统和二次复多项式）中进行验证。

Result: 部分决策方法的终止集在所有问题实例中是稠密的，并且在特定函数族（如二次复多项式）中具有完备性。

Conclusion: 该方法为点逃离闭子集问题提供了有效的决策手段，并验证了其在复杂动力学中的适用性，部分解决了Penrose（1989年）提出的Mandelbrot集可计算性问题。

Abstract: We study the problem of deciding whether a point escapes a closed subset of
$\mathbb{R}^d$ under the iteration of a continuous map $f \colon \mathbb{R}^d
\to \mathbb{R}^d$ in the bit-model of real computation. We give a sound partial
decision method for this problem which is complete in the sense that its
halting set contains the halting set of all sound partial decision methods for
the problem. Equivalently, our decision method terminates on all problem
instances whose answer is robust under all sufficiently small perturbations of
the function. We further show that the halting set of our algorithm is dense in
the set of all problem instances. While our algorithm applies to general
continuous functions, we demonstrate that it also yields complete decision
methods for much more rigid function families: affine linear systems and
quadratic complex polynomials. In the latter case, completeness is subject to
the density of hyperbolicity conjecture in complex dynamics. This in particular
yields an alternative proof of Hertling's (2004) conditional answer to a
question raised by Penrose (1989) regarding the computability of the Mandelbrot
set.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [23] [On pre-local tabularity above $\mathrm{S4}\times \mathrm{S4}$](https://arxiv.org/abs/2506.20874)
*Ilya B. Shapirovsky,Vladislav V. Sliusarev*

Main category: math.LO

TL;DR: 研究了S4×S4逻辑的正规扩展中的预局部表格性，发现有四种预局部表格逻辑，并给出了局部表格性的公理化准则。


<details>
  <summary>Details</summary>
Motivation: 探索S4×S4逻辑的正规扩展中的预局部表格性特性，并明确其在有限高度乘积中的分类及其行为。

Method: 分析了正规扩展中的预局部表格性，分类了有限高度乘积中的预局部表格逻辑，并给出了局部表格性的公理化准则。

Result: 确定了四种预局部表格逻辑在有限高度乘积中的存在，并描述了预局部表格双模态逻辑的例子。

Conclusion: 研究揭示了预局部表格逻辑的分类及其在S4×S4扩展中的分布，为相关逻辑领域提供了新的理论支持。

Abstract: We investigate pre-local tabularity in normal extensions of the logic
$\mathrm{S4}\times \mathrm{S4}$. We show that there are exactly four
pre-locally tabular logics in normal extensions of products of finite height,
and that every non-locally tabular logic in this family is contained in one of
them. We also give an axiomatic criterion of local tabularity above the logic
of products with Noetherian skeletons. Then we construct examples of
pre-locally tabular extensions of $\mathrm{S4}\times \mathrm{S4}$ outside this
class. In particular, we describe pre-locally tabular bimodal logics with the
converse and universal modalities.

</details>


### [24] [Splitting Families, Reaping Families, and Families of Permutations Associated with Asymptotic Density](https://arxiv.org/abs/2506.21059)
*David Valderrama*

Main category: math.LO

TL;DR: 研究了与自然数渐近密度相关的一些基数特征之间的关联，并回答了前述论文中的问题，证明了特定基数等于cov(\mathcal{M})和non(\mathcal{M})。


<details>
  <summary>Details</summary>
Motivation: 探讨基数特征之间的关联，验证和扩展前人研究中的问题。

Method: 研究了基数$\mathfrak{s}_X$、$\mathfrak{r}_X$和$\mathfrak{dd}_{X,Y}$的关系，并证明了特定等式。

Result: 证明了$\mathfrak{s}_0=$ cov$(\mathcal{M})$和$\mathfrak{r}_0=$ non$(\mathcal{M})$，并展示了其他基数关系的特定等式。

Conclusion: 通过研究，验证了基数特征之间的具体关系，并回答了前人提出的问题。

Abstract: We investigate several relations between cardinal characteristics of the
continuum related with the asymptotic density of the natural numbers and some
known cardinal invariants. Specifically, we study the cardinals of the form
$\mathfrak{s}_X$, $\mathfrak{r}_X$ and $\mathfrak{dd}_{X,Y}$ introduced in
arXiv:2304.09698 and arXiv:2410.21102, answering some questions raised in these
papers. In particular, we prove that $\mathfrak{s}_0=$ cov$(\mathcal{M})$ and
$\mathfrak{r}_0=$ non$(\mathcal{M})$. We also show that $\mathfrak{dd}_{\{r\},
\textsf{all}}=\mathfrak{dd}_{\{1/2\}, \textsf{all}}$ for all $r\in (0,1)$, and
we provide a proof of Con($\mathfrak{dd}_{(0,1),\{0,1\}}^{\textsf{rel}}<$
non$(\mathcal{N})$) and
Con($\mathfrak{dd}_{\textsf{all},\textsf{all}}^{\textsf{rel}}<$
non$(\mathcal{N})$).

</details>


### [25] [Polynomial fingerprinting for trees and formulas](https://arxiv.org/abs/2506.21114)
*Mihai Prunescu*

Main category: math.LO

TL;DR: 论文提出了一种将形式语句转化为2x2矩阵的方法，以支持零知识证明中的数学证明需求，并通过随机评估多项式变量生成数值序列，实现高效证明计算。


<details>
  <summary>Details</summary>
Motivation: 为了满足零知识证明中对数学证明的需求，需要一种能够将形式语句高效转化为可计算的技术，以便简化证明步骤（如假言推理和替换）的计算。

Method: 论文提出了一种将形式语句转化为2x2矩阵（包含整数系数的多元多项式）的方法。通过随机评估多项式变量的值并选择合适的有限域，证明被替换为数值序列。仅需重新计算公理对应的值，其他派生公式的值通过同态性质从祖先值中计算得出。

Result: 该方法能够高效地将复杂的数学证明转化为数值序列，并支持零知识证明技术在其上的应用。

Conclusion: 通过将形式语句转化为矩阵和数值序列，论文提供了一种高效的零知识证明方法，能够简化证明步骤的计算并支持多样化的零知识技术应用。

Abstract: To cater to the needs of (Zero Knowledge) proofs for (mathematical) proofs,
we describe a method to transform formal sentences in 2x2 - matrices over
multivariate polynomials with integer coefficients, such that usual proof-steps
like modus-ponens or the substitution are easy to compute from the matrices
corresponding to the terms or formulas used as arguments. By evaluating the
polynomial variables in random elements of a suitably chosen finite field, the
proof is replaced by a numeric sequence. Only the values corresponding to the
axioms have to be computed from scratch. The values corresponding to derived
formulas are computed from the values corresponding to their ancestors by
applying the homomorphic properties. On such sequences, various Zero Knowledge
methods can be applied.

</details>


<div id='math.RT'></div>

# math.RT [[Back]](#toc)

### [26] [On preservation of relative resolutions for poset representations](https://arxiv.org/abs/2506.21227)
*Toshitaka Aoki,Shunsuke Tada*

Main category: math.RT

TL;DR: 本文研究了Galois连接的一类特殊情况，其中左伴随为全子偏序集的典型包含，并引入收缩函子和归纳函子，证明了在有限可表示持续性模上的伴随关系，并分析了区间分解性和覆盖解析。


<details>
  <summary>Details</summary>
Motivation: 在表示理论中，Galois连接通过Kan扩展自然诱导持续性模类别的伴随四元组。本研究旨在探讨一类特殊的Galois连接，以便更好地理解持续性模的结构。

Method: 研究了一类Galois连接，其中左伴随为全子偏序集的典型包含，并引入收缩函子和归纳函子。证明了这些函子在有限可表示持续性模上的伴随关系，并分析了区间分解性。

Result: 证明了归纳和收缩函子在特定条件下保持模的区间分解性，并计算了某些有限偏序集的区间解析全局维度。

Conclusion: 通过研究特殊的Galois连接和引入的函子，本文为多参数持续性同调分析中的模结构提供了新的工具和结果。

Abstract: The concept of Galois connections (i.e., adjoint pairs between posets) is
ubiquitous in mathematics. In representation theory, it is interesting because
it naturally induces the adjoint quadruple between the categories of
persistence modules (representations) of the posets via Kan extensions. One of
central subjects in multiparameter persistent homology analysis is to
understand structures of persistence modules. In this paper, we mainly study a
class of Galois connections whose left adjoint is the canonical inclusion of a
full subposet. We refer to such a subposet as an interior system, with its
corresponding right adjoint given by the floor function. In the induced adjoint
quadruple, we call the left Kan extension along its floor function the
contraction functor. From its construction, it is left adjoint to the induction
functor. Under this setting, we firstly prove that this adjoint pair gives an
adjoint pair between finitely presentable persistence modules. Moreover, we
introduce a special class of interior systems called aligned interior systems,
and prove that both induction and contraction functors over them preserve
interval-decomposability of modules. Then, we use them to analyze interval
covers and resolutions. We also compute interval resolution global dimensions
for certain classes of finite posets.

</details>


### [27] [On some results of Harish-Chandra for representations of p-adic groups, extended to their central extensions](https://arxiv.org/abs/2506.21334)
*Volker Heiermann*

Main category: math.RT

TL;DR: 本文提供了Harish-Chandra理论中关于超尖表示抛物诱导不可约性与Harish-Chandra的mu函数解析行为关系的完整证明，并证明了该证明在中心扩张情况下依然有效。


<details>
  <summary>Details</summary>
Motivation: 本文旨在填补Harish-Chandra理论中关于超尖表示抛物诱导不可约性与mu函数解析行为关系的完整证明空白，并进一步验证该证明在中心扩展情况下的适用性。

Method: 通过分析Harish-Chandra的mu函数的解析行为，并结合抛物诱导的理论框架，本文给出了完整的证明过程。

Result: 结果表明，抛物诱导的超尖表示的不可约性与mu函数的解析行为直接相关，并且这一关系在中心扩张情况下依然成立。

Conclusion: 本文不仅完成了Harish-Chandra理论中一个重要问题的完整证明，还将其适用范围扩展到中心扩张的情况，为该领域的进一步研究提供了理论基础。

Abstract: The aim of this article is to give a complete proof of results of
Harish-Chandra linking the irreducibility of parabolic induction of a
supercuspidal representation of a p-adic group to the analytic behavior of the
mu-function of Harish-Chandra and to show that the proof remains valid in the
case of a central extension.

</details>


### [28] [The spectrum of global representations for families of bounded rank and VI-modules](https://arxiv.org/abs/2506.21525)
*Miguel Barrero,Tobias Barthel,Luca Pol,Neil Strickland,Jordan Williamson*

Main category: math.RT

TL;DR: 本文系统地研究了特征为零的域上的全局表示的派生范畴，通过张量三角几何计算了其Balmer谱，并揭示了其复杂的结构特性。


<details>
  <summary>Details</summary>
Motivation: 全局表示在经典表示理论、表示稳定性研究以及全局同伦理论中具有重要作用。本文旨在系统研究特征为零的域上全局表示的派生范畴，探索其在张量三角几何中的应用。

Method: 本文从张量三角几何的角度出发，计算了多种无限群族的Balmer谱，包括初等阿贝尔p-群、循环群和有界秩的有限阿贝尔p-群，并结合非刚性张量三角几何的新方法。

Result: 研究发现，有限阿贝尔p-群族的Balmer谱具有无限的Krull维度和无限的Cantor--Bendixson秩，揭示了复杂的现象。此外，还给出了有限生成派生VI模的完整tt理论分类。

Conclusion: 全局表示的派生范畴展现出丰富的结构和复杂的现象，为张量三角几何的研究提供了新的视角和应用。

Abstract: A global representation is a compatible collection of representations of the
outer automorphism groups of the finite groups belonging to a family
$\mathscr{U}$. These arise in classical representation theory, in the study of
representation stability, as well as in global homotopy theory. In this paper
we begin a systematic study of the derived category $\mathsf{D}(\mathscr{U};k)$
of global representations over fields $k$ of characteristic zero, from the
point-of-view of tensor-triangular geometry. We calculate its Balmer spectrum
for various infinite families of finite groups including elementary abelian
$p$-groups, cyclic groups, and finite abelian $p$-groups of bounded rank. We
then deduce that the Balmer spectrum associated to the family of finite abelian
$p$-groups has infinite Krull dimension and infinite Cantor--Bendixson rank,
illustrating the complex phenomena we encounter. As a concrete application, we
provide a complete tt-theoretic classification of finitely generated derived
VI-modules. Our proofs rely on subtle information about the growth behaviour of
global representations studied in a companion paper, as well as novel methods
from non-rigid tt-geometry.

</details>


### [29] [Transitivity of mutation of $τ$-exceptional sequences in the $τ$-tilting finite case](https://arxiv.org/abs/2506.21372)
*Aslak B. Buan,Eric J. Hanson,Bethany R. Marsh*

Main category: math.RT

TL;DR: 证明了对于τ-倾斜有限代数的完全τ-例外序列的突变是可传递的。


<details>
  <summary>Details</summary>
Motivation: 研究τ-倾斜有限代数中的完全τ-例外序列的突变性质，以深化对其结构和行为的理解。

Method: 使用数学证明方法，分析τ-倾斜有限代数中的完全τ-例外序列的突变性质。

Result: 证明了完全τ-例外序列的突变在τ-倾斜有限代数中具有可传递性。

Conclusion: 该结果为τ-倾斜有限代数的突变性质提供了新的理论基础，为进一步研究其结构和行为提供了支持。

Abstract: We prove that mutation of complete $\tau$-exceptional sequences is transitive
for $\tau$-tilting finite algebras.

</details>
