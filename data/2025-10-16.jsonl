{"id": "2510.13168", "categories": ["cs.GR", "cs.CG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.13168", "abs": "https://arxiv.org/abs/2510.13168", "authors": ["Aditya Ganeshan", "Kurt Fleischer", "Wenzel Jakob", "Ariel Shamir", "Daniel Ritchie", "Takeo Igarashi", "Maria Larsson"], "title": "MiGumi: Making Tightly Coupled Integral Joints Millable", "comment": "SIGGRAPH Asia/TOG 2025; project page:\n  https://bardofcodes.github.io/migumi/", "summary": "Traditional integral wood joints, despite their strength, durability, and\nelegance, remain rare in modern workflows due to the cost and difficulty of\nmanual fabrication. CNC milling offers a scalable alternative, but directly\nmilling traditional joints often fails to produce functional results because\nmilling induces geometric deviations, such as rounded inner corners, that alter\nthe target geometries of the parts. Since joints rely on tightly fitting\nsurfaces, such deviations introduce gaps or overlaps that undermine fit or\nblock assembly. We propose to overcome this problem by (1) designing a language\nthat represent millable geometry, and (2) co-optimizing part geometries to\nrestore coupling. We introduce Millable Extrusion Geometry (MXG), a language\nfor representing geometry as the outcome of milling operations performed with\nflat-end drill bits. MXG represents each operation as a subtractive extrusion\nvolume defined by a tool direction and drill radius. This parameterization\nenables the modeling of artifact-free geometry under an idealized zero-radius\ndrill bit, matching traditional joint designs. Increasing the radius then\nreveals milling-induced deviations, which compromise the integrity of the\njoint. To restore coupling, we formalize tight coupling in terms of both\nsurface proximity and proximity constraints on the mill-bit paths associated\nwith mating surfaces. We then derive two tractable, differentiable losses that\nenable efficient optimization of joint geometry. We evaluate our method on 30\ntraditional joint designs, demonstrating that it produces CNC-compatible,\ntightly fitting joints that approximates the original geometry. By\nreinterpreting traditional joints for CNC workflows, we continue the evolution\nof this heritage craft and help ensure its relevance in future making\npractices."}
{"id": "2510.13587", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.13587", "abs": "https://arxiv.org/abs/2510.13587", "authors": ["Chao Shi", "Shenghao Jia", "Jinhui Liu", "Yong Zhang", "Liangchao Zhu", "Zhonglei Yang", "Jinze Ma", "Chaoyue Niu", "Chengfei Lv"], "title": "HRM^2Avatar: High-Fidelity Real-Time Mobile Avatars from Monocular Phone Scans", "comment": "SIGGRAPH Asia 2025, Project Page:\n  https://acennr-engine.github.io/HRM2Avatar", "summary": "We present HRM$^2$Avatar, a framework for creating high-fidelity avatars from\nmonocular phone scans, which can be rendered and animated in real time on\nmobile devices. Monocular capture with smartphones provides a low-cost\nalternative to studio-grade multi-camera rigs, making avatar digitization\naccessible to non-expert users. Reconstructing high-fidelity avatars from\nsingle-view video sequences poses challenges due to limited visual and\ngeometric data. To address these limitations, at the data level, our method\nleverages two types of data captured with smartphones: static pose sequences\nfor texture reconstruction and dynamic motion sequences for learning\npose-dependent deformations and lighting changes. At the representation level,\nwe employ a lightweight yet expressive representation to reconstruct\nhigh-fidelity digital humans from sparse monocular data. We extract garment\nmeshes from monocular data to model clothing deformations effectively, and\nattach illumination-aware Gaussians to the mesh surface, enabling high-fidelity\nrendering and capturing pose-dependent lighting. This representation\nefficiently learns high-resolution and dynamic information from monocular data,\nenabling the creation of detailed avatars. At the rendering level, real-time\nperformance is critical for animating high-fidelity avatars in AR/VR, social\ngaming, and on-device creation. Our GPU-driven rendering pipeline delivers 120\nFPS on mobile devices and 90 FPS on standalone VR devices at 2K resolution,\nover $2.7\\times$ faster than representative mobile-engine baselines.\nExperiments show that HRM$^2$Avatar delivers superior visual realism and\nreal-time interactivity, outperforming state-of-the-art monocular methods."}
{"id": "2510.13794", "categories": ["cs.GR", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.13794", "abs": "https://arxiv.org/abs/2510.13794", "authors": ["Xue Bin Peng"], "title": "MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control", "comment": null, "summary": "MimicKit is an open-source framework for training motion controllers using\nmotion imitation and reinforcement learning. The codebase provides\nimplementations of commonly-used motion-imitation techniques and RL algorithms.\nThis framework is intended to support research and applications in computer\ngraphics and robotics by providing a unified training framework, along with\nstandardized environment, agent, and data structures. The codebase is designed\nto be modular and easily configurable, enabling convenient modification and\nextension to new characters and tasks. The open-source codebase is available\nat: https://github.com/xbpeng/MimicKit."}
{"id": "2510.12846", "categories": ["cs.GT", "math.PR", "91A05"], "pdf": "https://arxiv.org/pdf/2510.12846", "abs": "https://arxiv.org/abs/2510.12846", "authors": ["Andrea Collevecchio", "Gabor Lugosi", "Adrian Vetta", "Rui-Ray Zhang"], "title": "Finding a Nash equilibrium of a random win-lose game in expected polynomial time", "comment": null, "summary": "A long-standing open problem in algorithmic game theory asks whether or not\nthere is a polynomial time algorithm to compute a Nash equilibrium in a random\nbimatrix game. We study random win-lose games, where the entries of the\n$n\\times n$ payoff matrices are independent and identically distributed\n(i.i.d.) Bernoulli random variables with parameter $p=p(n)$. We prove that, for\nnearly all values of the parameter $p=p(n)$, there is an expected\npolynomial-time algorithm to find a Nash equilibrium in a random win-lose game.\nMore precisely, if $p\\sim cn^{-a}$ for some parameters $a,c\\ge 0$, then there\nis an expected polynomial-time algorithm whenever $a\\not\\in \\{1/2, 1\\}$. In\naddition, if $a = 1/2$ there is an efficient algorithm if either $c \\le e^{-52}\n2^{-8} $ or $c\\ge 0.977$. If $a=1$, then there is an expected polynomial-time\nalgorithm if either $c\\le 0.3849$ or $c\\ge \\log^9 n$."}
{"id": "2510.13082", "categories": ["cs.PL", "cs.SE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.13082", "abs": "https://arxiv.org/abs/2510.13082", "authors": ["Mark Koch", "Agustín Borgna", "Craig Roy", "Alan Lawrence", "Kartik Singhal", "Seyon Sivarajah", "Ross Duncan"], "title": "Imperative Quantum Programming with Ownership and Borrowing in Guppy", "comment": "Presented at the Fifth International Workshop on Programming\n  Languages for Quantum Computing (PLanQC 2025)", "summary": "Linear types enforce no-cloning and no-deleting theorems in functional\nquantum programming. However, in imperative quantum programming, they have not\ngained widespread adoption. This work aims to develop a quantum type system\nthat combines ergonomic linear typing with imperative semantics and maintains\nsafety guarantees. All ideas presented here have been implemented in\nQuantinuum's Guppy programming language."}
{"id": "2510.12862", "categories": ["cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.12862", "abs": "https://arxiv.org/abs/2510.12862", "authors": ["Rafał Kucharski", "Anastasia Psarou", "Natello Descormier"], "title": "Equilibria in routing games with connected autonomous vehicles will not be strong, as exclusive clubs may form", "comment": null, "summary": "User Equilibrium is the standard representation of the so-called routing game\nin which drivers adjust their route choices to arrive at their destinations as\nfast as possible. Asking whether this Equilibrium is strong or not was\nmeaningless for human drivers who did not form coalitions due to technical and\nbehavioral constraints. This is no longer the case for connected autonomous\nvehicles (CAVs), which will be able to communicate and collaborate to jointly\nform routing coalitions.\n  We demonstrate this for the first time on a carefully designed toy-network\nexample, where a `club` of three autonomous vehicles jointly decides to deviate\nfrom the user equilibrium and benefit (arrive faster). The formation of such a\nclub has negative consequences for other users, who are not invited to join it\nand now travel longer, and for the system, making it suboptimal and\ndisequilibrated, which triggers adaptation dynamics.\n  This discovery has profound implications for the future of our cities. We\ndemonstrate that, if not prevented, CAV operators may intentionally\ndisequilibrate traffic systems from their classic Nash equilibria, benefiting\ntheir own users and imposing costs on others. These findings suggest the\npossible emergence of an exclusive CAV elite, from which human-driven vehicles\nand non-coalition members may be excluded, potentially leading to\nsystematically longer travel times for those outside the coalition, which would\nbe harmful for the equity of public road networks."}
{"id": "2510.13236", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.13236", "abs": "https://arxiv.org/abs/2510.13236", "authors": ["Sebastian mateos Nicolajsen"], "title": "Extensibility in Programming Languages: An overview", "comment": null, "summary": "I here conduct an exploration of programming language extensibility, making\nan argument for an often overlooked component of conventional language design.\nNow, this is not a technical detailing of these components, rather, I attempt\nto provide an overview as I myself have lacked during my time investigating\nprogramming languages. Thus, read this as an introduction to the magical world\nof extensibility. Through a literature review, I identify key extensibility\nthemes - Macros, Modules, Types, and Reflection - highlighting diverse\nstrategies for fostering extensibility. The analysis extends to cross-theme\nproperties such as Parametricism and First-class citizen behaviour, introducing\nlayers of complexity by highlighting the importance of customizability and\nflexibility in programming language constructs. By outlining these facets of\nexisting programming languages and research, I aim to inspire future language\ndesigners to assess and consider the extensibility of their creations\ncritically."}
{"id": "2510.12952", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.12952", "abs": "https://arxiv.org/abs/2510.12952", "authors": ["Maneesha Papireddygari", "Xintong Wang", "Bo Waggoner", "David M. Pennock"], "title": "Efficiency of Constant Log Utility Market Makers", "comment": null, "summary": "Automated Market Makers (AMMs) are used to provide liquidity for\ncombinatorial prediction markets that would otherwise be too thinly traded.\nThey offer both buy and sell prices for any of the doubly exponential many\npossible securities that the market can offer. The problem of setting those\nprices is known to be #P-hard for the original and most well-known AMM, the\nlogarithmic market scoring rule (LMSR) market maker [Chen et al., 2008]. We\nfocus on another natural AMM, the Constant Log Utility Market Maker (CLUM).\nUnlike LMSR, whose worst-case loss bound grows with the number of outcomes,\nCLUM has constant worst-case loss, allowing the market to add outcomes on the\nfly and even operate over countably infinite many outcomes, among other\nfeatures. Simpler versions of CLUM underpin several Decentralized Finance\n(DeFi) mechanisms including the Uniswap protocol that handles billions of\ndollars of cryptocurrency trades daily. We first establish the computational\ncomplexity of the problem: we prove that pricing securities is #P-hard for\nCLUM, via a reduction from the model counting 2-SAT problem. In order to make\nCLUM more practically viable, we propose an approximation algorithm for pricing\nsecurities that works with high probability. This algorithm assumes access to\nan oracle capable of determining the maximum shares purchased of any one\noutcome and the total number of outcomes that has that maximum amount\npurchased. We then show that this oracle can be implemented in polynomial time\nwhen restricted to interval securities, which are used in designing financial\noptions."}
{"id": "2510.13426", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.13426", "abs": "https://arxiv.org/abs/2510.13426", "authors": ["Sehyeok Park", "Santosh Nagarakatte"], "title": "Fast Trigonometric Functions using the RLIBM Approach", "comment": "In Proceedings VSS 2025, arXiv:2510.12314", "summary": "This paper describes our experience developing polynomial approximations for\ntrigonometric functions that produce correctly rounded results for multiple\nrepresentations and rounding modes using the RLIBM approach. A key challenge\nwith trigonometric functions concerns range reduction with \"pi\", which reduces\na given input in the domain of a 32-bit float to a small domain. Any rounding\nerror in the value of \"pi\" is amplified during range reduction, which can\nresult in wrong results. We describe our experience implementing fast range\nreduction techniques that maintain a large number of bits of \"pi\" both with\nfloating-point and integer computations. The resulting implementations for\ntrigonometric functions are fast and produce correctly rounded results for all\ninputs for multiple representations up to 32-bits with a single implementation."}
{"id": "2510.13088", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.13088", "abs": "https://arxiv.org/abs/2510.13088", "authors": ["Rishi Patel", "Emmanouil Pountourakis", "Samuel Taggart"], "title": "Repeated Sales with Heterogeneous Buyer Sophistication", "comment": "To appear at WINE 2025", "summary": "This paper considers behavior-based price discrimination in the repeated sale\nof a non-durable good to a single long-lived buyer, by a seller without\ncommitment power. We assume that there is a mixed population of forward-looking\n``sophisticated'' buyers and myopic ``naive'' buyers. We investigate the impact\nof these dynamics on the seller's ability to learn about the buyer and exploit\nthis learning for revenue. We obtain conclusions that differ dramatically with\nthe time horizon of the interactions. To understand short time horizons, we\nanalyze a two-period model, and find that the strategic demand reduction\nobserved with fully sophisticated buyers is robust to the introduction of naive\ntypes. In fact, despite the inability of naive buyers to game the pricing\nalgorithm, their introduction can further harm the seller's revenue, due to\nmore intense demand reduction overall. For long horizons, we consider an\ninfinite-horizon model with time discounting. We find that the extreme demand\nreduction predicted by previous work does not survive the introduction of naive\nbuyers. Instead, we observe equilibria where the seller learns meaningfully\ndespite the sophisticated buyers' demand reduction. We prove that for a natural\nfamily of such equilibria, the seller's revenue is not just high, but\napproximates the revenue attainable with commitment power, even when the\nfraction of naive types is vanishingly small."}
{"id": "2510.13725", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.13725", "abs": "https://arxiv.org/abs/2510.13725", "authors": ["Celia Mengyue Li", "Sophie Pull", "Steven Ramsay"], "title": "A Complementary Approach to Incorrectness Typing", "comment": "Version conditionally accepted to POPL'26, with reviewer suggestions\n  incorporated", "summary": "We introduce a new two-sided type system for verifying the correctness and\nincorrectness of functional programs with atoms and pattern matching. A key\nidea in the work is that types should range over sets of normal forms, rather\nthan sets of values, and this allows us to define a complement operator on\ntypes that acts as a negation on typing formulas. We show that the complement\nallows us to derive a wide range of refutation principles within the system,\nincluding the type-theoretic analogue of co-implication, and we use them to\ncertify that a number of Erlang-like programs go wrong. An expressive\naxiomatisation of the complement operator via subtyping is shown decidable, and\nthe type system as a whole is shown to be not only sound, but also complete for\nnormal forms."}
{"id": "2510.13261", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.13261", "abs": "https://arxiv.org/abs/2510.13261", "authors": ["Björn Filter", "Ralf Möller", "Özgür Lütfü Özçep"], "title": "A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version", "comment": "Extended version of a paper accepted at the 26th International\n  Conference on Principles and Practice of Multi-Agent Systems (PRIMA 2025)", "summary": "Collaborative machine learning enables multiple data owners to jointly train\nmodels for improved predictive performance. However, ensuring incentive\ncompatibility and fair contribution-based rewards remains a critical challenge.\nPrior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative\nmachine learning with incentive-aware model rewards. In: International\nconference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by\nallocating model rewards, which are non-monetary and freely replicable, based\non the Shapley value of each party's data contribution, measured via\ninformation gain. In this paper, we introduce a ratio-based Shapley value that\nreplaces the standard additive formulation with a relative contribution\nmeasure. While our overall reward framework, including the incentive\ndefinitions and model-reward setting, remains aligned with that of Sim and\ncolleagues, the underlying value function is fundamentally different. Our\nalternative valuation induces a different distribution of model rewards and\noffers a new lens through which to analyze incentive properties. We formally\ndefine the ratio-based value and prove that it satisfies the same set of\nincentive conditions as the additive formulation, including adapted versions of\nfairness, individual rationality, and stability. Like the original approach,\nour method faces the same fundamental trade-offs between these incentives. Our\ncontribution is a mathematically grounded alternative to the additive Shapley\nframework, potentially better suited to contexts where proportionality among\ncontributors is more meaningful than additive differences."}
{"id": "2510.13518", "categories": ["cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.13518", "abs": "https://arxiv.org/abs/2510.13518", "authors": ["Shaul Rosner", "Marc Schröder", "Laura Vargas Koch"], "title": "Nash Flows Over Time with Tolls", "comment": null, "summary": "We study a dynamic routing game motivated by traffic flows. The base model\nfor an edge is the Vickrey bottleneck model. That is, edges are equipped with a\nfree flow transit time and a capacity. When the inflow into an edge exceeds its\ncapacity, a queue forms and the following particles experience a waiting time.\nIn this paper, we enhance the model by introducing tolls, i.e., a cost each\nflow particle must pay for traversing an edge. In this setting we consider\nnon-atomic equilibria, which means flows over time in which every particle is\non a cheapest path, when summing up toll and travel time. We first show that\nunlike in the non-tolled version of this model, dynamic equilibria are not\nunique in terms of costs and do not necessarily reach a steady state. As a main\nresult, we provide a procedure to compute steady states in the model with\ntolls."}
{"id": "2510.13633", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.13633", "abs": "https://arxiv.org/abs/2510.13633", "authors": ["Pooja Kulkarni", "Ruta Mehta", "Vishnu V. Narayan", "Tomasz Ponitka"], "title": "Online Fair Division With Subsidy: When Do Envy-Free Allocations Exist, and at What Cost?", "comment": "20 pages", "summary": "We study the problem of fairly allocating $m$ indivisible items arriving\nonline, among $n$ (offline) agents. Although envy-freeness has emerged as the\narchetypal fairness notion, envy-free (EF) allocations need not exist with\nindivisible items. To bypass this, a prominent line of research demonstrates\nthat there exist allocations that can be made envy-free by allowing a subsidy.\nExtensive work in the offline setting has focused on finding such envy-freeable\nallocations with bounded subsidy. We extend this literature to an online\nsetting where items arrive one at a time and must be immediately and\nirrevocably allocated. Our contributions are two-fold:\n  1. Maintaining EF Online: We show that envy-freeability cannot always be\npreserved online when the valuations are submodular or supermodular, even with\nbinary marginals. In contrast, we design online algorithms that maintain\nenvy-freeability at every step for the class of additive valuations, and for\nits superclasses including $k$-demand and SPLC valuations.\n  2. Ensuring Low Subsidy: We investigate the quantity of subsidy required to\nguarantee envy-freeness online. Surprisingly, even for additive valuations, the\nminimum subsidy may be as large as $\\Omega(mn)$, in contrast to the offline\nsetting, where the bound is $O(n)$. On the positive side, we identify valuation\nclasses where the minimum subsidy is small (i.e., does not depend on $m$),\nincluding $k$-valued, rank-one, restricted additive, and identical valuations,\nand we obtain (mostly) tight subsidy bounds for these classes."}
