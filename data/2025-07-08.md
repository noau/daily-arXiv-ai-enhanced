<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 6]
- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 13]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [MoDA: Multi-modal Diffusion Architecture for Talking Head Generation](https://arxiv.org/abs/2507.03256)
*Xinyang Li,Gen Li,Zhihui Lin,Yichen Qian,GongXin Yao,Weinan Jia,Weihua Chen,Fan Wang*

Main category: cs.GR

TL;DR: 论文提出了一种基于扩散模型的说话头生成方法MoDA，通过联合参数空间和多模态扩散架构，解决了现有方法中的推理效率低、面部表情不真实等问题。


<details>
  <summary>Details</summary>
Motivation: 数字人类和虚拟元宇宙中，说话头生成是一个重要问题。尽管扩散模型在此领域表现出色，但仍面临推理效率低、面部表情不真实等挑战，论文旨在解决这些问题。

Method: MoDA定义了联合参数空间以连接运动生成和神经渲染，并通过流匹配简化扩散学习过程；引入多模态扩散架构，以建模噪声运动、音频和辅助条件之间的交互。

Result: 实验结果表明，MoDA显著提高了视频的多样性、真实性和效率，适用于实际应用。

Conclusion: MoDA通过改进扩散模型的设计，解决了说话头生成中的关键挑战，提升了生成效果和实用性。

Abstract: Talking head generation with arbitrary identities and speech audio remains a
crucial problem in the realm of digital humans and the virtual metaverse.
Recently, diffusion models have become a popular generative technique in this
field with their strong generation and generalization capabilities. However,
several challenges remain for diffusion-based methods: 1) inefficient inference
and visual artifacts, which arise from the implicit latent space of Variational
Auto-Encoders (VAE), complicating the diffusion process; 2) authentic facial
expressions and head movements, resulting from insufficient multi-modal
information interaction. In this paper, MoDA handle these challenges by 1)
defines a joint parameter space to bridge motion generation and neural
rendering, and leverages flow matching to simplify the diffusion learning
process; 2) introduces a multi-modal diffusion architecture to model the
interaction among noisy motion, audio, and auxiliary conditions, ultimately
enhancing overall facial expressiveness. Subsequently, a coarse-to-fine fusion
strategy is adopted to progressively integrate different modalities, ensuring
effective integration across feature spaces. Experimental results demonstrate
that MoDA significantly improves video diversity, realism, and efficiency,
making it suitable for real-world applications.

</details>


### [2] [3D PixBrush: Image-Guided Local Texture Synthesis](https://arxiv.org/abs/2507.03731)
*Dale Decatur,Itai Lang,Kfir Aberman,Rana Hanocka*

Main category: cs.GR

TL;DR: 3D PixBrush是一种无需用户输入即可在3D网格上实现局部区域图像驱动编辑的方法，通过预测定位掩模和合成纹理来实现全局一致和局部精确的编辑。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种无需用户干预即可在3D网格上进行局部编辑的技术，以解决现有方法依赖用户输入（如涂鸦或边界框）的问题。

Method: 提出了一种改进的得分蒸馏采样技术，结合预测的定位掩模和参考图像（称为定位调制图像引导），以实现从零开始的定位掩模预测。

Result: 实验表明，该方法在各种3D网格和图像上均能实现准确的局部编辑，且定位掩模全局一致、局部精确。

Conclusion: 3D PixBrush提供了一种无需用户输入即可高效进行3D局部编辑的方案，为3D内容创作提供了新的可能性。

Abstract: We present 3D PixBrush, a method for performing image-driven edits of local
regions on 3D meshes. 3D PixBrush predicts a localization mask and a
synthesized texture that faithfully portray the object in the reference image.
Our predicted localizations are both globally coherent and locally precise.
Globally - our method contextualizes the object in the reference image and
automatically positions it onto the input mesh. Locally - our method produces
masks that conform to the geometry of the reference image. Notably, our method
does not require any user input (in the form of scribbles or bounding boxes) to
achieve accurate localizations. Instead, our method predicts a localization
mask on the 3D mesh from scratch. To achieve this, we propose a modification to
the score distillation sampling technique which incorporates both the predicted
localization and the reference image, referred to as localization-modulated
image guidance. We demonstrate the effectiveness of our proposed technique on a
wide variety of meshes and images.

</details>


### [3] [F-Hash: Feature-Based Hash Design for Time-Varying Volume Visualization via Multi-Resolution Tesseract Encoding](https://arxiv.org/abs/2507.03836)
*Jianxin Sun,David Lenz,Hongfeng Yu,Tom Peterka*

Main category: cs.GR

TL;DR: F-Hash是一种基于特征的多分辨率四维编码架构，显著提高了时变体数据建模的训练收敛速度，支持快速渲染和特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 时变体数据的可视化和处理面临数据量大、训练耗时长的问题，传统方法难以高效解决。

Method: 采用多级无碰撞哈希函数映射动态4D多分辨率嵌入网格，结合自适应光线行进算法优化渲染效率。

Result: 实验证明F-Hash在多种时变体数据集中实现了最快的训练收敛速度，并优化了渲染效果。

Conclusion: F-Hash为时变体数据的特征跟踪和演化可视化提供了一种高效且通用的编码解决方案。

Abstract: Interactive time-varying volume visualization is challenging due to its
complex spatiotemporal features and sheer size of the dataset. Recent works
transform the original discrete time-varying volumetric data into continuous
Implicit Neural Representations (INR) to address the issues of compression,
rendering, and super-resolution in both spatial and temporal domains. However,
training the INR takes a long time to converge, especially when handling
large-scale time-varying volumetric datasets. In this work, we proposed F-Hash,
a novel feature-based multi-resolution Tesseract encoding architecture to
greatly enhance the convergence speed compared with existing input encoding
methods for modeling time-varying volumetric data. The proposed design
incorporates multi-level collision-free hash functions that map dynamic 4D
multi-resolution embedding grids without bucket waste, achieving high encoding
capacity with compact encoding parameters. Our encoding method is agnostic to
time-varying feature detection methods, making it a unified encoding solution
for feature tracking and evolution visualization. Experiments show the F-Hash
achieves state-of-the-art convergence speed in training various time-varying
volumetric datasets for diverse features. We also proposed an adaptive ray
marching algorithm to optimize the sample streaming for faster rendering of the
time-varying neural representation.

</details>


### [4] [Attention-Guided Multi-Scale Local Reconstruction for Point Clouds via Masked Autoencoder Self-Supervised Learning](https://arxiv.org/abs/2507.04084)
*Xin Cao,Haoyu Wang,Yuzhu Mao,Xinda Liu,Linzhi Su,Kang Li*

Main category: cs.GR

TL;DR: PointAMaLR是一种新型的自监督学习框架，通过注意力引导的多尺度局部重建来增强点云的特征表示和处理精度。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要关注高层编码器的重建任务，忽视了低层局部特征的有效利用，这些特征通常仅用于激活计算。

Method: PointAMaLR实现了多尺度局部区域的分层重建，低层关注细粒度特征恢复，高层处理粗粒度特征重建，并结合了局部注意力模块增强语义特征理解。

Result: 在ModelNet和ShapeNet基准数据集上，PointAMaLR在分类和重建任务中表现出卓越的准确性和质量；在ScanObjectNN和S3DIS数据集上表现出高度竞争力。

Conclusion: PointAMaLR不仅验证了其在多尺度语义理解中的有效性，还强调了其在真实场景中的实际应用潜力。

Abstract: Self-supervised learning has emerged as a prominent research direction in
point cloud processing. While existing models predominantly concentrate on
reconstruction tasks at higher encoder layers, they often neglect the effective
utilization of low-level local features, which are typically employed solely
for activation computations rather than directly contributing to reconstruction
tasks. To overcome this limitation, we introduce PointAMaLR, a novel
self-supervised learning framework that enhances feature representation and
processing accuracy through attention-guided multi-scale local reconstruction.
PointAMaLR implements hierarchical reconstruction across multiple local
regions, with lower layers focusing on fine-scale feature restoration while
upper layers address coarse-scale feature reconstruction, thereby enabling
complex inter-patch interactions. Furthermore, to augment feature
representation capabilities, we incorporate a Local Attention (LA) module in
the embedding layer to enhance semantic feature understanding. Comprehensive
experiments on benchmark datasets ModelNet and ShapeNet demonstrate
PointAMaLR's superior accuracy and quality in both classification and
reconstruction tasks. Moreover, when evaluated on the real-world dataset
ScanObjectNN and the 3D large scene segmentation dataset S3DIS, our model
achieves highly competitive performance metrics. These results not only
validate PointAMaLR's effectiveness in multi-scale semantic understanding but
also underscore its practical applicability in real-world scenarios.

</details>


### [5] [A3FR: Agile 3D Gaussian Splatting with Incremental Gaze Tracked Foveated Rendering in Virtual Reality](https://arxiv.org/abs/2507.04147)
*Shuo Xin,Haiyu Wang,Sai Qian Zhang*

Main category: cs.GR

TL;DR: 论文提出了一种名为A3FR的高效渲染框架，通过并行化注视跟踪和注视点渲染过程，显著降低了实时图像渲染的延迟，同时保持了视觉质量。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实（VR）中的图像渲染方法如3D高斯泼溅计算需求高，导致实时渲染延迟大，影响用户体验。虽然注视点渲染可以降低计算负担，但注视跟踪过程本身的计算开销有时会超过渲染节省，增加延迟。

Method: 论文提出A3FR框架，通过并行化注视跟踪和注视点渲染过程，并使用3D高斯泼溅这一先进的神经渲染技术，以降低总体渲染延迟。

Result: 评估结果显示，A3FR能够在保持视觉质量的同时，将端到端渲染延迟降低至多2倍。

Conclusion: A3FR框架有效解决了注视点渲染中计算开销与延迟的权衡问题，为实时VR图像渲染提供了一种高效解决方案。

Abstract: Virtual reality (VR) significantly transforms immersive digital interfaces,
greatly enhancing education, professional practices, and entertainment by
increasing user engagement and opening up new possibilities in various
industries. Among its numerous applications, image rendering is crucial.
Nevertheless, rendering methodologies like 3D Gaussian Splatting impose high
computational demands, driven predominantly by user expectations for superior
visual quality. This results in notable processing delays for real-time image
rendering, which greatly affects the user experience. Additionally, VR devices
such as head-mounted displays (HMDs) are intricately linked to human visual
behavior, leveraging knowledge from perception and cognition to improve user
experience. These insights have spurred the development of foveated rendering,
a technique that dynamically adjusts rendering resolution based on the user's
gaze direction. The resultant solution, known as gaze-tracked foveated
rendering, significantly reduces the computational burden of the rendering
process.
  Although gaze-tracked foveated rendering can reduce rendering costs, the
computational overhead of the gaze tracking process itself can sometimes
outweigh the rendering savings, leading to increased processing latency. To
address this issue, we propose an efficient rendering framework
called~\textit{A3FR}, designed to minimize the latency of gaze-tracked foveated
rendering via the parallelization of gaze tracking and foveated rendering
processes. For the rendering algorithm, we utilize 3D Gaussian Splatting, a
state-of-the-art neural rendering technique. Evaluation results demonstrate
that A3FR can reduce end-to-end rendering latency by up to $2\times$ while
maintaining visual quality.

</details>


### [6] [Neuralocks: Real-Time Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.05191)
*Gene Wei-Chin Lin,Egor Larionov,Hsiao-yu Chen,Doug Roble,Tuur Stuyck*

Main category: cs.GR

TL;DR: 本文提出了一种新颖的神经网络方法，用于高效稳定的动态头发模拟，解决了现有方法无法捕捉头发动态行为的局限性。


<details>
  <summary>Details</summary>
Motivation: 实时头发模拟是创建逼真虚拟化身的重要组成部分，但目前的方法在动态行为模拟方面存在不足，尤其是神经方法仅限于准静态解决方案。

Method: 提出了一种完全自监督的神经网络方法，无需人工干预或艺术家生成的训练数据，利用紧凑、高效的内存网络实现头发丝级别的动态模拟。

Result: 该方法在多种发型示例中验证了有效性，展示了其在现实应用中的潜力，同时计算资源和内存需求较低。

Conclusion: 该方法突破了现有动态头发模拟的限制，为自动端到端虚拟化身重建提供了高效且稳定的解决方案。

Abstract: Real-time hair simulation is a vital component in creating believable virtual
avatars, as it provides a sense of immersion and authenticity. The dynamic
behavior of hair, such as bouncing or swaying in response to character
movements like jumping or walking, plays a significant role in enhancing the
overall realism and engagement of virtual experiences. Current methods for
simulating hair have been constrained by two primary approaches: highly
optimized physics-based systems and neural methods. However, state-of-the-art
neural techniques have been limited to quasi-static solutions, failing to
capture the dynamic behavior of hair. This paper introduces a novel neural
method that breaks through these limitations, achieving efficient and stable
dynamic hair simulation while outperforming existing approaches. We propose a
fully self-supervised method which can be trained without any manual
intervention or artist generated training data allowing the method to be
integrated with hair reconstruction methods to enable automatic end-to-end
methods for avatar reconstruction. Our approach harnesses the power of compact,
memory-efficient neural networks to simulate hair at the strand level, allowing
for the simulation of diverse hairstyles without excessive computational
resources or memory requirements. We validate the effectiveness of our method
through a variety of hairstyle examples, showcasing its potential for
real-world applications.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Towards Automatic Error Recovery in Parsing Expression](https://arxiv.org/abs/2507.03629)
*Sérgio Queiroz de Medeiros,Fabio Mascarenhas*

Main category: cs.PL

TL;DR: 本文提出了一种自动为解析表达式文法（PEGs）标注标签并构建恢复表达式的算法，用于实现语法错误的自动恢复，尤其在集成开发环境中（IDEs）中非常有用。


<details>
  <summary>Details</summary>
Motivation: 在集成开发环境中，解析器需要能够处理语法错误的程序以构建抽象语法树（AST），但目前为PEG手动标注标签和恢复表达式较为困难。

Method: 提出了一种算法，可以自动为PEG标注标签并构建相应的恢复表达式，利用PEG的表达能力实现语法错误的自动恢复。

Result: 通过在Titan编程语言的解析器中应用该算法，结果显示只需少量手动干预即可为大多数不重叠的替代项生成错误恢复解析器。

Conclusion: 该算法能够有效减少手动标注的工作量，为PEG生成具备错误恢复功能的解析器，尤其适用于集成开发环境中的语法分析任务。

Abstract: Error recovery is an essential feature for a parser that should be plugged in
Integrated Development Environments (IDEs), which must build Abstract Syntax
Trees (ASTs) even for syntactically invalid programs in order to offer features
such as automated refactoring and code completion.
  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes
recursive top-down parsers using a restricted form of backtracking. Labeled
failures are a conservative extension of PEGs that adds an error reporting
mechanism for PEG parsers, and these labels can also be associated with
recovery expressions to also be an error recovery mechanism. These expressions
can use the full expressivity of PEGs to recover from syntactic errors.
  Manually annotating a large grammar with labels and recovery expressions can
be difficult. In this work, we present an algorithm that automatically
annotates a PEG with labels, and builds their corresponding recovery
expressions. We evaluate this algorithm by adding error recovery to the parser
of the Titan programming language. The results shown that with a small amount
of manual intervention our algorithm can be used to produce error recovering
parsers for PEGs where most of the alternatives are disjoint.

</details>


### [8] [Semantically Separating Nominal Wyvern for Usability and Decidability](https://arxiv.org/abs/2507.03867)
*Yu Xiang Zhu,Amos Robinson,Sophia Roshal,Timothy Mou,Julian Mackay,Jonathan Aldrich,Alex Potanin*

Main category: cs.PL

TL;DR: 这篇论文提出了Nominal Wyvern，一种类似DOT的依赖类型系统，通过名义声明和结构精化的分离，解决了DOT中类型子类型可判定性的问题，同时保留了F边界多态和模块系统的表达能力。


<details>
  <summary>Details</summary>
Motivation: DOT演算结合了函数式语言和面向对象编程的特性，但导致了类型子类型可判定性的缺失。现有解决方案要么牺牲表达能力，要么牺牲易用性。论文旨在解决这一问题。

Method: 论文引入了Nominal Wyvern，通过在名义声明和结构精化之间建立"语义分离"，避免写出不可判定的递归类型。还采用了材料/形状分离技术来确保子类型的可判定性。

Result: Nominal Wyvern在不牺牲F边界多态和模块系统表达能力的前提下，实现了子类型的可判定性，同时保持了语法和结构对面向对象用户的友好性。

Conclusion: Nominal Wyvern提供了一种可行的解决方案，通过分离名义和结构类型，确保子类型的可判定性，同时保持了语言的表达能力。

Abstract: The Dependent Object Types (DOT) calculus incorporates concepts from
functional languages (e.g. modules) with traditional object-oriented features
(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded
polymorphism). However, this merger of paradigms comes at the cost of subtype
decidability. Recent work on bringing decidability to DOT has either sacrificed
expressiveness or ease of use. The unrestricted construction of recursive types
and type bounds has made subtype decidability a much harder problem than in
traditional object-oriented programming.
  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent
type system that takes an alternative approach: instead of having a uniform
structural syntax like DOT, Nominal Wyvern is designed around a "semantic
separation" between the nominal declaration of recursive types on the one hand,
and the structural refinement of those types when they are used on the other.
This design naturally guides the user to avoid writing undecidably recursive
structural types.
  From a technical standpoint, this separation also makes guaranteeing
decidability possible by allowing for an intuitive adaptation of material/shape
separation, a technique for achieving subtype decidability by separating types
responsible for subtyping constraints from types that represent concrete data.
The result is a type system with syntax and structure familiar to OOP users
that achieves decidability without compromising the expressiveness of F-bounded
polymorphism and module systems as they are used in practice.

</details>


### [9] [CCR 2.0: High-level Reasoning for Conditional Refinements](https://arxiv.org/abs/2507.04298)
*Youngju Song,Minki Cho*

Main category: cs.PL

TL;DR: CCR 2.0是一种新的形式验证方法，改进了CCR 1.0，提供了更直观的推理原则和更好的组合性定理，隐藏了分离逻辑的资源细节，并在Coq中进行了形式化验证。


<details>
  <summary>Details</summary>
Motivation: 近年来，低级系统的形式验证取得了巨大进展，但现有的两种主要方法（精化和分离逻辑）在性质上差异较大且具有互补优势。CCR 1.0尝试融合这两种方法的优点，但仍需改进。

Method: 本文提出CCR 2.0，改进了CCR 1.0的模型，引入了新的直观推理原则，包括更优的组合性定理和隐藏分离逻辑资源细节的证明技术。

Result: CCR 2.0显著提高了验证的可组合性和证明的重用性，同时解决了非平凡的逆向例子问题。研究成果已在Coq中形式化。

Conclusion: CCR 2.0为形式验证提供了一种更高效和直观的框架，既融合了现有方法的优势，又克服了其局限性，为未来的形式验证研究提供了新的方向。

Abstract: In recent years, great progress has been made in the field of formal
verification for low-level systems. Many of them are based on one of two
popular approaches: refinement or separation logic. These two approaches are
very different in nature and offer complementary benefits in terms of
compositionality. Recently, to fuse these benefits in a unified mechanism, a
new approach called Conditional Contextual Refinement (CCR 1.0 for short) was
proposed. In this paper, we advance the model of CCR 1.0 and provide novel and
intuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0
(i) comes with a better compositionality theorem, having the practical benefit
of facilitating more proof reuse, and (ii) provides a proof technique that
hides model-level (i.e., resources of the separation logic) details from the
user. Achieving this goal was challenging due to non-trivial counterexamples
which necessitated us to devise novel notions. Our results are formalized in
Coq.

</details>


### [10] [Retargeting an Abstract Interpreter for a New Language by Partial Evaluation](https://arxiv.org/abs/2507.04316)
*Jay Lee*

Main category: cs.PL

TL;DR: 提出一种通过部分评估技术，利用现有抽象解释器自动为目标语言生成新抽象解释器的方法，减少开发静态分析器的重复工作。


<details>
  <summary>Details</summary>
Motivation: 开发静态分析器通常耗时且重复，现有方法难以快速适应新语言需求，需探索自动化手段以减少开发成本。

Method: 利用部分评估技术，基于源语言的抽象解释器，通过目标语言语义进行特化，自动生成适用于目标语言的抽象解释器。

Result: 验证了该方法可以有效地将一种语言的抽象解释器转换为另一种语言的正确分析器。

Conclusion: 该方法避免了从头开发新目标分析器的需求，显著降低了开发负担，为自动生成抽象解释器提供了可行解决方案。

Abstract: It is well-known that abstract interpreters can be systematically derived
from their concrete counterparts using a "recipe," but developing sound static
analyzers remains a time-consuming task. Reducing the effort required and
mechanizing the process of developing analyzers continues to be a significant
challenge. Is it possible to automatically retarget an existing abstract
interpreter for a new language?
  We propose a novel technique to automatically derive abstract interpreters
for various languages from an existing abstract interpreter. By leveraging
partial evaluation, we specialize an abstract interpreter for a source
language. The specialization is performed using the semantics of target
languages written in the source language. Our approach eliminates the need to
develop analyzers for new targets from scratch. We show that our method can
effectively retarget an abstract interpreter for one language into a correct
analyzer for another language.

</details>


### [11] [React-tRace: A Semantics for Understanding React Hooks](https://arxiv.org/abs/2507.05234)
*Jay Lee,Joongwon Ahn,Kwangkeun Yi*

Main category: cs.PL

TL;DR: 这篇论文提出了一个名为React-tRace的框架，形式化React Hooks的语义，以帮助开发者更好地理解其行为，并展示了一个基于形式化的可视化工具。


<details>
  <summary>Details</summary>
Motivation: React Hooks在管理函数组件的副作用时，其语义对开发者而言通常显得不透明，导致用户界面错误。论文旨在澄清Hooks的行为，减少开发中的误解和错误。

Method: 论文通过形式化React Hooks的核心语义，提出了React-tRace框架，并通过理论证明和实验验证（与测试套件的对比）展示了模型的准确性。

Result: React-tRace框架成功捕捉了React Hooks的行为，并提供了一个实用的可视化工具，帮助开发者更直观地理解Hooks的语义。

Conclusion: 通过形式化和可视化工具，论文为开发者提供了更好的理解和调试React Hooks的方法，减少了因语义不透明导致的UI错误。

Abstract: React has become the most widely used web front-end framework, enabling the
creation of user interfaces in a declarative and compositional manner. Hooks
are a set of APIs that manage side effects in functional components in React.
However, their semantics are often seen as opaque to developers, leading to UI
bugs. In this paper, we formalize the semantics of the essence of React Hooks
we name React-tRace, providing a framework that clarifies their behavior. We
demonstrate that our model captures the behavior of React, by theoretically
showing that it embodies essential properties of Hooks and empirically
comparing our React-tRace-definitional interpreter against a test suite.
Furthermore, we showcase a practical visualization tool based on the
formalization to demonstrate how developers can better understand the semantics
of Hooks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [12] [Beyond Advertising: Mechanism Design for Platform-Wide Marketing Service "QuanZhanTui"](https://arxiv.org/abs/2507.02931)
*Ningyuan Li,Zhilin Zhang,Tianyan Long,Yuyao Liu,Rongquan Bai,Yurong Chen,Xiaotie Deng,Pengjie Wang,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.GT

TL;DR: 论文研究了电商平台新型营销服务QuanZhanTui的机制设计问题，提出了基于流动支付拍卖（LPA）的多目标优化方法，以平衡商家福利与平台用户体验。


<details>
  <summary>Details</summary>
Motivation: 商家在电商平台上的广告投入与总销售额关系不明确，导致运营效率低下。QuanZhanTui作为平台级营销服务，旨在提升商家营销效率和平台收入，但需要解决机制设计的挑战。

Method: 研究基于库存约束的价值最大化模型，提出了流动支付拍卖（LPA），通过商家流动福利的简单支付规则优化多目标平衡，并确保自动竞价环境下的激励机制兼容性。

Result: 理论证明LPA具有最优性和激励兼容性等理想特性。实验表明，LPA在QuanZhanTui中优于传统拍卖方式。

Conclusion: LPA为电商平台提供了一种高效且平衡的机制设计方法，显著提升了商家营销效率和平台收入。

Abstract: On e-commerce platforms, sellers typically bid for impressions from ad
traffic to promote their products. However, for most sellers, the majority of
their sales come from organic traffic. Consequently, the relationship between
their ad spending and total sales remains uncertain, resulting in operational
inefficiency. To address this issue, e-commerce platforms have recently
introduced a novel platform-wide marketing service known as QuanZhanTui, which
has reportedly enhanced marketing efficiency for sellers and driven substantial
revenue growth for platforms. QuanZhanTui allows sellers to bid for impressions
from the platform's entire traffic to boost their total sales without
compromising the platform's user experience. In this paper, we investigate the
mechanism design problem that arises from QuanZhanTui. The problem is
formulated as a multi-objective optimization to balance sellers' welfare and
platform's user experience. We first introduce the stock-constrained value
maximizer model, which reflects sellers' dual requirements on marketing
efficiency and platform-wide ROI. Then, we propose the Liquid Payment Auction
(LPA), an auction designed to optimize the balanced objectives while accounting
for sellers' requirements in the auto-bidding environment. It employs a simple
payment rule based on sellers' liquid welfare, providing a clearer link between
their investment and total sales. Under mild assumptions, we theoretically
prove desirable properties of LPA, such as optimality and incentive
compatibility. Extensive experiments demonstrate LPA's superior performance
over conventional auctions in QuanZhanTui.

</details>


### [13] [Last-Iterate Convergence of No-Regret Learning for Equilibria in Bargaining Games](https://arxiv.org/abs/2507.03150)
*Serafina Kamp,Reese Liebman,Benjamin Fish*

Main category: cs.GT

TL;DR: 本文研究了在议价博弈中无后悔学习算法何时收敛到纳什均衡的问题，特别是针对FTRL算法在最后迭代中的收敛性。


<details>
  <summary>Details</summary>
Motivation: 议价博弈是研究经济行为的重要工具，而在线学习算法在这些博弈中的收敛性是一个关键问题，尤其是针对无后悔学习算法在议价博弈中的表现。

Method: 使用了Follow the Regularized Leader (FTRL)算法，并在最简单的最后通牒博弈中验证其收敛性。进一步实验验证了在多轮议价博弈中的收敛行为。

Result: 研究发现，FTRL算法能够在最后迭代中收敛到近似纳什均衡，且在广泛的初始条件下也能收敛到具有不对称收益的纳什均衡。

Conclusion: 研究表明，简单的学习算法能够导致复杂的经济行为，并且FTRL算法在更广泛的博弈类型中具有收敛性。

Abstract: Bargaining games, where agents attempt to agree on how to split utility, are
an important class of games used to study economic behavior, which motivates a
study of online learning algorithms in these games. In this work, we tackle
when no-regret learning algorithms converge to Nash equilibria in bargaining
games. Recent results have shown that online algorithms related to Follow the
Regularized Leader (FTRL) converge to Nash equilibria (NE) in the last iterate
in a wide variety of games, including zero-sum games. However, bargaining games
do not have the properties used previously to established convergence
guarantees, even in the simplest case of the ultimatum game, which features a
single take-it-or-leave-it offer. Nonetheless, we establish that FTRL (without
the modifications necessary for zero-sum games) achieves last-iterate
convergence to an approximate NE in the ultimatum game along with a bound on
convergence time under mild assumptions. Further, we provide experimental
results to demonstrate that convergence to NE, including NE with asymmetric
payoffs, occurs under a broad range of initial conditions, both in the
ultimatum game and in bargaining games with multiple rounds. This work
demonstrates how complex economic behavior (e.g. learning to use threats and
the existence of many possible equilibrium outcomes) can result from using a
simple learning algorithm, and that FTRL can converge to equilibria in a more
diverse set of games than previously known.

</details>


### [14] [Iterative Vickrey Auctions via Linear Programming](https://arxiv.org/abs/2507.03252)
*Sébastien Lahaie,Benjamin Lubin*

Main category: cs.GT

TL;DR: 提出了一种基于线性规划的迭代拍卖方法，能够实现VCG结果，通过统一竞争均衡价格简化拍卖过程。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统迭代拍卖中多价格路径带来的复杂性和激励问题，探索一种透明且高效的拍卖机制。

Method: 将线性规划从竞争均衡价格转化为统一竞争均衡价格，结合原始-对偶算法，开发单一路径的迭代Vickrey拍卖。

Result: 成功设计了多单位环境和产品混合拍卖的迭代Vickrey拍卖，兼具价格发现的透明性和VCG机制的效率与激励性。

Conclusion: 该方法为拍卖机制设计提供了新的思路，实现了透明性和效率的结合，解决了传统拍卖中的问题。

Abstract: Building on the linear programming approach to competitive equilibrium
pricing, we develop a general method for constructing iterative auctions that
achieve Vickrey-Clarke-Groves (VCG) outcomes. We show how to transform a linear
program characterizing competitive equilibrium prices into one that
characterizes universal competitive equilibrium (UCE) prices, which elicit
precisely the information needed to compute VCG payments. By applying a
primal-dual algorithm to these transformed programs, we derive iterative
Vickrey auctions that maintain a single price path, eliminating the overhead
and incentive problems associated with multiple price paths used solely for
payment calculations. We demonstrate the versatility of our method by
developing a novel iterative Vickrey auction for the multi-unit setting and an
iterative variant of the Product-Mix auction. The resulting auctions combine
the transparency of iterative price discovery with the efficiency and incentive
properties of the VCG mechanism.

</details>


### [15] [Tight Efficiency Bounds for the Probabilistic Serial Mechanism under Cardinal Preferences](https://arxiv.org/abs/2507.03359)
*Jugal Garg,Yixin Tao,László A. Végh*

Main category: cs.GT

TL;DR: 该论文解决了概率串行（PS）机制在基数偏好下的效率问题，证明了其近似帕累托效率的上限，并为家务分配问题提供了首个公平且高效的近似保证。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索PS机制在基数偏好下的效率损失，并解决其在分配问题中的近似效率上限问题，同时扩展到家务分配领域。

Method: 通过分析PS机制的效率损失，证明了其在子模设置下的近似效率上限，并提出了一个多项式时间算法来计算无嫉妒且近似帕累托高效的分配。

Result: PS机制在基数偏好下达到(ln(n)+2)-近似帕累托效率，在子模设置下仍保持高效，同时在家务分配中提供n-近似效率。提出的算法实现了无嫉妒和e^{1/e}-近似高效。

Conclusion: PS机制在不同偏好和分配场景下均表现出高效性和公平性，为分配问题提供了理论基础和实用算法，填补了相关领域的空白。

Abstract: The Probabilistic Serial (PS) mechanism -- also known as the simultaneous
eating algorithm -- is a canonical solution for the assignment problem under
ordinal preferences. It guarantees envy-freeness and ordinal efficiency in the
resulting random assignment. However, under cardinal preferences, its
efficiency may degrade significantly: it is known that PS may yield allocations
that are $\Omega(\ln{n})$-worse than Pareto optimal, but whether this bound is
tight remained an open question.
  Our first result resolves this question by showing that the PS mechanism
guarantees $(\ln(n)+2)$-approximate Pareto efficiency, even in the more general
submodular setting introduced by Fujishige, Sano, and Zhan (ACM TEAC 2018).
This is established by showing that, although the PS mechanism may incur a loss
of up to $O(\sqrt{n})$ in utilitarian social welfare, it still achieves a
$(\ln{n}+2)$-approximation to the maximum Nash welfare. In addition, we present
a polynomial-time algorithm that computes an allocation which is envy-free and
$e^{1/e}$-approximately Pareto-efficient, answering an open question posed by
Tr\"obst and Vazirani (EC 2024).
  The PS mechanism also applies to the allocation of chores instead of goods.
We prove that it guarantees an $n$-approximately Pareto-efficient allocation in
this setting, and that this bound is asymptotically tight. This result provides
the first known approximation guarantee for computing a fair and efficient
allocation in the assignment problem with chores under cardinal preferences.

</details>


### [16] [On characterization and existence of a constrained correlated equilibria in Markov games](https://arxiv.org/abs/2507.03502)
*Tingting Ni,Anna Maddux,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 本文研究了耦合约束下的马尔可夫游戏中受约束的相关均衡，探讨了其在不同修改集合下的等价性及存在条件。


<details>
  <summary>Details</summary>
Motivation: 许多现实应用（如环境管理、电力市场和交通系统）中的决策涉及自利代理人的耦合约束，而现有的无约束相关均衡研究不足以解决这些问题。

Method: 作者首先通过表征受约束的相关均衡，证明不同修改集合可导致等价概念；随后，在玩家共享共同耦合约束的情况下，放宽了强Slater型条件，证明了受约束相关均衡的存在性。

Result: 研究结果表明，强Slater型条件在玩家独立的耦合约束下是必要的，但在共享共同约束时可以显著放宽，从而保证受约束相关均衡的存在。

Conclusion: 本文通过理论分析，为耦合约束下的马尔可夫游戏提供了受约束相关均衡的存在性证明及条件，为高效学习算法设计奠定了基础。

Abstract: Markov games with coupling constraints provide a natural framework to study
constrained decision-making involving self-interested agents, where the
feasibility of an individual agent's strategy depends on the joint strategies
of the others. Such games arise in numerous real-world applications involving
safety requirements and budget caps, for example, in environmental management,
electricity markets, and transportation systems. While correlated equilibria
have emerged as an important solution concept in unconstrained settings due to
their computational tractability and amenability to learning, their constrained
counterparts remain less explored. In this paper, we study constrained
correlated equilibria-feasible policies where any unilateral modifications are
either unprofitable or infeasible. We first characterize the constrained
correlated equilibrium showing that different sets of modifications result in
an equivalent notion, a result which may enable efficient learning algorithms.
We then address existence conditions. In particular, we show that a strong
Slater-type condition is necessary in games with playerwise coupling
constraints, but can be significantly weakened when all players share common
coupling constraints. Under this relaxed condition, we prove the existence of a
constrained correlated equilibrium.

</details>


### [17] [Fair and Efficient Allocation of Indivisible Mixed Manna](https://arxiv.org/abs/2507.03946)
*Siddharth Barman,Vishwa Prakash HV,Aditi Sethia,Mashbat Suzuki*

Main category: cs.GT

TL;DR: 研究不可分割混合物品（可能具有正、负或零价值）在加性估值代理人之间的公平分配，证明了存在一种松弛的无嫉妒分配（EFR-$k$）和帕累托最优分配（PO）的方法，并通过KKM定理实现。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在不可分割混合物品分配中同时实现公平性和效率，解决现有市场方法未能完全解决的问题。

Method: 通过松弛的无嫉妒分配（EFR-$k$）和帕累托最优分配（PO）结合，利用KKM定理和加扰估值的加权福利最大化实现目标。

Result: 证明在$n$个代理人中，EFR-$(n-1)$和PO分配始终存在，且可通过多项式时间计算；当物品为纯物品时，EFR-${\lfloor n/2 \rfloor}$分配存在且可高效计算。

Conclusion: 该研究通过新颖的数学工具和方法，进一步推动了不可分割混合物品公平和高效分配的理论与实践进步。

Abstract: We study fair division of indivisible mixed manna (items whose values may be
positive, negative, or zero) among agents with additive valuations. Here, we
establish that fairness -- in terms of a relaxation of envy-freeness -- and
Pareto efficiency can always be achieved together. Specifically, our fairness
guarantees are in terms of envy-freeness up to $k$ reallocations (EFR-$k$): An
allocation $A$ of the indivisible items is said to be EFR-$k$ if there exists a
subset $R$ of at most $k$ items such that, for each agent $i$, we can reassign
items from within $R$ (in $A$) and obtain an allocation, $A^i$, which is
envy-free for $i$. We establish that, when allocating mixed manna among $n$
agents with additive valuations, an EFR-$(n-1)$ and Pareto optimal (PO)
allocation $A$ always exists. Further, the individual envy-free allocations
$A^i$, induced by reassignments, are also PO. In addition, we prove that such
fair and efficient allocations are efficiently computable when the number of
agents, $n$, is fixed.
  We also obtain positive results focusing on EFR by itself (and without the PO
desideratum). Specifically, we show that an EFR-$(n-1)$ allocation of mixed
manna can be computed in polynomial time. In addition, we prove that when all
the items are goods, an EFR-${\lfloor n/2 \rfloor}$ allocation exists and can
be computed efficiently. Here, the $(n-1)$ bound is tight for chores and
$\lfloor n/2 \rfloor$ is tight for goods.
  Our results advance the understanding of fair and efficient allocation of
indivisible mixed manna and rely on a novel application of the
Knaster-Kuratowski-Mazurkiewicz (KKM) Theorem in discrete fair division. We
utilize weighted welfare maximization, with perturbed valuations, to achieve
Pareto efficiency, and overall, our techniques are notably different from
existing market-based approaches.

</details>


### [18] [Ex-Ante Truthful Distribution-Reporting Mechanisms](https://arxiv.org/abs/2507.04030)
*Xiaotie Deng,Yanru Guan,Ningyuan Li,Zihe Wang,Jie Zhang*

Main category: cs.GT

TL;DR: 本文研究在拍卖者不知买家真实价值分布的情境下，通过机制设计实现收入最大化。引入基于阈值增强机制的新方法，提出了Peer-Max机制，能够在一般非相同分布下实现近似收益保证。


<details>
  <summary>Details</summary>
Motivation: 经典机制如Myerson拍卖在事前阶段无法真实反映买家的价值分布，尽管在事中阶段满足贝叶斯激励相容。本文旨在设计事前激励相容的机制，以最大化收益。

Method: 提出了一种阈值增强机制家族，确保事前激励相容的同时通过事前阈值提升收益。基于此构建了Peer-Max机制，适用于非相同分布。

Result: Peer-Max机制对所有价值分布均能实现近似收益保证：其期望收益要么达到最优社会福利的常数比例，要么超过第二价格收益的常数比例。还提供了事前激励相容机制收益的上界。

Conclusion: 本文设计的新机制在事前激励相容和收益最大化方面取得了突破，并扩展到多单位同质物品拍卖场景。

Abstract: This paper studies mechanism design for revenue maximization in a
distribution-reporting setting, where the auctioneer does not know the buyers'
true value distributions. Instead, each buyer reports and commits to a bid
distribution in the ex-ante stage, which the auctioneer uses as input to the
mechanism. Buyers strategically decide the reported distributions to maximize
ex-ante utility, potentially deviating from their value distributions. As shown
in previous work, classical prior-dependent mechanisms such as the Myerson
auction fail to elicit truthful value distributions at the ex-ante stage,
despite satisfying Bayesian incentive compatibility at the interim stage. We
study the design of ex-ante incentive compatible mechanisms, and aim to
maximize revenue in a prior-independent approximation framework. We introduce a
family of threshold-augmented mechanisms, which ensures ex-ante incentive
compatibility while boosting revenue through ex-ante thresholds. Based on these
mechanisms, we construct the Peer-Max Mechanism, which achieves an either-or
approximation guarantee for general non-identical distributions. Specifically,
for any value distributions, its expected revenue either achieves a constant
fraction of the optimal social welfare, or surpasses the second-price revenue
by a constant fraction, where the constants depend on the number of buyers and
a tunable parameter. We also provide an upper bound on the revenue achievable
by any ex-ante incentive compatible mechanism, matching our lower bound up to a
constant factor. Finally, we extend our approach to a setting where multiple
units of identical items are sold to buyers with multi-unit demands.

</details>


### [19] [Deterministic Refund Mechanisms](https://arxiv.org/abs/2507.04148)
*Saeed Alaei,Shuchi Chawla,Zhiyi Huang,Ali Makhdoumi,Azarakhsh Malekian*

Main category: cs.GT

TL;DR: 论文研究了一种在买家和卖家共同建模但买家仅在收到商品后才知道真实价值的情况下，设计最优确定性机制的机制设计问题。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于探讨如何在买家和卖家共同建模但买家在收到商品后才确定其真实价值的情境下，设计最优的确定性机制，尤其是随机退款机制。

Method: 研究方法包括将机制解释为随机退款机制，并通过虚拟价值最大化的方式来描述连续和离散类型设置中的最优机制。此外，还结合菜单大小复杂度的界限来开发高效算法。

Result: 研究结果是成功设计了针对连续和离散类型设置的最优确定性机制，并开发了高效算法以找到最优或接近最优的确定性机制。

Conclusion: 论文的结论是，通过虚拟价值最大化和菜单大小复杂度的分析，可以有效设计并实现最优或接近最优的确定性机制，为实际应用提供了理论支持。

Abstract: We consider a mechanism design setting with a single item and a single buyer
who is uncertain about the value of the item. Both the buyer and the seller
have a common model for the buyer's value, but the buyer discovers her true
value only upon receiving the item. Mechanisms in this setting can be
interpreted as randomized refund mechanisms, which allocate the item at some
price and then offer a (partial and/or randomized) refund to the buyer in
exchange for the item if the buyer is unsatisfied with her purchase. Motivated
by their practical importance, we study the design of optimal deterministic
mechanisms in this setting. We characterize optimal mechanisms as virtual value
maximizers for both continuous and discrete type settings. We then use this
characterization, along with bounds on the menu size complexity, to develop
efficient algorithms for finding optimal and near-optimal deterministic
mechanisms.

</details>


### [20] [Adaptive Two-sided Assortment Optimization: Revenue Maximization](https://arxiv.org/abs/2507.04156)
*Mohammadreza,Ahmadnejadsaein,Omar El Housni*

Main category: cs.GT

TL;DR: 提出了用于最大化收益的自适应双边组合优化算法，针对选择匹配平台中的双边代理问题。


<details>
  <summary>Details</summary>
Motivation: 研究在双边代理匹配平台中，如何通过自适应选择策略最大化收益，填补现有工作在收益最大化背景下的不足。

Method: 设计多项式时间近似算法，基于多类别逻辑模型（MNL），并利用线性规划松弛、相关性间隙论证和收益函数的结构特性。

Result: 提出了随机算法，预期实现 (1/2 - ε) 近似保证；均匀收益场景下提升至 (1 - 1/e - ε)；特定结构场景下提出确定性算法实现 1/2 近似。

Conclusion: 所提出的算法在多种代理到达设置下均提供恒定因子保证，扩展了现有工作并解决了收益最大化问题。

Abstract: We study adaptive two-sided assortment optimization for revenue maximization
in choice-based matching platforms. The platform has two sides of agents, an
initiating side, and a responding side. The decision-maker sequentially selects
agents from the initiating side, shows each an assortment of agents from the
responding side, and observes their choices. After processing all initiating
agents, the responding agents are shown assortments and make their selections.
A match occurs when two agents mutually select each other, generating
pair-dependent revenue. Choices follow Multinomial Logit (MNL) models. This
setting generalizes prior work focused on maximizing the number of matches
under submodular demand assumptions, which do not hold in our
revenue-maximization context. Our main contribution is the design of
polynomial-time approximation algorithms with constant-factor guarantees. In
particular, for general pairwise revenues, we develop a randomized algorithm
that achieves a $(\frac{1}{2} - \epsilon)$-approximation in expectation for any
$\epsilon > 0$. The algorithm is static and provides guarantees under various
agent arrival settings, including fixed order, simultaneous processing, and
adaptive selection. When revenues are uniform across all pairs involving any
given responding-side agent, the guarantee improves to $(1 - \frac{1}{e} -
\epsilon)$. In structural settings where responding-side agents share a common
revenue-based ranking, we design a simpler adaptive deterministic algorithm
achieving a $\frac{1}{2}$-approximation. Our approach leverages novel linear
programming relaxations, correlation gap arguments, and structural properties
of the revenue functions.

</details>


### [21] [Constant-Approximate and Constant-Strategyproof Two-Facility Location](https://arxiv.org/abs/2507.04485)
*Elijah Journey Fullerton,Zeyuan Hu,C. Gregory Plaxton*

Main category: cs.GT

TL;DR: 论文研究了双设施选址问题的确定性机制，通过放松策略防护性和选址空间限制，提出了两种近似最优且策略防护的机制。


<details>
  <summary>Details</summary>
Motivation: 双设施选址问题中，任何策略防护机制的近似度都高达Ω(n)，因此需要通过放松问题要求来规避这一强下限。

Method: 论文采用了两种放松方式：1) 放松策略防护性至常数倍改进；2) 允许设施（而非代理）在平面上选址。并提出了两种机制：一种具有大输入变化敏感性，另一种满足Lipschitz连续性。

Result: 第一种机制是常数近似和常数策略防护的；第二种机制在此基础上还具备Lipschitz连续性。

Conclusion: 通过放松问题要求，论文成功设计了高性能的双设施选址机制，解决了策略防护性和近似度的根本矛盾。

Abstract: We study deterministic mechanisms for the two-facility location problem.
Given the reported locations of n agents on the real line, such a mechanism
specifies where to build the two facilities. The single-facility variant of
this problem admits a simple strategyproof mechanism that minimizes social
cost. For two facilities, however, it is known that any strategyproof mechanism
is $\Omega(n)$-approximate. We seek to circumvent this strong lower bound by
relaxing the problem requirements. Following other work in the facility
location literature, we consider a relaxed form of strategyproofness in which
no agent can lie and improve their outcome by more than a constant factor.
Because the aforementioned $\Omega(n)$ lower bound generalizes easily to
constant-strategyproof mechanisms, we introduce a second relaxation: Allowing
the facilities (but not the agents) to be located in the plane. Our first main
result is a natural mechanism for this relaxation that is constant-approximate
and constant-strategyproof. A characteristic of this mechanism is that a small
change in the input profile can produce a large change in the solution.
Motivated by this observation, and also by results in the facility reallocation
literature, our second main result is a constant-approximate,
constant-strategyproof, and Lipschitz continuous mechanism.

</details>


### [22] [Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments](https://arxiv.org/abs/2507.04592)
*Aadityan Ganesh,Qianfan Zhang*

Main category: cs.GT

TL;DR: 本文研究了一种在单维环境中的收入优化拍卖模型，扩展了之前针对单物品拍卖的研究成果，提出了一种适用于拟阵可行性约束的延迟揭示拍卖机制（DRA）。


<details>
  <summary>Details</summary>
Motivation: 此前的研究（Akbarpour和Li，2020）表明，任何收入最优、真实可信的机制都需要无限通信。本文通过使用加密承诺和区块链技术，将这一研究扩展到拟阵可行性约束的环境。

Method: 本文采用了延迟揭示拍卖（DRA）机制，要求竞标者提交押金，并通过可验证证据确保其行为符合机制要求。此外，还修改了此前提出的上升延迟揭示拍卖（ADRA）以适应更广泛的竞标者价值分布。

Result: 研究表明，DRA在拟阵环境中对所有α-强规则分布的竞标者价值，具有真实性、可信性和收入最优性。同时，DRA在非拟阵环境中或押金不足的情况下不可信。

Conclusion: 本文成功将延迟揭示拍卖机制扩展到拟阵约束环境，并验证了其有效性和局限性，为未来研究提供了新的方向。

Abstract: We consider a revenue-optimizing auctioneer in single-dimensional
environments with matroid feasibility constraints. Akbarpour and Li (2020)
argue that any revenue-optimal, truthful, and credible mechanism requires
unbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et
al., 2022; Chitra et al., 2024) circumvent their impossibility for the
single-item setting through the use of cryptographic commitments and
blockchains. We extend their results to matroid feasibility constraints.
  At a high level, the two-round Deferred-Revelation Auction (DRA) discussed by
Ferreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to
submit a deposit, which is slashed upon presenting verifiable evidence
indicating a deviation from the behaviour prescribed by the mechanism. We prove
that the DRA satisfies truthfulness, credibility and revenue-optimality for all
matroid environments when bidders' values are drawn from $\alpha$-strongly
regular distributions for $\alpha > 0$. Further, we argue that the DRA is not
credible for any feasibility constraint beyond matroids and for any smaller
deposits than suggested by previous literature even in single-item
environments.
  Finally, we modify the Ascending Deferred-Revelation Auction (ADRA) for
single-item settings proposed by Essaidi et al., (2022) for arbitrary bidder
value distributions. We implement a deferred-revelation variant of the
deferred-acceptance auction for matroids due to Bikhchandani et al., (2011),
which requires the same bounded communication as the ADRA.

</details>


### [23] [A number game reconciliation](https://arxiv.org/abs/2507.04717)
*Prem Kant,Urban Larsson*

Main category: cs.GT

TL;DR: 该论文重新审视了组合博弈理论中的数字游戏，指出了文献中的不一致和疏忽，并提出了一种更一致和健壮的表述方式。


<details>
  <summary>Details</summary>
Motivation: 论文的动机源于对组合博弈理论中数字游戏的重新审视，旨在解决现有文献中的不一致和疏忽，特别是游戏作为数字和游戏等于数字之间的区别。

Method: 作者从整数和二元游戏入手，分析了Conway和Siegel的定义，揭示了概念上的缺陷，并通过提出数字的精细化分类（如二元游戏、标准形式、群论闭包和zugzwangs）来改进理论。

Result: 研究提出了一种更一致和健壮的数字游戏理论框架，澄清了现有的模糊之处，并发现了几个开放性问题。

Conclusion: 论文通过重新定义和精细化数字游戏的分类，不仅解决了文献中的不一致问题，还为未来的研究提出了新的方向。

Abstract: Number games play a central role in alternating normal play combinatorial
game theory due to their real-number-like properties (Conway 1976). Here we
undertake a critical re-examination: we begin with integer and dyadic games and
identify subtle inconsistencies and oversights in the established literature
(e.g. Siegel 2013), most notably, the lack of distinction between a game being
a number and a game being equal to a number. After addressing this, we move to
the general theory of number games. We analyze Conway's original definition and
a later refinement by Siegel, and highlight conceptual gaps that have largely
gone unnoticed. Through a careful dissection of these issues, we propose a more
coherent and robust formulation. Specifically, we develop a refined
characterization of numbers, via several subclasses, dyadics, canonical forms,
their group theoretic closure and zugzwangs, that altogether better capture the
essence of number games. This reconciliation not only clarifies existing
ambiguities but also uncovers several open problems.

</details>


### [24] [Vector Cost Bimatrix Games with Applications to Autonomous Racing](https://arxiv.org/abs/2507.05171)
*Benjamin R. Toaz,Shaunak D. Bopardikar*

Main category: cs.GT

TL;DR: 提出了一种向量成本替代方法，用于加权和组合多目标成本，通过优化调整实现纯且唯一的纳什均衡和帕累托最优解。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过向量成本替代传统标量化方法，以在多重目标成本中找到更优的平衡点，避免最坏结果。

Method: 采用精确势博弈约束来引导成本调整，最小化与原始成本结构的偏差，并通过调整幅度区分帕累托最优解。

Result: 在异构成本结构的智能体竞赛中实施该方法，减少了碰撞事件且性能下降最小。

Conclusion: 该方法成功实现了纯且唯一的纳什均衡和帕累托最优解，有效优化了多目标成本问题。

Abstract: We formulate a vector cost alternative to the scalarization method for
weighting and combining multi-objective costs. The algorithm produces solutions
to bimatrix games that are simultaneously pure, unique Nash equilibria and
Pareto optimal with guarantees for avoiding worst case outcomes. We achieve
this by enforcing exact potential game constraints to guide cost adjustments
towards equilibrium, while minimizing the deviation from the original cost
structure. The magnitude of this adjustment serves as a metric for
differentiating between Pareto optimal solutions. We implement this approach in
a racing competition between agents with heterogeneous cost structures,
resulting in fewer collision incidents with a minimal decrease in performance.
Code is available at https://github.com/toazbenj/race_simulation.

</details>
