<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 15]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 8]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [DiffTex: Differentiable Texturing for Architectural Proxy Models](https://arxiv.org/abs/2509.23336)
*Weidan Xiong,Yongli Wu,Bochuan Zeng,Jianwei Guo,Dani Lischinski,Daniel Cohen-Or,Hui Huang*

Main category: cs.GR

TL;DR: 本文提出了一种自动化方法，用于从无序RGB照片中为建筑代理模型生成高质量的纹理贴图，以补偿几何简化带来的细节损失。


<details>
  <summary>Details</summary>
Motivation: 建筑代理模型的几何简化会导致精细颜色和几何细节的丢失，因此需要纹理来补偿这些损失。然而，从无序RGB照片中保留原始密集建筑重建的丰富纹理信息仍是一个挑战。

Method: 该方法通过建立UV贴图上的纹理单元与输入图像中的像素之间的对应关系，并优化混合参数，利用可微分渲染确保光度和透视一致性，同时保持无缝纹理连贯性。

Result: 实验结果表明，该方法在不同建筑模型和多种摄影条件下均表现出高效性和鲁棒性，能够生成保留视觉保真度和结构细节的高质量纹理。

Conclusion: 本文的方法成功地解决了建筑代理模型纹理生成的挑战，为高质量纹理的自动化创建提供了有效工具。

Abstract: Simplified proxy models are commonly used to represent architectural
structures, reducing storage requirements and enabling real-time rendering.
However, the geometric simplifications inherent in proxies result in a loss of
fine color and geometric details, making it essential for textures to
compensate for the loss. Preserving the rich texture information from the
original dense architectural reconstructions remains a daunting task,
particularly when working with unordered RGB photographs. We propose an
automated method for generating realistic texture maps for architectural proxy
models at the texel level from an unordered collection of registered
photographs. Our approach establishes correspondences between texels on a UV
map and pixels in the input images, with each texel's color computed as a
weighted blend of associated pixel values. Using differentiable rendering, we
optimize blending parameters to ensure photometric and perspective consistency,
while maintaining seamless texture coherence. Experimental results demonstrate
the effectiveness and robustness of our method across diverse architectural
models and varying photographic conditions, enabling the creation of
high-quality textures that preserve visual fidelity and structural detail.

</details>


### [2] [Modeling and Exploiting the Time Course of Chromatic Adaptation for Display Power Optimizations in Virtual Reality](https://arxiv.org/abs/2509.23489)
*Ethan Chen,Sushant Kondguli,Carl Marshall,Yuhao Zhu*

Main category: cs.GR

TL;DR: 提出一种无眼动追踪的方法，通过利用色适应的时间过程，减少VR中OLED显示的功耗，同时最小化感知影响。


<details>
  <summary>Details</summary>
Motivation: VR设备中OLED显示的高功耗问题需要解决，同时需确保用户的感知质量不受显著影响。

Method: 利用人类视觉系统在光照变化下保持颜色感知稳定的能力，提出了一种新的心理物理范式，计算最优光照偏移轨迹以减少功耗。

Result: 该方法显著提高了感知质量，并可与其他技术结合，减少31%的显示功耗，且不影响感知质量。

Conclusion: 该技术为VR显示提供了高效的节能方案，同时保持了用户体验。

Abstract: We introduce a gaze-tracking--free method to reduce OLED display power
consumption in VR with minimal perceptual impact. This technique exploits the
time course of chromatic adaptation, the human visual system's ability to
maintain stable color perception under changing illumination. To that end, we
propose a novel psychophysical paradigm that models how human adaptation state
changes with the scene illuminant. We exploit this model to compute an optimal
illuminant shift trajectory, controlling the rate and extent of illumination
change, to reduce display power under a given perceptual loss budget. Our
technique significantly improves the perceptual quality over prior work that
applies illumination shifts instantaneously. Our technique can also be combined
with prior work on luminance dimming to reduce display power by 31% with no
statistical loss of perceptual quality.

</details>


### [3] [Automated design of compound lenses with discrete-continuous optimization](https://arxiv.org/abs/2509.23572)
*Arjun Teh,Delio Vicini,Bernd Bickel,Ioannis Gkioulekas,Matthew O'Toole*

Main category: cs.GR

TL;DR: 本文提出了一种可以自动联合更新复合透镜设计的连续和离散参数的方法，以提高其锐度和速度性能。该方法通过结合梯度优化和马尔可夫链蒙特卡洛采样算法，实现了对透镜元素数量和类型等离散参数的优化。


<details>
  <summary>Details</summary>
Motivation: 传统的复合透镜设计方法仅通过梯度优化更新连续参数（如单个透镜元素的曲率），需要专家干预以实现拓扑变化。本文旨在实现一种无需专家干预即可自动优化离散参数的方法。

Method: 该方法结合了梯度优化和定制化的马尔可夫链蒙特卡洛采样算法，利用跨维度突变和近轴投影操作进行高效的全局探索。

Result: 实验结果表明，该方法能有效扩展复合透镜的设计空间，产生优于传统方法的设计，并突破自动透镜设计中速度与锐度权衡的极限。

Conclusion: 本文的方法在自动优化透镜设计的连续和离散参数方面表现出色，显著提升了设计效果，为自动化透镜设计开辟了新途径。

Abstract: We introduce a method that automatically and jointly updates both continuous
and discrete parameters of a compound lens design, to improve its performance
in terms of sharpness, speed, or both. Previous methods for compound lens
design use gradient-based optimization to update continuous parameters (e.g.,
curvature of individual lens elements) of a given lens topology, requiring
extensive expert intervention to realize topology changes. By contrast, our
method can additionally optimize discrete parameters such as number and type
(e.g., singlet or doublet) of lens elements. Our method achieves this
capability by combining gradient-based optimization with a tailored Markov
chain Monte Carlo sampling algorithm, using transdimensional mutation and
paraxial projection operations for efficient global exploration. We show
experimentally on a variety of lens design tasks that our method effectively
explores an expanded design space of compound lenses, producing better designs
than previous methods and pushing the envelope of speed-sharpness tradeoffs
achievable by automated lens design.

</details>


### [4] [ZeroScene: A Zero-Shot Framework for 3D Scene Generation from a Single Image and Controllable Texture Editing](https://arxiv.org/abs/2509.23607)
*Xiang Tang,Ruotong Li,Xiaopeng Fan*

Main category: cs.GR

TL;DR: ZeroScene是一种新型系统，利用大型视觉模型的先验知识，以零样本方式实现单图像到3D场景重建和纹理编辑，同时确保场景一致性和纹理多视角连续性。


<details>
  <summary>Details</summary>
Motivation: 在3D内容生成领域，单图像场景重建方法难以同时保证复杂环境中单个资产的质量和整体场景的连贯性，而纹理编辑技术则难以维持局部连续性和多视角一致性。

Method: ZeroScene通过提取输入图像的物体级2D分割和深度信息推断场景空间关系，联合优化点云的3D和2D投影损失以更新物体姿态，实现精确场景对齐，并通过扩散模型约束和掩码引导的渐进图像生成策略支持纹理编辑。

Result: 实验结果表明，ZeroScene不仅能确保生成资产的几何和外观准确性，还能忠实重建场景布局并生成与文本提示高度一致的详细纹理。

Conclusion: ZeroScene为复杂环境中的3D内容生成提供了一种高效解决方案，显著提升了场景重建和纹理编辑的质量与一致性。

Abstract: In the field of 3D content generation, single image scene reconstruction
methods still struggle to simultaneously ensure the quality of individual
assets and the coherence of the overall scene in complex environments, while
texture editing techniques often fail to maintain both local continuity and
multi-view consistency. In this paper, we propose a novel system ZeroScene,
which leverages the prior knowledge of large vision models to accomplish both
single image-to-3D scene reconstruction and texture editing in a zero-shot
manner. ZeroScene extracts object-level 2D segmentation and depth information
from input images to infer spatial relationships within the scene. It then
jointly optimizes 3D and 2D projection losses of the point cloud to update
object poses for precise scene alignment, ultimately constructing a coherent
and complete 3D scene that encompasses both foreground and background.
Moreover, ZeroScene supports texture editing of objects in the scene. By
imposing constraints on the diffusion model and introducing a mask-guided
progressive image generation strategy, we effectively maintain texture
consistency across multiple viewpoints and further enhance the realism of
rendered results through Physically Based Rendering (PBR) material estimation.
Experimental results demonstrate that our framework not only ensures the
geometric and appearance accuracy of generated assets, but also faithfully
reconstructs scene layouts and produces highly detailed textures that closely
align with text prompts.

</details>


### [5] [DFG-PCN: Point Cloud Completion with Degree-Flexible Point Graph](https://arxiv.org/abs/2509.23703)
*Zhenyu Shu,Jian Yao,Shiqing Xin*

Main category: cs.GR

TL;DR: 本文提出了一种名为DFG-PCN的自适应点云补全框架，通过结合特征变化和曲率的细节感知度量，灵活分配节点度数，并结合几何感知图集成模块，显著提升了点云补全效果。


<details>
  <summary>Details</summary>
Motivation: 点云补全任务由于遮挡和传感器分辨率限制导致的不完整性，传统方法依赖于固定的局部区域划分（如k近邻），无法适应形状不同区域的几何复杂度不均分布，导致表示效率低下和重构效果不佳，特别是在细粒度细节或结构不连续的区域。

Method: 提出了DFG-PCN框架，采用结合特征变化和曲率的细节感知度量自适应分配节点度数，并引入几何感知图集成模块，利用曼哈顿距离进行边聚合和细节引导的局部与全局特征融合。

Result: 在多个基准数据集上的广泛实验表明，DFG-PCN方法在点云补全任务中持续优于现有最先进方法。

Conclusion: DFG-PCN框架通过自适应节点分配和几何感知特征融合，有效解决了点云补全中的几何分布不均问题，显著提升了补全效果。

Abstract: Point cloud completion is a vital task focused on reconstructing complete
point clouds and addressing the incompleteness caused by occlusion and limited
sensor resolution. Traditional methods relying on fixed local region
partitioning, such as k-nearest neighbors, which fail to account for the highly
uneven distribution of geometric complexity across different regions of a
shape. This limitation leads to inefficient representation and suboptimal
reconstruction, especially in areas with fine-grained details or structural
discontinuities. This paper proposes a point cloud completion framework called
Degree-Flexible Point Graph Completion Network (DFG-PCN). It adaptively assigns
node degrees using a detail-aware metric that combines feature variation and
curvature, focusing on structurally important regions. We further introduce a
geometry-aware graph integration module that uses Manhattan distance for edge
aggregation and detail-guided fusion of local and global features to enhance
representation. Extensive experiments on multiple benchmark datasets
demonstrate that our method consistently outperforms state-of-the-art
approaches.

</details>


### [6] [StrucADT: Generating Structure-controlled 3D Point Clouds with Adjacency Diffusion Transformer](https://arxiv.org/abs/2509.23709)
*Zhenyu Shu,Jiajun Shen,Zhongui Chen,Xiaoguang Han,Shiqing Xin*

Main category: cs.GR

TL;DR: 提出了一种基于结构控制的点云生成方法StrucADT，通过手动标注点云形状的相邻关系构建StructureGraph表示，实现了用户指定结构的可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云生成方法虽能生成多样且真实的形状，但缺乏对生成的精确控制，限制了其大规模应用。

Method: 通过手动标注点云部分的相邻关系构建StructureGraph表示，设计StrucADT模型，包括StructureGraphNet、cCNF Prior和Diffusion Transformer模块，实现结构一致的点云生成。

Result: 实验表明，该方法能在ShapeNet数据集上生成高质量、多样且结构可控的点云，性能达到当前最优。

Conclusion: 提出的结构可控点云生成方法有效解决了生成控制不足的问题，为大规模应用提供了可能性。

Abstract: In the field of 3D point cloud generation, numerous 3D generative models have
demonstrated the ability to generate diverse and realistic 3D shapes. However,
the majority of these approaches struggle to generate controllable 3D point
cloud shapes that meet user-specific requirements, hindering the large-scale
application of 3D point cloud generation. To address the challenge of lacking
control in 3D point cloud generation, we are the first to propose controlling
the generation of point clouds by shape structures that comprise part
existences and part adjacency relationships. We manually annotate the adjacency
relationships between the segmented parts of point cloud shapes, thereby
constructing a StructureGraph representation. Based on this StructureGraph
representation, we introduce StrucADT, a novel structure-controllable point
cloud generation model, which consists of StructureGraphNet module to extract
structure-aware latent features, cCNF Prior module to learn the distribution of
the latent features controlled by the part adjacency, and Diffusion Transformer
module conditioned on the latent features and part adjacency to generate
structure-consistent point cloud shapes. Experimental results demonstrate that
our structure-controllable 3D point cloud generation method produces
high-quality and diverse point cloud shapes, enabling the generation of
controllable point clouds based on user-specified shape structures and
achieving state-of-the-art performance in controllable point cloud generation
on the ShapeNet dataset.

</details>


### [7] [Diff-3DCap: Shape Captioning with Diffusion Models](https://arxiv.org/abs/2509.23718)
*Zhenyu Shu,Jiawei Wen,Shiyang Li,Shiqing Xin,Ligang Liu*

Main category: cs.GR

TL;DR: 本文提出Diff-3DCap，一种利用投影视图和连续扩散模型进行3D形状描述的方法，通过高斯噪声扰动和重建标注提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统3D形状描述方法依赖于昂贵的体素表示或目标检测技术，但效果不佳，因此需要一种更高效且性能优越的替代方案。

Method: Diff-3DCap使用投影视图表示3D对象，并采用连续扩散模型在前向阶段引入高斯噪声扰动嵌入标注，反向阶段预测重建标注，同时利用预训练的视觉语言模型的视觉嵌入作为指导信号。

Result: 实验结果表明，Diff-3DCap的性能可与当前最先进方法相媲美。

Conclusion: Diff-3DCap提供了一种高效且有效的3D形状描述方法，通过扩散模型和视觉嵌入的结合，显著提升了性能。

Abstract: The task of 3D shape captioning occupies a significant place within the
domain of computer graphics and has garnered considerable interest in recent
years. Traditional approaches to this challenge frequently depend on the
utilization of costly voxel representations or object detection techniques, yet
often fail to deliver satisfactory outcomes. To address the above challenges,
in this paper, we introduce Diff-3DCap, which employs a sequence of projected
views to represent a 3D object and a continuous diffusion model to facilitate
the captioning process. More precisely, our approach utilizes the continuous
diffusion model to perturb the embedded captions during the forward phase by
introducing Gaussian noise and then predicts the reconstructed annotation
during the reverse phase. Embedded within the diffusion framework is a
commitment to leveraging a visual embedding obtained from a pre-trained
visual-language model, which naturally allows the embedding to serve as a
guiding signal, eliminating the need for an additional classifier. Extensive
results of our experiments indicate that Diff-3DCap can achieve performance
comparable to that of the current state-of-the-art methods.

</details>


### [8] [ReLumix: Extending Image Relighting to Video via Video Diffusion Models](https://arxiv.org/abs/2509.23769)
*Lezhong Wang,Shutong Jin,Ruiqi Cui,Anders Bjorholm Dahl,Jeppe Revall Frisvad,Siavash Bigdeli*

Main category: cs.GR

TL;DR: ReLumix是一种新型的视频重光照框架，通过将重光照算法与时序合成解耦，使得任何图像重光照技术都能无缝应用于视频中。该方法通过两阶段流程实现：艺术家在参考帧上使用喜欢的图像技术进行重光照，然后通过微调的稳定视频扩散模型将目标光照传播到整个序列中。


<details>
  <summary>Details</summary>
Motivation: 现有的视频重光照方法缺乏灵活性，限制了用户对重光照模型的选择。ReLumix旨在提供一种更灵活、可扩展的视频重光照解决方案。

Method: ReLumix采用两阶段流程：首先在单帧参考图像上应用任意图像重光照技术（如扩散模型或物理渲染器），然后通过微调的稳定视频扩散模型（SVD）将目标光照传播到整个视频序列中。为了确保时序一致性和避免伪影，引入了门控交叉注意力机制和时间引导策略。

Result: 尽管仅在合成数据上训练，ReLumix在真实世界视频中表现出竞争性的泛化能力。该方法在视觉保真度上表现出显著改进。

Conclusion: ReLumix提供了一种高效、灵活的视频重光照解决方案，能够在动态光照控制中显著提升视觉质量。

Abstract: Controlling illumination during video post-production is a crucial yet
elusive goal in computational photography. Existing methods often lack
flexibility, restricting users to certain relighting models. This paper
introduces ReLumix, a novel framework that decouples the relighting algorithm
from temporal synthesis, thereby enabling any image relighting technique to be
seamlessly applied to video. Our approach reformulates video relighting into a
simple yet effective two-stage process: (1) an artist relights a single
reference frame using any preferred image-based technique (e.g., Diffusion
Models, physics-based renderers); and (2) a fine-tuned stable video diffusion
(SVD) model seamlessly propagates this target illumination throughout the
sequence. To ensure temporal coherence and prevent artifacts, we introduce a
gated cross-attention mechanism for smooth feature blending and a temporal
bootstrapping strategy that harnesses SVD's powerful motion priors. Although
trained on synthetic data, ReLumix shows competitive generalization to
real-world videos. The method demonstrates significant improvements in visual
fidelity, offering a scalable and versatile solution for dynamic lighting
control.

</details>


### [9] [SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where](https://arxiv.org/abs/2509.23852)
*Yiheng Huang,Junran Peng,Silei Shen,Jingwei Yang,ZeJi Wei,ChenCheng Bai,Yonghao He,Wei Sui,Muyi Sun,Yan Liu,Xu-Cheng Yin,Man Zhang,Zhaoxiang Zhang,Chuanchen Luo*

Main category: cs.GR

TL;DR: 提出了一种全栈解决方案，通过音频、语言和空间数据驱动的生成模型，结合交互时机和空间准确性的评估指标，提升了对话手势生成的交互性和空间意图表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖描述性语言或音频生成动作，缺乏对交互时机和空间意图的表征，限制了对话手势生成在机器人或游戏动画领域的应用。

Method: 首先建立了独特的数据收集方法，同时捕获高精度人体动作和空间意图；然后开发了由音频、语言和空间数据驱动的生成模型，并设计了评估交互时机和空间准确性的指标；最后在类人机器人上部署了解决方案。

Result: 提出的解决方案能够实现丰富且上下文感知的物理交互，显著提升了对话手势生成的交互性和空间意图表现。

Conclusion: 该研究填补了现有方法的不足，通过全栈解决方案提升了对话手势生成的实用性，为机器人、游戏和动画领域提供了新的可能性。

Abstract: The accompanying actions and gestures in dialogue are often closely linked to
interactions with the environment, such as looking toward the interlocutor or
using gestures to point to the described target at appropriate moments. Speech
and semantics guide the production of gestures by determining their timing
(WHEN) and style (HOW), while the spatial locations of interactive objects
dictate their directional execution (WHERE). Existing approaches either rely
solely on descriptive language to generate motions or utilize audio to produce
non-interactive gestures, thereby lacking the characterization of interactive
timing and spatial intent. This significantly limits the applicability of
conversational gesture generation, whether in robotics or in the fields of game
and animation production. To address this gap, we present a full-stack
solution. We first established a unique data collection method to
simultaneously capture high-precision human motion and spatial intent. We then
developed a generation model driven by audio, language, and spatial data,
alongside dedicated metrics for evaluating interaction timing and spatial
accuracy. Finally, we deployed the solution on a humanoid robot, enabling rich,
context-aware physical interactions.

</details>


### [10] [Neural Visibility of Point Sets](https://arxiv.org/abs/2509.24150)
*Jun-Hao Wang,Yi-Yang Tian,Baoquan Chen,Peng-Shuai Wang*

Main category: cs.GR

TL;DR: 本文提出了一种基于3D U-Net和多层感知机的新型方法，用于点云中的可见性判定，相比传统方法在精度和计算效率上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 点云作为3D数据的表示形式，其可见性判定因稀疏性和缺乏显式连接而具有挑战性。传统方法如HPR在计算效率、噪声鲁棒性等方面存在局限性。

Method: 将可见性判定建模为二元分类任务，使用3D U-Net提取视点无关的点特征，结合多层感知机预测点可见性，并通过端到端训练优化模型。

Result: 该方法在精度和计算效率上显著优于HPR，最高可达126倍的加速，同时对噪声和点云密度变化表现出鲁棒性，并在ShapeNet等数据集上验证了有效性。

Conclusion: 该方法在多场景应用中展现了广泛的适用性，包括点云可视化、表面重建和阴影渲染等，代码和模型已公开。

Abstract: Point clouds are widely used representations of 3D data, but determining the
visibility of points from a given viewpoint remains a challenging problem due
to their sparse nature and lack of explicit connectivity. Traditional methods,
such as Hidden Point Removal (HPR), face limitations in computational
efficiency, robustness to noise, and handling concave regions or low-density
point clouds. In this paper, we propose a novel approach to visibility
determination in point clouds by formulating it as a binary classification
task. The core of our network consists of a 3D U-Net that extracts
view-independent point-wise features and a shared multi-layer perceptron (MLP)
that predicts point visibility using the extracted features and view direction
as inputs. The network is trained end-to-end with ground-truth visibility
labels generated from rendered 3D models. Our method significantly outperforms
HPR in both accuracy and computational efficiency, achieving up to 126 times
speedup on large point clouds. Additionally, our network demonstrates
robustness to noise and varying point cloud densities and generalizes well to
unseen shapes. We validate the effectiveness of our approach through extensive
experiments on the ShapeNet, ABC Dataset and real-world datasets, showing
substantial improvements in visibility accuracy. We also demonstrate the
versatility of our method in various applications, including point cloud
visualization, surface reconstruction, normal estimation, shadow rendering, and
viewpoint optimization. Our code and models are available at
https://github.com/octree-nn/neural-visibility.

</details>


### [11] [NeuralPVS: Learned Estimation of Potentially Visible Sets](https://arxiv.org/abs/2509.24677)
*Xiangyu Wang,Thomas Köhler,Jun Lin Qiu,Shohei Mori,Markus Steinberger,Dieter Schmalstieg*

Main category: cs.GR

TL;DR: NeuralPVS是一种基于深度学习的实时可见性计算方法，首次在大规模场景中以约100 Hz的速度高效计算区域可见性，且几何缺失率低于1%。


<details>
  <summary>Details</summary>
Motivation: 在计算机图形学中，实时确定广阔或动态变化环境中的可见性一直是一个重大挑战。现有方法计算成本高，通常作为静态场景的预计算步骤。

Method: NeuralPVS使用神经网络对场景的体素化表示进行操作，通过结合稀疏卷积和3D体积保持交错数据压缩技术实现高性能。此外，还引入了一种新颖的排斥可见性损失函数，有效引导网络收敛到正确的数据分布。

Result: NeuralPVS在准确性和效率上均优于现有方法，几何缺失率低于1%，适用于实时可见性计算。

Conclusion: NeuralPVS是一种高效且准确的实时可见性计算解决方案，具有较强的鲁棒性和对未知场景的泛化能力。

Abstract: Real-time visibility determination in expansive or dynamically changing
environments has long posed a significant challenge in computer graphics.
Existing techniques are computationally expensive and often applied as a
precomputation step on a static scene. We present NeuralPVS, the first
deep-learning approach for visibility computation that efficiently determines
from-region visibility in a large scene, running at approximately 100 Hz
processing with less than $1\%$ missing geometry. This approach is possible by
using a neural network operating on a voxelized representation of the scene.
The network's performance is achieved by combining sparse convolution with a 3D
volume-preserving interleaving for data compression. Moreover, we introduce a
novel repulsive visibility loss that can effectively guide the network to
converge to the correct data distribution. This loss provides enhanced
robustness and generalization to unseen scenes. Our results demonstrate that
NeuralPVS outperforms existing methods in terms of both accuracy and
efficiency, making it a promising solution for real-time visibility
computation.

</details>


### [12] [Light-SQ: Structure-aware Shape Abstraction with Superquadrics for Generated Meshes](https://arxiv.org/abs/2509.24986)
*Yuhan Wang,Weikai Chen,Zeyu Hu,Runze Zhang,Yingda Yin,Ruoyu Wu,Keyang Luo,Shengju Qian,Yiyan Ma,Hongyi Li,Yuan Gao,Yuhuan Zhou,Hao Luo,Wan Wang,Xiaobin Shen,Zhaowei Li,Kuixin Zhu,Chuanlang Hong,Yueyue Wang,Lijie Feng,Xin Wang,Chen Change Loy*

Main category: cs.GR

TL;DR: Light-SQ是一个基于超二次曲面的优化框架，通过SDF雕刻、结构化分区和自适应残差修剪，实现高效、高保真且可编辑的形状抽象，支持3D用户生成内容的创建。


<details>
  <summary>Details</summary>
Motivation: 在用户生成内容（UGC）应用中，非专业用户依赖图像到3D生成模型创建3D资产。原始形状抽象提供了一种压缩高分辨率网格为紧凑且可编辑表示的解决方案，但需要结构感知能力以减少重叠并保持紧凑。

Method: Light-SQ通过三方面实现结构感知：(a) SDF雕刻迭代更新目标符号距离场以减少重叠；(b) 结构化体积分解驱动的块-再生-填充策略；(c) 基于SDF更新历史的自适应残差修剪以避免过度分割。

Result: 实验表明，Light-SQ在复杂几何形状上实现了高效、高保真和可编辑的形状抽象，并通过3DGen-Prim基准验证了其重建质量和原始级可编辑性。

Conclusion: Light-SQ通过结构化感知优化，显著提升了3D UGC创建的可行性，为复杂几何形状提供了紧凑且可编辑的抽象表示。

Abstract: In user-generated-content (UGC) applications, non-expert users often rely on
image-to-3D generative models to create 3D assets. In this context,
primitive-based shape abstraction offers a promising solution for UGC scenarios
by compressing high-resolution meshes into compact, editable representations.
Towards this end, effective shape abstraction must therefore be
structure-aware, characterized by low overlap between primitives, part-aware
alignment, and primitive compactness. We present Light-SQ, a novel
superquadric-based optimization framework that explicitly emphasizes
structure-awareness from three aspects. (a) We introduce SDF carving to
iteratively udpate the target signed distance field, discouraging overlap
between primitives. (b) We propose a block-regrow-fill strategy guided by
structure-aware volumetric decomposition, enabling structural partitioning to
drive primitive placement. (c) We implement adaptive residual pruning based on
SDF update history to surpress over-segmentation and ensure compact results. In
addition, Light-SQ supports multiscale fitting, enabling localized refinement
to preserve fine geometric details. To evaluate our method, we introduce
3DGen-Prim, a benchmark extending 3DGen-Bench with new metrics for both
reconstruction quality and primitive-level editability. Extensive experiments
demonstrate that Light-SQ enables efficient, high-fidelity, and editable shape
abstraction with superquadrics for complex generated geometry, advancing the
feasibility of 3D UGC creation.

</details>


### [13] [CharGen: Fast and Fluent Portrait Modification](https://arxiv.org/abs/2509.25058)
*Jan-Niklas Dihlmann,Arnela Killguss,Hendrik P. A. Lensch*

Main category: cs.GR

TL;DR: CharGen是一种基于扩散模型的字符图像交互编辑器，通过属性滑块和Repair Step实现快速、精细的编辑控制。


<details>
  <summary>Details</summary>
Motivation: 当前交互式编辑字符图像面临控制精细度、生成速度和视觉保真度的权衡问题，CharGen旨在解决这一挑战。

Method: CharGen结合属性滑块（Concept Sliders）和StreamDiffusion采样管道，并通过Repair Step修复细节损失，实现快速和高保真编辑。

Result: 与InstructPix2Pix和Google Gemini相比，CharGen编辑速度快2-4倍，提供精确控制和一致性的结果。

Conclusion: CharGen在交互式编辑中实现了速度和质量的平衡，为用户提供了高效的字符图像编辑工具。

Abstract: Interactive editing of character images with diffusion models remains
challenging due to the inherent trade-off between fine-grained control,
generation speed, and visual fidelity. We introduce CharGen, a
character-focused editor that combines attribute-specific Concept Sliders,
trained to isolate and manipulate attributes such as facial feature size,
expression, and decoration with the StreamDiffusion sampling pipeline for more
interactive performance. To counteract the loss of detail that often
accompanies accelerated sampling, we propose a lightweight Repair Step that
reinstates fine textures without compromising structural consistency.
Throughout extensive ablation studies and in comparison to open-source
InstructPix2Pix and closed-source Google Gemini, and a comprehensive user
study, CharGen achieves two-to-four-fold faster edit turnaround with precise
editing control and identity-consistent results. Project page:
https://chargen.jdihlmann.com/

</details>


### [14] [Unsupervised Representation Learning for 3D Mesh Parameterization with Semantic and Visibility Objectives](https://arxiv.org/abs/2509.25094)
*AmirHossein Zamani,Bruno Roy,Arianna Rampini*

Main category: cs.GR

TL;DR: 提出了一种无监督的可微分框架，用于自动化3D网格参数化（UV映射），结合语义和可见性感知目标，以减少纹理生成中的瓶颈和缝线伪影。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型依赖手动UV映射，这是一个耗时且需要专业知识的过程，成为3D内容创作的主要瓶颈。现有自动方法忽视了语义一致性和可见性感知的重要性。

Method: 采用无监督可微分框架，结合语义分割和可见性感知目标（使用环境遮蔽作为代理），自动生成UV图集。

Result: 所提方法在定性和定量评估中优于现有方法，生成支持更好纹理生成且减少缝线伪影的UV图集。

Conclusion: 该方法成功实现了自动化UV参数化，显著减少了人工干预的需求，并提升了纹理生成效果。

Abstract: Recent 3D generative models produce high-quality textures for 3D mesh
objects. However, they commonly rely on the heavy assumption that input 3D
meshes are accompanied by manual mesh parameterization (UV mapping), a manual
task that requires both technical precision and artistic judgment. Industry
surveys show that this process often accounts for a significant share of asset
creation, creating a major bottleneck for 3D content creators. Moreover,
existing automatic methods often ignore two perceptually important criteria:
(1) semantic awareness (UV charts should align semantically similar 3D parts
across shapes) and (2) visibility awareness (cutting seams should lie in
regions unlikely to be seen). To overcome these shortcomings and to automate
the mesh parameterization process, we present an unsupervised differentiable
framework that augments standard geometry-preserving UV learning with semantic-
and visibility-aware objectives. For semantic-awareness, our pipeline (i)
segments the mesh into semantic 3D parts, (ii) applies an unsupervised learned
per-part UV-parameterization backbone, and (iii) aggregates per-part charts
into a unified UV atlas. For visibility-awareness, we use ambient occlusion
(AO) as an exposure proxy and back-propagate a soft differentiable AO-weighted
seam objective to steer cutting seams toward occluded regions. By conducting
qualitative and quantitative evaluations against state-of-the-art methods, we
show that the proposed method produces UV atlases that better support texture
generation and reduce perceptible seam artifacts compared to recent baselines.
Our implementation code is publicly available at:
https://github.com/AHHHZ975/Semantic-Visibility-UV-Param.

</details>


### [15] [LayerD: Decomposing Raster Graphic Designs into Layers](https://arxiv.org/abs/2509.25134)
*Tomoyuki Suzuki,Kang-Jun Liu,Naoto Inoue,Kota Yamaguchi*

Main category: cs.GR

TL;DR: LayerD是一种将栅格图形设计分解为可重新编辑的图层的方法，通过迭代提取未被遮挡的前景图层，并利用图形设计中图层通常具有统一外观的假设进行优化。


<details>
  <summary>Details</summary>
Motivation: 当前一旦图形设计被合成栅格图像，就无法进行基于图层的编辑，限制了设计的灵活性和可修改性。

Method: LayerD通过迭代提取未被遮挡的前景图层，并提出一种基于图层外观一致性的优化方法。此外，还开发了一种质量度量来评估分解结果。

Result: 实验表明，LayerD能够高质量地完成分解任务，并优于基线方法。它还展示了与先进图像生成器和图层编辑工具的结合使用。

Conclusion: LayerD通过分解栅格图像为可编辑的图层，显著提升了图形设计的灵活性和可修改性，具有实际应用价值。

Abstract: Designers craft and edit graphic designs in a layer representation, but
layer-based editing becomes impossible once composited into a raster image. In
this work, we propose LayerD, a method to decompose raster graphic designs into
layers for re-editable creative workflow. LayerD addresses the decomposition
task by iteratively extracting unoccluded foreground layers. We propose a
simple yet effective refinement approach taking advantage of the assumption
that layers often exhibit uniform appearance in graphic designs. As
decomposition is ill-posed and the ground-truth layer structure may not be
reliable, we develop a quality metric that addresses the difficulty. In
experiments, we show that LayerD successfully achieves high-quality
decomposition and outperforms baselines. We also demonstrate the use of LayerD
with state-of-the-art image generators and layer-based editing.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [16] [Efficient Cost Bounds with Linear Maps](https://arxiv.org/abs/2509.22982)
*David M Kahn,Jan Hoffmann,Thomas Reps,Jessie Grosen*

Main category: cs.PL

TL;DR: 本文提出了一种新方法，通过线性映射表示函数的无成本类型，解决了现有算法在无成本类型推断上的效率问题，适用于多项式和非多项式成本界限。


<details>
  <summary>Details</summary>
Motivation: 现有自动摊销资源分析（AARA）方法在推断无成本类型时效率低下，且仅适用于多项式成本界限。本文旨在通过线性映射解决这些问题。

Method: 采用线性映射表示函数的无成本类型，通过矩阵不等式推理成本界限，并利用现成的线性规划工具解决这些不等式。

Result: 实验评估表明，线性映射推断方法的效率比现有算法高出指数级，适用于更多程序。

Conclusion: 线性映射方法显著提升了无成本类型的推断效率，扩展了成本界限的分析范围，特别是非多项式界限。

Abstract: The Automatic Amortized Resource Analysis (AARA) derives program-execution
cost bounds using types. To do so, AARA often makes use of cost-free types,
which are critical for the composition of types and cost bounds. However,
inferring cost-free types using the current state-of-the-art algorithm is
expensive due to recursive dependence on additional cost-free types.
Furthermore, that algorithm uses a heuristic only applicable to polynomial cost
bounds, and not, e.g., exponential bounds. This paper presents a new approach
to these problems by representing the cost-free types of a function in a new
way: with a linear map, which can stand for infinitely many cost-free types.
Such maps enable an algebraic flavor of reasoning about cost bounds (including
non-polynomial bounds) via matrix inequalities. These inequalities can be
solved with off-the-shelf linear-programming tools for many programs, so that
types can always be efficiently checked and often be efficiently inferred. An
experimental evaluation with a prototype implementation shows that-when it is
applicable-the inference of linear maps is exponentially more efficient than
the state-of-the-art algorithm.

</details>


### [17] [Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification](https://arxiv.org/abs/2509.23061)
*Xu Xu,Xin Li,Xingwei Qu,Jie Fu,Binhang Yuan*

Main category: cs.PL

TL;DR: DafnyCOMP是一个评估大型语言模型在Dafny中组合规范生成能力的基准测试，专注于多函数交互任务并揭示了模型在跨功能推理中的系统性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单函数任务，缺乏对多函数交互和数据依赖的评估，DafnyCOMP旨在填补这一空白。

Method: DafnyCOMP包含300个自动合成的多函数程序，用于评估多个先进的大型语言模型家族。

Result: 模型在单函数验证中表现良好，但在组合任务中性能显著下降，表现出脆弱的规范、实现与证明之间的不一致以及不稳定的推理。

Conclusion: DafnyCOMP为衡量大型语言模型在可靠、可验证和组合代码生成方面的进展提供了诊断工具。

Abstract: We introduce DafnyCOMP, a benchmark for evaluating large language models
(LLMs) on compositional specification generation in Dafny. Unlike prior
benchmarks that focus on single-function tasks, DafnyCOMP targets programs
composed of multiple interacting functions with data dependencies, requiring
reasoning across component boundaries. The benchmark consists of 300
automatically synthesized multi-function programs. We evaluate several
state-of-the-art LLM families and find that, while they perform well on
single-function verification, their performance drops sharply on compositional
tasks. Analysis reveals systematic failures in cross-functional reasoning,
including fragile specifications, misalignment between implementations and
proofs, and unstable reasoning. DafnyCOMP thus provides a diagnostic tool for
measuring progress toward reliable, verifiable, and compositional code
generation with LLMs.

</details>


### [18] [Fine-Grained Reasoning About Container-Internal Pointers with Logical Pinning](https://arxiv.org/abs/2509.23229)
*Yawen Guan,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 逻辑钉扎是一种轻量级借用模型，允许选择性跟踪容器内部指针，适用于顺序程序，提升了分离逻辑的模块化和验证能力。


<details>
  <summary>Details</summary>
Motivation: 传统分离逻辑隐藏容器内部指针以保持模块化，但这使得在容器API临时暴露指针时难以进行规范和验证。

Method: 提出逻辑钉扎模型，通过概括魔杖算子（magic-wand operator），允许在逻辑层面选择性跟踪内部指针，保持与现有分离逻辑的兼容性。

Result: 验证了小而具有代表性的指针操作程序，并生成了更精确的容器规范，简化了某些复杂证明，支持传统规范无法处理的程序模式。

Conclusion: 逻辑钉扎不仅涵盖了已知的证明模式，还提升了分离逻辑的实用性和表达能力，所有结果均在Rocq证明助手中通过CFML库实现。

Abstract: Most separation logics hide container-internal pointers for modularity. This
makes it difficult to specify container APIs that temporarily expose those
pointers to the outside, and to verify programs that use these APIs. We present
logical pinning, a lightweight borrowing model for sequential programs that
allows users to selectively track container-internal pointers at the logical
level. Our model generalizes the magic-wand operator, making it easy to write
and prove precise specifications, including pointer-stability properties.
Because it only changes how representation predicates and specifications are
written, our approach is compatible with most separation logic variants. We
demonstrate the practicality of logical pinning by verifying small but
representative pointer-manipulating programs, and deriving more precise
versions of common container specifications. In doing so, we show that our
approach subsumes some well-known proof patterns, simplifies some complex
proofs, and enables reasoning about program patterns not supported by
traditional specifications. All of our results are mechanized in the Rocq proof
assistant, using the CFML library.

</details>


### [19] [From Affine to Polynomial: Synthesizing Loops with Branches via Algebraic Geometry](https://arxiv.org/abs/2509.25114)
*Erdenebayar Bayarmagnai,Fatemeh Mohammadi,Rémi Prébet*

Main category: cs.PL

TL;DR: 本文提出了一种更通用的方法，通过代数几何工具设计和实现算法，从给定的多项式不变量合成具有多项式更新映射和不等式的循环。


<details>
  <summary>Details</summary>
Motivation: 软件正确性验证是形式程序验证中的核心挑战，而多项式不变量是循环分析的关键。现有方法仅能从多项式不变量合成无保护条件的仿射循环，本文旨在解决更一般的循环合成问题。

Method: 利用代数几何工具设计并实现算法，生成一组多项式方程，其解对应于满足给定不变量的所有非确定性分支循环。此外，针对特定类别的不变量，提出了一种更高效的算法。

Result: 成功将循环合成问题转化为求解有理数多变量多项式系统的问题，并通过SMT求解器实现。

Conclusion: 本文提出的方法显著扩展了循环合成的适用范围，并为复杂循环的正确性验证提供了新工具。

Abstract: Ensuring software correctness remains a fundamental challenge in formal
program verification. One promising approach relies on finding polynomial
invariants for loops. Polynomial invariants are properties of a program loop
that hold before and after each iteration. Generating such invariants is a
crucial task in loop analysis, but it is undecidable in the general case.
Recently, an alternative approach to this problem has emerged, focusing on
synthesizing loops from invariants. However, existing methods only synthesize
affine loops without guard conditions from polynomial invariants. In this
paper, we address a more general problem, allowing loops to have polynomial
update maps with a given structure, inequations in the guard condition, and
polynomial invariants of arbitrary form.
  We use algebraic geometry tools to design and implement an algorithm that
computes a finite set of polynomial equations whose solutions correspond to all
nondeterministic branching loops satisfying the given invariants. Furthermore,
we introduce a new class of invariants for which we present a significantly
more efficient algorithm. In other words, we reduce the problem of synthesizing
loops to find solutions of multivariate polynomial systems with rational
entries. This final step is handled in our software using an SMT solver.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [20] [Grouped Satisficing Paths in Pure Strategy Games: a Topological Perspective](https://arxiv.org/abs/2509.23157)
*Yanqing Fu,Chao Huang,Chenrun Wang,Zhuping Wang*

Main category: cs.GT

TL;DR: 该论文研究了多智能体强化学习（MARL）中的“胜者保持，败者改变”原则，证明了在任何有限状态马尔可夫游戏或N玩家游戏中，从任意初始策略到某个均衡存在有限长度的满足路径。


<details>
  <summary>Details</summary>
Motivation: 研究MARL中“胜者保持，败者改变”原则的适用条件，为MARL算法设计提供更强的理论基础。

Method: 通过分析有限状态马尔可夫游戏和N玩家游戏中的策略序列，建立了一个充分条件证明有限长度满足路径的存在性。

Result: 证明了在任何有限状态马尔可夫游戏或N玩家游戏中，从任意初始策略到某个均衡都存在有限长度的满足路径。

Conclusion: 该研究结果为MARL算法的设计提供了更强的理论支持，扩展了“胜者保持，败者改变”原则的应用范围。

Abstract: In game theory and multi-agent reinforcement learning (MARL), each agent
selects a strategy, interacts with the environment and other agents, and
subsequently updates its strategy based on the received payoff. This process
generates a sequence of joint strategies $(s^t)_{t \geq 0}$, where $s^t$
represents the strategy profile of all agents at time step $t$. A widely
adopted principle in MARL algorithms is "win-stay, lose-shift", which dictates
that an agent retains its current strategy if it achieves the best response.
This principle exhibits a fixed-point property when the joint strategy has
become an equilibrium. The sequence of joint strategies under this principle is
referred to as a satisficing path, a concept first introduced in [40] and
explored in the context of $N$-player games in [39]. A fundamental question
arises regarding this principle: Under what conditions does every initial joint
strategy $s$ admit a finite-length satisficing path $(s^t)_{0 \leq t \leq T}$
where $s^0=s$ and $s^T$ is an equilibrium? This paper establishes a sufficient
condition for such a property, and demonstrates that any finite-state Markov
game, as well as any $N$-player game, guarantees the existence of a
finite-length satisficing path from an arbitrary initial strategy to some
equilibrium. These results provide a stronger theoretical foundation for the
design of MARL algorithms.

</details>


### [21] [Beyond Game Theory Optimal: Profit-Maximizing Poker Agents for No-Limit Holdem](https://arxiv.org/abs/2509.23747)
*SeungHyun Yi,Seungjun Yi*

Main category: cs.GT

TL;DR: 本文提出了一种超越传统游戏理论最优策略的模型，旨在最大化德州扑克的利润，尤其是在单挑和多玩家情境下，通过结合GTO基础策略和实时对手行为分析实现更高的胜率。


<details>
  <summary>Details</summary>
Motivation: 传统的游戏理论最优策略（GTO）虽然能够避免损失，但无法保证最大利润。因此，作者的目标是开发一种能够在单挑和多玩家情境下超越GTO策略的模型，以最大化利润。

Method: 模型首先通过模拟大量扑克手牌对阵自身，调整决策直至无法被击败，形成接近理论最佳策略的基线。随后，模型通过观察对手行为动态调整策略以获取额外价值。

Result: 结果表明，蒙特卡洛反事实遗憾最小化（CFR）在单挑情境下表现最佳，且在多数多玩家情境中仍是最强方法。

Conclusion: 通过将GTO的防御性与实时对手行为分析相结合，该模型成功实现了从避免损失到持续击败多样化对手的转变。

Abstract: Game theory has grown into a major field over the past few decades, and poker
has long served as one of its key case studies. Game-Theory-Optimal (GTO)
provides strategies to avoid loss in poker, but pure GTO does not guarantee
maximum profit. To this end, we aim to develop a model that outperforms GTO
strategies to maximize profit in No Limit Holdem, in heads-up (two-player) and
multi-way (more than two-player) situations. Our model finds the GTO foundation
and goes further to exploit opponents. The model first navigates toward many
simulated poker hands against itself and keeps adjusting its decisions until no
action can reliably beat it, creating a strong baseline that is close to the
theoretical best strategy. Then, it adapts by observing opponent behavior and
adjusting its strategy to capture extra value accordingly. Our results indicate
that Monte-Carlo Counterfactual Regret Minimization (CFR) performs best in
heads-up situations and CFR remains the strongest method in most multi-way
situations. By combining the defensive strength of GTO with real-time
exploitation, our approach aims to show how poker agents can move from merely
not losing to consistently winning against diverse opponents.

</details>


### [22] [Evolutionary hypergame dynamics: Introspection reasoning and social learning](https://arxiv.org/abs/2509.24398)
*Feipeng Zhang,Te Wu,Guofeng Zhang,Long Wang*

Main category: cs.GT

TL;DR: 本文研究了进化超博弈中的策略多样性及其影响，揭示了与传统进化博弈不同的复杂相变现象，并发现理性提升显著促进合作行为。


<details>
  <summary>Details</summary>
Motivation: 现实社会中个体的知识和信息获取存在异质性，而传统进化博弈理论假设所有玩家拥有完整策略知识，因此需要研究这种不对称性对进化动态的影响。

Method: 研究采用原型模型，包含合作、背叛和独行三种策略，模拟其在混合和空间网格人口中的超博弈动态。

Result: 研究发现复杂的相变现象，包括独行者主导、多策略共存及合作与独行组合主导等，且理性提高显著增强了合作行为。

Conclusion: 进化超博弈揭示了比传统博弈更为复杂的动态现象，理性对合作行为的促进作用尤为重要。

Abstract: In the realm of evolutionary game theory, standard frameworks typically
presuppose that every player possesses comprehensive knowledge and unrestricted
access to the entire strategy space. However, real-world human society
inherently harbors diverse levels of knowledge, experience, and background
among individuals. Hypergames incorporate this heterogeneity by permitting
individuals to differ in their access to the full strategy set, reflecting
cognitive or informational constraints and giving rise to asymmetric strategic
interactions. Yet, their evolutionary consequences remain underexplored. Our
inquiry employs prototype models featuring three available strategies, focusing
on social dilemmas involving cooperation, defection, and loner. These
strategies manifest cyclic dominance, akin to the well-studied
rock-paper-scissors dynamics, a foundational model in game theory. Our study
spans both well-mixed and spatial lattice populations, delving into the
intricacies of learning and evolution of the strategy set within the
evolutionary hypergame dynamics. In stark contrast to traditional evolutionary
game dynamics, our findings unveil nuanced and intricate phases, encompassing
scenarios of loner dominance, coexistence of multiple strategy sets,
combinations of cooperation and loner dominance, and more. Remarkably, we
discern that heightened rationality significantly promotes cooperative
behaviors.

</details>


### [23] [Dynamic Pricing of an Expiring Item under Strategic Buyers with Stochastic Arrival](https://arxiv.org/abs/2509.24720)
*Suyeon Choi,Changhyun Kwon,Seungki Min*

Main category: cs.GT

TL;DR: 研究过期票券的动态定价问题，解决卖家紧迫性与买家等待激励的冲突，提出基于价值的阈值策略（VBT），并验证线性折扣和固定定价在不同市场条件下的适用性。


<details>
  <summary>Details</summary>
Motivation: 过期票券的动态定价面临卖家紧迫性与买家等待激励的冲突，现有方法难以处理买家类型的二维性（估值和到达时间）。

Method: 引入基于价值的阈值策略（VBT），将买家类型的二维性解耦，并通过常微分方程证明均衡存在性，提出构造性表征方法。

Result: 在薄市场中固定定价有效，厚市场中线性折扣更优；数值分析验证了这些基准，并展示了定价策略如何随卖家时间敏感性变化。

Conclusion: 线性折扣适用于厚市场或高时间敏感性卖家，固定定价适用于薄市场；耐心卖家可采用准拍卖策略以高效聚集需求。

Abstract: We study the optimal dynamic pricing of an expiring ticket or voucher, sold
by a time-sensitive seller to strategic buyers who arrive stochastically with
private values. The expiring nature creates a conflict: the seller's urgency to
sell before expiration drives price reductions, which in turn incentivize
buyers to wait. We seek the seller's optimal pricing policy that resolves this
tension. The main analytical challenge is that buyer type is two-dimensional
(valuation and arrival time), which makes equilibrium intractable under general
strategies. To address this, we introduce the Value-Based Threshold (VBT)
strategy, a tractable framework that decouples these two dimensions. Using this
framework, we prove equilibrium existence via an ordinary differential equation
and provide a constructive procedure for its characterization. We then derive
near-optimal pricing policies for two stylized regimes: a constant price in
thin markets and a linear discount in thick markets. Numerical frontier
analysis confirms these benchmarks and shows how optimal policy adapts as the
seller's time sensitivity changes. Our findings clarify the conflict between
quick sales and strategic waiting. Sellers facing thick markets or high time
sensitivity benefit from linear discounts, while in thin markets a constant
price neutralizes buyers' incentive to wait. We also show this simple policy
remains robust across broad conditions. For patient sellers, a quasi-auction
schedule that maintains a high price until a sharp final drop is most effective
in aggregating demand.

</details>


### [24] [A Bilevel Approach to Integrated Surgeon Scheduling and Surgery Planning solved via Branch-and-Price](https://arxiv.org/abs/2509.24806)
*Broos Maenhout,Přemysl Šůcha,Viktorie Valdmanová,Ondřej Tkadlec,Jana Thao Rozlivková*

Main category: cs.GT

TL;DR: 本文研究了一种多智能体调度问题，旨在优化手术室部门内的工作安排。通过双层优化方法找到最优的纳什均衡解，提出了一种分支定价算法来提高效率。


<details>
  <summary>Details</summary>
Motivation: 手术室部门的操作安排需要外科团队负责人和个体外科医生共同参与。个体外科医生的独立计划可能影响整体调度质量，因此需要一种方法来协调二者的目标。

Method: 提出了一种分支定价算法，通过添加惰性约束确保双层优化的可行性，从而高效搜索解空间。

Result: 通过计算稳定价格和分散化价格，验证了算法的性能及其在不同场景下达到均衡解的益处。

Conclusion: 该方法不仅尊重了外科团队负责人和个体外科医生的目标需求，还高效找到了最优解，提升了手术室的调度质量。

Abstract: In this paper, we study a multi-agent scheduling problem for organising the
operations within the operating room department. The head of the surgeon group
and individual surgeons are together responsible for the surgeon schedule and
surgical case planning. The surgeon head allocates time blocks to individual
surgeons, whereas individual surgeons determine the planning of surgical cases
independently, which might degrade the schedule quality envisaged by the
surgeon head. The bilevel optimisation under study seeks an optimal Nash
equilibrium solution -- a surgeon schedule and surgical case plan that optimise
the objectives of the surgeon head, while ensuring that no individual surgeon
can improve their own objective within the allocated time blocks. We propose a
dedicated branch-and-price that adds lazy constraints to the formulation of
surgeon-specific pricing problems to ensure an optimal bilevel feasible
solution is retrieved. In this way, the surgeon head respects the objective
requirements of the individual surgeons and the solution space can be searched
efficiently. In the computational experiments, we validate the performance of
the proposed algorithm and its dedicated components and provide insights into
the benefits of attaining an equilibrium solution under different scenarios by
calculating the price of stability and the price of decentralisation.

</details>


### [25] [The Free Option Problem of ePBS](https://arxiv.org/abs/2509.24849)
*Bruno Mazorra,Burak Öz,Christoph Schlegel,Fei Wu*

Main category: cs.GT

TL;DR: 以太坊的Glamsterdam升级引入EIP-7732（ePBS），改善区块生产管道的信任和可扩展性问题，但也引入了新的活跃性风险——构建者可以免费阻止其承诺的执行负载成为规范，导致空块出现。本文首次系统研究了这一问题。


<details>
  <summary>Details</summary>
Motivation: 研究以太坊Glamsterdam升级中ePBS机制带来的新活跃性风险，即构建者可以通过免费选项阻止其承诺的执行负载成为规范，导致网络活跃性下降。

Method: 通过理论分析和历史区块数据的实证研究，评估免费选项的价值和执行概率，并探讨市场波动、选项窗口长度以及区块价值来源对其影响。

Result: 研究发现，免费选项的价值和执行概率受市场波动等因素影响，在高波动时期可能影响多达6%的区块。此外，依赖CEX-DEX套利的构建者更可能执行该选项。缓解策略如缩短选项窗口或惩罚执行选项可以有效降低风险。

Conclusion: 免费选项问题在高波动时期会显著影响以太坊网络的活跃性。缓解措施可以降低风险，但需进一步探索以保证网络的稳定性和用户体验。

Abstract: Ethereum's upcoming Glamsterdam upgrade introduces EIP-7732 enshrined
Proposer--Builder Separation (ePBS), which improves the block production
pipeline by addressing trust and scalability challenges. Yet it also creates a
new liveness risk: builders gain a short-dated ``free'' option to prevent the
execution payload they committed to from becoming canonical, without incurring
an additional penalty. Exercising this option renders an empty block for the
slot in question, thereby degrading network liveness.
  We present the first systematic study of the free option problem. Our
theoretical results predict that option value and exercise probability grow
with market volatility, the length of the option window, and the share of block
value derived from external signals such as external market prices. The
availability of a free option will lead to mispricing and LP losses. The
problem would be exacerbated if Ethereum further scales and attracts more
liquidity. Empirical estimates of values and exercise probabilities on
historical blocks largely confirm our theoretical predictions. While the option
is rarely profitable to exercise on average (0.82\% of blocks assuming an
8-second option time window), it becomes significant in volatile periods,
reaching up to 6\% of blocks on high-volatility days -- precisely when users
most require timely execution.
  Moreover, builders whose block value relies heavily on CEX-DEX arbitrage are
more likely to exercise the option. We demonstrate that mitigation strategies
-- shortening the option window or penalizing exercised options -- effectively
reduce liveness risk.

</details>


### [26] [A Management Framework for Vehicular Cloudtoward Economic and Environmental Efficiency](https://arxiv.org/abs/2509.24946)
*Rosario Patanè,Andrea Araldo,Nadjib Achir,Lila Boukhatem*

Main category: cs.GT

TL;DR: 论文提出了一种结合能量感知任务分配和博弈论收入共享机制的车载云计算管理方案，旨在量化证明其在盈利性和环境可持续性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 车载云计算（VCC）虽然概念上具有吸引力，但由于缺乏在实际场景中证明其盈利性和环境优势的定量证据，其采用受到阻碍。

Method: 论文提出了一种管理方案，结合了能量感知任务分配和基于博弈论的收入共享机制，首次在城区移动和5G通信环境中共同建模了延迟、能耗、货币激励和碳排放。

Result: 模拟结果显示，该方案支持低延迟任务执行，有效实现了车辆资源的货币化，并将CO2排放量减少了99%以上，优于传统的边缘基础设施。

Conclusion: 研究表明，车载云计算是一种既实用又可持续的边缘计算替代方案。

Abstract: Vehicular Cloud Computing (VCC) leverages the idle computing capacity of
vehicles to execute end-users' offloaded tasks without requiring new
computation infrastructure. Despite its conceptual appeal, VCC adoption is
hindered by the lack of quantitative evidence demonstrating its profitability
and environmental advantages in real-world scenarios. This paper tackles the
fundamental question: Can VCC be both profitable and sustainable? We address
this problem by proposing a management scheme for VCC that combines
energy-aware task allocation with a game-theoretic revenue-sharing mechanism.
Our framework is the first to jointly model latency, energy consumption,
monetary incentives, and carbon emissions within urban mobility and 5G
communication settings. The task allocation strategy maximizes the aggregate
stakeholder utility while satisfying deadlines and minimizing energy costs. The
payoffs are distributed via a coalitional game theory adapted to dynamic
vehicular environments, to prevent disincentivizing participants with
potentially negative contributions. Extensive simulations demonstrate that our
approach supports low-latency task execution, enables effective monetization of
vehicular resources, and reduces CO2 emissions by more than 99% compared to
conventional edge infrastructures, making VCC a practical and sustainable
alternative to edge computing.

</details>


### [27] [The Popular Dimension of Matchings](https://arxiv.org/abs/2509.25150)
*Frank Connor,Louis-Roy Langevin,Ndiamé Ndiaye,Agnès Totschnig,Rohit Vasishta,Adrian Vetta*

Main category: cs.GT

TL;DR: 论文研究了三种经典场景中的受欢迎匹配问题：房屋分配问题、婚姻问题和室友问题。定义了一种称为“受欢迎获胜集合”的松弛概念，并提出了“受欢迎维度”的最小基数概念。


<details>
  <summary>Details</summary>
Motivation: 探讨在受欢迎匹配通常不存在的背景下，如何通过引入受欢迎获胜集的概念来解决这一问题，并量化其最小规模。

Method: 研究房屋分配、婚姻和室友问题中的受欢迎匹配，提出受欢迎维度的定义，并在不同条件下（如加权代理人和允许偏好列表中的平局）分析其值。

Result: 房屋分配问题的受欢迎维度为2，婚姻问题和室友问题的受欢迎维度在2和3之间。在无权重且严格偏好的特殊情况下，婚姻问题的受欢迎维度为1，室友问题为2。

Conclusion: 受欢迎维度在不同问题场景中有不同的表现，为理解受欢迎匹配的最小规模提供了理论支持。

Abstract: We study popular matchings in three classical settings: the house allocation
problem, the marriage problem, and the roommates problem. In the popular
matching problem, (a subset of) the vertices in a graph have preference
orderings over their potential matches. A matching is popular if it gets a
plurality of votes in a pairwise election against any other matching.
Unfortunately, popular matchings typically do not exist. So we study a natural
relaxation, namely popular winning sets which are a set of matchings that
collectively get a plurality of votes in a pairwise election against any other
matching. The $\textit{popular dimension}$ is the minimum cardinality of a
popular winning set, in the worst case over the problem class.
  We prove that the popular dimension is exactly $2$ in the house allocation
problem, even if the voters are weighted and ties are allowed in their
preference lists. For the marriage problem and the roommates problem, we prove
that the popular dimension is between $2$ and $3$, when the agents are weighted
and/or their preferences orderings allow ties. In the special case where the
agents are unweighted and have strict preference orderings, the popular
dimension of the marriage problem is known to be exactly $1$ and we prove the
popular dimension of the roommates problem is exactly $2$.

</details>
