<div id=toc></div>

# Table of Contents

- [cs.DM](#cs.DM) [Total: 1]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.PL](#cs.PL) [Total: 1]
- [math.LO](#math.LO) [Total: 2]
- [math.RT](#math.RT) [Total: 5]


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [1] [On Obtaining New MUBs by Finding Points on Complete Intersection Varieties over $\mathbb{R}$](https://arxiv.org/abs/2507.02492)
*Arindam Banerjee,Kanoy Kumar Das,Ajeet Kumar,Rakesh Kumar,Subhamoy Maitra*

Main category: cs.DM

TL;DR: 该论文研究了相互无偏基（MUBs）的扩展条件，通过代数簇的实点分析，揭示了MUBs与正交正规矩阵的最大交换类之间的对应关系。


<details>
  <summary>Details</summary>
Motivation: 相互无偏基（MUBs）在量子物理中具有重要意义，但其扩展条件和数学结构尚不明确，因此需要深入研究其代数簇和交换类的特性。

Method: 通过研究一个特定仿射代数簇的实点，为MUBs的扩展提供等价条件，并分析其与正交正规矩阵的最大交换类之间的对应关系。

Result: 证明了代数簇的某些部分可以生成完全交集域，并展示了MUBs与正交正规矩阵的最大交换类之间的一一对应关系，从而确保MUBs的完整集合存在。

Conclusion: 研究不仅深化了对MUBs数学结构的理解，还提供了一种通过交换类来构造完整MUBs集的方法。

Abstract: Mutually Unbiased Bases (MUBs) are closely connected with quantum physics,
and the structure has a rich mathematical background. We provide equivalent
criteria for extending a set of MUBs for $C^n$ by studying real points of a
certain affine algebraic variety. This variety comes from the relations that
determine the extendability of a system of MUBs. Finally, we show that some
part of this variety gives rise to complete intersection domains. Further, we
show that there is a one-to-one correspondence between MUBs and the maximal
commuting classes (bases) of orthogonal normal matrices in $\mathcal
M_n({\mathbb{C}})$. It means that for $m$ MUBs in $C^n$, there are $m$
commuting classes, each consisting of $n$ commuting orthogonal normal matrices
and the existence of maximal commuting basis for $\mathcal M_n({\mathbb{C}})$
ensures the complete set of MUBs in $\mathcal M_n({\mathbb{C}})$.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [2] [New algorithms for girth and cycle detection](https://arxiv.org/abs/2507.02061)
*Liam Roditty,Plia Trabelsi*

Main category: cs.DS

TL;DR: 该论文提出了一个随机算法，用于在无权重无向图中高效找到短周期，推广了现有算法并引入混合周期检测技术的概念。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进现有算法，使其在更广泛的参数选择和运行时间与周期长度之间提供更灵活的权衡。

Method: 论文提出了一种随机算法，运行时间为$	ilde{O}\big(\ell \cdot n^{1 + \frac{1}{\ell - \varepsilon}}\big)$，并引入了混合周期检测技术的定义。

Result: 算法在图中找到一个长度不超过特定界限的周期，并针对稀疏图提出了更好的时间与周期长度的权衡方案。

Conclusion: 该算法推广了现有算法，提供了更大的参数选择灵活性，并为稀疏图提供了更优的性能。

Abstract: Let $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$
edges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in
$G$. We present a randomized algorithm with a running time of
$\tilde{O}\big(\ell \cdot n^{1 + \frac{1}{\ell - \varepsilon}}\big)$ that
returns a cycle of length at most $ 2\ell \left\lceil \frac{g}{2} \right\rceil
- 2 \left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil
\right\rfloor, $ where $\ell \geq 2$ is an integer and $\varepsilon \in [0,1]$,
for every graph with $g = polylog(n)$.
  Our algorithm generalizes an algorithm of Kadria \etal{} [SODA'22] that
computes a cycle of length at most $4\left\lceil \frac{g}{2} \right\rceil -
2\left\lfloor \varepsilon \left\lceil \frac{g}{2} \right\rceil \right\rfloor $
in $\tilde{O}\big(n^{1 + \frac{1}{2 - \varepsilon}}\big)$ time. Kadria \etal{}
presented also an algorithm that finds a cycle of length at most $ 2\ell
\left\lceil \frac{g}{2} \right\rceil $ in $\tilde{O}\big(n^{1 +
\frac{1}{\ell}}\big)$ time, where $\ell$ must be an integer. Our algorithm
generalizes this algorithm, as well, by replacing the integer parameter $\ell$
in the running time exponent with a real-valued parameter $\ell - \varepsilon$,
thereby offering greater flexibility in parameter selection and enabling a
broader spectrum of combinations between running times and cycle lengths.
  We also show that for sparse graphs a better tradeoff is possible, by
presenting an $\tilde{O}(\ell\cdot m^{1+1/(\ell-\varepsilon)})$ time randomized
algorithm that returns a cycle of length at most $2\ell(\lfloor
\frac{g-1}{2}\rfloor) - 2(\lfloor \varepsilon \lfloor \frac{g-1}{2}\rfloor
\rfloor+1)$, where $\ell\geq 3$ is an integer and $\varepsilon\in [0,1)$, for
every graph with $g=polylog(n)$.
  To obtain our algorithms we develop several techniques and introduce a formal
definition of hybrid cycle detection algorithms. [...]

</details>


### [3] [A Computational Proof of the Highest-Scoring Boggle Board](https://arxiv.org/abs/2507.02117)
*Dan Vanderkam*

Main category: cs.DS

TL;DR: 论文提出了一种首次通过Branch and Bound和决策图样数据结构对Boggle棋盘进行全局最优搜索的方法，发现通过爬山法找到的高分棋盘实际为全局最优解。


<details>
  <summary>Details</summary>
Motivation: 由于Boggle棋盘可能的组合数量庞大，历史上一直无法进行全局最优解的全面搜索，而局部优化方法如爬山法和模拟退火找到的高分棋盘是否真正最优尚不明确。

Method: 采用了Branch and Bound算法和一种类似决策图的数据结构，首次对Boggle棋盘的所有可能组合进行了全局最优搜索。

Result: 研究发现，通过爬山法找到的最高分棋盘实际上是全局最优解。

Conclusion: 论文验证了局部优化方法在Boggle棋盘问题中的有效性，并提供了一种全局搜索的新方法。

Abstract: Finding all the words on a Boggle board is a classic computer programming
problem. With a fast Boggle solver, local optimization techniques such as
hillclimbing and simulated annealing can be used to find particularly
high-scoring boards. The sheer number of possible Boggle boards has
historically prevented an exhaustive search for the global optimum board. We
apply Branch and Bound and a decision diagram-like data structure to perform
the first such search. We find that the highest-scoring boards found via
hillclimbing are, in fact, the global optima.

</details>


### [4] [On the Adversarial Robustness of Online Importance Sampling](https://arxiv.org/abs/2507.02394)
*Yotam Kenneth-Mordoch,Shay Sapir*

Main category: cs.DS

TL;DR: 本文研究了在线重要性采样的对抗鲁棒性，证明了即使在自适应输入流中，该方法仍能保持逼近精度，并应用于超图切稀疏化和子空间嵌入问题。


<details>
  <summary>Details</summary>
Motivation: 重要性采样是一种重要的算法技术，但在自适应输入流中的鲁棒性尚未得到充分研究。本文旨在填补这一空白，特别是在线环境下。

Method: 通过理论和实验验证在线重要性采样的对抗鲁棒性，分析了算法在自适应输入流下的表现。

Result: 结果表明，在线重要性采样能够在自适应输入流中保持(1±ε)-逼近，同时存储成本与非自适应情况相近。

Conclusion: 本文证明了在线重要性采样在对抗适应性输入流中的有效性，并将其成功应用于超图切稀疏化和子空间嵌入问题。

Abstract: This paper studies the adversarial-robustness of importance-sampling (aka
sensitivity sampling); a useful algorithmic technique that samples elements
with probabilities proportional to some measure of their importance. A
streaming or online algorithm is called adversarially-robust if it succeeds
with high probability on input streams that may change adaptively depending on
previous algorithm outputs. Unfortunately, the dependence between stream
elements breaks the analysis of most randomized algorithms, and in particular
that of importance-sampling algorithms. Previously, Braverman et al. [NeurIPS
2021] suggested that streaming algorithms based on importance-sampling may be
adversarially-robust; however, they proved it only for well-behaved inputs.
  We focus on the adversarial-robustness of online importance-sampling, a
natural variant where sampling decisions are irrevocable and made as data
arrives. Our main technical result shows that, given as input an adaptive
stream of elements $x_1,\ldots,x_T\in \mathbb{R}_+$, online importance-sampling
maintains a $(1\pm\epsilon)$-approximation of their sum while matching (up to
lower order terms) the storage guarantees of the oblivious (non-adaptive) case.
We then apply this result to develop adversarially-robust online algorithms for
two fundamental problems: hypergraph cut sparsification and $\ell_p$ subspace
embedding.

</details>


### [5] [Numerical Linear Algebra in Linear Space](https://arxiv.org/abs/2507.02433)
*Yiping Liu,Hoai-An Nguyen,Junzhao Yang*

Main category: cs.DS

TL;DR: 提出了一种随机化的线性空间求解器，用于解决一般线性系统，无需假设矩阵的条件数，并在多项时间内提供近似解。


<details>
  <summary>Details</summary>
Motivation: 为解决一般线性系统的高效求解问题，特别是在无需假设矩阵条件数的限制下，提供一种空间和时间高效的算法。

Method: 使用随机化的线性空间方法，适用于整数矩阵和向量，通过多项式时间的计算提供近似解。

Result: 提出的求解器能在多项式时间内提供$(1+\epsilon)$近似解，且空间复杂度为线性，适用于高值右端向量。

Conclusion: 该方法是第一个在多项式时间和线性空间内求解一般线性系统的算法，并成功应用于多种数值线性代数问题。

Abstract: We present a randomized linear-space solver for general linear systems
$\mathbf{A} \mathbf{x} = \mathbf{b}$ with $\mathbf{A} \in \mathbb{Z}^{n \times
n}$ and $\mathbf{b} \in \mathbb{Z}^n$, without any assumption on the condition
number of $\mathbf{A}$. For matrices whose entries are bounded by
$\mathrm{poly}(n)$, the solver returns a $(1+\epsilon)$-multiplicative
entry-wise approximation to vector $\mathbf{x} \in \mathbb{Q}^{n}$ using
$\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ bit operations and $O(n
\log n)$ bits of working space (i.e., linear in the size of a vector), where
$\mathrm{nnz}$ denotes the number of nonzero entries. Our solver works for
right-hand vector $\mathbf{b}$ with entries up to $n^{O(n)}$. To our knowledge,
this is the first linear-space linear system solver over the rationals that
runs in $\widetilde{O}(n^2 \cdot \mathrm{nnz}(\mathbf{A}))$ time.
  We also present several applications of our solver to numerical linear
algebra problems, for which we provide algorithms with efficient polynomial
running time and near-linear space. In particular, we present results for
linear regression, linear programming, eigenvalues and eigenvectors, and
singular value decomposition.

</details>


### [6] [Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds](https://arxiv.org/abs/2507.02548)
*Itai Boneh,Egor Gorbachev,Tomasz Kociumaka*

Main category: cs.DS

TL;DR: 本文研究了动态版本的加权编辑距离问题，提出了一种在预处理后以近似最优时间维护加权编辑距离的算法。


<details>
  <summary>Details</summary>
Motivation: 近年来，针对编辑距离的快速计算取得了显著进展，尤其是在距离较小的场景下。然而，动态维护加权编辑距离的问题尚未得到充分研究。本文旨在填补这一空白，提供高效的动态算法。

Method: 提出了一种动态算法，通过预处理和参数调整，可以在每次更新后以近似最优的时间复杂度维护加权编辑距离。算法采用了一个实数参数γ来权衡预处理时间和更新时间的复杂度。

Result: 算法在预处理时间为O~(n·k^γ)后，每次更新的时间为O~(k^(3-γ))。此外，本文还通过条件性下界证明了对γ∈[0.5,1)的权衡参数的精细最优性。

Conclusion: 本文的研究为动态加权编辑距离问题提供了一个高效的解决方案，并通过理论分析验证了算法的近优性。

Abstract: The edit distance $ed(X,Y)$ of two strings $X,Y\in \Sigma^*$ is the minimum
number of character edits (insertions, deletions, and substitutions) needed to
transform $X$ into $Y$. Its weighted counterpart $ed^w(X,Y)$ minimizes the
total cost of edits, which are specified using a function $w$, normalized so
that each edit costs at least one. The textbook dynamic-programming procedure,
given strings $X,Y\in \Sigma^{\le n}$ and oracle access to $w$, computes
$ed^w(X,Y)$ in $O(n^2)$ time. Nevertheless, one can achieve better running
times if the computed distance, denoted $k$, is small: $O(n+k^2)$ for unit
weights [Landau and Vishkin; JCSS'88] and $\tilde{O}(n+\sqrt{nk^3})$ for
arbitrary weights [Cassis, Kociumaka, Wellnitz; FOCS'23].
  In this paper, we study the dynamic version of the weighted edit distance
problem, where the goal is to maintain $ed^w(X,Y)$ for strings $X,Y\in
\Sigma^{\le n}$ that change over time, with each update specified as an edit in
$X$ or $Y$. Very recently, Gorbachev and Kociumaka [STOC'25] showed that the
unweighted distance $ed(X,Y)$ can be maintained in $\tilde{O}(k)$ time per
update after $\tilde{O}(n+k^2)$-time preprocessing; here, $k$ denotes the
current value of $ed(X,Y)$. Their algorithm generalizes to small integer
weights, but the underlying approach is incompatible with large weights.
  Our main result is a dynamic algorithm that maintains $ed^w(X,Y)$ in
$\tilde{O}(k^{3-\gamma})$ time per update after $\tilde{O}(nk^\gamma)$-time
preprocessing. Here, $\gamma\in [0,1]$ is a real trade-off parameter and $k\ge
1$ is an integer threshold fixed at preprocessing time, with $\infty$ returned
whenever $ed^w(X,Y)>k$. We complement our algorithm with conditional lower
bounds showing fine-grained optimality of our trade-off for $\gamma \in
[0.5,1)$ and justifying our choice to fix $k$.

</details>


### [7] [On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms](https://arxiv.org/abs/2507.02657)
*Jens Schlöter*

Main category: cs.DS

TL;DR: 论文研究了基于可探索不确定性的背包问题，目标是自适应地查询物品利润以找到最优解，同时最小化查询次数。离线变种被证明是$Σ_2^p$-完全的，且无法近似。通过资源增强设置，作者展示了非平凡的算法结果。


<details>
  <summary>Details</summary>
Motivation: 传统背包问题中物品利润不确定，仅给出区间范围，需要通过查询获取实际利润。由于查询成本高，研究如何最小化查询次数以找到近似或最优解成为关键问题。

Method: 研究离线变种问题，假设已知精确利润，目标是计算最小查询集以使第三方能识别最优解。此外，还探索了资源增强设置，放宽算法查询集的要求。

Result: 离线变种被证明是$Σ_2^p$-完全的，且无法近似。资源增强设置下，作者提出了非平凡的算法结果。

Conclusion: 尽管离线问题具有高计算复杂度，资源增强设置为解决此类问题提供了新的研究方向，展示了算法的潜力。

Abstract: In the knapsack problem under explorable uncertainty, we are given a knapsack
instance with uncertain item profits. Instead of having access to the precise
profits, we are only given uncertainty intervals that are guaranteed to contain
the corresponding profits. The actual item profit can be obtained via a query.
The goal of the problem is to adaptively query item profits until the revealed
information suffices to compute an optimal (or approximate) solution to the
underlying knapsack instance. Since queries are costly, the objective is to
minimize the number of queries.
  In the offline variant of this problem, we assume knowledge of the precise
profits and the task is to compute a query set of minimum cardinality that a
third party without access to the profits could use to identify an optimal (or
approximate) knapsack solution. We show that this offline variant is complete
for the second-level of the polynomial hierarchy, i.e., $\Sigma_2^p$-complete,
and cannot be approximated within a non-trivial factor unless $\Sigma_2^p =
\Delta_2^p$. Motivated by these strong hardness results, we consider a
resource-augmented variant of the problem where the requirements on the query
set computed by an algorithm are less strict than the requirements on the
optimal solution we compare against. More precisely, a query set computed by
the algorithm must reveal sufficient information to identify an approximate
knapsack solution, while the optimal query set we compare against has to reveal
sufficient information to identify an optimal solution. We show that this
resource-augmented setting allows interesting non-trivial algorithmic results.

</details>


### [8] [Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime](https://arxiv.org/abs/2507.02701)
*Tomasz Kociumaka,Ali Shahali*

Main category: cs.DS

TL;DR: 该论文提出了一种改进的算法，用于计算加权和非加权树编辑距离的有界版本，时间复杂度为O(n + k^6 log k)，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的树编辑距离算法在处理大型但高度相似的树时，时间复杂度较高，尤其是加权版本。为了提升效率，研究专注于有界版本的问题，即运行时参数化为距离k。

Method: 论文首先提出了一种易于分析的O(nk^2 log n)时间算法，适用于加权情况。随后引入了一种优化方法，利用输入树中的周期性结构，并通过修改现有的通用核来利用这些结构。

Result: 提出的算法在加权和非加权设置下，时间复杂度优化为O(n + k^6 log k)，显著优于之前的最佳结果。

Conclusion: 通过利用周期性结构和改进的通用核，论文成功降低了有界树编辑距离的计算复杂度，为处理大型相似树提供了更高效的算法。

Abstract: The tree edit distance is a natural dissimilarity measure between rooted
ordered trees whose nodes are labeled over an alphabet $\Sigma$. It is defined
as the minimum number of node edits (insertions, deletions, and relabelings)
required to transform one tree into the other. In the weighted variant, the
edits have associated costs (depending on the involved node labels) normalized
so that each cost is at least one, and the goal is to minimize the total cost
of edits.
  The unweighted tree edit distance between two trees of total size $n$ can be
computed in $O(n^{2.6857})$ time; in contrast, determining the weighted tree
edit distance is fine-grained equivalent to the All-Pairs Shortest Paths
problem and requires $n^3/2^{\Omega(\sqrt{\log n})}$ time [Nogler et al.;
STOC'25]. These super-quadratic running times are unattractive for large but
very similar trees, which motivates the bounded version of the problem, where
the runtime is parameterized by the computed distance $k$, potentially yielding
faster algorithms for $k\ll n$.
  Previous best algorithms for the bounded unweighted setting run in
$O(nk^2\log n)$ time [Akmal & Jin; ICALP'21] and $O(n + k^7\log k)$ time [Das
et al.; STOC'23]. For the weighted variant, the only known running time has
been $O(n + k^{15})$.
  We present an $O(n + k^6\log k)$-time algorithm for computing the bounded
tree edit distance in both the weighted and unweighted settings. Our approach
begins with an alternative $O(nk^2\log n)$-time algorithm that handles weights
and is significantly easier to analyze than the existing counterpart. We then
introduce a novel optimization that leverages periodic structures within the
input trees. To utilize it, we modify the $O(k^5)$-size $O(n)$-time universal
kernel, the central component of the prior $O(n + k^{O(1)})$-time algorithms,
so that it produces instances containing these periodic structures.

</details>


### [9] [Indexing Tries within Entropy-Bounded Space](https://arxiv.org/abs/2507.02728)
*Lorenzo Carfagna,Carlo Tosoni*

Main category: cs.DS

TL;DR: 该研究探讨了基于BWT的索引和压缩tries的方法，提出了XBWT的简洁和压缩表示，并分析了其空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决tries的索引和压缩问题，特别是如何高效地统计由给定字符串模式到达的节点数量。

Method: 方法包括提出XBWT的简洁和压缩表示，并证明组合问题的计数公式，用于定义tries的最坏情况熵和k阶经验熵。

Result: 结果显示XBWT可以在k阶经验熵加上o(n)项的空间内编码，且在某些情况下，FM-index的空间复杂度比r-index更优。

Conclusion: 结论表明，XBWT的压缩表示在空间复杂度上表现优越，尤其是在k阶经验熵的基础上，能够实现更高效的空间利用。

Abstract: We study the problem of indexing and compressing tries using a BWT-based
approach. Specifically, we consider a succinct and compressed representation of
the XBWT of Ferragina et al.\ [FOCS '05, JACM '09] corresponding to the
analogous of the FM-index [FOCS '00, JACM '05] for tries. This representation
allows to efficiently count the number of nodes reached by a given string
pattern. To analyze the space complexity of the above trie index, we propose a
proof for the combinatorial problem of counting the number of tries with a
given symbol distribution. We use this formula to define a worst-case entropy
measure for tries, as well as a notion of k-th order empirical entropy. In
particular, we show that the relationships between these two entropy measures
are similar to those between the corresponding well-known measures for strings.
We use these measures to prove that the XBWT of a trie can be encoded within a
space bounded by our k-th order empirical entropy plus a o(n) term, with n
being the number of nodes in the trie. Notably, as happens for strings, this
space bound can be reached for every sufficiently small k simultaneously.
Finally, we compare the space complexity of the above index with that of the
r-index for tries proposed by Prezza [SODA '21] and we prove that in some cases
the FM-index for tries is asymptotically smaller.

</details>


### [10] [Connected k-Median with Disjoint and Non-disjoint Clusters](https://arxiv.org/abs/2507.02774)
*Jan Eube,Kelin Luo,Dorian Reineccius,Heiko Röglin,Melanie Schmidt*

Main category: cs.DS

TL;DR: 论文研究了连通k-中值问题，提出了一种近似算法和精确算法，并探讨了其在多个领域的应用。


<details>
  <summary>Details</summary>
Motivation: 连通k-中值问题结合了距离聚类和连通性信息，在测量学、社交网络分析和生物信息学等领域有广泛应用，尤其是重叠聚类的情况。

Method: 研究提出了一种$$\mathcal{O}(k^2 \log n)$-近似算法，并在不重叠聚类的情况下给出了$$\Omega(n^{1-\epsilon})$-难解性结果，以及在树结构连通图中提供了精确算法。

Result: 论文的主要结果是$$\mathcal{O}(k^2 \log n)$-近似算法，同时证明了在不重叠聚类情况下问题的难解性，并提出了树结构连通图中的精确算法。

Conclusion: 连通k-中值问题在重叠聚类的情况下可以实现有效近似，但在不重叠聚类的情况下具有较高的计算复杂度，除非连通图具有特定结构（如树）。

Abstract: The connected $k$-median problem is a constrained clustering problem that
combines distance-based $k$-clustering with connectivity information. The
problem allows to input a metric space and an unweighted undirected
connectivity graph that is completely unrelated to the metric space. The goal
is to compute $k$ centers and corresponding clusters such that each cluster
forms a connected subgraph of $G$, and such that the $k$-median cost is
minimized.
  The problem has applications in very different fields like geodesy
(particularly districting), social network analysis (especially community
detection), or bioinformatics. We study a version with overlapping clusters
where points can be part of multiple clusters which is natural for the use case
of community detection. This problem variant is $\Omega(\log n)$-hard to
approximate, and our main result is an $\mathcal{O}(k^2 \log n)$-approximation
algorithm for the problem. We complement it with an
$\Omega(n^{1-\epsilon})$-hardness result for the case of disjoint clusters
without overlap with general connectivity graphs, as well as an exact algorithm
in this setting if the connectivity graph is a tree.

</details>


### [11] [On the Structure of Replicable Hypothesis Testers](https://arxiv.org/abs/2507.02842)
*Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Shyam Narayanan,Sandeep Silwal*

Main category: cs.DS

TL;DR: 本文提出了可复现假设测试算法的通用工具，通过定义规范属性并改进设计策略，为均匀性、一致性和接近性测试提供了新的下界，并在高斯均值测试中实现了高效算法。


<details>
  <summary>Details</summary>
Motivation: 可复现性能够增强对测试过程的信任，并与算法稳定性、泛化性和隐私性密切相关。本文旨在为可复现测试器的样本复杂度提供统一且定量的改进工具。

Method: 通过定义一组规范属性，并将任何可复现测试算法调整为满足这些属性的形式。采用基于已知期望和有限方差测试统计量的设计策略，使非可复现测试器以最小开销实现可复现性。

Result: 为硬币测试和接近性测试提供了常数倍最优界，并在均匀性测试中实现免费可复现性。此外，在高斯均值测试中，提出了多项式时间算法，优于现有工作。

Conclusion: 本文通过规范属性和改进设计策略，显著提升了可复现假设测试算法的效率和适用范围，解决了多个开放性问题，并为未来研究提供了通用框架。

Abstract: A hypothesis testing algorithm is replicable if, when run on two different
samples from the same distribution, it produces the same output with high
probability. This notion, defined by by Impagliazzo, Lei, Pitassi, and Sorell
[STOC'22], can increase trust in testing procedures and is deeply related to
algorithmic stability, generalization, and privacy. We build general tools to
prove lower and upper bounds on the sample complexity of replicable testers,
unifying and quantitatively improving upon existing results.
  We identify a set of canonical properties, and prove that any replicable
testing algorithm can be modified to satisfy these properties without worsening
accuracy or sample complexity. A canonical replicable algorithm computes a
deterministic function of its input (i.e., a test statistic) and thresholds
against a uniformly random value in $[0,1]$. It is invariant to the order in
which the samples are received, and, if the testing problem is ``symmetric,''
then the algorithm is also invariant to the labeling of the domain elements,
resolving an open question by Liu and Ye [NeurIPS'24]. We prove new lower
bounds for uniformity, identity, and closeness testing by reducing to the case
where the replicable algorithm satisfies these canonical properties.
  We systematize and improve upon a common strategy for replicable algorithm
design based on test statistics with known expectation and bounded variance.
Our framework allow testers which have been extensively analyzed in the
non-replicable setting to be made replicable with minimal overhead. As direct
applications of our framework, we obtain constant-factor optimal bounds for
coin testing and closeness testing and get replicability for free in a large
parameter regime for uniformity testing.
  We also give state-of-the-art bounds for replicable Gaussian mean testing,
and, unlike prior work, our algorithm runs in polynomial time.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [12] [Engineering an LTLf Synthesis Tool](https://arxiv.org/abs/2507.02491)
*Alexandre Duret-Lutz,Shufang Zhu,Nir Piterman,Giuseppe de Giacomo,Moshe Y Vardi*

Main category: cs.FL

TL;DR: 该论文提出了一种基于MTBDD的LTLf合成方法，能够高效构建满足LTLf规范的转换器，并在基准测试中超越了现有工具。


<details>
  <summary>Details</summary>
Motivation: 为了解决LTLf反应式合成的问题，即构建一个转换器，使其输出基于输入历史，并为每个无限输入序列生成满足LTLf规范的轨迹。

Method: 提出了一种新的、直接的LTLf到DFA的转换方法，通过共享节点的MTBDD数组表示，并将其解释为一个在构建时动态求解的可达性游戏。

Result: 该方法在基准测试中表现出优于现有工具的性能。

Conclusion: 基于MTBDD的LTLf合成方法是高效且可行的，能够显著提升合成器的性能表现。

Abstract: The problem of LTLf reactive synthesis is to build a transducer, whose output
is based on a history of inputs, such that, for every infinite sequence of
inputs, the conjoint evolution of the inputs and outputs has a prefix that
satisfies a given LTLf specification. We describe the implementation of an LTLf
synthesizer that outperforms existing tools on our benchmark suite. This is
based on a new, direct translation from LTLf to a DFA represented as an array
of Binary Decision Diagrams (MTBDDs) sharing their nodes. This MTBDD-based
representation can be interpreted directly as a reachability game that is
solved on-the-fly during its construction.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [13] [Gbake: Baking 3D Gaussian Splats into Reflection Probes](https://arxiv.org/abs/2507.02257)
*Stephen Pasch,Joel K. Salzman,Changxi Zheng*

Main category: cs.GR

TL;DR: GBake是一个专门用于从高斯散射场景中烘焙反射探针的工具，使传统3D网格在Unity游戏引擎中实现逼真的反射映射。


<details>
  <summary>Details</summary>
Motivation: 随着3D高斯散射技术的普及，需要在散射环境中集成传统计算机图形技术和资源。由于3D高斯基元将光照和几何信息编码为外观，直接插入3D高斯混合物中的网格会出现光照不匹配的问题。

Method: 作者提出了GBake工具，用于从高斯散射场景中烘焙反射探针，从而在Unity游戏引擎中实现传统3D网格的逼真反射映射。

Result: GBake能够有效解决3D网格在高斯散射环境中光照不匹配的问题，实现更自然的视觉效果。

Conclusion: GBake为3D高斯散射环境中的传统3D网格提供了逼真的反射映射解决方案，提升了视觉一致性。

Abstract: The growing popularity of 3D Gaussian Splatting has created the need to
integrate traditional computer graphics techniques and assets in splatted
environments. Since 3D Gaussian primitives encode lighting and geometry jointly
as appearance, meshes are relit improperly when inserted directly in a mixture
of 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a
specialized tool for baking reflection probes from Gaussian-splatted scenes
that enables realistic reflection mapping of traditional 3D meshes in the Unity
game engine.

</details>


### [14] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
*Tom Kneiphof,Reinhard Klein*

Main category: cs.GR

TL;DR: 该论文提出了一种高效的图像光照近似方法，用于实时渲染具有闪光或闪烁外观的材料，支持动态材质属性和环境贴图。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在实时渲染中模拟离散微面材质（如闪光或闪烁表面）时遇到的挑战，特别是在动态光照条件下的高效渲染问题。

Method: 论文方法基于实时区域光照下的闪光渲染，采用标准的环境贴图滤波技术。通过将环境贴图划分为少量均匀区域，并使用正态分布函数滤波，计算微面从每个区域反射光的概率。

Result: 实验证明，该方法的实时近似结果接近真实渲染效果，适用于多种材质属性和光照条件，性能稳定且额外开销低。

Conclusion: 该方法在实时渲染闪光效果上表现出色，虽需两倍内存存储预滤波环境贴图，但性能优势显著。

Abstract: Image-based lighting is a widely used technique to reproduce shading under
real-world lighting conditions, especially in real-time rendering applications.
A particularly challenging scenario involves materials exhibiting a sparkling
or glittering appearance, caused by discrete microfacets scattered across their
surface. In this paper, we propose an efficient approximation for image-based
lighting of glints, enabling fully dynamic material properties and environment
maps. Our novel approach is grounded in real-time glint rendering under area
light illumination and employs standard environment map filtering techniques.
Crucially, our environment map filtering process is sufficiently fast to be
executed on a per-frame basis. Our method assumes that the environment map is
partitioned into few homogeneous regions of constant radiance. By filtering the
corresponding indicator functions with the normal distribution function, we
obtain the probabilities for individual microfacets to reflect light from each
region. During shading, these probabilities are utilized to hierarchically
sample a multinomial distribution, facilitated by our novel dual-gated Gaussian
approximation of binomial distributions. We validate that our real-time
approximation is close to ground-truth renderings for a range of material
properties and lighting conditions, and demonstrate robust and stable
performance, with little overhead over rendering glints from a single
directional light. Compared to rendering smooth materials without glints, our
approach requires twice as much memory to store the prefiltered environment
map.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [15] [Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems](https://arxiv.org/abs/2507.02464)
*Craig S Wright*

Main category: cs.GT

TL;DR: 本文提出了一种基于自动机理论和经济学的框架，将CAP定理中的权衡问题重新定义为约束优化问题，并通过经济激励机制在分布式系统中实现稳定共识行为。


<details>
  <summary>Details</summary>
Motivation: CAP定理揭示了分布式系统中一致性、可用性和分区容忍性之间的三难问题。本文旨在通过引入经济学和控制理论的方法，重新定义和解决这一权衡问题。

Method: 作者将分布式系统建模为分区感知状态机，并嵌入经济激励机制以稳定在分区网络中的共识行为。通过将博弈论机制整合到全局转移语义中，定义了收敛、活性和正确性的可证明边界。

Result: 结果表明，在有限的ε边界内，可以同时保持一致性和可用性，从而通过形式化的经济控制扩展了经典CAP定理的限制。

Conclusion: 本文通过经济激励和状态机建模，为分布式系统中的CAP权衡问题提供了新的解决方案，有效地扩展了传统理论的边界。

Abstract: The CAP theorem asserts a trilemma between consistency, availability, and
partition tolerance. This paper introduces a rigorous automata-theoretic and
economically grounded framework that reframes the CAP trade-off as a constraint
optimization problem. We model distributed systems as partition-aware state
machines and embed economic incentive layers to stabilize consensus behavior
across adversarially partitioned networks. By incorporating game-theoretic
mechanisms into the global transition semantics, we define provable bounds on
convergence, liveness, and correctness. Our results demonstrate that
availability and consistency can be simultaneously preserved within bounded
epsilon margins, effectively extending the classical CAP limits through formal
economic control.

</details>


### [16] [TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games](https://arxiv.org/abs/2507.02675)
*Zhaoqilin Yang,Xin Wang,Ruichen Zhang,Chanchan Li,Youliang Tian*

Main category: cs.GT

TL;DR: 论文提出了一种名为TUC-PPO的新强化学习框架，通过整合团队福利目标来优化空间公共物品游戏中的合作行为，相比传统方法具有更快的收敛速度和更强的稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法在空间公共物品游戏中仅通过个体奖励间接促进合作，缺乏对团队目标的直接优化。TUC-PPO旨在通过明确的团队效用约束来解决这一问题。

Method: TUC-PPO扩展了PPO框架，通过双层目标整合策略梯度和团队效用约束，使用自适应拉格朗日乘子进行约束优化，使策略更新明确包含集体收益阈值。

Result: 实验显示，TUC-PPO在收敛速度和抵抗背叛者入侵的稳定性上优于未修改的PPO和进化博弈理论基线，更快达到合作均衡。

Conclusion: TUC-PPO将团队目标正式整合到策略更新中，为多智能体强化学习和进化博弈理论研究提供了新的计算工具，推动了社会困境问题的解决。

Abstract: We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO),
a new deep reinforcement learning framework. It extends Proximal Policy
Optimization (PPO) by integrating team welfare objectives specifically for
spatial public goods games. Unlike conventional approaches where cooperation
emerges indirectly from individual rewards, TUC-PPO instead optimizes a
bi-level objective integrating policy gradients and team utility constraints.
Consequently, all policy updates explicitly incorporate collective payoff
thresholds. The framework preserves PPO's policy gradient core while
incorporating constrained optimization through adaptive Lagrangian multipliers.
Therefore, decentralized agents dynamically balance selfish and cooperative
incentives. The comparative analysis demonstrates superior performance of this
constrained deep reinforcement learning approach compared to unmodified PPO and
evolutionary game theory baselines. It achieves faster convergence to
cooperative equilibria and greater stability against invasion by defectors. The
framework formally integrates team objectives into policy updates. This work
advances multi-agent deep reinforcement learning for social dilemmas while
providing new computational tools for evolutionary game theory research.

</details>


### [17] [Learning to Coordinate Bidders in Non-Truthful Auctions](https://arxiv.org/abs/2507.02801)
*Hu Fu,Tao Lin*

Main category: cs.GT

TL;DR: 研究了在非真实拍卖（如一价拍卖和全支付拍卖）中学习贝叶斯相关均衡（BCE）的样本复杂度，证明了可以用多项式样本量实现学习。


<details>
  <summary>Details</summary>
Motivation: 非真实拍卖中投标人的独立策略行为（贝叶斯纳什均衡）难以描述且可能导致不良结果，因此需要协调投标人，但BCE的实现需要投标人私人估值的分布信息，而这些信息通常不可得。

Method: 采用了一种将问题转化为估计投标人期望效用的方法，并结合了对投标人所有单调投标策略类的伪维度分析。

Result: 证明了在一大类非真实拍卖中，包括一价拍卖和全支付拍卖，可以用多项式数量的样本（$\tilde O(\frac{n}{\varepsilon^2})$）学习BCE。

Conclusion: 研究为在缺乏投标人估值分布信息的情况下实现BCE提供了可行方案，拓展了非真实拍卖的设计思路。

Abstract: In non-truthful auctions such as first-price and all-pay auctions, the
independent strategic behaviors of bidders, with the corresponding equilibrium
notion -- Bayes Nash equilibria -- are notoriously difficult to characterize
and can cause undesirable outcomes. An alternative approach to designing better
auction systems is to coordinate the bidders: let a mediator make
incentive-compatible recommendations of correlated bidding strategies to the
bidders, namely, implementing a Bayes correlated equilibrium (BCE). The
implementation of BCE, however, requires knowledge of the distribution of
bidders' private valuations, which is often unavailable. We initiate the study
of the sample complexity of learning Bayes correlated equilibria in
non-truthful auctions. We prove that the BCEs in a large class of non-truthful
auctions, including first-price and all-pay auctions, can be learned with a
polynomial number $\tilde O(\frac{n}{\varepsilon^2})$ of samples from the
bidders' value distributions. Our technique is a reduction to the problem of
estimating bidders' expected utility from samples, combined with an analysis of
the pseudo-dimension of the class of all monotone bidding strategies of
bidders.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [18] [SMT-Sweep: Word-Level Representation Unification for Hardware Verification](https://arxiv.org/abs/2507.02008)
*Ziyi Yang,Guangyu Hu,Mingkai Miao,Changyuan Yu,Hongce Zhang*

Main category: cs.LO

TL;DR: SMT-Sweep是一种基于SMT的硬件验证新方法，扩展了传统的SAT技术，以处理复杂的字级构造，如位向量和数组操作，展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着硬件验证中字级构造（如位向量操作和数组）的广泛使用，传统的位级SAT技术已无法满足需求，因此需要一种新的字级简化与等价验证方法。

Method: SMT-Sweep通过结合随机化和约束驱动的字级模拟，利用SMT技术处理字级逻辑表达式和操作语义，弥补了传统SAT技术的不足。

Result: 实验结果表明，SMT-Sweep在速度上显著优于现有的位级SAT技术和字级SMT求解方法，平均提升44倍和69倍。

Conclusion: SMT-Sweep首次将简化技术引入基于SMT的硬件验证，并展示了其高效性，为相关领域的研究提供了新方向。

Abstract: SAT sweeping has long been a cornerstone technique in logic simplification
and equivalence checking at the bit level, leveraging structural hashing,
simulation and SAT solving to prune redundant logic. However, with the growing
adoption of word-level constructs in hardware verification, such as bit-vector
operations, arithmetics and arrays, there lacks a counterpart of SAT sweeping
at the word level. In this paper, we introduce SMT-Sweep, a novel extension of
SAT sweeping into the word level, grounded in Satisfiability Modulo Theories
(SMT). SMT-Sweep takes advantage of simulation and equivalence detection to
handle SMT terms with rich bit-vector operations and array semantics. Our
framework incorporates both randomized and constraint-driven word-level
simulation tailored to symbolic expressions and operator semantics beyond pure
Boolean logic. Experimental results show that SMT-Sweep achieves significant
speed-up compared to state-of-the-art bit-level SAT sweeping and word-level
monolithic SMT solving (averaging around 44x and 69x, respectively).To the best
of our knowledge, this is the first work that brings sweeping techniques to
SMT-based hardware verification. The implementation is open-sourced at:
https://github.com/yangziyiiii/SMT-Sweep.

</details>


### [19] [Decision algorithms for fragments of real analysis. III: A theory of differentiable functions with (semi-)open intervals](https://arxiv.org/abs/2507.02742)
*G. Buriola,D. Cantone,G. Cincotti,E. G. Omodeo,G. T. Spartà*

Main category: cs.LO

TL;DR: 本文扩展了未量化语言的可满足性测试，通过引入具有连续一阶导数的实函数变量，提出了一种将公式预处理为实数初等代数的方法。


<details>
  <summary>Details</summary>
Motivation: 为了扩展Tarski的初等代数片段，使其包含具有连续一阶导数的实函数，并解决这些函数在区间上的性质比较问题。

Method: 通过预处理将给定的公式转换为等价的实数初等代数的无量词公式，再利用Tarski的决策方法检查其可满足性。

Result: 展示了如何将包含函数变量的公式转换为仅含实数变量的公式，并通过插值函数保证了转换的可满足性保持性。

Conclusion: 提出的方法成功地将函数变量引入的复杂性问题转化为实数变量的可满足性检查，扩展了现有理论的适用范围。

Abstract: This paper enriches preexisting satisfiability tests for unquantified
languages, which in turn augment a fragment of Tarski's elementary algebra with
unary real functions possessing a continuous first derivative.
  Two sorts of individual variables are available, one ranging over real
numbers and the other one ranging over the functions of interest. Numerical
terms are built from real variables through constructs designating the four
basic arithmetic operations and through the function-application constructs
$f(t)$ and $D[\,f\,](t)$, where $f$ stands for a function variable, $t$ for a
numerical term, and $D[\,\sqdot\,]$ designates the differentiation operator.
Comparison relators can be placed between numerical terms. An array of
predicate symbols are also available, designating various relationships between
functions, as well as function properties, that may hold over intervals of the
real line; those are: (pointwise) function comparisons, strict and nonstrict
monotonicity~/~convexity~/~concavity properties, comparisons between the
derivative of a function and a real term--here, w.r.t.\ earlier research, they
are extended to (semi)-open intervals.
  The decision method we propose consists in preprocessing the given formula
into an equisatisfiable quantifier-free formula of the elementary algebra of
real numbers, whose satisfiability can then be checked by means of Tarski's
decision method. No direct reference to functions will appear in the target
formula, each function variable having been superseded by a collection of stub
real variables; hence, in order to prove that the proposed translation is
satisfiability-preserving, we must figure out a sufficiently flexible family of
interpolating $C^1$ functions that can accommodate a model for the source
formula whenever the target formula turns out to be satisfiable.

</details>


### [20] [A Proof-Theoretic View of Basic Intuitionistic Conditional Logic (Extended Version)](https://arxiv.org/abs/2507.02767)
*Tiziano Dalmonte,Marianna Girlando*

Main category: cs.LO

TL;DR: 本文研究了直觉主义条件逻辑，通过结合Chellas的条件逻辑CK和直觉主义框架，提出了IntCK和CCKbox两种变体，并进一步扩展了CCK逻辑。


<details>
  <summary>Details</summary>
Motivation: 旨在为条件推理提供一个构造性的分析框架，并解决直觉主义条件下运算符不可互定义的问题。

Method: 结合了Chellas的条件逻辑CK和直觉主义模态逻辑框架，提出了IntCK和CCKbox的证明系统，并扩展为带might运算符的CCK逻辑。

Result: 提出了IntCK的嵌套演算和CCKbox的序列演算，并定义了CCK逻辑的模型类和公理化系统，进一步扩展了CCK的逻辑变体。

Conclusion: 通过构造性方法成功扩展了直觉主义条件逻辑，为条件推理提供了更丰富的逻辑工具和分析框架。

Abstract: Intuitionistic conditional logic, studied by Weiss, Ciardelli and Liu, and
Olkhovikov, aims at providing a constructive analysis of conditional reasoning.
In this framework, the would and the might conditional operators are no longer
interdefinable. The intuitionistic conditional logics considered in the
literature are defined by setting Chellas' conditional logic CK, whose
semantics is defined using selection functions, within the constructive and
intuitionistic framework introduced for intuitionistic modal logics. This
operation gives rise to a constructive and an intuitionistic variant of
(might-free-) CK, which we call CCKbox and IntCK respectively. Building on the
proof systems defined for CK and for intuitionistic modal logics, in this paper
we introduce a nested calculus for IntCK and a sequent calculus for CCKbox.
Based on the sequent calculus, we define CCK, a conservative extension of
Weiss' logic CCKbox with the might operator. We introduce a class of models and
an axiomatization for CCK, and extend these result to several extensions of
CCK.

</details>


### [21] [Subtyping in DHOL -- Extended preprint](https://arxiv.org/abs/2507.02855)
*Colin Rothgang,Florian Rabe*

Main category: cs.LO

TL;DR: DHOL是一种依赖类型的高阶逻辑，通过牺牲类型系统的可判定性来增强表达能力，同时保持了自动定理证明的支持。本文通过将DHOL扩展为包含精化和商类型，进一步提升了其实用性。


<details>
  <summary>Details</summary>
Motivation: 精化和商类型在实践中需求广泛，但由于它们需要不可判定的类型系统，很少被自动定理证明器提供。DHOL的设计使得这种扩展成为可能。

Method: 通过将精化和商类型作为子类型的特例引入DHOL，避免复杂的表示变化。扩展语言的语法、语义以及到HOL的翻译，并提供了相关证明。

Result: 扩展后的DHOL支持精化和商类型，同时保持了自动化支持，证明了其语法和语义的合理性。

Conclusion: DHOL的扩展展示了一种优雅且简单的解决方案，既满足了实践需求，又保留了自动化定理证明的能力。

Abstract: The recently introduced dependent typed higher-order logic (DHOL) offers an
interesting compromise between expressiveness and automation support. It
sacrifices the decidability of its type system in order to significantly extend
its expressiveness over standard HOL. Yet it retains strong automated theorem
proving support via a sound and complete translation to HOL.
  We leverage this design to extend DHOL with refinement and quotient types.
Both of these are commonly requested by practitioners but rarely provided by
automated theorem provers. This is because they inherently require undecidable
typing and thus are very difficult to retrofit to decidable type systems. But
with DHOL already doing the heavy lifting, adding them is not only possible but
elegant and simple.
  Concretely, we add refinement and quotient types as special cases of
subtyping. This turns the associated canonical inclusion resp. projection maps
into identity maps and thus avoids costly changes in representation. We present
the syntax, semantics, and translation to HOL for the extended language,
including the proofs of soundness and completeness.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [22] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
*Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 该论文提出了DecoRTL，一种新型的运行时解码策略，专门用于提升大型语言模型在RTL代码生成中的表现。该方法通过自一致性采样和语法感知的温度调整，显著提高了生成代码的语法有效性、功能正确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM解码策略在RTL代码生成中常导致代码重复、无效或与语义不符的问题。论文通过分析令牌级熵，发现模型在结构或语义复杂的区域置信度低，需要新的解码策略来解决这一问题。

Method: 论文提出DecoRTL方法，包含两个关键组件：自一致性采样（生成多个候选并重新排序）和语法感知的温度调整（按语法功能动态调整采样温度）。

Result: 在VerilogEval基准测试中，DecoRTL显著提高了生成代码的语法有效性、功能正确性和多样性，且运行时开销几乎不可感知。

Conclusion: DecoRTL是一种无需额外模型微调的解决方案，适用于RTL代码生成任务，有效解决了传统解码策略的局限性。

Abstract: As one of their many applications, large language models (LLMs) have recently
shown promise in automating register transfer level (RTL) code generation.
However, conventional LLM decoding strategies, originally designed for natural
language, often fail to meet the structural and semantic demands of RTL,
leading to hallucinated, repetitive, or invalid code outputs. In this paper, we
first investigate the root causes of these decoding failures through an
empirical analysis of token-level entropy during RTL generation. Our findings
reveal that LLMs exhibit low confidence in regions of structural ambiguity or
semantic complexity, showing that standard decoding strategies fail to
differentiate between regions requiring determinism (syntax-critical regions)
and those that benefit from creative exploratory variability (design-critical
regions). Then, to overcome this, we introduce DecoRTL, a novel run-time
decoding strategy, that is both syntax-aware and contrastive for RTL code
generation. DecoRTL integrates two complementary components: (i)
self-consistency sampling, which generates multiple candidates and re-ranks
them based on token-level agreement to promote correctness while maintaining
diversity; and (ii) syntax-aware temperature adaptation, which classifies
tokens by their syntactical and functional roles and adjusts the sampling
temperature accordingly, enforcing low temperature for syntax-critical tokens
and higher temperature for exploratory ones. Our approach operates entirely at
inference time without requiring any additional model fine-tuning. Through
evaluations on multiple open-source LLMs using the VerilogEval benchmark, we
demonstrate significant improvements in syntactic validity, functional
correctness, and output diversity, while the execution overhead (performance
overhead) is imperceptible.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [23] [Computability of a Whitney Extension](https://arxiv.org/abs/2507.02113)
*Andrea Brun,Guido Gherardi,Alberto Marcone*

Main category: math.LO

TL;DR: 证明了在输入适当表示时，Whitney扩展的可计算性，即可以从Whitney jet构造出相应的光滑扩展函数。


<details>
  <summary>Details</summary>
Motivation: 研究Whitney扩展问题的可计算性，为处理闭集上的函数扩展提供计算理论基础。

Method: 利用闭集上的距离函数可计算性，以及Whitney jet的输入表示，构造满足条件的$C^{m}$光滑扩展函数。

Result: 成功证明了在输入适当表示时，Whitney扩展的可计算性，并构造出满足条件的扩展函数。

Conclusion: 该研究为Whitney扩展问题的可计算性提供了理论依据，并在实际应用中展示了其可行性。

Abstract: We prove the computability of a version of Whitney Extension, when the input
is suitably represented. More specifically, if $F \subseteq \mathbb{R}^n$ is a
closed set represented so that the distance function $x \mapsto d(x,F)$ can be
computed, and $(f^{(\bar{k})})_{|\bar{k}| \le m}$ is a Whitney jet of order $m$
on $F$, then we can compute $g \in C^{m}(\mathbb{R}^n)$ such that $g$ and its
partial derivatives coincide on $F$ with the corresponding functions of
$(f^{(\bar{k})})_{|\bar{k}| \le m}$.

</details>


### [24] [Abstract Model Structures and Compactness Theorems](https://arxiv.org/abs/2507.02343)
*Sayantan Roy,Sankha S. Basu,Mihir K. Chakraborty*

Main category: math.LO

TL;DR: 该论文提出了一个独立于逻辑语法/语义特性的广义紧致性概念，通过抽象模型结构实现了紧致性定理的通用化，并证明了一类特定紧致抽象模型结构的若干特征定理。


<details>
  <summary>Details</summary>
Motivation: 传统的紧致性定理证明依赖于特定逻辑的语法或语义特性，限制了其通用性。本文旨在通过抽象模型结构，发展一种不依赖于这些特性的广义紧致性概念。

Method: 使用抽象模型结构（abstract model structures）的概念，构建了一个广义的紧致性定义，该方法摆脱了对具体逻辑语法或语义特性的依赖。

Result: 成功定义了一种广义的紧致性概念，并证明了一类特定紧致抽象模型结构的特征定理，显示了该方法的有效性。

Conclusion: 通过抽象模型结构，本文提供了一种独立于逻辑具体特性的紧致性定义，为逻辑学中的紧致性研究提供了新的理论工具。

Abstract: The compactness theorem for a logic states, roughly, that the satisfiability
of a set of well-formed formulas can be determined from the satisfiability of
its finite subsets, and vice versa. Usually, proofs of this theorem depend on
the syntactic/semantic particularities of the corresponding logic. In this
paper, using the notion of \emph{abstract model structures}, we show that one
can develop a generalized notion of compactness that is independent of these.
Several characterization theorems for a particular class of compact abstract
model structures are also proved.

</details>


<div id='math.RT'></div>

# math.RT [[Back]](#toc)

### [25] [Group schemes and their Lie algebras over a symmetric tensor category](https://arxiv.org/abs/2507.02031)
*Dave Benson,Julia Pevtsova*

Main category: math.RT

TL;DR: 文章研究了对称张量范畴上的仿射群概形理论，重点关注单位元的切空间，并证明其具有限制李代数结构。


<details>
  <summary>Details</summary>
Motivation: 研究对称张量范畴上的仿射群概形及其切空间的结构，为进一步理解群概形的性质提供理论基础。

Method: 通过分析单位元的切空间，将其视为限制李代数，并展示其与群概形上的度一分布或坐标环上的右不变导数的等价性。

Result: 证明了切空间具有限制李代数结构，并在特征为二的对称张量范畴 $ackslash ackslash mathsf{Ver}_4^+$ 中具体展示了理论应用。

Conclusion: 该研究为对称张量范畴上的群概形提供了新的理论视角，特别在特征二的特定范畴中验证了理论的可行性。

Abstract: We investigate the theory of affine group schemes over a symmetric tensor
category, with particular attention to the tangent space at the identity. We
show that this carries the structure of a restricted Lie algebra, and can be
viewed as the degree one distributions on the group scheme, or as the right
invariant derivations on the coordinate ring. In the second half of the paper,
we illustrate the theory in the particular case of the symmetric tensor
category $\mathsf{Ver}_4^+$ in characteristic two.

</details>


### [26] [A geometric model for the non-$τ$-rigid modules of type $\widetilde{D}_n$](https://arxiv.org/abs/2507.02218)
*Blake Jackson*

Main category: math.RT

TL;DR: 本文为类型$ackslash widetilde{D}\_n$的非$ackslash tau$-刚性模块提供了一个几何模型，并讨论了其与扩展空间维度的关系。


<details>
  <summary>Details</summary>
Motivation: 先前已有对类型$A\_n, D\_n, \widetilde{A}\_n$的模块类别以及类型$\widetilde{D}\_n$的$\tau$-刚性模块的几何模型研究，本文旨在填补非$\tau$-刚性模块的模型空缺。

Method: 利用几何模型中的"相交-维度公式"，将曲线的交点数与模块间的扩展空间维度关联起来，从而通过组合计算得到同调数据。

Result: 由于类型$\widetilde{D}\_n$的Auslander-Reiten箭图有无限多个不相交的稳定管，几何模型中需要对可接受边进行额外标记以避免混淆。

Conclusion: 本文成功构建了非$\tau$-刚性模块的几何模型，并通过额外标记解决了稳定管不相交的问题。

Abstract: We give a geometric model for the non-$\tau$-rigid modules over acyclic path
algebras of type $\widetilde{D}_n$. Similar models have been provided for
module categories over path algebras of types $A_n, D_n,$ and $\widetilde{A}_n$
as well as the $\tau$-rigid modules of type $\widetilde{D}_n$. A major draw of
these geometric models is the "intersection-dimension formulas" they often come
with. These formulas give an equality between the intersection number of the
curves representing the modules in the geometric model and the dimension of the
extension spaces between the two modules. This formula allows us to calculate
the homological data between two modules combinatorially. Since there are
infinitely many distinct homogeneous stable tubes in the regular component of
the Auslander-Reiten quiver of type $\widetilde{D}_n$, all of which are
disjoint, our geometric data requires an extra decoration on the admissible
edges in our geometric model to prevent intersections between curves
corresponding to modules in distinct stable tubes of the Auslander-Reiten
quiver.

</details>


### [27] [Induction for extended affine type A Soergel bimodules from a maximal parabolic](https://arxiv.org/abs/2507.02347)
*Marco Mackaay,Vanessa Miemietz,Pedro Vaz*

Main category: math.RT

TL;DR: 本文首次尝试将拓展仿射A型Hecke代数的有限维表示的Zelevinsky张量积进行分类。


<details>
  <summary>Details</summary>
Motivation: 研究拓展仿射A型Hecke代数的有限维表示的Zelevinsky张量积的分类问题，以填补相关领域的理论空白。

Method: 采用分类方法，对拓展仿射A型Hecke代数的有限维表示的Zelevinsky张量积进行初步探索。

Result: 本文首次提出了拓展仿射A型Hecke代数的有限维表示的分类理论框架。

Conclusion: 为拓展仿射A型Hecke代数的表示理论提供了新的理论基础和分类方向。

Abstract: In this paper we take a first step towards the categorification of the
Zelevinsky tensor product of finite dimensional representations of extended
affine type A Hecke algebras.

</details>


### [28] [Non-weight modules over the BMS-Kac-Moody algebra](https://arxiv.org/abs/2507.02553)
*Qiufan Chen,Cong Guo*

Main category: math.RT

TL;DR: 本文构建并分类了BMS-Kac-Moody代数上的一类非权模，这些模在限制于Cartan子代数的通用包络代数时是秩为一的自由模，并确定了这些模的不可约性和同构类。


<details>
  <summary>Details</summary>
Motivation: 研究BMS-Kac-Moody代数上的非权模的性质和分类，特别是秩为一的自由模的特性和结构。

Method: 通过构造和分类BMS-Kac-Moody代数上的非权模，特别是限制于Cartan子代数的通用包络代数时的秩为一自由模。

Result: 成功分类了这类非权模，并确定了它们的不可约性和同构类。

Conclusion: 这些结果为BMS-Kac-Moody代数上的非权模研究提供了重要的分类和性质分析工具。

Abstract: In this paper, we construct and classify a class of non-weight modules over
the BMS-Kac-Moody algebra, which are free modules of rank one when restricted
to the universal enveloping algebra of the Cartan subalgebra (modulo center).
We give the classification of such modules. Moreover, the irreducibility and
the isomorphism classes of these modules are determined.

</details>


### [29] [A conjecture on the tensor ideal for an elementary p-group generated by the restriction of a Steinberg module](https://arxiv.org/abs/2507.02722)
*Kevin Coulembier,Johannes Flake*

Main category: math.RT

TL;DR: 该论文探讨了一个猜想，即有限维模表示与最大非投影限制Steinberg模的张量积是限制倾斜模，并展示了其在张量分类中的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 研究这一猜想有助于推动正特征张量分类理论的进展，特别是关于不可压缩对称张量分类的主要开放猜想。

Method: 作者通过分析和证明，为猜想提供了部分支持性证据。

Result: 论文展示了一些支持猜想的证据，表明其在理论中的潜在重要性。

Conclusion: 该研究为张量分类理论中的核心问题提供了新的视角和证据。

Abstract: In previous work (Coulembier--Flake 2024), the authors conjectured that the
tensor product of an arbitrary finite-dimensional modular representation of an
elementary abelian $p$-group with the biggest non-projective restricted
Steinberg $SL_2$-module is a restricted tilting module. We showed that the
validity of the conjecture would have interesting implications in the theory of
tensor categories in positive characteristic, in particular, with respect to
the classification of incompressible symmetric tensor categories, which is the
subject of arguably the main open conjecture in the area. We present here some
evidence for the conjecture to hold.

</details>
