<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Extrinsic Vector Field Processing](https://arxiv.org/abs/2601.10621)
*Hongyi Liu,Oded Stein,Amir Vaxman,Mirela Ben-Chen,Misha Kazhdan*

Main category: cs.GR

TL;DR: 该论文提出了一种新颖的三角网格切向量场的离散化方法，通过Phong映射和Rodrigues旋转定义连续切向量场的外在基，从而支持协变导数场的定义和标准向量场处理算子的计算。


<details>
  <summary>Details</summary>
Motivation: 传统的切向量场离散化方法在连续性和弱可微性方面存在局限性，论文旨在通过一种新方法解决这些问题，并支持更高效的向量场处理。

Method: 利用Phong映射连续分配网格点的法向量，通过Rodrigues旋转将顶点切向量扩展到三角形内部，定义连续且弱可微的切向量场，进而计算协变导数场和相关算子。

Result: 该方法能够定义协变导数场并支持点级求值，从而实现了Hodge拉普拉斯能量、连接拉普拉斯能量、Killing能量以及李括号等标准算子的计算。

Conclusion: 论文提出的离散化方法为三角网格上的切向量场处理提供了新的工具，支持更多高效的向量场操作。

Abstract: We propose a novel discretization of tangent vector fields for triangle meshes. Starting with a Phong map continuously assigning normals to all points on the mesh, we define an extrinsic bases for continuous tangent vector fields by using the Rodrigues rotation to transport tangent vectors assigned to vertices to tangent vectors in the interiors of the triangles. As our vector fields are continuous and weakly differentiable, we can use them to define a covariant derivative field that is evaluatable almost-everywhere on the mesh. Decomposing the covariant derivative in terms of diagonal multiple of the identity, anti-symmetric, and trace-less symmetric components, we can define the standard operators used for vector field processing including the Hodge Laplacian energy, Connection Laplacian energy, and Killing energy. Additionally, the ability to perform point-wise evaluation of the covariant derivative also makes it possible for us to define the Lie bracket.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [From Dynamic to Lexical: A Comparative Exploration of Scoping Rules in SAS and R](https://arxiv.org/abs/2601.09808)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 该论文探讨了SAS和R语言中不同的变量作用域规则，重点是SAS的动态作用域和R的词法作用域，并通过示例展示了它们对代码行为的影响。


<details>
  <summary>Details</summary>
Motivation: 研究SAS和R中的变量作用域规则，以帮助程序员更好地理解和管理变量，从而优化代码效率和可靠性。

Method: 通过比较SAS的动态作用域（使用符号表）和R的词法作用域（使用环境），并提供示例来说明差异。

Result: 论文展示了两种作用域策略对代码行为的影响，并提供了调试和优化的实用方法。

Conclusion: 理解SAS和R中的作用域规则有助于程序员优化变量管理，提升代码的效率和可靠性。

Abstract: Variable scoping dictates how and where variables are accessible within programming languages, playing a crucial role in code efficiency and organization. This paper examines the distinct scoping rules in SAS and R, focusing on SAS's dynamic scoping and R's lexical scoping. In SAS, dynamic scoping utilizes symbol tables, resolving variables at runtime by dynamically searching through active macro layers. R, in contrast, employs lexical scoping, using environments to resolve variables based on the structure in which functions are defined. Illustrative examples highlight the differences between these scoping strategies, showcasing their impact on code behavior. Additionally, the paper outlines methods for inspecting variables in SAS's symbol tables and R's environments, offering practical insights for debugging and optimization. Strategies for controlling variable scope in both languages are discussed, enhancing code precision and reliability. This exploration equips programmers with critical understanding to optimize variable management, improving their programming practices in SAS and R.

</details>


### [3] [Lazy Evaluation: A Comparative Analysis of SAS MACROs and R Functions](https://arxiv.org/abs/2601.09839)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 该论文比较了SAS MACRO和R函数中的惰性求值机制，分析了它们在数据结构、内存占用和求值策略上的差异，并探讨了这些差异对编程效率的影响。


<details>
  <summary>Details</summary>
Motivation: 研究惰性求值在SAS中的应用较少，而在R中较为常见。随着制药行业从SAS转向R的趋势增加，理解这些技术有助于程序员优化代码效率。

Method: 论文通过对比分析SAS的符号表和R的Promise数据结构，探究了它们在惰性求值策略上的异同，并结合示例说明其影响。

Result: 研究发现，SAS通过符号表以按名调用的方式实现惰性求值，而R通过Promise以按需调用的方式实现。这些差异显著影响了两种语言的编程效率和内存占用。

Conclusion: 理解SAS和R中惰性求值的不同机制，有助于程序员在两种语言中优化代码性能，提升编程效率和能力。

Abstract: Lazy evaluation is a powerful technique that can optimize code execution by deferring evaluations until their results are required, thus enhancing efficiency. In most modern programming languages, like R, lazy evaluation is commonly applied to function arguments. However, the application of lazy evaluation in SAS has not been extensively explored. This paper focuses on the mechanisms of lazy evaluation in SAS MACROs and R functions, offering a comparative analysis of the underlying principles that drive these processes.
  R's lazy evaluation is driven by a data structure called Promise, which postpones evaluation and does not occupy memory until the value is needed, utilizing a call-by-need strategy. SAS, on the other hand, achieves lazy evaluation through its symbol tables, employing memory to store parameters, and operates on a call-by-name basis. These discrepancies in lazy evaluation strategies can notably impact the results of R functions and SAS MACROs. By examining these distinct approaches, the paper illuminates the impact of lazy evaluation on programming efficiency, supported by illustrative examples. As the shift from SAS to R becomes increasingly prevalent in the pharmaceutical industry, understanding these techniques enables programmers to optimize their code for greater efficacy. This exploration serves as a guide to enhance programming capabilities and performance in both languages.

</details>


### [4] [Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT](https://arxiv.org/abs/2601.09986)
*Cheng Zhang,Qiancheng Fu,Hang Ji,Ines Santacruz Del Valle,Alexandra Silva,Marco Gaboardi*

Main category: cs.PL

TL;DR: 本文提出了几种用于GKAT自动机跟踪等价性的高效决策过程，利用了基于SAT求解器的符号化技术。通过设计CF-GKAT的符号导数并实现Rust算法，展示了其在实际控制流转换验证中的应用。实验表明，性能相较现有KAT和CF-GKAT实现有数量级提升，并发现了Ghidra解编译器的一个错误。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于提高GKAT自动机跟踪等价性验证的效率，并在实际控制流转换验证中验证算法的实用性。

Method: 采用了基于SAT求解器的符号化技术，设计了CF-GKAT的符号导数，并在Rust中实现了相关算法。

Result: 实验结果显示，该算法在随机生成的基准测试和实际控制流转换中表现优异，性能显著优于现有KAT和CF-GKAT实现，并且发现了Ghidra解编译器的一个错误。

Conclusion: 本文提出的方法不仅提升了GKAT自动机跟踪等价性验证的效率，还在实际应用中展示了其实用性和有效性。

Abstract: This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [5] [A Control Theoretic Approach to Decentralized AI Economy Stabilization via Dynamic Buyback-and-Burn Mechanisms](https://arxiv.org/abs/2601.09961)
*Zehua Cheng,Wei Dai,Zhipeng Wang,Rui Sun,Nick Wen,Jiahao Sun*

Main category: cs.GT

TL;DR: 论文提出了一种动态控制回购机制（DCBM），通过PID控制器和严格偿付约束，显著降低了代币价格波动和运营者流失率。


<details>
  <summary>Details</summary>
Motivation: 当前去中心化人工智能网络中，经济层的极端波动性威胁了生态系统的长期生存能力，现有的静态回购机制无法应对复杂动态，迫切需要改进。

Method: 提出动态控制回购机制（DCBM），利用PID控制器和严格偿付约束，将代币经济视为动态系统进行调控。

Result: DCBM在模拟测试中将代币价格波动降低了约66%，运营者流失率从19.5%降至8.1%。

Conclusion: 将静态代币规则转化为连续且结构受限的控制循环，是确保去中心化人工智能网络安全和可持续性的必要条件。

Abstract: The democratization of artificial intelligence through decentralized networks represents a paradigm shift in computational provisioning, yet the long-term viability of these ecosystems is critically endangered by the extreme volatility of their native economic layers. Current tokenomic models, which predominantly rely on static or threshold-based buyback heuristics, are ill-equipped to handle complex system dynamics and often function pro-cyclically, exacerbating instability during market downturns. To bridge this gap, we propose the Dynamic-Control Buyback Mechanism (DCBM), a formalized control-theoretic framework that utilizes a Proportional-Integral-Derivative (PID) controller with strict solvency constraints to regulate the token economy as a dynamical system. Extensive agent-based simulations utilizing Jump-Diffusion processes demonstrate that DCBM fundamentally outperforms static baselines, reducing token price volatility by approximately 66% and lowering operator churn from 19.5% to 8.1% in high-volatility regimes. These findings establish that converting tokenomics from static rules into continuous, structurally constrained control loops is a necessary condition for secure and sustainable decentralized intelligence networks.

</details>


### [6] [Inverse Learning in $2\times2$ Games: From Synthetic Interactions to Traffic Simulation](https://arxiv.org/abs/2601.10367)
*Daniela Aguirre Salazar,Firas Moatemri,Tatiana Tatarenko*

Main category: cs.GT

TL;DR: 研究通過兩種最大似然估計器（CE-ML和LBR-ML）來理解行為數據中的協調與競爭問題，揭示了解釋性、計算可行性和行為表達性之間的權衡。


<details>
  <summary>Details</summary>
Motivation: 理解如何在有限的行為數據中模擬代理的協調或競爭，是建模交通、機器人等多代理系統中戰略互動的核心問題。

Method: 提出了兩種逆博弈論學習方法：(i) 專用於2×2遊戲的閉式相關均衡最大似然估計器（CE-ML），(ii) 通過隨機響應過程捕捉長期適應動態的Logit最佳響應最大似然估計器（LBR-ML）。

Result: 在合成“膽小鬼博弈”和SUMO模擬的交通互動情景中評估了這些方法，並比較了參數恢復和分佈擬合效果。結果顯示了這些模型在解釋性、計算可行性和行為表達性之間的明確權衡。

Conclusion: 研究展示了靜態均衡一致性與動態行為真實性之間的譜系，並為多代理系統中的戰略互動建模提供了實用工具。

Abstract: Understanding how agents coordinate or compete from limited behavioral data is central to modeling strategic interactions in traffic, robotics, and other multi-agent systems. In this work, we investigate the following complementary formulations of inverse game-theoretic learning: (i) a Closed-form Correlated Equilibrium Maximum-Likelihood estimator (CE-ML) specialized for $2\times2$ games; and (ii) a Logit Best Response Maximum-Likelihood estimator (LBR-ML) that captures long-run adaptation dynamics via stochastic response processes. Together, these approaches span the spectrum between static equilibrium consistency and dynamic behavioral realism. We evaluate them on synthetic "chicken-dare" games and traffic-interaction scenarios simulated in SUMO, comparing parameter recovery and distributional fit. Results reveal clear trade-offs between interpretability, computational tractability, and behavioral expressiveness across models.

</details>
