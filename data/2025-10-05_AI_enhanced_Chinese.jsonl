{"id": "2510.01387", "categories": ["cs.GT", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.01387", "abs": "https://arxiv.org/abs/2510.01387", "authors": ["Gerson Personnat", "Tao Lin", "Safwan Hossain", "David C. Parkes"], "title": "Learning to Play Multi-Follower Bayesian Stackelberg Games", "comment": null, "summary": "In a multi-follower Bayesian Stackelberg game, a leader plays a mixed\nstrategy over $L$ actions to which $n\\ge 1$ followers, each having one of $K$\npossible private types, best respond. The leader's optimal strategy depends on\nthe distribution of the followers' private types. We study an online learning\nversion of this problem: a leader interacts for $T$ rounds with $n$ followers\nwith types sampled from an unknown distribution every round. The leader's goal\nis to minimize regret, defined as the difference between the cumulative utility\nof the optimal strategy and that of the actually chosen strategies. We design\nlearning algorithms for the leader under different feedback settings. Under\ntype feedback, where the leader observes the followers' types after each round,\nwe design algorithms that achieve $\\mathcal O\\big(\\sqrt{\\min\\{L\\log(nKA T), nK\n\\} \\cdot T} \\big)$ regret for independent type distributions and $\\mathcal\nO\\big(\\sqrt{\\min\\{L\\log(nKA T), K^n \\} \\cdot T} \\big)$ regret for general type\ndistributions. Interestingly, those bounds do not grow with $n$ at a polynomial\nrate. Under action feedback, where the leader only observes the followers'\nactions, we design algorithms with $\\mathcal O( \\min\\{\\sqrt{ n^L K^L A^{2L} L T\n\\log T}, K^n\\sqrt{ T } \\log T \\} )$ regret. We also provide a lower bound of\n$\\Omega(\\sqrt{\\min\\{L, nK\\}T})$, almost matching the type-feedback upper\nbounds.", "AI": {"tldr": "\u7814\u7a76\u591a\u8ffd\u968f\u8005\u8d1d\u53f6\u65afStackelberg\u535a\u5f08\u7684\u5728\u7ebf\u5b66\u4e60\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u5728\u4e0d\u540c\u53cd\u9988\u8bbe\u7f6e\u4e0b\u9886\u5bfc\u8005\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6b21\u7ebf\u6027\u540e\u6094\u3002", "motivation": "\u591a\u8ffd\u968f\u8005\u8d1d\u53f6\u65afStackelberg\u535a\u5f08\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u9886\u5bfc\u8005\u5982\u4f55\u5728\u672a\u77e5\u7c7b\u578b\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\u5728\u7ebf\u5b66\u4e60\u6700\u4f18\u7b56\u7565\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u53cd\u9988\u8bbe\u7f6e\u4e0b\u7684\u5b66\u4e60\u7b97\u6cd5\uff1a\u7c7b\u578b\u53cd\u9988\u4e0b\u5b9e\u73b0\u6b21\u7ebf\u6027\u540e\u6094\uff0c\u884c\u52a8\u53cd\u9988\u4e0b\u5219\u6839\u636e\u89c2\u5bdf\u5230\u7684\u8ffd\u968f\u8005\u884c\u52a8\u8c03\u6574\u7b56\u7565\u3002", "result": "\u5728\u7c7b\u578b\u53cd\u9988\u4e0b\uff0c\u5b9e\u73b0\u4e86\u4e0d\u968f\u8ffd\u968f\u8005\u6570\u91cf\u591a\u9879\u5f0f\u589e\u957f\u7684\u540e\u6094\u754c\uff1b\u5728\u884c\u52a8\u53cd\u9988\u4e0b\uff0c\u7b97\u6cd5\u540e\u6094\u754c\u63a5\u8fd1\u7406\u8bba\u4e0b\u754c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u9988\u5bf9\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2510.01434", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.01434", "abs": "https://arxiv.org/abs/2510.01434", "authors": ["Caleb Probine", "Mustafa O. Karabag", "Ufuk Topcu"], "title": "Designing Inferable Signaling Schemes for Bayesian Persuasion", "comment": "13 pages, 7 figures", "summary": "In Bayesian persuasion, an informed sender, who observes a state, commits to\na randomized signaling scheme that guides a self-interested receiver's actions.\nClassical models assume the receiver knows the commitment. We, instead, study\nthe setting where the receiver infers the scheme from repeated interactions. We\nbound the sender's performance loss relative to the known-commitment case by a\nterm that grows with the signal space size and shrinks as the receiver's\noptimal actions become more distinct. We then lower bound the samples required\nfor the sender to approximately achieve their known-commitment performance in\nthe inference setting. We show that the sender requires more samples in\npersuasion compared to the leader in a Stackelberg game, which includes\ncommitment but lacks signaling. Motivated by these bounds, we propose two\nmethods for designing inferable signaling schemes, one being stochastic\ngradient descent (SGD) on the sender's inference-setting utility, and the other\nbeing optimization with a boundedly-rational receiver model. SGD performs best\nin low-interaction regimes, but modeling the receiver as boundedly-rational and\ntuning the rationality constant still provides a flexible method for designing\ninferable schemes. Finally, we apply SGD to a safety alert example and show it\nto find schemes that have fewer signals and make citizens' optimal actions more\ndistinct compared to the known-commitment case.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8d1d\u53f6\u65af\u8bf4\u670d\u4e2d\u63a5\u6536\u8005\u4ece\u91cd\u590d\u4e92\u52a8\u4e2d\u63a8\u65ad\u4fe1\u53f7\u65b9\u6848\u7684\u60c5\u51b5\uff0c\u5206\u6790\u4e86\u53d1\u9001\u8005\u76f8\u5bf9\u4e8e\u5df2\u77e5\u627f\u8bfa\u7684\u6027\u80fd\u635f\u5931\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u8bbe\u8ba1\u53ef\u63a8\u65ad\u4fe1\u53f7\u65b9\u6848\u7684\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u63a5\u6536\u8005\u4ece\u4e92\u52a8\u4e2d\u63a8\u65ad\u4fe1\u53f7\u65b9\u6848\u7684\u8d1d\u53f6\u65af\u8bf4\u670d\u573a\u666f\uff0c\u800c\u975e\u4f20\u7edf\u6a21\u578b\u4e2d\u5047\u8bbe\u63a5\u6536\u8005\u5df2\u77e5\u627f\u8bfa\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7SGD\u4f18\u5316\u53d1\u9001\u8005\u5728\u63a8\u65ad\u8bbe\u7f6e\u4e0b\u7684\u6548\u7528\uff0c\u4ee5\u53ca\u4f7f\u7528\u6709\u9650\u7406\u6027\u63a5\u6536\u8005\u6a21\u578b\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u53d1\u9001\u8005\u5728\u8bf4\u670d\u573a\u666f\u4e2d\u9700\u8981\u66f4\u591a\u6837\u672c\uff0cSGD\u5728\u4f4e\u4e92\u52a8\u60c5\u51b5\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u6709\u9650\u7406\u6027\u6a21\u578b\u5219\u662f\u7075\u6d3b\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "SGD\u5728\u5b89\u5168\u6027\u8b66\u62a5\u793a\u4f8b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u627e\u5230\u4fe1\u53f7\u8f83\u5c11\u4e14\u4f7f\u63a5\u6536\u8005\u884c\u4e3a\u66f4\u660e\u786e\u7684\u65b9\u6848\u3002"}}
{"id": "2510.01689", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.01689", "abs": "https://arxiv.org/abs/2510.01689", "authors": ["Haoqiang Huang", "Biaoshuai Tao", "Mingwei Yang", "Shengwei Zhou"], "title": "Incentive Analysis of Collusion in Fair Division", "comment": "To appear at WINE 2025", "summary": "We study fair division problems with strategic agents capable of gaining\nadvantages by manipulating their reported preferences. Although several\nimpossibility results have revealed the incompatibility of truthfulness with\nstandard fairness criteria, subsequent works have circumvented this limitation\nthrough the incentive ratio framework. Previous studies demonstrate that\nfundamental mechanisms like Maximum Nash Welfare (MNW) and Probabilistic Serial\n(PS) for divisible goods, and Round-Robin (RR) for indivisible goods achieve an\nincentive ratio of $2$, implying that no individual agent can gain more than\ndouble his truthful utility through manipulation. However, collusive\nmanipulation by agent groups remains unexplored.\n  In this work, we define strong group incentive ratio (SGIR) and group\nincentive ratio (GIR) to measure the gain of collusive manipulation, where SGIR\nand GIR are respectively the maximum and minimum of the incentive ratios of\ncorrupted agents. Then, we tightly characterize the SGIRs and GIRs of MNW, PS,\nand RR. In particular, the GIR of MNW is $2$ regardless of the coalition size.\nMoreover, for coalition size $c \\geq 1$, the SGIRs of MNW and PS, and the GIRs\nof PS and RR are $c + 1$. Finally, the SGIR of RR is unbounded for coalition\nsize $c \\geq 2$. Our results reveal fundamental differences of these three\nmechanisms in their vulnerability to collusion.", "AI": {"tldr": "\u7814\u7a76\u4e86\u7b56\u7565\u6027\u4ee3\u7406\u5728\u516c\u5e73\u5206\u95ee\u9898\u4e2d\u901a\u8fc7\u64cd\u7eb5\u62a5\u544a\u504f\u597d\u83b7\u53d6\u4f18\u52bf\u7684\u60c5\u51b5\uff0c\u5b9a\u4e49\u4e86SGIR\u548cGIR\u6765\u8861\u91cf\u5408\u8c0b\u64cd\u7eb5\u7684\u6536\u76ca\uff0c\u5e76\u63ed\u793a\u4e86MNW\u3001PS\u548cRR\u4e09\u79cd\u673a\u5236\u5728\u5408\u8c0b\u6f0f\u6d1e\u4e0a\u7684\u5dee\u5f02\u3002", "motivation": "\u867d\u7136\u5df2\u6709\u7814\u7a76\u8868\u660e\u771f\u7406\u6027\u4e0e\u6807\u51c6\u516c\u5e73\u6807\u51c6\u7684\u4e0d\u53ef\u8c03\u548c\u6027\uff0c\u4f46\u901a\u8fc7\u6fc0\u52b1\u6bd4\u6846\u67b6\u53ef\u4ee5\u7ed5\u8fc7\u8fd9\u4e00\u9650\u5236\u3002\u7136\u800c\uff0c\u4ee3\u7406\u7fa4\u4f53\u7684\u5408\u8c0b\u64cd\u7eb5\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5b9a\u4e49\u4e86\u5f3a\u7fa4\u4f53\u6fc0\u52b1\u6bd4\uff08SGIR\uff09\u548c\u7fa4\u4f53\u6fc0\u52b1\u6bd4\uff08GIR\uff09\u6765\u8861\u91cf\u5408\u8c0b\u64cd\u7eb5\u7684\u6536\u76ca\uff0c\u5e76\u5206\u6790\u4e86MNW\u3001PS\u548cRR\u4e09\u79cd\u673a\u5236\u7684SGIR\u548cGIR\u3002", "result": "MNW\u7684GIR\u59cb\u7ec8\u4e3a2\uff0c\u800cMNW\u548cPS\u7684SGIR\u4ee5\u53caPS\u548cRR\u7684GIR\u5747\u4e3ac+1\uff08c\u22651\uff09\uff0cRR\u7684SGIR\u5728c\u22652\u65f6\u65e0\u754c\u3002", "conclusion": "\u63ed\u793a\u4e86MNW\u3001PS\u548cRR\u4e09\u79cd\u673a\u5236\u5728\u5408\u8c0b\u64cd\u7eb5\u4e0b\u7684\u4e0d\u540c\u8106\u5f31\u6027\uff0c\u586b\u8865\u4e86\u7fa4\u4f53\u64cd\u7eb5\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.01766", "categories": ["cs.GT", "math.OC", "90C05, 91A12, 91A68"], "pdf": "https://arxiv.org/pdf/2510.01766", "abs": "https://arxiv.org/abs/2510.01766", "authors": ["J Camacho", "JC Gon\u00e7alves-Dosantos", "J S\u00e1nchez-Soriano"], "title": "A Linear Programming Approach to Estimate the Core in Cooperative Games", "comment": null, "summary": "This paper proposes a novel algorithm to approximate the core of transferable\nutility (TU) cooperative games via linear programming. Given the computational\nhardness of determining the full core, our approach provides a tractable\napproximation by sampling extreme points through randomized linear problems\n(LPs). We analyze its convergence and computational complexity, and validate\nits effectiveness through extensive simulations on various game models. Our\nresults show that the method is scalable and achieves high accuracy in terms of\ncore reconstruction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7ebf\u6027\u89c4\u5212\u8fd1\u4f3c\u8ba1\u7b97\u8f6c\u79fb\u6548\u7528\u5408\u4f5c\u535a\u5f08\u6838\u5fc3\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u7ebf\u6027\u95ee\u9898\u91c7\u6837\u6781\u503c\u70b9\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u548c\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u7531\u4e8e\u8ba1\u7b97\u8f6c\u79fb\u6548\u7528\u5408\u4f5c\u535a\u5f08\u7684\u5b8c\u6574\u6838\u5fc3\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u5904\u7406\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u968f\u673a\u7ebf\u6027\u95ee\u9898\uff08LPs\uff09\u91c7\u6837\u6781\u503c\u70b9\u7684\u7ebf\u6027\u89c4\u5212\u7b97\u6cd5\uff0c\u5206\u6790\u4e86\u5176\u6536\u655b\u6027\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u5404\u79cd\u535a\u5f08\u6a21\u578b\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u6a21\u62df\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u5728\u6838\u5fc3\u91cd\u5efa\u65b9\u9762\u8fbe\u5230\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3a\u8f6c\u79fb\u6548\u7528\u5408\u4f5c\u535a\u5f08\u7684\u6838\u5fc3\u8fd1\u4f3c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.01619", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.01619", "abs": "https://arxiv.org/abs/2510.01619", "authors": ["Changmin Lee", "Jihyun Lee", "Tae-Kyun Kim"], "title": "MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics", "comment": "Accepted to NeurIPS 2025", "summary": "While there has been significant progress in the field of 3D avatar creation\nfrom visual observations, modeling physically plausible dynamics of humans with\nloose garments remains a challenging problem. Although a few existing works\naddress this problem by leveraging physical simulation, they suffer from\nlimited accuracy or robustness to novel animation inputs. In this work, we\npresent MPMAvatar, a framework for creating 3D human avatars from multi-view\nvideos that supports highly realistic, robust animation, as well as\nphotorealistic rendering from free viewpoints. For accurate and robust dynamics\nmodeling, our key idea is to use a Material Point Method-based simulator, which\nwe carefully tailor to model garments with complex deformations and contact\nwith the underlying body by incorporating an anisotropic constitutive model and\na novel collision handling algorithm. We combine this dynamics modeling scheme\nwith our canonical avatar that can be rendered using 3D Gaussian Splatting with\nquasi-shadowing, enabling high-fidelity rendering for physically realistic\nanimations. In our experiments, we demonstrate that MPMAvatar significantly\noutperforms the existing state-of-the-art physics-based avatar in terms of (1)\ndynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and\nefficiency. Additionally, we present a novel application in which our avatar\ngeneralizes to unseen interactions in a zero-shot manner-which was not\nachievable with previous learning-based methods due to their limited simulation\ngeneralizability. Our project page is at:\nhttps://KAISTChangmin.github.io/MPMAvatar/", "AI": {"tldr": "MPMAvatar\u662f\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u591a\u89c6\u89d2\u89c6\u9891\u521b\u5efa3D\u4eba\u7c7b\u5934\u50cf\uff0c\u652f\u6301\u9ad8\u5ea6\u903c\u771f\u3001\u7a33\u5065\u7684\u52a8\u753b\u4ee5\u53ca\u81ea\u7531\u89c6\u89d2\u7684\u903c\u771f\u6e32\u67d3\u3002", "motivation": "\u5c3d\u7ba13D\u5934\u50cf\u521b\u5efa\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e3a\u677e\u6563\u8863\u7269\u7684\u4eba\u7c7b\u5efa\u6a21\u7269\u7406\u5408\u7406\u7684\u52a8\u6001\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u6027\u95ee\u9898\u3002\u73b0\u6709\u5de5\u4f5c\u867d\u7136\u5229\u7528\u4e86\u7269\u7406\u6a21\u62df\uff0c\u4f46\u5728\u51c6\u786e\u6027\u548c\u5bf9\u65b0\u52a8\u753b\u8f93\u5165\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "MPMAvatar\u4f7f\u7528\u57fa\u4e8eMaterial Point Method\u7684\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u5404\u5411\u5f02\u6027\u672c\u6784\u6a21\u578b\u548c\u65b0\u578b\u78b0\u649e\u5904\u7406\u7b97\u6cd5\uff0c\u7cbe\u786e\u5efa\u6a21\u8863\u7269\u590d\u6742\u53d8\u5f62\u548c\u4e0e\u8eab\u4f53\u63a5\u89e6\u7684\u52a8\u6001\u3002\u6b64\u5916\uff0c\u8fd8\u7ed3\u5408\u4e86\u53ef\u6e32\u67d3\u7684\u9ad8\u65af\u98de\u6e85\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6e32\u67d3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMPMAvatar\u5728\u52a8\u6001\u5efa\u6a21\u51c6\u786e\u6027\u3001\u6e32\u67d3\u51c6\u786e\u6027\u4ee5\u53ca\u9c81\u68d2\u6027\u548c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u7269\u7406\u7684\u5934\u50cf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u96f6\u6837\u672c\u4ea4\u4e92\u573a\u666f\u3002", "conclusion": "MPMAvatar\u901a\u8fc7\u7ed3\u5408\u5148\u8fdb\u7684\u7269\u7406\u6a21\u62df\u4e0e\u9ad8\u4fdd\u771f\u6e32\u67d3\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u5934\u50cf\u7684\u52a8\u6001\u903c\u771f\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u4f7f\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.02078", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.02078", "abs": "https://arxiv.org/abs/2510.02078", "authors": ["Hongxing Yuan", "Xuan Zhang", "Chunyu Wei", "Yushun Fan"], "title": "Multi-group Bayesian Games", "comment": null, "summary": "This paper presents a model of multi-group Bayesian games (MBGs) to describe\nthe group behavior in Bayesian games, and gives methods to find (strongly)\nmulti-group Bayesian Nash equilibria (MBNE) of this model with a proposed\ntransformation. MBNE represent the optimal strategy \\textit{profiles} under the\nsituation where players within a group play a cooperative game, while strongly\nMBNE characterize the optimal strategy \\textit{profiles} under the situation\nwhere players within a group play a noncooperative game. Firstly, we propose a\nmodel of MBGs and give a transformation to convert any MBG into a multi-group\nex-ante agent game (MEAG) which is a normal-form game. Secondly, we give a\nsufficient and necessary condition for a MBG's MEAG to be (strongly) potential.\nIf it is (strongly) potential, all its (strongly) Nash equilibria can be found,\nand then all (strongly) MBNE of the MBG can be obtained by leveraging the\ntransformation's good properties. Finally, we provide algorithms for finding\n(strongly) MBNE of a MBG whose MEAG is (strongly) potential and use an\nillustrative example to verify the correctness of our results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u7fa4\u7ec4\u8d1d\u53f6\u65af\u535a\u5f08\uff08MBGs\uff09\u6a21\u578b\uff0c\u63cf\u8ff0\u4e86\u8d1d\u53f6\u65af\u535a\u5f08\u4e2d\u7684\u7fa4\u7ec4\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u63d0\u51fa\u7684\u8f6c\u6362\u65b9\u6cd5\u627e\u5230\u4e86\uff08\u5f3a\uff09\u591a\u7fa4\u7ec4\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff08MBNE\uff09\u3002", "motivation": "\u7814\u7a76\u8d1d\u53f6\u65af\u535a\u5f08\u4e2d\u7fa4\u7ec4\u884c\u4e3a\u7684\u4f18\u5316\u7b56\u7565\uff0c\u63d0\u51fa\u4e00\u79cd\u6a21\u578b\u548c\u8f6c\u6362\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u7fa4\u7ec4\u5185\u5408\u4f5c\u4e0e\u975e\u5408\u4f5c\u535a\u5f08\u7684\u6700\u4f18\u7b56\u7565\u95ee\u9898\u3002", "method": "\u63d0\u51faMBGs\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u591a\u7fa4\u7ec4\u4e8b\u524d\u4ee3\u7406\u535a\u5f08\uff08MEAG\uff09\uff1b\u7ed9\u51fa\u4e86MEAG\u4e3a\uff08\u5f3a\uff09\u52bf\u535a\u5f08\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5bfb\u627e\uff08\u5f3a\uff09MBNE\u7684\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u7b97\u6cd5\u6210\u529f\u627e\u5230MBGs\u7684\uff08\u5f3a\uff09MBNE\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "MBGs\u6a21\u578b\u53ca\u5176\u8f6c\u6362\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7fa4\u7ec4\u884c\u4e3a\u5728\u8d1d\u53f6\u65af\u535a\u5f08\u4e2d\u7684\u6700\u4f18\u7b56\u7565\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2510.01690", "categories": ["cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.01690", "abs": "https://arxiv.org/abs/2510.01690", "authors": ["Hu Guo", "Lily Patel", "Rohan Gupt"], "title": "Multimodal Feedback for Task Guidance in Augmented Reality", "comment": null, "summary": "Optical see-through augmented reality (OST-AR) overlays digital targets and\nannotations on the physical world, offering promising guidance for hands-on\ntasks such as medical needle insertion or assembly. Recent work on OST-AR depth\nperception shows that target opacity and tool visualization significantly\naffect accuracy and usability; opaque targets and rendering the real instrument\nreduce depth errors, whereas transparent targets and absent tools impair\nperformance. However, reliance on visual overlays may overload attention and\nleaves little room for depth cues when occlusion or lighting hampers\nperception. To address these limitations, we explore multimodal feedback that\ncombines OST-AR with wrist-based vibrotactile haptics. The past two years have\nseen rapid advances in haptic technology. Researchers have investigated\nskin-stretch and vibrotactile cues for conveying spatial information to blind\nusers, wearable ring actuators that support precise pinching in AR, cross-modal\naudio-haptic cursors that enable eyes-free object selection, and wrist-worn\nfeedback for teleoperated surgery that improves force awareness at the cost of\nlonger task times. Studies comparing pull versus push vibrotactile metaphors\nfound that pull cues yield faster gesture completion and lower cognitive load.\nThese findings motivate revisiting OST-AR guidance with a fresh perspective on\nwrist-based haptics. We design a custom wristband with six vibromotors\ndelivering directional and state cues, integrate it with a handheld tool and\nOST-AR, and assess its impact on cue recognition and depth guidance. Through a\nformative study and two experiments (N=21 and N=27), we show that participants\naccurately identify haptic patterns under cognitive load and that multimodal\nfeedback improves spatial precision and usability compared with visual-only or\nhaptic-only conditions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7ed3\u5408\u5149\u5b66\u900f\u5c04\u589e\u5f3a\u73b0\u5b9e\uff08OST-AR\uff09\u548c\u8155\u90e8\u632f\u52a8\u89e6\u89c9\u53cd\u9988\u7684\u591a\u6a21\u6001\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u6df1\u5ea6\u611f\u77e5\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684OST-AR\u7cfb\u7edf\u4f9d\u8d56\u89c6\u89c9\u53e0\u52a0\u53ef\u80fd\u5bfc\u81f4\u6ce8\u610f\u529b\u8fc7\u8f7d\uff0c\u4e14\u5728\u67d0\u4e9b\u73af\u5883\u4e0b\uff08\u5982\u906e\u6321\u6216\u5149\u7167\u4e0d\u8db3\uff09\u9650\u5236\u4e86\u6df1\u5ea6\u7ebf\u7d22\u7684\u611f\u77e5\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u63a2\u7d22\u7ed3\u5408\u632f\u52a8\u89e6\u89c9\u53cd\u9988\u4ee5\u5f25\u8865\u8fd9\u4e9b\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5e26\u6709\u516d\u4e2a\u632f\u52a8\u9a6c\u8fbe\u7684\u8155\u5e26\uff0c\u63d0\u4f9b\u65b9\u5411\u548c\u72b6\u6001\u63d0\u793a\uff0c\u5e76\u5c06\u5176\u4e0e\u624b\u6301\u5de5\u5177\u548cOST-AR\u7cfb\u7edf\u96c6\u6210\u3002\u901a\u8fc7\u4e00\u9879\u5f62\u6210\u6027\u7814\u7a76\u548c\u4e24\u9879\u5b9e\u9a8c\uff08N=21\u548cN=27\uff09\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u591a\u6a21\u6001\u53cd\u9988\u663e\u8457\u63d0\u9ad8\u4e86\u7a7a\u95f4\u7cbe\u5ea6\u548c\u53ef\u7528\u6027\uff0c\u7528\u6237\u5728\u8ba4\u77e5\u8d1f\u8377\u4e0b\u80fd\u51c6\u786e\u8bc6\u522b\u89e6\u89c9\u6a21\u5f0f\uff0c\u8868\u73b0\u4f18\u4e8e\u7eaf\u89c6\u89c9\u6216\u7eaf\u89e6\u89c9\u6761\u4ef6\u3002", "conclusion": "\u7ed3\u5408OST-AR\u548c\u8155\u90e8\u632f\u52a8\u89e6\u89c9\u7684\u591a\u6a21\u6001\u53cd\u9988\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6539\u5584\u4efb\u52a1\u6267\u884c\u6548\u679c\u5e76\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2510.01743", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.01743", "abs": "https://arxiv.org/abs/2510.01743", "authors": ["Daniel Brooks", "Emily Carter", "Hu Guo", "Rajesh Nair"], "title": "MIRAGE: Patient-Specific Mixed Reality Coaching for MRI via Depth-Only Markerless Registration and Immersive VR", "comment": null, "summary": "Magnetic resonance imaging (MRI) is an indispensable diagnostic tool, yet the\nconfined bore and acoustic noise can evoke considerable anxiety and\nclaustrophobic reactions. High anxiety leads to motion artifacts, incomplete\nscans and reliance on pharmacological sedation. MIRAGE (Mixed Reality Anxiety\nGuidance Environment) harnesses the latest mixed reality (MR) hardware to\nprepare patients for MRI through immersive virtual reality (VR) and markerless\naugmented reality (AR) registration. In this paper, we extend our previous work\nby providing a comprehensive review of related research, detailing the system\narchitecture, and exploring metrics for patient and clinician experience. We\nalso present considerations for clinical deployment of MR systems within\nhospital workflows. Our results indicate that depth-based registration achieves\nsub-centimeter accuracy with minimal setup, while the immersive coaching\nenvironment reduces patient anxiety and yields favourable usability scores.", "AI": {"tldr": "MIRAGE\u5229\u7528\u6df7\u5408\u73b0\u5b9e\u6280\u672f\u964d\u4f4eMRI\u60a3\u8005\u7684\u7126\u8651\uff0c\u901a\u8fc7\u865a\u62df\u73b0\u5b9e\u548c\u65e0\u6807\u8bb0\u589e\u5f3a\u73b0\u5b9e\u6ce8\u518c\u5b9e\u73b0\u5398\u7c73\u7ea7\u7cbe\u5ea6\uff0c\u63d0\u5347\u60a3\u8005\u4f53\u9a8c\u3002", "motivation": "MRI\u68c0\u67e5\u4e2d\u7684\u7a7a\u95f4\u9650\u5236\u548c\u566a\u97f3\u4f1a\u5f15\u53d1\u60a3\u8005\u7126\u8651\u548c\u5e7d\u95ed\u6050\u60e7\u75c7\uff0c\u5bfc\u81f4\u626b\u63cf\u5931\u8d25\u6216\u4f9d\u8d56\u836f\u7269\u9547\u9759\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528MIRAGE\u7cfb\u7edf\uff0c\u7ed3\u5408\u865a\u62df\u73b0\u5b9e\u548c\u65e0\u6807\u8bb0\u589e\u5f3a\u73b0\u5b9e\u6ce8\u518c\u6280\u672f\uff0c\u4e3a\u60a3\u8005\u63d0\u4f9b\u6c89\u6d78\u5f0f\u6307\u5bfc\u73af\u5883\uff0c\u5e76\u8bc4\u4f30\u5176\u4e34\u5e8a\u90e8\u7f72\u53ef\u884c\u6027\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u4e9a\u5398\u7c73\u7ea7\u7684\u7cbe\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u60a3\u8005\u7126\u8651\uff0c\u5e76\u83b7\u5f97\u79ef\u6781\u7684\u53ef\u7528\u6027\u8bc4\u5206\u3002", "conclusion": "MIRAGE\u7cfb\u7edf\u5728\u964d\u4f4eMRI\u60a3\u8005\u7126\u8651\u548c\u63d0\u9ad8\u626b\u63cf\u6210\u529f\u7387\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u9002\u5408\u4e34\u5e8a\u63a8\u5e7f\u5e94\u7528\u3002"}}
{"id": "2510.01978", "categories": ["cs.GR", "cs.CV", "68U05, 68T45 (Primary) 68T07, 68-04 (Secondary)", "I.2.10; I.3.3; I.3.5; I.3.7; I.4.5; I.4.6; I.4.8; I.4.10"], "pdf": "https://arxiv.org/pdf/2510.01978", "abs": "https://arxiv.org/abs/2510.01978", "authors": ["Quoc-Anh Bui", "Gilles Rougeron", "G\u00e9raldine Morin", "Simone Gasparini"], "title": "ROI-GS: Interest-based Local Quality 3D Gaussian Splatting", "comment": "4 pages, 3 figures, 2 tables", "summary": "We tackle the challenge of efficiently reconstructing 3D scenes with high\ndetail on objects of interest. Existing 3D Gaussian Splatting (3DGS) methods\nallocate resources uniformly across the scene, limiting fine detail to Regions\nOf Interest (ROIs) and leading to inflated model size. We propose ROI-GS, an\nobject-aware framework that enhances local details through object-guided camera\nselection, targeted Object training, and seamless integration of high-fidelity\nobject of interest reconstructions into the global scene. Our method\nprioritizes higher resolution details on chosen objects while maintaining\nreal-time performance. Experiments show that ROI-GS significantly improves\nlocal quality (up to 2.96 dB PSNR), while reducing overall model size by\n$\\approx 17\\%$ of baseline and achieving faster training for a scene with a\nsingle object of interest, outperforming existing methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aROI-GS\u7684\u5bf9\u8c61\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u8c61\u5f15\u5bfc\u7684\u76f8\u673a\u9009\u62e9\u3001\u9488\u5bf9\u6027\u5bf9\u8c61\u8bad\u7ec3\u4ee5\u53ca\u9ad8\u4fdd\u771f\u5bf9\u8c61\u91cd\u5efa\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u573a\u666f\u4e2d\u611f\u5174\u8da3\u533a\u57df\u7684\u7ec6\u8282\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u76843D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u65b9\u6cd5\u5728\u573a\u666f\u4e2d\u5747\u5300\u5206\u914d\u8d44\u6e90\uff0c\u5bfc\u81f4\u611f\u5174\u8da3\u533a\u57df\uff08ROI\uff09\u7684\u7ec6\u8282\u53d7\u9650\u4e14\u6a21\u578b\u4f53\u79ef\u8fc7\u5927\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u4e13\u6ce8\u4e8e\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u7ec6\u8282\u91cd\u5efa\uff0c\u63d0\u5347\u6a21\u578b\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "ROI-GS\u6846\u67b6\u91c7\u7528\u5bf9\u8c61\u5f15\u5bfc\u7684\u76f8\u673a\u9009\u62e9\u3001\u9488\u5bf9\u6027\u5bf9\u8c61\u8bad\u7ec3\uff0c\u4ee5\u53ca\u5c06\u9ad8\u4fdd\u771f\u5bf9\u8c61\u91cd\u5efa\u65e0\u7f1d\u96c6\u6210\u5230\u5168\u5c40\u573a\u666f\u4e2d\u3002\u8be5\u65b9\u6cd5\u4f18\u5148\u5904\u7406\u9009\u5b9a\u5bf9\u8c61\u7684\u9ad8\u5206\u8fa8\u7387\u7ec6\u8282\uff0c\u540c\u65f6\u786e\u4fdd\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cROI-GS\u663e\u8457\u63d0\u5347\u4e86\u5c40\u90e8\u8d28\u91cf\uff08PSNR\u63d0\u5347\u9ad8\u8fbe2.96 dB\uff09\uff0c\u540c\u65f6\u5c06\u6a21\u578b\u603b\u4f53\u5927\u5c0f\u51cf\u5c11\u4e86\u7ea617%\uff0c\u5e76\u5728\u5355\u4e2a\u611f\u5174\u8da3\u5bf9\u8c61\u7684\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ROI-GS\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf3DGS\u65b9\u6cd5\u5728\u8d44\u6e90\u5206\u914d\u548c\u7ec6\u8282\u91cd\u5efa\u4e0a\u7684\u74f6\u9888\uff0c\u4e3a3D\u573a\u666f\u91cd\u5efa\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.02069", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.02069", "abs": "https://arxiv.org/abs/2510.02069", "authors": ["Georgios Kouros", "Minye Wu", "Tinne Tuytelaars"], "title": "Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects", "comment": null, "summary": "Accurate reconstruction and relighting of glossy objects remain a\nlongstanding challenge, as object shape, material properties, and illumination\nare inherently difficult to disentangle. Existing neural rendering approaches\noften rely on simplified BRDF models or parameterizations that couple diffuse\nand specular components, which restricts faithful material recovery and limits\nrelighting fidelity. We propose a relightable framework that integrates a\nmicrofacet BRDF with the specular-glossiness parameterization into 2D Gaussian\nSplatting with deferred shading. This formulation enables more physically\nconsistent material decomposition, while diffusion-based priors for surface\nnormals and diffuse color guide early-stage optimization and mitigate\nambiguity. A coarse-to-fine optimization of the environment map accelerates\nconvergence and preserves high-dynamic-range specular reflections. Extensive\nexperiments on complex, glossy scenes demonstrate that our method achieves\nhigh-quality geometry and material reconstruction, delivering substantially\nmore realistic and consistent relighting under novel illumination compared to\nexisting Gaussian splatting methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u8868\u9762BRDF\u548c2D\u9ad8\u65af\u6cfc\u6e85\u7684\u53ef\u91cd\u5149\u7167\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u9ad8\u5149\u7269\u4f53\u51e0\u4f55\u91cd\u5efa\u548c\u5149\u7167\u5206\u79bb\u7684\u96be\u9898\u3002", "motivation": "\u9ad8\u5149\u7269\u4f53\u7684\u51e0\u4f55\u91cd\u5efa\u548c\u5149\u7167\u5206\u79bb\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7b80\u5316\u7684BRDF\u6a21\u578b\uff0c\u9650\u5236\u4e86\u6750\u6599\u7684\u7cbe\u786e\u6062\u590d\u548c\u5149\u7167\u4fdd\u771f\u5ea6\u3002", "method": "\u91c7\u7528\u5fae\u8868\u9762BRDF\u548c2D\u9ad8\u65af\u6cfc\u6e85\u7684\u7ed3\u5408\uff0c\u901a\u8fc7\u57fa\u4e8e\u6269\u6563\u7684\u5148\u9a8c\u6307\u5bfc\u4f18\u5316\uff0c\u5e76\u91c7\u7528\u4ece\u7c97\u5230\u7ec6\u7684\u73af\u5883\u5149\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728\u590d\u6742\u9ad8\u5149\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u9ad8\u8d28\u91cf\u7684\u51e0\u4f55\u548c\u6750\u6599\u91cd\u5efa\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u771f\u5b9e\u3001\u4e00\u81f4\u7684\u91cd\u5149\u7167\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u5149\u7269\u4f53\u7684\u91cd\u5efa\u548c\u91cd\u5149\u7167\u8d28\u91cf\uff0c\u4e3a\u795e\u7ecf\u6e32\u67d3\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u548c\u7269\u7406\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
