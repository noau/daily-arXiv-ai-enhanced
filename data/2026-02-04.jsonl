{"id": "2602.02907", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.02907", "abs": "https://arxiv.org/abs/2602.02907", "authors": ["Ningna Wang", "Zilong Wang", "Xiana Carrera", "Xiaohu Guo", "Silvia Sellán"], "title": "VoroUDF: Meshing Unsigned Distance Fields with Voronoi Optimization", "comment": null, "summary": "We present VoroUDF, an algorithm for reconstructing high-quality triangle meshes from Unsigned Distance Fields (UDFs). Our algorithm supports non-manifold geometry, sharp features, and open boundaries, without relying on error-prone inside/outside estimation, restrictive look-up tables nor topologically noisy optimization. Our Voronoi-based formulation combines a L_1 tangent minimization with feature-aware repulsion to robustly recover complex surface topology. It achieves significantly improved topological consistency and geometric fidelity compared to existing methods, while producing lightweight meshes suitable for downstream real-time and interactive applications."}
{"id": "2602.02947", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.02947", "abs": "https://arxiv.org/abs/2602.02947", "authors": ["Anuradha Madugall", "Yuqing Xiao", "John Grundy"], "title": "Role of Graphics in Disaster Communication: Practitioner Perspectives on Use, Challenges, and Inclusivity", "comment": null, "summary": "Information graphics, such as hazard maps, evacuation diagrams, and pictorial action guides, are widely used in disaster risk communication. These visuals are important because they convey hazard information quickly, reduce reliance on lengthy text, and support decision-making in time-critical situations. However, despite their importance, disaster information graphics do not work equally well for all audiences. In practice, many graphics remain difficult to interpret, and their accessibility for vulnerable populations is still uneven and underexplored. Despite their central role, there has been little empirical work examining how graphics shape disaster communication, what challenges practitioners face in using them, and, most importantly, how inclusive current disaster graphics are in real-world settings. To address this gap, we examine how information graphics are currently produced and used in disaster communication, what issues emerge in practice, and how inclusivity is addressed. We conducted semi-structured interviews with disaster communication practitioners and researchers to examine the role of graphics across preparedness, warning, and response contexts, as well as the barriers experienced by vulnerable communities. Our findings show that graphics are widely expected and heavily relied upon, yet significant accessibility gaps persist for groups such as people with vision impairments, older adults, and culturally and linguistically diverse communities. Participants also highlighted that inclusive adaptations are difficult to achieve during unfolding emergencies due to operational constraints, limited guidance, and resource barriers. Based on these findings, we outline recommendations for disaster management agencies and graphic designers and identify research directions for technological and adaptive support to make disaster graphics more inclusive at scale."}
{"id": "2602.03207", "categories": ["cs.GR", "cs.CV", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.03207", "abs": "https://arxiv.org/abs/2602.03207", "authors": ["Yudong Han", "Chao Xu", "Xiaodan Ye", "Weichen Bi", "Zilong Dong", "Yun Ma"], "title": "WebSplatter: Enabling Cross-Device Efficient Gaussian Splatting in Web Browsers via WebGPU", "comment": null, "summary": "We present WebSplatter, an end-to-end GPU rendering pipeline for the heterogeneous web ecosystem. Unlike naive ports, WebSplatter introduces a wait-free hierarchical radix sort that circumvents the lack of global atomics in WebGPU, ensuring deterministic execution across diverse hardware. Furthermore, we propose an opacity-aware geometry culling stage that dynamically prunes splats before rasterization, significantly reducing overdraw and peak memory footprint. Evaluation demonstrates that WebSplatter consistently achieves 1.2$\\times$ to 4.5$\\times$ speedups over state-of-the-art web viewers."}
{"id": "2602.03327", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03327", "abs": "https://arxiv.org/abs/2602.03327", "authors": ["Manuel Hofer", "Markus Steinberger", "Thomas Köhler"], "title": "Pi-GS: Sparse-View Gaussian Splatting with Dense π^3 Initialization", "comment": null, "summary": "Novel view synthesis has evolved rapidly, advancing from Neural Radiance Fields to 3D Gaussian Splatting (3DGS), which offers real-time rendering and rapid training without compromising visual fidelity. However, 3DGS relies heavily on accurate camera poses and high-quality point cloud initialization, which are difficult to obtain in sparse-view scenarios. While traditional Structure from Motion (SfM) pipelines often fail in these settings, existing learning-based point estimation alternatives typically require reliable reference views and remain sensitive to pose or depth errors. In this work, we propose a robust method utilizing π^3, a reference-free point cloud estimation network. We integrate dense initialization from π^3 with a regularization scheme designed to mitigate geometric inaccuracies. Specifically, we employ uncertainty-guided depth supervision, normal consistency loss, and depth warping. Experimental results demonstrate that our approach achieves state-of-the-art performance on the Tanks and Temples, LLFF, DTU, and MipNeRF360 datasets."}
{"id": "2602.02628", "categories": ["cs.GT", "cs.CC", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.02628", "abs": "https://arxiv.org/abs/2602.02628", "authors": ["Florian Galliot", "Nacim Oijid", "Jonas Sénizergues"], "title": "A two-player version of the assignment problem", "comment": null, "summary": "We introduce the competitive assignment problem, a two-player version of the well-known assignment problem. Given a set of tasks and a set of agents with different efficiencies for different tasks, Alice and Bob take turns picking agents one by one. Once all agents have been picked, Alice and Bob compute the optimal values $s_A$ and $s_B$ for the assignment problem on their respective sets of agents, i.e. they assign their own agents to tasks (with at most one agent per task and at most one task per agent) so as to maximize the sum of the efficiencies. The score of the game is then defined as $s_A-s_B$. Alice aims at maximizing the score, while Bob aims at minimizing it. This problem can model drafts in sports and card games, or more generally situations where two entities fight for the same resources and then use them to compete against each other. We show that the problem is PSPACE-complete, even restricted to agents that have at most two nonzero efficiencies. On the other hand, in the case of agents having at most one nonzero efficiency, the problem lies in XP parameterized by the number of tasks, and the optimal score can be computed in linear time when there are only two tasks."}
{"id": "2602.03033", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.03033", "abs": "https://arxiv.org/abs/2602.03033", "authors": ["Haoxuan Yin", "Andrzej S. Murawski", "C. -H. Luke Ong"], "title": "Layered Modal ML: Syntax and Full Abstraction", "comment": "22 pages, 6 figures", "summary": "MetaML-style metaprogramming languages allow programmers to construct, manipulate and run code. In the presence of higher-order references for code, ensuring type safety is challenging, as free variables can escape their binders. In this paper, we present Layered Modal ML (LMML), \\textit{the first metaprogramming language that supports storing and running open code under a strong type safety guarantee}. The type system utilises contextual modal types to track and reason about free variables in code explicitly.\n  A crucial concern in metaprogramming-based program optimisations is whether the optimised program preserves the meaning of the original program. Addressing this question requires a notion of program equivalence and techniques to reason about it. In this paper, we provide a semantic model that captures contextual equivalence for LMML, establishing \\textit{the first full abstraction result for an imperative MetaML-style language}. Our model is based on traces derived via operational game semantics, where the meaning of a program is modelled by its possible interactions with the environment. We also establish a novel closed instances of use theorem that accounts for both call-by-value and call-by-name closing substitutions."}
{"id": "2602.03809", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.03809", "abs": "https://arxiv.org/abs/2602.03809", "authors": ["Leonardo Monchieri", "Elena Camuffo", "Francesco Barbato", "Pietro Zanuttigh", "Simone Milani"], "title": "Split&Splat: Zero-Shot Panoptic Segmentation via Explicit Instance Modeling and 3D Gaussian Splatting", "comment": null, "summary": "3D Gaussian Splatting (GS) enables fast and high-quality scene reconstruction, but it lacks an object-consistent and semantically aware structure. We propose Split&Splat, a framework for panoptic scene reconstruction using 3DGS. Our approach explicitly models object instances. It first propagates instance masks across views using depth, thus producing view-consistent 2D masks. Each object is then reconstructed independently and merged back into the scene while refining its boundaries. Finally, instance-level semantic descriptors are embedded in the reconstructed objects, supporting various applications, including panoptic segmentation, object retrieval, and 3D editing. Unlike existing methods, Split&Splat tackles the problem by first segmenting the scene and then reconstructing each object individually. This design naturally supports downstream tasks and allows Split&Splat to achieve state-of-the-art performance on the ScanNetv2 segmentation benchmark."}
{"id": "2602.03145", "categories": ["cs.GT", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03145", "abs": "https://arxiv.org/abs/2602.03145", "authors": ["Ya-Ting Yang", "Quanyan Zhu"], "title": "Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow", "comment": null, "summary": "Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, and interoperability. This paper proposes a framework for scalable agentic intelligence, termed the Internet of Agentic AI, in which autonomous, heterogeneous agents distributed across cloud and edge infrastructure dynamically form coalitions to execute task-driven workflows. We formalize a network-native model of agentic collaboration and introduce an incentive-compatible workflow-coalition feasibility framework that integrates capability coverage, network locality, and economic implementability. To enable scalable coordination, we formulate a minimum-effort coalition selection problem and propose a decentralized coalition formation algorithm. The proposed framework can operate as a coordination layer above the Model Context Protocol (MCP). A healthcare case study demonstrates how domain specialization, cloud-edge heterogeneity, and dynamic coalition formation enable scalable, resilient, and economically viable agentic workflows. This work lays the foundation for principled coordination and scalability in the emerging era of Internet of Agentic AI."}
{"id": "2602.03777", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03777", "abs": "https://arxiv.org/abs/2602.03777", "authors": ["Federico Bruzzone", "Walter Cazzola", "Luca Favalli"], "title": "From Separate Compilation to Sound Language Composition", "comment": "43 pages, 1 figure, 5 Listing", "summary": "The development of programming languages involves complex theoretical and practical challenges, particularly when addressing modularity and reusability through language extensions. While language workbenches aim to enable modular development under the constraints of the language extension problem, one critical constraint -- separate compilation -- is often relaxed due to its complexity. However, this relaxation undermines artifact reusability and integration with common dependency systems. A key difficulty under separate compilation arises from managing attribute grammars, as extensions may introduce new attributes that invalidate previously generated abstract syntax tree structures. Existing approaches, such as the use of dynamic maps in the Neverlang workbench, favor flexibility at the cost of compile-time correctness, leading to potential runtime errors due to undefined attributes. This work addresses this issue by introducing nlgcheck, a theoretically sound static analysis tool based on data-flow analysis for the Neverlang language workbench. nlgcheck detects potential runtime errors -- such as undefined attribute accesses -- at compile time, preserving separate compilation while maintaining strong static correctness guarantees. Experimental evaluation using mutation testing on Neverlang-based projects demonstrates that nlgcheck effectively enhances robustness without sacrificing modularity or flexibility and with a level of performance that does not impede its adoption in daily development activities."}
{"id": "2602.03381", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.03381", "abs": "https://arxiv.org/abs/2602.03381", "authors": ["Axel Benyamine", "Julien Grand-Clément", "Marek Petrik", "Michael I. Jordan", "Alain Durmus"], "title": "Dynamic Programming for Epistemic Uncertainty in Markov Decision Processes", "comment": null, "summary": "In this paper, we propose a general theory of ambiguity-averse MDPs, which treats the uncertain transition probabilities as random variables and evaluates a policy via a risk measure applied to its random return. This ambiguity-averse MDP framework unifies several models of MDPs with epistemic uncertainty for specific choices of risk measures. We extend the concepts of value functions and Bellman operators to our setting. Based on these objects, we establish the consequences of dynamic programming principles in this framework (existence of stationary policies, value and policy iteration algorithms), and we completely characterize law-invariant risk measures compatible with dynamic programming. Our work draws connections among several variants of MDP models and fully delineates what is possible under the dynamic programming paradigm and which risk measures require leaving it."}
{"id": "2602.03387", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03387", "abs": "https://arxiv.org/abs/2602.03387", "authors": ["Zhengwei Ni", "Zhidu Li", "Wei Chen", "Zhaoyang Zhang", "Zehua Wang", "F. Richard Yu", "Victor C. M. Leung"], "title": "Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation", "comment": "7 pages, 3 figures, submitted to IEEE Network", "summary": "Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem."}
{"id": "2602.03543", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.03543", "abs": "https://arxiv.org/abs/2602.03543", "authors": ["Kanstantsin Pashkovich", "Jacob Skitsko", "Yun Xing"], "title": "Sequential Linear Contracts on Matroids", "comment": null, "summary": "In this work, we study sequential contracts under matroid constraints. In the sequential setting, an agent can take actions one by one. After each action, the agent observes the stochastic value of the action and then decides which action to take next, if any. At the end, the agent decides what subset of taken actions to use for the principal's reward; and the principal receives the total value of this subset as a reward. Taking each action induces a certain cost for the agent. Thus, to motivate the agent to take actions the principal is expected to offer an appropriate contract. A contract describes the payment from the principal to the agent as a function of the principal's reward obtained through the agent's actions. In this work, we concentrate on studying linear contracts, i.e.\\ the contracts where the principal transfers a fraction of their total reward to the agent. We assume that the total principal's reward is calculated based on a subset of actions that forms an independent set in a given matroid. We establish a relationship between the problem of finding an optimal linear contract (or computing the corresponding principal's utility) and the so called matroid (un)reliability problem. Generally, the above problems turn out to be equivalent subject to adding parallel copies of elements to the given matroid."}
{"id": "2602.03687", "categories": ["cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.03687", "abs": "https://arxiv.org/abs/2602.03687", "authors": ["Martin Bullinger", "Edith Elkind", "Kassian Köck"], "title": "Efficient Investment in Multi-Agent Models of Public Transportation", "comment": null, "summary": "We study two stylized, multi-agent models aimed at investing a limited, indivisible resource in public transportation. In the first model, we face the decision of which potential stops to open along a (e.g., bus) path, given agents' travel demands. While it is known that utilitarian optimal solutions can be identified in polynomial time, we find that computing approximately optimal solutions with respect to egalitarian welfare is NP-complete. This is surprising as we operate on the simple topology of a line graph.\n  In the second model, agents navigate a more complex network modeled by a weighted graph where edge weights represent distances. We face the decision of improving travel time along a fixed number of edges. We provide a polynomial-time algorithm that combines Dijkstra's algorithm with a dynamical program to find the optimal decision for one or two agents. By contrast, if the number of agents is variable, we find \\np-completeness and inapproximability results for utilitarian and egalitarian welfare. Moreover, we demonstrate implications of our results for a related model of railway network design."}
