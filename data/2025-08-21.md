<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 3]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 4]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [A Real-world Display Inverse Rendering Dataset](https://arxiv.org/abs/2508.14411)
*Seokjun Choi,Hoon-Gyu Chung,Yujin Jeon,Giljoo Nam,Seung-Hwan Baek*

Main category: cs.GR

TL;DR: 该论文介绍了首个基于显示器相机的真实世界逆渲染数据集，并提供了一个有效的基线方法，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏使用显示器相机系统捕获的公开真实世界数据集，阻碍了基于显示器的逆渲染方法的发展与评估。

Method: 构建了一个包含LCD显示器和立体偏振相机的成像系统，捕获了多种几何和反射率的物体在单光模式下的图像，并提供高质量的真实几何数据。

Result: 数据集支持任意显示模式和不同噪声级别的图像合成，评估显示新方法优于现有逆渲染方法。

Conclusion: 该数据集为显示器逆渲染技术的发展提供了重要资源，并提出了一种简单但高效的基线方法。

Abstract: Inverse rendering aims to reconstruct geometry and reflectance from captured
images. Display-camera imaging systems offer unique advantages for this task:
each pixel can easily function as a programmable point light source, and the
polarized light emitted by LCD displays facilitates diffuse-specular
separation. Despite these benefits, there is currently no public real-world
dataset captured using display-camera systems, unlike other setups such as
light stages. This absence hinders the development and evaluation of
display-based inverse rendering methods. In this paper, we introduce the first
real-world dataset for display-based inverse rendering. To achieve this, we
construct and calibrate an imaging system comprising an LCD display and stereo
polarization cameras. We then capture a diverse set of objects with diverse
geometry and reflectance under one-light-at-a-time (OLAT) display patterns. We
also provide high-quality ground-truth geometry. Our dataset enables the
synthesis of captured images under arbitrary display patterns and different
noise levels. Using this dataset, we evaluate the performance of existing
photometric stereo and inverse rendering methods, and provide a simple, yet
effective baseline for display inverse rendering, outperforming
state-of-the-art inverse rendering methods. Code and dataset are available on
our project page at https://michaelcsj.github.io/DIR/

</details>


### [2] [MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds](https://arxiv.org/abs/2508.14879)
*Bingquan Dai,Li Ray Luo,Qihong Tang,Jie Wang,Xinyu Lian,Hao Xu,Minghan Qin,Xudong Xu,Bo Dai,Haoqian Wang,Zhaoyang Lyu,Jiangmiao Pang*

Main category: cs.GR

TL;DR: MeshCoder是一种新框架，将3D点云重建为可编辑的Blender Python脚本，通过大规模数据集和LLM技术实现复杂几何的建模和编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的3D对象重建方法依赖有限的领域特定语言和小规模数据集，无法建模复杂几何和结构。MeshCoder旨在解决这一问题。

Method: 开发了一套全面的Blender Python API，构建了大规模配对对象-代码数据集，并训练了多模态LLM，将点云转化为可执行脚本。

Result: MeshCoder在形状到代码重建任务中表现优异，支持直观的几何和拓扑编辑，并通过代码表示增强LLM的3D形状推理能力。

Conclusion: MeshCoder为3D形状的程序化重建和理解提供了强大灵活的解决方案。

Abstract: Reconstructing 3D objects into editable programs is pivotal for applications
like reverse engineering and shape editing. However, existing methods often
rely on limited domain-specific languages (DSLs) and small-scale datasets,
restricting their ability to model complex geometries and structures. To
address these challenges, we introduce MeshCoder, a novel framework that
reconstructs complex 3D objects from point clouds into editable Blender Python
scripts. We develop a comprehensive set of expressive Blender Python APIs
capable of synthesizing intricate geometries. Leveraging these APIs, we
construct a large-scale paired object-code dataset, where the code for each
object is decomposed into distinct semantic parts. Subsequently, we train a
multimodal large language model (LLM) that translates 3D point cloud into
executable Blender Python scripts. Our approach not only achieves superior
performance in shape-to-code reconstruction tasks but also facilitates
intuitive geometric and topological editing through convenient code
modifications. Furthermore, our code-based representation enhances the
reasoning capabilities of LLMs in 3D shape understanding tasks. Together, these
contributions establish MeshCoder as a powerful and flexible solution for
programmatic 3D shape reconstruction and understanding.

</details>


### [3] [Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds](https://arxiv.org/abs/2508.14892)
*Jia Lu,Taoran Yi,Jiemin Fang,Chen Yang,Chuiyun Wu,Wei Shen,Wenyu Liu,Qi Tian,Xinggang Wang*

Main category: cs.GR

TL;DR: 该论文提出了一种从仅两张图像（前视图和后视图）重建3D人体模型的方法，显著降低了用户创建3D数字人的门槛。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于从稀疏视图重建3D人体，以扩展相关应用范围，尤其是降低用户创建3D数字人的难度。

Method: 方法包括基于基础重建模型设计的几何重建模型，用于预测一致的点云，以及增强算法补充缺失的颜色信息，最后将点云转换为3D高斯模型以提高渲染质量。

Result: 实验表明，该方法在单张NVIDIA RTX 4090上仅需190毫秒即可完成重建，且在THuman2.0和跨域数据集上表现出最先进的性能，还能适配低成本移动设备采集的图像。

Conclusion: 该方法有效解决了稀疏输入下重建3D人体的挑战，降低了数据采集要求，具有广泛的应用潜力。

Abstract: Reconstructing 3D human bodies from sparse views has been an appealing topic,
which is crucial to broader the related applications. In this paper, we propose
a quite challenging but valuable task to reconstruct the human body from only
two images, i.e., the front and back view, which can largely lower the barrier
for users to create their own 3D digital humans. The main challenges lie in the
difficulty of building 3D consistency and recovering missing information from
the highly sparse input. We redesign a geometry reconstruction model based on
foundation reconstruction models to predict consistent point clouds even input
images have scarce overlaps with extensive human data training. Furthermore, an
enhancement algorithm is applied to supplement the missing color information,
and then the complete human point clouds with colors can be obtained, which are
directly transformed into 3D Gaussians for better rendering quality.
Experiments show that our method can reconstruct the entire human in 190 ms on
a single NVIDIA RTX 4090, with two images at a resolution of 1024x1024,
demonstrating state-of-the-art performance on the THuman2.0 and cross-domain
datasets. Additionally, our method can complete human reconstruction even with
images captured by low-cost mobile devices, reducing the requirements for data
collection. Demos and code are available at
https://hustvl.github.io/Snap-Snap/.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [4] [Tuning Random Generators: Property-Based Testing as Probabilistic Programming](https://arxiv.org/abs/2508.14394)
*Ryan Tjoa,Poorva Garg,Harrison Goldstein,Todd Millstein,Benjamin Pierce,Guy Van den Broeck*

Main category: cs.PL

TL;DR: 本文提出了一种自动离线调整生成器的方法，通过优化目标函数自动学习符号权重，以实现更好的测试输入分布和更高的测试案例多样性及有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于属性的测试中，用户需要手动调整生成器的权重以达到理想的测试输入分布，这一过程繁琐且限制了实际可实现的分布范围。

Method: 提出了一种方法，通过给定带有未确定符号权重的生成器和目标函数，自动学习这些权重以优化目标。采用了离散概率编程系统Loaded Dice作为生成器的语言，支持微分和参数学习。

Result: 实验证明，该方法能有效优化生成器的分布，且在自动调整后，生成器在bug发现上表现出3.1-7.4倍的加速。

Conclusion: 通过自动调整生成器的权重，可以显著提高测试案例的多样性和有效性，从而更快地发现软件中的bug。

Abstract: Property-based testing validates software against an executable specification
by evaluating it on randomly generated inputs. The standard way that PBT users
generate test inputs is via generators that describe how to sample test inputs
through random choices. To achieve a good distribution over test inputs, users
must tune their generators, i.e., decide on the weights of these individual
random choices. Unfortunately, it is very difficult to understand how to choose
individual generator weights in order to achieve a desired distribution, so
today this process is tedious and limits the distributions that can be
practically achieved.
  In this paper, we develop techniques for the automatic and offline tuning of
generators. Given a generator with undetermined symbolic weights and an
objective function, our approach automatically learns values for these weights
that optimize for the objective. We describe useful objective functions that
allow users to (1) target desired distributions and (2) improve the diversity
and validity of their test cases. We have implemented our approach in a novel
discrete probabilistic programming system, Loaded Dice, that supports
differentiation and parameter learning, and use it as a language for
generators. We empirically demonstrate that our approach is effective at
optimizing generator distributions according to the specified objective
functions. We also perform a thorough evaluation on PBT benchmarks,
demonstrating that, when automatically tuned for diversity and validity, the
generators exhibit a 3.1-7.4x speedup in bug finding.

</details>


### [5] [Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity](https://arxiv.org/abs/2508.14614)
*Ashish Mishra,Suresh Jagannathan*

Main category: cs.PL

TL;DR: 本文提出了一种基于组件合成（CBS）的新方法，通过在搜索中利用逻辑相似性来避免探索语义相似的路径，从而更高效地合成满足复杂查询的循环无程序。


<details>
  <summary>Details</summary>
Motivation: 传统的组件合成方法在面对严格的逻辑约束时，可行解的搜索空间会变得非常稀疏。因此，如何在复杂的约束条件下高效合成程序成为了一个关键挑战。

Method: 本文提出了一种基于修正类型规范的搜索方法，利用称为“限定树自动机”的变体来记录枚举项的信息，并通过子类型约束推理候选解之间的相似性，避免探索语义相似的路径。

Result: 通过工具\name的实现和评估，展示了该方法能够合成远超现有技术的复杂CBS查询的解决方案。

Conclusion: 通过引入逻辑相似性推理，本文的方法显著提升了组件合成的能力，能够高效处理复杂约束条件下的程序合成问题。

Abstract: Component-based synthesis (CBS) aims to generate loop-free programs from a
set of libraries whose methods are annotated with specifications and whose
output must satisfy a set of logical constraints, expressed as a query. The
effectiveness of a CBS algorithm critically depends on the severity of the
constraints imposed by the query. The more exact these constraints are, the
sparser the space of feasible solutions. This maxim also applies when we enrich
the expressiveness of the specifications affixed to library methods. In both
cases, the search must now contend with constraints that may only hold over a
small number of the possible execution paths that can be enumerated by a CBS
procedure.
  In this paper, we address this challenge by equipping CBS search with the
ability to reason about logical similarities among the paths it explores. Our
setting considers library methods equipped with refinement-type specifications
that enrich ordinary base types with a set of rich logical qualifiers to
constrain the set of values accepted by that type. We perform a search over a
tree automata variant called Qualified Tree Automata that intelligently records
information about enumerated terms, leveraging subtyping constraints over the
refinement types associated with these terms to enable reasoning about
similarity among candidate solutions as search proceeds, thereby avoiding
exploration of semantically similar paths.
  We present an implementation of this idea in a tool called \name, and provide
a comprehensive evaluation that demonstrates \name's ability to synthesize
solutions to complex CBS queries that go well-beyond the capabilities of the
existing state-of-the-art.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Algorithms for Stable Roommate with Externalities](https://arxiv.org/abs/2508.14194)
*Jing Leng,Sanjukta Roy*

Main category: cs.GT

TL;DR: 论文研究了室友匹配模型中两种稳定的分配方式（4PS和2PS），并探讨了它们的效率与策略证明性。通过设计基于序列独裁的算法，实现了4PS分配的帕累托最优和策略证明性，但发现其不适用于2PS。同时，分析了基于TTC的算法在策略证明性和PO方面的局限性，并识别了在多项式时间内找到2PS分配的特殊偏好结构。


<details>
  <summary>Details</summary>
Motivation: 室友匹配问题在代理人同时对房间和室友有偏好的情况下尚未充分研究。本文旨在填补这一空白，探讨两种稳定分配方式（4PS和2PS）的效率与策略证明性，并提出有效的算法解决方案。

Method: 采用序列独裁算法设计用于4PS分配，实现帕累托最优和策略证明性；分析基于TTC的算法在策略证明性和PO方面的局限性；识别特定偏好结构以在多项式时间内找到2PS分配。

Result: 序列独裁算法适用于4PS分配但不适用于2PS；TTC算法的变种无法同时满足策略证明性和PO；在特定偏好结构下，2PS分配可在多项式时间内完成。

Conclusion: 论文展示了在室友匹配模型中，4PS分配可通过简单算法实现高效和策略证明性，而2PS分配的复杂性和计算难度则需进一步研究。同时，某些特殊偏好结构可以简化2PS分配的计算复杂度。

Abstract: In the roommate matching model, given a set of 2n agents and n rooms, we find
an assignment of a pair of agents to a room. Although the roommate matching
problem is well studied, the study of the model when agents have preference
over both rooms and roommates was recently initiated by Chan et al. [11]. We
study two types of stable roommate assignments, namely, 4-person stable (4PS)
and 2-person stable (2PS) in conjunction with efficiency and
strategy-proofness. We design a simple serial dictatorship based algorithm for
finding a 4PS assignment that is Pareto optimal and strategy-proof. However,
the serial dictatorship algorithm is far from being 2PS. Next, we study top
trading cycle (TTC) based algorithms. We show that variations of TTC cannot be
strategy-proof or PO. Finally, as Chan et al. (2016) showed that deciding the
existence of 2PS assignment is NP-complete, we identify preference structures
where a 2PS assignment can be found in polynomial time.

</details>


### [7] [Explainable Information Design](https://arxiv.org/abs/2508.14196)
*Yiling Chen,Tao Lin,Wei Tang,Jamie Tucker-Foltz*

Main category: cs.GT

TL;DR: 该论文研究了在信息设计中可解释的信号方案，证明了可分区信号方案在性能上不会比任意信号方案差超过2倍，并展示了在特定条件下的计算效率和算法结果。


<details>
  <summary>Details</summary>
Motivation: 传统信息设计中的最优信号方案常常涉及难以解释或审计的随机化或复杂分区。论文旨在提出一种可解释的信号设计方法，以便更易于审计和沟通。

Method: 论文将信息设计限制为使用确定性且单调的分区信号方案，提出了一种转换方法，将任意最优信号方案转换为分区信号方案，并证明其在性能上不会低于原方案的1/2。

Result: 证明了分区信号方案在性能上不会比任意信号方案差超过2倍，并展示了在特定条件下的计算复杂度和算法效率，如多项式时间内的近似计算和1/2近似比的算法。

Conclusion: 论文展示了可解释的分区信号方案在实际应用中的可行性，并通过理论分析和算法设计验证了其性能和计算效率。

Abstract: The optimal signaling schemes in information design (Bayesian persuasion)
problems often involve non-explainable randomization or disconnected partitions
of state space, which are too intricate to be audited or communicated. We
propose explainable information design in the context of information design
with a continuous state space, restricting the information designer to use
$K$-partitional signaling schemes defined by deterministic and monotone
partitions of the state space, where a unique signal is sent for all states in
each part. We first prove that the price of explainability (PoE) -- the ratio
between the performances of the optimal explainable signaling scheme and
unrestricted signaling scheme -- is exactly $1/2$ in the worst case, meaning
that partitional signaling schemes are never worse than arbitrary signaling
schemes by a factor of 2.
  We then study the complexity of computing optimal explainable signaling
schemes. We show that the exact optimization problem is NP-hard in general. But
for Lipschitz utility functions, an $\varepsilon$-approximately optimal
explainable signaling scheme can be computed in polynomial time. And for
piecewise constant utility functions, we provide an efficient algorithm to find
an explainable signaling scheme that provides a $1/2$ approximation to the
optimal unrestricted signaling scheme, which matches the worst-case PoE bound.
  A technical tool we develop is a conversion from any optimal signaling scheme
(which satisfies a bi-pooling property) to a partitional signaling scheme that
achieves $1/2$ fraction of the expected utility of the former. We use this tool
in the proofs of both our PoE result and algorithmic result.

</details>


### [8] [Properties of Egalitarian Sequences of Committees: Theory and Experiments](https://arxiv.org/abs/2508.14439)
*Paula Böhm,Robert Bredereck,Till Fluschnik*

Main category: cs.GT

TL;DR: 本文研究了如何选举平等主义的委员会序列，提出了一系列规则并分析了其计算复杂性和实证表现。


<details>
  <summary>Details</summary>
Motivation: 研究在多个层级上如何选举代表公平性的委员会序列，以满足代理人对候选人的累加效用需求。

Method: 引入了几种选举平等主义委员会序列的规则，并定义了这些规则的性质，同时探讨了其计算复杂性和分类。

Result: 通过理论分析和实验数据验证，比较了不同规则的性能，并测试了它们是否符合定义的性质。

Conclusion: 提出的规则在理论和实证上都表现良好，为多层级委员会选举提供了有效的解决方案。

Abstract: We study the task of electing egalitarian sequences of $\tau$ committees
given a set of agents with additive utilities for candidates available on each
of $\tau$ levels. We introduce several rules for electing an egalitarian
committee sequence as well as properties for such rules. We settle the
computational complexity of finding a winning sequence for our rules and
classify them against our properties. Additionally, we transform sequential
election data from existing election data from the literature. Using this data
set, we compare our rules empirically and test them experimentally against our
properties.

</details>


### [9] [Learning in Repeated Multi-Objective Stackelberg Games with Payoff Manipulation](https://arxiv.org/abs/2508.14705)
*Phurinut Srisawad,Juergen Branke,Long Tran-Thanh*

Main category: cs.GT

TL;DR: 研究多目标Stackelberg博弈中的回报操纵问题，提出基于预期效用和长期预期效用的操纵策略，平衡短期收益与长期影响。


<details>
  <summary>Details</summary>
Motivation: 在重复的多目标Stackelberg博弈中，领袖如何通过策略性操纵回报来影响追随者的最佳响应，无需显式谈判或预先了解追随者的效用函数。

Method: 假设追随者的效用函数为线性但未知，提出基于预期效用（EU）和长期预期效用（longEU）的操纵策略，平衡偏好探索与即时效用最大化。

Result: 在无限重复交互条件下，longEU收敛于最优操纵；实验证明该方法提升领袖累积效用并促进互惠结果。

Conclusion: 提出的方法无需显式谈判或预先知识，有效提升领袖的长期效用，并在多目标环境中实现互惠。

Abstract: We study payoff manipulation in repeated multi-objective Stackelberg games,
where a leader may strategically influence a follower's deterministic best
response, e.g., by offering a share of their own payoff. We assume that the
follower's utility function, representing preferences over multiple objectives,
is unknown but linear, and its weight parameter must be inferred through
interaction. This introduces a sequential decision-making challenge for the
leader, who must balance preference elicitation with immediate utility
maximisation. We formalise this problem and propose manipulation policies based
on expected utility (EU) and long-term expected utility (longEU), which guide
the leader in selecting actions and offering incentives that trade off
short-term gains with long-term impact. We prove that under infinite repeated
interactions, longEU converges to the optimal manipulation. Empirical results
across benchmark environments demonstrate that our approach improves cumulative
leader utility while promoting mutually beneficial outcomes, all without
requiring explicit negotiation or prior knowledge of the follower's utility
function.

</details>
