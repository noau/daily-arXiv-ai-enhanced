<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SPLICE: Part-Level 3D Shape Editing from Local Semantic Extraction to Global Neural Mixing](https://arxiv.org/abs/2512.04514)
*Jin Zhou,Hongliang Yang,Pengfei Xu,Hui Huang*

Main category: cs.GR

TL;DR: SPLICE是一种新型的3D形状部分级别神经隐式表示方法，支持直观、结构感知且高保真的形状编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D形状编辑中存在可编辑性受限、缺乏部分级别控制以及修改或重组部分形状时结果不自然的问题。

Method: SPLICE通过独立编码每个形状部分并使用参数化高斯椭球定位，隔离部分特定特征，并通过全局注意力解码器和注意力引导过滤机制实现部分的高效整合。

Result: SPLICE支持多种部分级别编辑操作，包括平移、旋转、缩放、删除、复制和跨形状部分混合，在实验中表现优于现有方法。

Conclusion: SPLICE为3D形状编辑提供了更灵活且高质量的方法，同时保持了语义一致性和结构合理性。

Abstract: Neural implicit representations of 3D shapes have shown great potential in 3D shape editing due to their ability to model high-level semantics and continuous geometric representations. However, existing methods often suffer from limited editability, lack of part-level control, and unnatural results when modifying or rearranging shape parts. In this work, we present SPLICE, a novel part-level neural implicit representation of 3D shapes that enables intuitive, structure-aware, and high-fidelity shape editing. By encoding each shape part independently and positioning them using parameterized Gaussian ellipsoids, SPLICE effectively isolates part-specific features while discarding global context that may hinder flexible manipulation. A global attention-based decoder is then employed to integrate parts coherently, further enhanced by an attention-guiding filtering mechanism that prevents information leakage across symmetric or adjacent components. Through this architecture, SPLICE supports various part-level editing operations, including translation, rotation, scaling, deletion, duplication, and cross-shape part mixing. These operations enable users to flexibly explore design variations while preserving semantic consistency and maintaining structural plausibility. Extensive experiments demonstrate that SPLICE outperforms existing approaches both qualitatively and quantitatively across a diverse set of shape-editing tasks.

</details>


### [2] [Efficient Spatially-Variant Convolution via Differentiable Sparse Kernel Complex](https://arxiv.org/abs/2512.04556)
*Zhizhen Wu,Zhe Cao,Yuchi Huo*

Main category: cs.GR

TL;DR: 提出了一种可微分核分解框架，通过稀疏核样本表示复杂的空间变体密集核，提高了计算效率并保持了高保真度。


<details>
  <summary>Details</summary>
Motivation: 图像卷积在摄影、科学成像和动画效果中至关重要，但直接密集卷积在资源受限设备上计算成本过高。现有方法在效率或非凸核捕捉方面存在不足。

Method: 采用可微分优化框架，通过稀疏核样本分解目标核，包括可微分优化、非凸形状初始化策略和核空间插值方案。

Result: 在高斯和非凸核实验中，该方法比模拟退火保真度更高，且比低秩分解成本显著降低。

Conclusion: 该方法为移动成像和实时渲染提供了实用解决方案，同时完全可微分，便于集成到更广泛的学习流程中。

Abstract: Image convolution with complex kernels is a fundamental operation in photography, scientific imaging, and animation effects, yet direct dense convolution is computationally prohibitive on resource-limited devices. Existing approximations, such as simulated annealing or low-rank decompositions, either lack efficiency or fail to capture non-convex kernels. We introduce a differentiable kernel decomposition framework that represents a target spatially-variant, dense, complex kernel using a set of sparse kernel samples. Our approach features (i) a decomposition that enables differentiable optimization of sparse kernels, (ii) a dedicated initialization strategy for non-convex shapes to avoid poor local minima, and (iii) a kernel-space interpolation scheme that extends single-kernel filtering to spatially varying filtering without retraining and additional runtime overhead. Experiments on Gaussian and non-convex kernels show that our method achieves higher fidelity than simulated annealing and significantly lower cost than low-rank decompositions. Our approach provides a practical solution for mobile imaging and real-time rendering, while remaining fully differentiable for integration into broader learning pipelines.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts](https://arxiv.org/abs/2512.04755)
*Stian Lybech,Daniele Gorla,Luca Aceto*

Main category: cs.PL

TL;DR: 本文提出了一种在智能合约环境中实现语义类型的方法，以确保使用静态无法类型化的语言构造（如回退函数）的代码类型安全，通过提供形式化证明来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 智能合约中常使用静态无法类型化的语言构造（如回退函数），导致类型安全问题。本文旨在通过语义类型和形式化证明来确保此类代码的安全性。

Method: 作者采用了一种基于语义类型的证明携带代码方法，合约创建者为代码提供类型安全的形式化证明，用户只需验证证明的有效性。具体应用于TINYSOL语言的信息流控制和非干扰性检查。

Result: 研究为TINYSOL语言提供了类型语义和安全性证明的表达方式，并通过向上技术压缩证明表示。此外，展示了如何对基于回退函数的典型实现指针模式进行类型检查。

Conclusion: 本文的主要贡献不是安全性定理本身，而是提出了在区块链/智能合约环境中实现这一方法所需的理论基础。

Abstract: This paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate' of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment.
  As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.

</details>


### [4] [Optimizations and extensions for fair join pattern matching](https://arxiv.org/abs/2512.04876)
*Ioannis Karras*

Main category: cs.PL

TL;DR: 该论文优化了基于状态树的匹配算法，提升了公平连接模式匹配的时间效率，并在微服务架构中展示了其应用。


<details>
  <summary>Details</summary>
Motivation: 连接模式在并发和分布式系统中被低估，而公平连接模式匹配的时间效率问题尚未充分研究。

Method: 通过优化基于状态树的匹配算法，实现了性能提升，并扩展了基准测试套件的功能和用户友好性。

Result: 优化后的算法在特定基准测试中实现了高达十倍的性能提升，接近Rete算法的表现，同时保留了多功能性和对复杂条件的优势。

Conclusion: 该研究不仅提升了公平连接模式匹配的时间效率，还通过新的复杂模型用例展示了其在微服务架构中的适用性。

Abstract: Join patterns are an underexplored approach for the programming of concurrent and distributed systems. When applied to the actor model, join patterns offer the novel capability of matching combinations of messages in the mailbox of an actor. Previous work by Philipp Haller et al. in the paper "Fair Join Pattern Matching for Actors" (ECOOP 2024) explored join patterns with conditional guards in an actor-based setting with a specification of fair and deterministic matching semantics. Nevertheless, the question of time efficiency in fair join pattern matching has remained underexplored. The stateful tree-based matching algorithm of Haller et al. performs worse than an implementation that adapts the Rete algorithm to the regular version of a join pattern matching benchmark, while outperforming on a variant with heavy conditional guards, which take longer to evaluate. Nevertheless, conforming Rete to the problem of join pattern matching requires heavy manual adaptation.
  In this thesis, we enhance and optimize the stateful tree-based matching algorithm of Haller et al. to achieve up to tenfold performance improvements on certain benchmarks, approaching the performance of Rete on regular benchmarks while maintaining the advantages of versatility and performance with heavy guards. We also enhance the benchmark suite, adding new features and enhancing its extensibility and user-friendliness. We extend the join pattern implementation with a less ambiguous syntax as well as dynamic pattern switching. Finally, we present a new complex model use case for join patterns, showing their applicability in a microservice web architecture.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [5] [Omniscient Attacker in Stochastic Security Games with Interdependent Nodes](https://arxiv.org/abs/2512.04561)
*Yuksel Arslantas,Ahmed Said Donmez,Ege Yuceel,Muhammed O. Sayin*

Main category: cs.GT

TL;DR: 本文探讨了强化学习在关键基础设施防御中的应用漏洞，提出了一种针对防御算法的神经动态规划方法，以应对攻击者对学习动态的战略性利用。


<details>
  <summary>Details</summary>
Motivation: 现有研究在处理重复常态博弈中的漏洞时取得了进展，但扩展到随机博弈领域仍是一个开放的研究空白。本文旨在填补这一空白。

Method: 我们研究了强化学习防御者与全知攻击者之间的随机安全博弈，提出了可处理的线性影响网络模型，并应用了神经动态规划方法来克服先前方法的局限性。

Result: 实验结果表明，全知攻击者能显著优于未经优化的防御者，揭示了学习动态引入的严重漏洞以及所提策略的有效性。

Conclusion: 本文填补了随机博弈领域的研究空白，验证了神经动态规划方法的有效性，并强调了防御算法在设计时需考虑攻击者的战略性利用。

Abstract: The adoption of reinforcement learning for critical infrastructure defense introduces a vulnerability where sophisticated attackers can strategically exploit the defense algorithm's learning dynamics. While prior work addresses this vulnerability in the context of repeated normal-form games, its extension to the stochastic games remains an open research gap. We close this gap by examining stochastic security games between an RL defender and an omniscient attacker, utilizing a tractable linear influence network model. To overcome the structural limitations of prior methods, we propose and apply neuro-dynamic programming. Our experimental results demonstrate that the omniscient attacker can significantly outperform a naive defender, highlighting the critical vulnerability introduced by the learning dynamics and the effectiveness of the proposed strategy.

</details>


### [6] [Side-by-side first-price auctions with imperfect bidders](https://arxiv.org/abs/2512.04850)
*Benjamin Heymann*

Main category: cs.GT

TL;DR: 论文研究了两个不完美投标者在展示广告中的并行竞价场景，证明了迭代最佳响应算法在标准分布假设下收敛到均衡，并提供了独一性的充分条件。


<details>
  <summary>Details</summary>
Motivation: 展示广告中的并行竞价配置在理论上尚未充分探讨，因此需要建立模型和分析方法来填补这一空白。

Method: 使用迭代最佳响应算法，并在标准分布假设下进行分析。

Result: 证明了算法收敛到均衡，并提供了均衡独一性的充分条件，同时提出了一种可计算的数值方法。

Conclusion: 研究不仅建立了并行竞价的理论基础，还提供了定量研究的实用工具。

Abstract: We model a procurement scenario in which two \textit{imperfect} bidders act simultaneously on behalf of a single buyer, a configuration common in display advertising and referred to as \textit{side-by-side bidding} but largely unexplored in theory. We prove that the iterated best response algorithm converges to an equilibrium under standard distributional assumptions and provide sufficient condition for uniqueness. Beyond establishing existence and convergence, our analysis provides a tractable numerical method for quantitative studies of side-by-side procurement.

</details>
