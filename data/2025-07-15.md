<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 6]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 11]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Interactive Drawing Guidance for Anime Illustrations with Diffusion Model](https://arxiv.org/abs/2507.09140)
*Chuang Chen,Xiaoxuan Xie,Yongming Zhang,Tianyu Zhang,Haoran Xie*

Main category: cs.GR

TL;DR: 本文提出了一种交互式动漫插画绘制引导系统，通过实时指导和优化工具帮助用户提升绘图效率和精度。


<details>
  <summary>Details</summary>
Motivation: 动漫插画因其复杂的风格和精细的细节对初学者具有挑战性，作者旨在提供一个实时引导系统以简化绘制过程。

Method: 系统基于StreamDiffusion流程，通过LoRA微调Stable Diffusion生成动漫风格RGB图像，并结合Informative Drawings模型将图像转化为草图，最终优化为结构化引导草图。

Result: 用户研究表明，该系统显著提升了绘图效率和准确性，并获得了良好的用户反馈。

Conclusion: 该系统通过实时引导和优化工具，成功解决了动漫插画绘制的挑战，为创作者提供了有力的支持。

Abstract: Creating high-quality anime illustrations presents notable challenges,
particularly for beginners, due to the intricate styles and fine details
inherent in anime art. We present an interactive drawing guidance system
specifically designed for anime illustrations to address this issue. It offers
real-time guidance to help users refine their work and streamline the creative
process. Our system is built upon the StreamDiffusion pipeline to deliver
real-time drawing assistance. We fine-tune Stable Diffusion with LoRA to
synthesize anime style RGB images from user-provided hand-drawn sketches and
prompts. Leveraging the Informative Drawings model, we transform these RGB
images into rough sketches, which are further refined into structured guidance
sketches using a custom-designed optimizer. The proposed system offers precise,
real-time guidance aligned with the creative intent of the user, significantly
enhancing both the efficiency and accuracy of the drawing process. To assess
the effectiveness of our approach, we conducted a user study, gathering
empirical feedback on both system performance and interface usability.

</details>


### [2] [Physics-Aware Fluid Field Generation from User Sketches Using Helmholtz-Hodge Decomposition](https://arxiv.org/abs/2507.09146)
*Ryuichi Miyauchi,Hengyuan Chang,Tsukasa Fukusato,Kazunori Miyata,Haoran Xie*

Main category: cs.GR

TL;DR: 该论文提出了一种交互式设计二维向量场的方法，结合了生成模型和物理属性编辑，以解决现有方法难以保持物理属性的问题。


<details>
  <summary>Details</summary>
Motivation: 流体模拟技术在电影制作等领域广泛应用，但控制复杂流体行为仍具挑战性。现有生成模型虽能通过用户草图直观生成向量场，但难以保持物理属性如不可压缩性。

Method: 论文采用两阶段方法：首先使用潜在扩散模型（LDM）从用户草图中自动生成初始二维向量场；随后应用Helmholtz-Hodge分解从LDM结果中局部提取物理属性（如不可压缩性），并根据用户意图重新组合。

Result: 通过多次实验验证，所提出的方法在保持物理属性的同时，有效实现了用户交互式的向量场设计。

Conclusion: 该方法结合生成模型和物理属性编辑，显著提升了向量场设计的直观性和物理准确性，为流体模拟领域提供了新的解决方案。

Abstract: Fluid simulation techniques are widely used in various fields such as film
production, but controlling complex fluid behaviors remains challenging. While
recent generative models enable intuitive generation of vector fields from user
sketches, they struggle to maintain physical properties such as
incompressibility. To address these issues, this paper proposes a method for
interactively designing 2D vector fields. Conventional generative models can
intuitively generate vector fields from user sketches, but remain difficult to
consider physical properties. Therefore, we add a simple editing process after
generating the vector field. In the first stage, we use a latent diffusion
model~(LDM) to automatically generate initial 2D vector fields from user
sketches. In the second stage, we apply the Helmholtz-Hodge decomposition to
locally extract physical properties such as incompressibility from the results
generated by LDM and recompose them according to user intentions. Through
multiple experiments, we demonstrate the effectiveness of our proposed method.

</details>


### [3] [RectifiedHR: High-Resolution Diffusion via Energy Profiling and Adaptive Guidance Scheduling](https://arxiv.org/abs/2507.09441)
*Ankit Sanjyal*

Main category: cs.GR

TL;DR: 该论文提出了一种自适应无分类器引导（CFG）调度方法，用于解决扩散模型在高分辨率图像合成中的能量不稳定和引导伪影问题，显著提升了图像质量和模型稳定性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率图像合成中的扩散模型常因能量不稳定和引导伪影问题导致视觉质量下降，论文旨在通过分析潜在能量景观并提出自适应调度策略来改善这一现象。

Method: 论文提出了能量感知的调度策略，使用自适应无分类器引导（CFG）计划来动态调整引导强度，并通过能量分析框架对扩散模型的行为进行诊断和优化。

Result: 结果表明，采用线性递减CFG调度的DPM++ 2M模型表现最佳，稳定性得分（0.9998）和一致性指标（0.9873）均优于固定引导方法，生成了更清晰且更少伪影的图像。

Conclusion: 论文证明自适应CFG调度和能量分析框架能有效提升扩散模型的性能，为理解及改进扩散模型行为提供了有力的诊断工具。

Abstract: High-resolution image synthesis with diffusion models often suffers from
energy instabilities and guidance artifacts that degrade visual quality. We
analyze the latent energy landscape during sampling and propose adaptive
classifier-free guidance (CFG) schedules that maintain stable energy
trajectories. Our approach introduces energy-aware scheduling strategies that
modulate guidance strength over time, achieving superior stability scores
(0.9998) and consistency metrics (0.9873) compared to fixed-guidance
approaches. We demonstrate that DPM++ 2M with linear-decreasing CFG scheduling
yields optimal performance, providing sharper, more faithful images while
reducing artifacts. Our energy profiling framework serves as a powerful
diagnostic tool for understanding and improving diffusion model behavior.

</details>


### [4] [Real-time and Controllable Reactive Motion Synthesis via Intention Guidance](https://arxiv.org/abs/2507.09704)
*Xiaotang Zhang,Ziyi Chang,Qianhui Men,Hubert Shum*

Main category: cs.GR

TL;DR: 提出了一种基于已知角色输入轨迹的实时反应性运动合成方法，通过预测关键关节意图和对抗训练，实现实时、长期的交互式运动合成。


<details>
  <summary>Details</summary>
Motivation: 为了克服离线方法无法实时处理用户控制的运动轨迹和未来运动不确定性的问题，提出了一种能够实时生成反应性运动的新方法。

Method: 引入意图预测器来预测关键关节意图，并通过潜在空间编码和对抗训练增强模型鲁棒性。该方法递归生成意图和反应性运动，支持实时交互。

Result: 定量和定性实验表明，该方法在稳定性和泛化能力上优于其他基于匹配的运动合成方法。用户还能通过控制运动方向主动影响结果。

Conclusion: 该方法能够实时生成高质量的反应性运动，支持个性化的交互路径，优于已有方法。

Abstract: We propose a real-time method for reactive motion synthesis based on the
known trajectory of input character, predicting instant reactions using only
historical, user-controlled motions. Our method handles the uncertainty of
future movements by introducing an intention predictor, which forecasts key
joint intentions to make pose prediction more deterministic from the historical
interaction. The intention is later encoded into the latent space of its
reactive motion, matched with a codebook which represents mappings between
input and output. It samples a categorical distribution for pose generation and
strengthens model robustness through adversarial training. Unlike previous
offline approaches, the system can recursively generate intentions and reactive
motions using feedback from earlier steps, enabling real-time, long-term
realistic interactive synthesis. Both quantitative and qualitative experiments
show our approach outperforms other matching-based motion synthesis approaches,
delivering superior stability and generalizability. In our method, user can
also actively influence the outcome by controlling the moving directions,
creating a personalized interaction path that deviates from predefined
trajectories.

</details>


### [5] [CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design](https://arxiv.org/abs/2507.09792)
*Prashant Govindarajan,Davide Baldelli,Jay Pathak,Quentin Fournier,Sarath Chandar*

Main category: cs.GR

TL;DR: 论文提出了一种基于LLMs的方法，通过微调代码-LLMs来从自然语言描述生成CAD序列，显著提高了CAD设计的自动化效率。


<details>
  <summary>Details</summary>
Motivation: CAD设计长期以来是一项耗时的手工任务，虽然有尝试用小型Transformer模型自动化，但尚未充分利用大型语言模型（LLMs）的潜力。

Method: 通过构建一个包含17万多个CAD模型的数据集，并使用GPT-4.1生成高质量描述，论文微调了代码-LLMs来生成基于JSON格式的CAD序列。

Result: 实验证明该方法能够自动化CAD设计，并显著提高新对象的设计速度。通过引入球度、平均曲率和欧拉特征等几何和拓扑指标，提供了更丰富的结构分析。

Conclusion: 论文展示了LLMs在CAD设计中的可行性和有效性，为未来自动化设计提供了新的方向。

Abstract: Computer-aided design (CAD) is the digital construction of 2D and 3D objects,
and is central to a wide range of engineering and manufacturing applications
like automobile and aviation. Despite its importance, CAD modeling remains
largely a time-intensive, manual task. Recent works have attempted to automate
this process with small transformer-based models and handcrafted CAD sequence
representations. However, there has been little effort to leverage the
potential of large language models (LLMs) for sequential CAD design. In this
work, we introduce a new large-scale dataset of more than 170k CAD models
annotated with high-quality, human-like descriptions generated with our
pipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs
to generate CAD sequences represented in a JSON-based format from natural
language descriptions, demonstrating the viability and effectiveness of this
approach for text-conditioned CAD generation. Because simple metrics often fail
to reflect the quality of generated objects, we introduce geometric and
topological metrics based on sphericity, mean curvature, and Euler
characteristic to provide richer structural insights. Our experiments and
ablation studies on both synthetic and human-annotated data demonstrate that
CADmium is able to automate CAD design, drastically speeding up the design of
new objects. The dataset, code, and fine-tuned models are available online.

</details>


### [6] [ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions](https://arxiv.org/abs/2507.10542)
*Shivangi Aneja,Sebastian Weiss,Irene Baeza,Prashanth Chandran,Gaspard Zoss,Matthias Nießner,Derek Bradley*

Main category: cs.GR

TL;DR: 该论文提出了一种基于局部面部表情和3D高斯抛光的超高清、逼真3D头部头像生成方法，显著提升了表情和皮肤细节的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D头像生成方法通常在全局表情空间上操作，难以捕捉面部微表情和皮肤细节。为了实现更高保真度的头像渲染，特别是在近距离展示面部微特征时，需要一种更精细的方法。

Method: 论文提出了一种结合局部面部表情和3D高斯抛光的方法，使用基于补丁的几何3D面部模型提取局部表情特征，并通过将这些补丁与Scaffold-GS的锚点耦合，实时合成3D高斯。同时采用基于颜色的密集化和渐进式训练来提升渲染质量和收敛速度。

Result: ScaffoldAvatar方法在多种面部表情和风格下实现了实时渲染，并在视觉上表现出自然运动，其性能达到了当前最先进的水平。

Conclusion: 通过局部表情特征与3D高斯抛光的结合，该方法显著提升了3D头部头像的逼真度和动态表现力，为沉浸式远程呈现和电影等应用提供了高质量的解决方案。

Abstract: Generating high-fidelity real-time animated sequences of photorealistic 3D
head avatars is important for many graphics applications, including immersive
telepresence and movies. This is a challenging problem particularly when
rendering digital avatar close-ups for showing character's facial microfeatures
and expressions. To capture the expressive, detailed nature of human heads,
including skin furrowing and finer-scale facial movements, we propose to couple
locally-defined facial expressions with 3D Gaussian splatting to enable
creating ultra-high fidelity, expressive and photorealistic 3D head avatars. In
contrast to previous works that operate on a global expression space, we
condition our avatar's dynamics on patch-based local expression features and
synthesize 3D Gaussians at a patch level. In particular, we leverage a
patch-based geometric 3D face model to extract patch expressions and learn how
to translate these into local dynamic skin appearance and motion by coupling
the patches with anchor points of Scaffold-GS, a recent hierarchical scene
representation. These anchors are then used to synthesize 3D Gaussians
on-the-fly, conditioned by patch-expressions and viewing direction. We employ
color-based densification and progressive training to obtain high-quality
results and faster convergence for high resolution 3K training images. By
leveraging patch-level expressions, ScaffoldAvatar consistently achieves
state-of-the-art performance with visually natural motion, while encompassing
diverse facial expressions and styles in real time.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Bounded Model Checking of RISC-V Machine Code with Context-Free-Language Ordered Binary Decision Diagrams](https://arxiv.org/abs/2507.09539)
*Anna Bolotina,Christoph M. Kirsch,Stefanie Muroya Lei,Matthias Pleschinger*

Main category: cs.PL

TL;DR: 该论文提出了两种工具rotor和bitme，通过将符号执行推至机器代码级别并完全依赖SMT求解器，以应对软件分析中的状态爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 符号执行在软件行为分析中具有强大能力，但由于控制流和数据流的状态爆炸问题，其可扩展性受到限制。现有工具往往牺牲完整性来管理控制流，而将数据流推理交给SMT求解器处理。

Method: 论文开发了两种工具：rotor用于模型生成，bitme用于边界模型检查。通过将推理推至机器代码级别，并利用BDD（如ADDs和CFLOBDDs）技术进行程序输入传播，减少对SMT求解器的依赖。

Result: 实验表明，尽管现有SMT求解器表现不佳，但通过BDD技术显著加速了SMT求解，特别是在模型输入不可传播的情况下。CFLOBDDs显示出比ADDs更高的可扩展潜力。

Conclusion: 论文展示了在机器代码级别进行位精确推理的可能性，并通过BDD技术有效缓解了状态爆炸问题，为符号执行的进一步优化提供了新思路。

Abstract: Symbolic execution is a powerful technique for analyzing the behavior of
software yet scalability remains a challenge due to state explosion in control
and data flow. Existing tools typically aim at managing control flow
internally, often at the expense of completeness, while offloading reasoning
over data flow to SMT solvers. Moreover, reasoning typically happens on source
code or intermediate representation level to leverage structural information,
making machine code generation part of the trust base. We are interested in
changing the equation in two non-trivial ways: pushing reasoning down to
machine code level, and then offloading reasoning entirely into SMT solvers and
other, possibly more efficient solver technology. In more abstract terms, we
are asking if bit-precise reasoning technology can be made scalable on
software, and not just hardware. For this purpose, we developed two tools
called rotor and bitme for model generation and bounded model checking,
respectively. We chose RISC-V restricted to integer arithmetic as modeling
target for rotor since RISC-V integer semantics is essentially equivalent to
established SMT semantics over bitvectors and arrays of bitvectors. While
state-of-the-art SMT solvers struggle in our experiments, we have evidence that
there is potential for improvement. To show the potential, we have slightly
generalized and then implemented in bitme two types of binary decision diagrams
(BDDs): algebraic decision diagrams (ADDs) and context-free-language ordered
binary decision diagrams (CFLOBDDs). Bitme uses BDDs to propagate program input
through models, essentially generalizing constant propagation to domain
propagation. SMT solvers only get involved when model input cannot be
propagated, significanly speeding up SMT solving. We then study the impact on
state explosion of CFLOBDDs, which are potentially more scalable than ADDs.

</details>


### [8] [BeePL: Correct-by-compilation kernel extensions](https://arxiv.org/abs/2507.09883)
*Swarn Priya,Frédéric Besson,Connor Sughrue,Tim Steenvoorden,Jamie Fulford,Freek Verbeek,Binoy Ravindran*

Main category: cs.PL

TL;DR: BeePL是一种专为eBPF设计的领域特定语言，通过形式化验证的类型系统确保程序的安全性和正确性，解决了现有eBPF验证器的保守性和不健全问题。


<details>
  <summary>Details</summary>
Motivation: 现有eBPF验证器在拒绝有效程序时过于保守，同时在允许不安全行为时不够健全，这促使了BeePL的开发以提供更可靠的解决方案。

Method: BeePL通过形式化验证的类型系统静态强制执行关键安全属性，如类型正确性、指针安全性和有限循环，同时为动态检查插入运行时检查。

Result: BeePL确保了类型良好的程序满足eBPF执行环境的安全不变量，并通过形式化验证证明了编译过程的正确性。

Conclusion: BeePL为安全内核扩展提供了一个端到端可验证的工具链，弥补了现有eBPF验证器的不足。

Abstract: eBPF is a technology that allows developers to safely extend kernel
functionality without modifying kernel source code or developing loadable
kernel modules. Since the kernel governs critical system operations and
enforces isolation boundaries between user space and privileged data, any
mechanism that modifies its behavior must meet the highest standards of safety
and correctness. To this end, the eBPF toolchain includes a verifier, which
statically checks safety properties such as memory access validity, bounded
loops, and type correctness before loading the program into the kernel.
However, the existing verifier is both overly conservative in some
cases-rejecting valid programs-and unsound in others, permitting unsafe
behavior that violates the intended semantics of the kernel interface.
  To address these challenges, we introduce BeePL, a domain-specific language
for eBPF with a formally verified type system. The BeePL type system, along
with the language design, statically enforces key safety properties such as
type-correct memory access, safe pointer usage, absence of unbounded loops, and
structured control flow. These guarantees are backed by formal type soundness
proofs, ensuring that well-typed programs satisfy the safety invariants
required by the eBPF execution environment. BeePL also proves that well-typed
source programs meet critical eBPF-specific properties related to memory
safety, termination, and control flow, enabling high-level reasoning prior to
compilation. For properties not fully enforceable statically-such as dynamic
bounds and undefined behavior-BeePL inserts semantics-preserving runtime checks
during compilation. We develop a verified compilation strategy that extends
CompCert to generate BPF bytecode from BeePL programs, establishing a
principled foundation for an end-to-end verifiable toolchain for safe kernel
extensions.

</details>


### [9] [Rows and Capabilities as Modal Effects](https://arxiv.org/abs/2507.10301)
*Wenhao Tang,Sam Lindley*

Main category: cs.PL

TL;DR: 本文提出了一个统一的框架，用于编码、分析和比较基于行多态和能力的效应系统，通过模态效应类型解耦效应跟踪与函数。


<details>
  <summary>Details</summary>
Motivation: 现有的基于行多态和能力的效应系统在效应跟踪机制上存在差异，且其理解尚未统一。本文旨在填补这一理解差距。

Method: 利用并推广模态效应类型，提出一个统一的框架，该框架通过宏翻译将现有行多态和能力基础的效应系统编码到框架中，并保持类型和语义的完整性。

Result: 编码揭示了不同效应系统中效应跟踪机制的本质，提供了直接的差异分析，并为语言设计提供了有价值的见解。

Conclusion: 模态效应类型为效应系统提供了灵活的跟踪策略，统一框架有助于比较和理解不同效应系统的工作原理。

Abstract: Effect handlers allow programmers to model and compose computational effects
modularly. Effect systems statically guarantee that all effects are handled.
Several recent practical effect systems are based on either row polymorphism or
capabilities. However, there remains a gap in understanding the precise
relationship between effect systems with such disparate foundations. The main
difficulty is that in both row-based and capability-based systems, effect
tracking is typically entangled with other features such as functions.
  We propose a uniform framework for encoding, analysing, and comparing effect
systems. Our framework exploits and generalises modal effect types, a recent
novel effect system which decouples effect tracking from functions via
modalities. Modalities offer fine-grained control over when and how effects are
tracked, enabling us to express different strategies for effect tracking. We
give encodings as macro translations from existing row-based and
capability-based effect systems into our framework and show that these
encodings preserve types and semantics. Our encodings reveal the essence of
effect tracking mechanisms in different effect systems, enable a direct
analysis on their differences, and provide valuable insights on language
design.

</details>


### [10] [Orthologic Type Systems](https://arxiv.org/abs/2507.10482)
*Simon Guilloud,Viktor Kunčak*

Main category: cs.PL

TL;DR: 论文提出基于正交逻辑设计支持交集、并集和否定类型的类型系统，并在存在子类型假设的情况下进行扩展。展示了如何支持单调和反单调函数，并提出了部分消剪消除的证明系统，及O(n²(1+m))的子类型判定算法和O(n²)的多项式时间规范化算法。


<details>
  <summary>Details</summary>
Motivation: 在类型系统中支持交集、并集和否定类型，并在子类型假设下扩展正交逻辑以满足实际需求。

Method: 扩展正交逻辑以支持单调和反单调函数，提出带函数符号的正交逻辑证明系统，并开发部分消剪消除技术。

Result: 提出了O(n²(1+m))的子类型判定算法，以及O(n²)的多项式时间规范化算法，用于简化类型到最小规范形式。

Conclusion: 通过正交逻辑的扩展，论文成功设计了一个高效的子类型判定和类型规范化方法，为类型系统提供了新的理论支持。

Abstract: We propose to use orthologic as the basis for designing type systems
supporting intersection, union, and negation types in the presence of subtyping
assumptions. We show how to extend orthologic to support monotonic and
antimonotonic functions, supporting the use of type constructors in such type
systems. We present a proof system for orthologic with function symbols,
showing that it admits partial cut elimination. Using these insights, we
present an $\mathcal O(n^2(1+m))$ algorithm for deciding the subtyping relation
under $m$ assumptions. We also show $O(n^2)$ polynomial-time normalization
algorithm, allowing simplification of types to their minimal canonical form.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [Precomputed Dominant Resource Fairness](https://arxiv.org/abs/2507.08846)
*Serdar Metin*

Main category: cs.GT

TL;DR: 该论文提出了一种名为预计算主导资源公平（Precomputed Dominant Resource Fairness）的新算法，旨在以更少的步骤近似原有主导资源公平（Dominant Resource Fairness）的资源分配方案。


<details>
  <summary>Details</summary>
Motivation: 随着分布式系统（如云计算和数据中心）的普及，多资源类型的公平分配问题变得尤为重要。原有的主导资源公平（Dominant Resource Fairness）虽然是一个广泛应用且具有多种理想特性的算法，但其计算步骤较多，因此需要一个更高效的替代方案。

Method: 基于原有的主导资源公平算法，研究者通过更深入分析其结构，提出了一种名为预计算主导资源公平的新算法。该算法能够在更少的步骤内近似原有算法的资源分配结果。

Result: 新算法预计算主导资源公平能够有效近似原有主导资源公平的资源分配方案，同时显著减少了计算步骤，提升了效率。

Conclusion: 该研究通过改进原有的主导资源公平算法，提出了一个更高效的替代方案，为多资源类型场景下的公平分配问题提供了新的解决思路。

Abstract: Although resource allocation is a well studied problem in computer science,
until the prevalence of distributed systems, such as computing clouds and data
centres, the question had been addressed predominantly for single resource type
scenarios. At the beginning of the last decade, with the introuction of
Dominant Resource Fairness, the studies of the resource allocation problem has
finally extended to the multiple resource type scenarios. Dominant Resource
Fairness is a solution, addressing the problem of fair allocation of multiple
resource types, among users with heterogeneous demands. Based on Max-min
Fairness, which is a well established algorithm in the literature for
allocating resources in the single resource type scenarios, Dominant Resource
Fairness generalises the scheme to the multiple resource case. It has a number
of desirable properties that makes it preferable over alternatives, such as
Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness,
and as such, it is widely adopted in distributed systems. In the present study,
we revisit the original study, and analyse the structure of the algorithm in
closer view, to come up with an alternative algorithm, which approximates the
Dominant Resource Fairness allocation in fewer steps. We name the new algorithm
Precomputed Dominant Resource Fairness, after its main working principle.

</details>


### [12] [A Survey on Bilateral Multi-Round Cloud-SLA Negotiation Strategies](https://arxiv.org/abs/2507.08868)
*Benedikt Pittl,Werner Mach,Erich Schikuta*

Main category: cs.GT

TL;DR: 论文对云计算资源的多轮双边协商策略进行了调查，分析了趋势、差距和相似性，并为行业实现提供了建议。


<details>
  <summary>Details</summary>
Motivation: 当前静态云市场主导，消费者无法协商价格和服务特性。动态交易机制（如亚马逊的EC2平台）的出现促使学术界探索自主多轮协商以实现未来云市场。

Method: 通过分析同行评审文章，识别协商策略的趋势、差距和相似性，并调查了描述这些策略的形式化方法。

Result: 研究发现多轮双边协商策略的差异和共同点，为行业实现提供了形式化描述和文档化建议。

Conclusion: 论文为未来云市场的多轮双边协商策略提供了理论基础和实施建议，有助于提升数据中心利用率和定制化服务。

Abstract: Today, static cloud markets where consumers purchase services directly from
providers are dominating. Thus, consumers neither negotiate the price nor the
characteristics of the service. In recent years, providers have adopted more
dynamic trading mechanisms, as e.g. Amazon's EC2 platform shows: In addition to
the reservation marketspace and the on-demand marketspace, Amazon offers a spot
marketspace where consumers can bid for virtual machines. This spot marketspace
was extended with spot blocks, and recently Amazon reworked the bidding
options. In addition, other cloud providers, such as Virtustream, adopt dynamic
trading mechanisms. The scientific community envisions autonomous multi-round
negotiations for realizing future cloud marketspaces. Consequently, consumers
and providers exchange offers and counteroffers to reach an agreement. This
helps providers increase the utilization of their datacenters, while consumers
can purchase highly customized cloud services.
  In the paper at hand, we present a survey on multi-round bilateral
negotiation strategies for trading cloud resources. Thus, we analyzed
peer-reviewed articles in order to identify trends, gaps, similarities, and the
scope of such negotiation strategies. In addition, we surveyed the formalism
that the scientific community uses to describe such strategies. Based on these
findings, we derived recommendations for creating and documenting bilateral
multi-round negotiation strategies to foster their implementation in the
industry.

</details>


### [13] [Learning from Synthetic Labs: Language Models as Auction Participants](https://arxiv.org/abs/2507.09083)
*Anand Shah,Kehang Zhu,Yanchen Jiang,Jeffrey G. Wang,Arif K. Dayi,John J. Horton,David C. Parkes*

Main category: cs.GT

TL;DR: 该论文研究了模拟AI代理（大型语言模型，LLM）在拍卖中的行为，提出了一种新的合成数据生成方法，用于促进拍卖研究和设计。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM在拍卖中的表现，并与人类实验数据对比，同时为拍卖实验提供低成本、高效的研究框架。

Method: 论文通过引入链式思维推理能力的LLM，在多种经典拍卖形式中进行了实验，并开发了一种灵活的拍卖实验框架。

Result: 研究发现LLM在拍卖中的表现与风险厌恶的人类竞标者一致，且在策略明显的拍卖中更接近理论预测，但在共同价值拍卖中易受“赢家诅咒”影响。

Conclusion: 论文结论表明，LLM可作为拍卖研究的低成本代理，并通过优化的提示设计显著改善其表现，为未来拍卖实验提供了新思路。

Abstract: This paper investigates the behavior of simulated AI agents (large language
models, or LLMs) in auctions, introducing a novel synthetic data-generating
process to help facilitate the study and design of auctions. We find that LLMs
-- when endowed with chain of thought reasoning capacity -- agree with the
experimental literature in auctions across a variety of classic auction
formats. In particular, we find that LLM bidders produce results consistent
with risk-averse human bidders; that they perform closer to theoretical
predictions in obviously strategy-proof auctions; and, that they succumb to the
winner's curse in common value settings. On prompting, we find that LLMs are
not very sensitive to naive changes in prompts (e.g., language, currency) but
can improve dramatically towards theoretical predictions with the right mental
model (i.e., the language of Nash deviations). We run 1,000$+$ auctions for
less than $\$$400 with GPT-4 models (three orders of magnitude cheaper than
modern auction experiments) and develop a framework flexible enough to run
auction experiments with any LLM model and a wide range of auction design
specifications, facilitating further experimental study by decreasing costs and
serving as a proof-of-concept for the use of LLM proxies.

</details>


### [14] [Nash Equilibria with Irradical Probabilities](https://arxiv.org/abs/2507.09422)
*Edan Orzech,Martin Rinard*

Main category: cs.GT

TL;DR: 针对每个n≥4的玩家，提出了一种具有独特完全混合纳什均衡的正规形式博弈，均衡中的概率权重均为不可化简的代数数。


<details>
  <summary>Details</summary>
Motivation: 探讨在多玩家博弈中是否存在独特的完全混合纳什均衡，并且其均衡概率权重为不可化简的代数数（即无法用有限根式表示）。

Method: 通过构造一个n玩家正规形式博弈，其支付值为0、1或2，证明其存在唯一的完全混合纳什均衡，且权重为不可化简的代数数。

Result: 展示了对于任何n≥4的玩家，存在一个具有独特完全混合纳什均衡的博弈，均衡权重为不可化简的代数数。

Conclusion: 该研究为博弈论中纳什均衡的性质提供了新的视角，表明即使在简单的支付结构中，也可能存在复杂的均衡解。

Abstract: We present for every $n\ge4$ an $n$-player game in normal form with payoffs
in $\{0,1,2\}$ that has a unique, fully mixed, Nash equilibrium in which all
the probability weights are irradical (i.e., algebraic but not closed form
expressible even with $m$-th roots for any integer $m$).

</details>


### [15] [Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints](https://arxiv.org/abs/2507.09473)
*Yan Dai,Negin Golrezaei,Patrick Jaillet*

Main category: cs.GT

TL;DR: 本文研究了在战略代理环境中动态分配可重用资源的问题，提出了一种激励感知框架，能够在满足长期成本约束和确保真实报告的同时最大化社会福利。


<details>
  <summary>Details</summary>
Motivation: 研究动机来源于实际应用需求，如云平台向用户分配GPU资源或政府在竞争地区部署移动医疗单元，需要解决战略代理环境下资源的动态分配问题。

Method: 方法包括设计一种激励感知框架，结合基于时段的懒更新和随机探索轮次，利用专门设计的在线学习子程序更新对偶变量，以实现对战略行为的鲁棒性。

Result: 结果表明，该机制实现了$\tilde{\mathcal{O}}(\sqrt{T})$的社会福利损失，满足所有成本约束，并能确保激励一致性，与非战略分配方法的性能相当。

Conclusion: 结论表明，所提出的框架在战略代理环境中具有鲁棒性，能够同时满足社会福利最大化、成本约束和激励对齐的要求。

Abstract: Motivated by applications such as cloud platforms allocating GPUs to users or
governments deploying mobile health units across competing regions, we study
the dynamic allocation of a reusable resource to strategic agents with private
valuations. Our objective is to simultaneously (i) maximize social welfare,
(ii) satisfy multi-dimensional long-term cost constraints, and (iii)
incentivize truthful reporting. We begin by numerically evaluating primal-dual
methods widely used in constrained online optimization and find them to be
highly fragile in strategic settings -- agents can easily manipulate their
reports to distort future dual updates for future gain.
  To address this vulnerability, we develop an incentive-aware framework that
makes primal-dual methods robust to strategic behavior. Our design combines
epoch-based lazy updates -- where dual variables remain fixed within each epoch
-- with randomized exploration rounds that extract approximately truthful
signals for learning. Leveraging carefully designed online learning subroutines
that can be of independent interest for dual updates, our mechanism achieves
$\tilde{\mathcal{O}}(\sqrt{T})$ social welfare regret, satisfies all cost
constraints, and ensures incentive alignment. This matches the performance of
non-strategic allocation approaches while being robust to strategic agents.

</details>


### [16] [Existence of Fair and Efficient Allocation of Indivisible Chores](https://arxiv.org/abs/2507.09544)
*Ryoga Mahara*

Main category: cs.GT

TL;DR: 该论文证明了在不可分割的杂务分配问题中，存在一种满足EF1（近似无嫉妒）和PO（帕累托最优）的分配方式，并通过固定点论证和离散算法提供了一种新的解决方法。


<details>
  <summary>Details</summary>
Motivation: 研究不可分割杂务在代理人之间的公平和高效分配问题，解决EF1和PO是否总是存在这一开放性问题。

Method: 通过固定点论证和离散算法结合的方法，证明了EF1和PO分配的存在性。

Result: 证明了在加性成本函数下存在EF1和PO的分配，并且EF1和fPO（更强的效率概念）分配总是存在。此外，当代理人数量固定时，EF1和PO分配可在多项式时间内计算。

Conclusion: 该研究为不可分割杂务分配问题提供了理论和方法上的突破，并将结果扩展到了带权重的EF1（wEF1）场景。

Abstract: We study the problem of allocating indivisible chores among agents with
additive cost functions in a fair and efficient manner. A major open question
in this area is whether there always exists an allocation that is envy-free up
to one chore (EF1) and Pareto optimal (PO). Our main contribution is to provide
a positive answer to this question by proving the existence of such an
allocation for indivisible chores under additive cost functions. This is
achieved by a novel combination of a fixed point argument and a discrete
algorithm, providing a significant methodological advance in this area.
  Our additional key contributions are as follows. We show that there always
exists an allocation that is EF1 and fractional Pareto optimal (fPO), where fPO
is a stronger efficiency concept than PO. We also show that an EF1 and PO
allocation can be computed in polynomial time when the number of agents is
constant. Finally, we extend all of these results to the more general setting
of weighted EF1 (wEF1), which accounts for the entitlements of agents.

</details>


### [17] [Tie-breaking Agnostic Lower Bound for Fictitious Play](https://arxiv.org/abs/2507.09902)
*Yuanhao Wang*

Main category: cs.GT

TL;DR: 本文反驳了卡尔关于虚构博弈（FP）在零和博弈中以$O(t^{-1/2})$速率收敛到纳什均衡的猜想，证明了存在10x10的零和矩阵博弈中FP以$\Omega(t^{-1/3})$速率收敛。


<details>
  <summary>Details</summary>
Motivation: 研究虚构博弈（FP）在零和博弈中的收敛速率，验证或反驳卡尔关于FP收敛速率的猜想。

Method: 通过构造一个10x10的零和矩阵博弈，分析FP的收敛速率，证明其收敛速率为$\Omega(t^{-1/3})$。

Result: 成功反驳了卡尔1959年的猜想，证明FP在某些情况下收敛速率慢于$O(t^{-1/2})$。

Conclusion: 卡尔关于FP收敛速率的猜想不成立，FP在某些零和博弈中的收敛速率可能更慢。

Abstract: Fictitious play (FP) is a natural learning dynamic in two-player zero-sum
games. Samuel Karlin conjectured in 1959 that FP converges at a rate of
$O(t^{-1/2})$ to Nash equilibrium, where $t$ is the number of steps played.
However, Daskalakis and Pan disproved the stronger form of this conjecture in
2014, where \emph{adversarial} tie-breaking is allowed.
  This paper disproves Karlin's conjecture in its weaker form. In particular,
there exists a 10-by-10 zero-sum matrix game, in which FP converges at a rate
of $\Omega(t^{-1/3})$, and no ties occur except for the first step.

</details>


### [18] [Generalized Quantal Response Equilibrium: Existence and Efficient Learning](https://arxiv.org/abs/2507.09928)
*Apurv Shukla,Vijay Subramanian,Andy Zhao,Rahul Jain*

Main category: cs.GT

TL;DR: 该论文提出了一种称为广义量子响应均衡（GQRE）的新解概念，用于有限正规形式一般和博弈中的有限理性代理，并介绍了一种高效的独立学习算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决有限理性代理在一般和博弈中的行为问题，通过引入GQRE来更准确地反映其决策过程。

Method: 方法包括提出GQRE概念，并通过平滑化的Frank-Wolfe算法实现高效的无悔独立学习，使用仿真器生成梯度估计。

Result: 证明了在温和条件下GQRE存在性，算法在复杂一般和博弈（如高秩双人博弈和多人博弈）中表现出色。

Conclusion: 结论是GQRE为有限理性代理提供了有效的解概念，并通过高效算法在实际应用中验证了其有效性。

Abstract: We introduce a new solution concept for bounded rational agents in finite
normal-form general-sum games called Generalized Quantal Response Equilibrium
(GQRE) which generalizes Quantal Response
Equilibrium~\citep{mckelvey1995quantal}. In our setup, each player maximizes a
smooth, regularized expected utility of the mixed profiles used, reflecting
bounded rationality that subsumes stochastic choice. After establishing
existence under mild conditions, we present computationally efficient no-regret
independent learning via smoothened versions of the Frank-Wolfe algorithm. Our
algorithm uses noisy but correlated gradient estimates generated via a
simulation oracle that reports on repeated plays of the game. We analyze
convergence properties of our algorithm under assumptions that ensure
uniqueness of equilibrium, using a class of gap functions that generalize the
Nash gap. We end by demonstrating the effectiveness of our method on a set of
complex general-sum games such as high-rank two-player games, large action
two-player games, and known examples of difficult multi-player games.

</details>


### [19] [A New Incentive Model For Content Trust](https://arxiv.org/abs/2507.09972)
*Lucas Barbosa,Sam Kirshner,Rob Kopel,Eric Tze Kuan Lim,Tom Pagram*

Main category: cs.GT

TL;DR: 本文提出了一种基于激励和去中心化的方法来验证数字内容的真实性，通过智能合约和数字身份将‘信任’纳入内容发布的奖励机制，以应对现代数字世界中的虚假信息问题。


<details>
  <summary>Details</summary>
Motivation: 虚假信息的广泛传播、AI生成内容的爆炸式增长以及传统新闻来源的减少，需要一种新的方法来确保内容的真实性和追求真相。

Method: 采用智能合约和数字身份将‘信任’纳入内容发布的奖励机制，要求内容创作者为事实声明提供金融担保，并由公正的陪审团进行验证，同时对贡献者提供金融奖励。

Result: 假设通过正确的金融和社会激励模型，用户将参与众包的事实核查，内容创作者也会更加谨慎地发表声明。

Conclusion: 本文是一个探索性研究，提出了一个社区治理模型来应对虚假信息，但仍有许多开放性问题需要进一步分析和探索。

Abstract: This paper outlines an incentive-driven and decentralized approach to
verifying the veracity of digital content at scale. Widespread misinformation,
an explosion in AI-generated content and reduced reliance on traditional news
sources demands a new approach for content authenticity and truth-seeking that
is fit for a modern, digital world. By using smart contracts and digital
identity to incorporate 'trust' into the reward function for published content,
not just engagement, we believe that it could be possible to foster a
self-propelling paradigm shift to combat misinformation through a
community-based governance model. The approach described in this paper requires
that content creators stake financial collateral on factual claims for an
impartial jury to vet with a financial reward for contribution. We hypothesize
that with the right financial and social incentive model users will be
motivated to participate in crowdsourced fact-checking and content creators
will place more care in their attestations. This is an exploratory paper and
there are a number of open issues and questions that warrant further analysis
and exploration.

</details>


### [20] [A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges](https://arxiv.org/abs/2507.10149)
*Abhimanyu Nag,Madhur Prabhakar,Tanuj Behl*

Main category: cs.GT

TL;DR: 提出了一个数学严谨的框架，用于识别和完成去中心化交易所（DEX）聚合器中的需求巧合（CoW）周期。该方法通过资产矩阵公式化，验证可行性并通过图形遍历完成部分CoW周期交易。


<details>
  <summary>Details</summary>
Motivation: 现有的拍卖系统（如CoWSwap）存在局限性，需要更高效且无滑点的解决方案来优化流动性提供者（LP）的交易执行。

Method: 采用资产矩阵公式化验证可行性，结合图形遍历和失衡校正完成部分CoW周期交易，并引入桥接订单。

Result: 在Arbitrum实际交易数据中，算法高效地发现了CoW周期，并支持通过合成订单实现原子周期闭合。

Conclusion: 该方法为流动性提供者提供了一种无滑点且资本保留的潜在策略，即结构化的CoW周期执行。

Abstract: We propose a mathematically rigorous framework for identifying and completing
Coincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators.
Unlike existing auction based systems such as CoWSwap, our approach introduces
an asset matrix formulation that not only verifies feasibility using oracle
prices and formal conservation laws but also completes partial CoW cycles of
swap orders that are discovered using graph traversal and are settled using
imbalance correction. We define bridging orders and show that the resulting
execution is slippage free and capital preserving for LPs. Applied to real
world Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW
cycles and supports the insertion of synthetic orders for atomic cycle closure.
This work can be thought of as the detailing of a potential delta-neutral
strategy by liquidity providing market makers: a structured CoW cycle
execution.

</details>


### [21] [The Value Problem for Weighted Timed Games with Two Clocks is Undecidable](https://arxiv.org/abs/2507.10550)
*Quentin Guilmant,Joël Ouaknine,Isa Vialard*

Main category: cs.GT

TL;DR: 该论文证明了在非负权重和时间受限的条件下，双时钟加权定时博弈（WTGs）的价值问题是不可判定的，填补了这一领域的主要研究空白。


<details>
  <summary>Details</summary>
Motivation: 加权定时博弈（WTGs）的价值问题长期以来存在未解决的缺口，尤其是双时钟情况下的可判定性尚未明确，研究试图填补这一关键空白。

Method: 通过分析双时钟加权定时博弈的非负权重和时间受限条件，研究采用逻辑和计算理论方法探讨其价值问题的不可判定性。

Result: 研究证明，即使在非负权重和时间受限的情况下，双时钟WTGs的价值问题仍然是不可判定的。

Conclusion: 这一结果填补了WTGs领域对双时钟情况下算法理解的最后空白，完善了对加权定时博弈复杂性的分类。

Abstract: The Value Problem for weighted timed games (WTGs) consists in determining,
given a two-player weighted timed game with a reachability objective and a
rational threshold, whether or not the value of the game exceeds the threshold.
This problem was shown to be undecidable some ten years ago for WTGs making use
of at least three clocks, and is known to be decidable for single-clock WTGs.
In this paper, we establish undecidability for two-clock WTGs making use of
non-negative weights, even in a time-bounded setting, closing the last
remaining major gap in our algorithmic understanding of WTGs.

</details>
