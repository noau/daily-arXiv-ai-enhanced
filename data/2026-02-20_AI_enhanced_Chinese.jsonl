{"id": "2602.17040", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.17040", "abs": "https://arxiv.org/abs/2602.17040", "authors": ["Xuancheng Jin", "Rengan Xie", "Wenting Zheng", "Rui Wang", "Hujun Bao", "Yuchi Huo"], "title": "Fuse3D: Generating 3D Assets Controlled by Multi-Image Fusion", "comment": null, "summary": "Recently, generating 3D assets with the control of condition images has achieved impressive quality. However, existing 3D generation methods are limited to handling a single control objective and lack the ability to utilize multiple images to independently control different regions of a 3D asset, which hinders their flexibility in applications. We propose Fuse3D, a novel method that enables generating 3D assets under the control of multiple images, allowing for the seamless fusion of multi-level regional controls from global views to intricate local details. First, we introduce a Multi-Condition Fusion Module to integrate the visual features from multiple image regions. Then, we propose a method to automatically align user-selected 2D image regions with their associated 3D regions based on semantic cues. Finally, to resolve control conflicts and enhance local control features from multi-condition images, we introduce a Local Attention Enhancement Strategy that flexibly balances region-specific feature fusion. Overall, we introduce the first method capable of controllable 3D asset generation from multiple condition images. The experimental results indicate that Fuse3D can flexibly fuse multiple 2D image regions into coherent 3D structures, resulting in high-quality 3D assets. Code and data for this paper are at https://jinnmnm.github.io/Fuse3d.github.io/.", "AI": {"tldr": "Fuse3D\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u591a\u5f20\u6761\u4ef6\u56fe\u50cf\u751f\u62103D\u8d44\u4ea7\uff0c\u5b9e\u73b0\u4ece\u5168\u5c40\u89c6\u89d2\u5230\u5c40\u90e8\u7ec6\u8282\u7684\u591a\u5c42\u6b21\u533a\u57df\u63a7\u5236\u3002", "motivation": "\u73b0\u67093D\u751f\u6210\u65b9\u6cd5\u4ec5\u80fd\u5904\u7406\u5355\u4e00\u63a7\u5236\u76ee\u6807\uff0c\u65e0\u6cd5\u5229\u7528\u591a\u5f20\u56fe\u50cf\u72ec\u7acb\u63a7\u52363D\u8d44\u4ea7\u7684\u4e0d\u540c\u533a\u57df\uff0c\u9650\u5236\u4e86\u5e94\u7528\u7684\u7075\u6d3b\u6027\u3002", "method": "Fuse3D\u5f15\u5165\u4e86\u591a\u6761\u4ef6\u878d\u5408\u6a21\u5757\u6574\u5408\u591a\u56fe\u50cf\u533a\u57df\u7684\u89c6\u89c9\u7279\u5f81\uff0c\u81ea\u52a8\u5bf9\u9f502D\u56fe\u50cf\u533a\u57df\u4e0e3D\u533a\u57df\u7684\u8bed\u4e49\u7ebf\u7d22\uff0c\u5e76\u901a\u8fc7\u5c40\u90e8\u6ce8\u610f\u529b\u589e\u5f3a\u7b56\u7565\u89e3\u51b3\u63a7\u5236\u51b2\u7a81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFuse3D\u80fd\u591f\u7075\u6d3b\u5730\u5c06\u591a\u4e2a2D\u56fe\u50cf\u533a\u57df\u878d\u5408\u4e3a\u8fde\u8d2f\u76843D\u7ed3\u6784\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u76843D\u8d44\u4ea7\u3002", "conclusion": "Fuse3D\u662f\u9996\u4e2a\u80fd\u591f\u4ece\u591a\u5f20\u6761\u4ef6\u56fe\u50cf\u53ef\u63a7\u751f\u62103D\u8d44\u4ea7\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u751f\u6210\u7684\u7075\u6d3b\u6027\u548c\u8d28\u91cf\u3002"}}
{"id": "2602.17044", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.17044", "abs": "https://arxiv.org/abs/2602.17044", "authors": ["Temesgen Muruts Weldengus", "Binnan Liu", "Fei Kou", "Youwei Lyu", "Jinwei Chen", "Qingnan Fan", "Changqing Zou"], "title": "InstantRetouch: Personalized Image Retouching without Test-time Fine-tuning Using an Asymmetric Auto-Encoder", "comment": "19 pages, 11 figures", "summary": "Personalized image retouching aims to adapt retouching style of individual users from reference examples, but existing methods often require user-specific fine-tuning or fail to generalize effectively. To address these challenges, we introduce $\\textbf{InstantRetouch}$, a general framework for personalized image retouching that instantly adapts to user retouching styles without any test-time fine-tuning. It employs an $\\textit{asymmetric auto-encoder}$ to encode the retouching style from paired examples into a content disentangled latent representation that enables faithful transfer of the retouching style to new images. To adaptively apply the encoded retouching style to new images, we further propose $\\textit{retrieval-augmented retouching}$ (RAR), which retrieves and aggregates style latents from reference pairs most similar in content to the query image. With these components, $\\textbf{InstantRetouch}$ enables superior and generic content-aware retouching personalization across diverse scenarios, including single-reference, multi-reference, and mixed-style setups, while also generalizing out of the box to photorealistic style transfer.", "AI": {"tldr": "InstantRetouch\u662f\u4e00\u4e2a\u65e0\u9700\u6d4b\u8bd5\u65f6\u5fae\u8c03\u5373\u53ef\u4e2a\u6027\u5316\u56fe\u50cf\u4fee\u9970\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u5bf9\u79f0\u81ea\u7f16\u7801\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u4fee\u9970\u6280\u672f\u5b9e\u73b0\u5185\u5bb9\u611f\u77e5\u7684\u98ce\u683c\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u56fe\u50cf\u4fee\u9970\u65b9\u6cd5\u9700\u8981\u7528\u6237\u7279\u5b9a\u7684\u5fae\u8c03\u6216\u6cdb\u5316\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u975e\u5bf9\u79f0\u81ea\u7f16\u7801\u5668\u7f16\u7801\u4fee\u9970\u98ce\u683c\u4e3a\u89e3\u8026\u7684\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u4fee\u9970\u6280\u672f\u81ea\u9002\u5e94\u5730\u5c06\u98ce\u683c\u5e94\u7528\u5230\u65b0\u56fe\u50cf\u3002", "result": "InstantRetouch\u5728\u5355\u53c2\u8003\u3001\u591a\u53c2\u8003\u548c\u6df7\u5408\u98ce\u683c\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u4e2a\u6027\u5316\u4fee\u9970\u6548\u679c\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u7167\u7247\u98ce\u683c\u8fc1\u79fb\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e2a\u6027\u5316\u56fe\u50cf\u4fee\u9970\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u6d4b\u8bd5\u65f6\u5fae\u8c03\u5373\u53ef\u9002\u5e94\u591a\u6837\u5316\u7684\u4fee\u9970\u98ce\u683c\u3002"}}
{"id": "2602.16809", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.16809", "abs": "https://arxiv.org/abs/2602.16809", "authors": ["Paulo R. Pereira", "Jose N. Oliveira"], "title": "Haskell meets Evariste", "comment": null, "summary": "Since its birth as a new scientific body of knowledge in the late 1950s, computer programming has become a fundamental skill needed in many other disciplines. However, programming is not easy, it is prone to errors and code re-use is key for productivity. This calls for high-quality documentation in software libraries, which is quite often not the case. Taking a few Haskell functions available from the Hackage repository as case-studies, and comparing their descriptions with similar functions in other languages, this paper shows how clarity and good conceptual design can be achieved by following a so-called easy-hard-split formal strategy that is quite general and productive, even if used informally. This strategy is easy to use in functional programming and can be applied to both program analysis and synthesis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3aeasy-hard-split\u7684\u7b56\u7565\u6765\u63d0\u5347Haskell\u51fd\u6570\u7684\u6587\u6863\u8d28\u91cf\u548c\u8bbe\u8ba1\u6e05\u6670\u5ea6\u3002", "motivation": "\u7f16\u7a0b\u662f\u4e00\u9879\u590d\u6742\u4e14\u5bb9\u6613\u51fa\u9519\u7684\u4efb\u52a1\uff0c\u9ad8\u8d28\u91cf\u7684\u6587\u6863\u5bf9\u4ee3\u7801\u91cd\u7528\u548c\u751f\u4ea7\u529b\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u8f6f\u4ef6\u5e93\u7684\u6587\u6863\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u3002", "method": "\u4f5c\u8005\u4ee5Hackage\u5e93\u4e2d\u7684Haskell\u51fd\u6570\u4e3a\u4f8b\uff0c\u5c06\u5176\u4e0e\u5176\u4ed6\u8bed\u8a00\u7684\u7c7b\u4f3c\u51fd\u6570\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u5e94\u7528easy-hard-split\u7b56\u7565\u6765\u63d0\u5347\u6587\u6863\u548c\u8bbe\u8ba1\u7684\u6e05\u6670\u5ea6\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0ceasy-hard-split\u7b56\u7565\u4e0d\u4ec5\u6613\u4e8e\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u4f7f\u7528\uff0c\u8fd8\u80fd\u6709\u6548\u63d0\u5347\u7a0b\u5e8f\u5206\u6790\u548c\u5408\u6210\u7684\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7easy-hard-split\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u63d0\u5347\u6587\u6863\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u589e\u5f3a\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u548c\u91cd\u7528\u6027\u3002"}}
{"id": "2602.16734", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.16734", "abs": "https://arxiv.org/abs/2602.16734", "authors": ["Ariel Calver", "Serena Pallan", "Alice", "Park", "Jennifer Wilson"], "title": "Bloc Voting on Single Peaked Preferences", "comment": null, "summary": "We analyze the winning coalitions that arise under Bloc voting when voters preferences are single-peaked. For small numbers of candidates and numbers of winners, we determine conditions under which candidates in winning coalitions are adjacent. We also analyze the results of pairwise contests between winning and losing candidates and assess when the winning coalitions satisfy several proposed extensions of the Condorcet criterion to multiwinner voting methods. Finally, we use Monte Carlo simulations to investigate how frequently these coalitions arise under different assumptions about voter behavior.", "AI": {"tldr": "\u5206\u6790\u5355\u5cf0\u504f\u597d\u4e0bBloc\u6295\u7968\u4e2d\u83b7\u80dc\u8054\u76df\u7684\u5f62\u6210\uff0c\u63a2\u8ba8\u5019\u9009\u4eba\u548c\u83b7\u80dc\u8005\u6570\u91cf\u8f83\u5c11\u65f6\u83b7\u80dc\u8054\u76df\u4e2d\u5019\u9009\u4eba\u7684\u90bb\u63a5\u6761\u4ef6\uff0c\u8bc4\u4f30\u5176\u5bf9Condorcet\u51c6\u5219\u7684\u6269\u5c55\u6ee1\u8db3\u7a0b\u5ea6\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u7814\u7a76\u5176\u5728\u4e0d\u540c\u9009\u6c11\u884c\u4e3a\u5047\u8bbe\u4e0b\u7684\u51fa\u73b0\u9891\u7387\u3002", "motivation": "\u7814\u7a76Bloc\u6295\u7968\u673a\u5236\u4e0b\u83b7\u80dc\u8054\u76df\u7684\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u9009\u6c11\u504f\u597d\u4e3a\u5355\u5cf0\u5206\u5e03\u65f6\u7684\u8868\u73b0\uff0c\u4ee5\u7406\u89e3\u591a\u8d62\u5bb6\u6295\u7968\u65b9\u6cd5\u4e2dCondorcet\u51c6\u5219\u7684\u6269\u5c55\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5c0f\u89c4\u6a21\u5019\u9009\u4eba\u548c\u83b7\u80dc\u8005\u6570\u91cf\u7684\u60c5\u51b5\uff0c\u786e\u5b9a\u83b7\u80dc\u8054\u76df\u4e2d\u5019\u9009\u4eba\u7684\u90bb\u63a5\u6761\u4ef6\uff1b\u8bc4\u4f30\u83b7\u80dc\u8054\u76df\u4e0eCondorcet\u51c6\u5219\u6269\u5c55\u7684\u5339\u914d\u5ea6\uff1b\u5229\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\u7814\u7a76\u4e0d\u540c\u9009\u6c11\u884c\u4e3a\u5047\u8bbe\u4e0b\u8054\u76df\u7684\u51fa\u73b0\u9891\u7387\u3002", "result": "\u5728\u5c0f\u89c4\u6a21\u5019\u9009\u4eba\u548c\u83b7\u80dc\u8005\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u83b7\u80dc\u8054\u76df\u4e2d\u7684\u5019\u9009\u4eba\u901a\u5e38\u662f\u90bb\u63a5\u7684\uff1b\u90e8\u5206\u8054\u76df\u6ee1\u8db3Condorcet\u51c6\u5219\u7684\u6269\u5c55\uff1b\u8499\u7279\u5361\u6d1b\u6a21\u62df\u63ed\u793a\u4e86\u4e0d\u540c\u9009\u6c11\u884c\u4e3a\u5bf9\u8054\u76df\u5f62\u6210\u7684\u5f71\u54cd\u3002", "conclusion": "Bloc\u6295\u7968\u5728\u5355\u5cf0\u504f\u597d\u4e0b\u5f62\u6210\u7684\u83b7\u80dc\u8054\u76df\u8868\u73b0\u826f\u597d\uff0c\u7279\u522b\u662f\u5728\u5c0f\u89c4\u6a21\u60c5\u5883\u4e2d\uff0c\u4f46\u5bf9Condorcet\u51c6\u5219\u7684\u6269\u5c55\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u8499\u7279\u5361\u6d1b\u6a21\u62df\u63d0\u4f9b\u4e86\u5176\u5728\u5b9e\u9645\u9009\u6c11\u884c\u4e3a\u4e2d\u7684\u9002\u7528\u6027\u53c2\u8003\u3002"}}
{"id": "2602.16913", "categories": ["cs.PL", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.16913", "abs": "https://arxiv.org/abs/2602.16913", "authors": ["Ivan Lanese", "Germ\u00e1n Vidal"], "title": "A Reversible Semantics for Janus", "comment": "Submitted for publication", "summary": "Janus is a paradigmatic example of reversible programming language. Indeed, Janus programs can be executed backwards as well as forwards. However, its small-step semantics (useful, e.g., for debugging or as a basis for extensions with concurrency primitives) is not reversible, since it loses information while computing forwards. E.g., it does not satisfy the Loop Lemma, stating that any reduction has an inverse, a main property of reversibility in process calculi, where small-step semantics is commonly used. We present here a novel small-step semantics which is actually reversible, while remaining equivalent to the previous one. It involves the non-trivial challenge of defining a semantics based on a \"program counter\" for a high-level programming language.", "AI": {"tldr": "Janus\u662f\u4e00\u79cd\u53ef\u9006\u7f16\u7a0b\u8bed\u8a00\u7684\u5178\u8303\uff0c\u4f46\u5176\u5c0f\u6b65\u8bed\u4e49\u5728\u6b63\u5411\u8ba1\u7b97\u65f6\u4f1a\u4e22\u5931\u4fe1\u606f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u53ef\u9006\u6027\u7684\u5173\u952e\u5c5e\u6027\u2014\u5faa\u73af\u5f15\u7406\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5c0f\u6b65\u8bed\u4e49\uff0c\u65e2\u4fdd\u7559\u4e86\u7b49\u6548\u6027\uff0c\u53c8\u771f\u6b63\u5b9e\u73b0\u4e86\u53ef\u9006\u6027\u3002", "motivation": "Janus\u4f5c\u4e3a\u4e00\u79cd\u53ef\u9006\u7f16\u7a0b\u8bed\u8a00\uff0c\u5176\u5c0f\u6b65\u8bed\u4e49\u5728\u6b63\u5411\u8ba1\u7b97\u65f6\u4f1a\u4e22\u5931\u4fe1\u606f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u53ef\u9006\u6027\u7684\u5173\u952e\u5c5e\u6027\uff08\u5982\u5faa\u73af\u5f15\u7406\uff09\u3002\u8fd9\u9650\u5236\u4e86\u5b83\u5728\u8c03\u8bd5\u6216\u6269\u5c55\u5e76\u53d1\u539f\u8bed\u7b49\u65b9\u9762\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5c0f\u6b65\u8bed\u4e49\uff0c\u901a\u8fc7\u57fa\u4e8e\u201c\u7a0b\u5e8f\u8ba1\u6570\u5668\u201d\u7684\u5b9a\u4e49\u6765\u89e3\u51b3\u9ad8\u62bd\u8c61\u7ea7\u522b\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7684\u53ef\u9006\u6027\u95ee\u9898\u3002", "result": "\u65b0\u578b\u5c0f\u6b65\u8bed\u4e49\u4e0d\u4ec5\u4fdd\u7559\u4e86\u4e0e\u539f\u8bed\u4e49\u7684\u7b49\u6548\u6027\uff0c\u8fd8\u771f\u6b63\u5b9e\u73b0\u4e86\u53ef\u9006\u6027\uff0c\u6ee1\u8db3\u4e86\u5982\u5faa\u73af\u5f15\u7406\u7b49\u5173\u952e\u5c5e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86Janus\u5c0f\u6b65\u8bed\u4e49\u7684\u53ef\u9006\u6027\u95ee\u9898\uff0c\u4e3a\u9ad8\u62bd\u8c61\u7ea7\u522b\u7f16\u7a0b\u8bed\u8a00\u7684\u53ef\u9006\u8bed\u4e49\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.16919", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.16919", "abs": "https://arxiv.org/abs/2602.16919", "authors": ["Nivasini Ananthakrishnan", "Alireza Fallah", "Michael I. Jordan"], "title": "Signaling in Data Markets via Free Samples", "comment": null, "summary": "We study a setting in which a data buyer seeks to estimate an unknown parameter by purchasing samples from one of K data sellers. Each seller has privately known data quality (e.g., high vs. low variance) and a private per-sample cost. We consider a multi-stage game in which the first stage is a free-trial stage in which the sellers have the option of signaling data quality by offering a few samples of data for free. Buyers update their beliefs based on the sample variance of the free data and then run a procurement auction to buy data in a second stage. For the auction stage, we characterize an approximately optimal Bayesian incentive compatible mechanism: the buyer selects a single seller by minimizing a belief-adjusted virtual cost and chooses the purchased sample size as a function of posterior quality and virtual cost. For the free-trial stage, we characterize the equilibrium, taking the above mechanism as the continuation game. Free trials may fail to emerge: for some parameters, all sellers reveal zero samples. However, under sufficiently strong competition (large K), there is an equilibrium in which sellers reveal the maximum allowable number of samples; in fact, it is the unique equilibrium.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u4e2a\u6570\u636e\u4e70\u5bb6\u901a\u8fc7\u4ece\u591a\u4e2a\u6570\u636e\u5356\u5bb6\u8d2d\u4e70\u6837\u672c\u4f30\u8ba1\u672a\u77e5\u53c2\u6570\u7684\u573a\u666f\uff0c\u63a2\u8ba8\u4e86\u514d\u8d39\u8bd5\u7528\u9636\u6bb5\u548c\u62cd\u5356\u9636\u6bb5\u7684\u535a\u5f08\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6570\u636e\u5e02\u573a\u4e2d\uff0c\u901a\u8fc7\u514d\u8d39\u8bd5\u7528\u548c\u62cd\u5356\u673a\u5236\u4fc3\u8fdb\u6570\u636e\u8d28\u91cf\u7684\u900f\u660e\u5316\u548c\u9ad8\u6548\u4ea4\u6613\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u535a\u5f08\u6a21\u578b\uff0c\u7b2c\u4e00\u9636\u6bb5\u4e3a\u514d\u8d39\u8bd5\u7528\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e3a\u91c7\u8d2d\u62cd\u5356\uff0c\u8bbe\u8ba1\u4e86\u8fd1\u4f3c\u6700\u4f18\u7684\u8d1d\u53f6\u65af\u6fc0\u52b1\u76f8\u5bb9\u673a\u5236\u3002", "result": "\u514d\u8d39\u8bd5\u7528\u5728\u67d0\u4e9b\u53c2\u6570\u4e0b\u65e0\u6cd5\u5b9e\u73b0\uff0c\u4f46\u5728\u7ade\u4e89\u8db3\u591f\u5f3a\u65f6\uff0c\u5b58\u5728\u5356\u5bb6\u63d0\u4f9b\u6700\u5927\u5141\u8bb8\u6837\u672c\u91cf\u7684\u552f\u4e00\u5747\u8861\u3002", "conclusion": "\u514d\u8d39\u8bd5\u7528\u548c\u62cd\u5356\u673a\u5236\u5728\u6570\u636e\u5e02\u573a\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u7ade\u4e89\u6fc0\u70c8\u7684\u73af\u5883\u4e2d\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2602.16981", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.16981", "abs": "https://arxiv.org/abs/2602.16981", "authors": ["Jasper Geer", "Fox Huston", "Jeffrey S. Foster"], "title": "Mason: Type- and Name-Guided Program Synthesis", "comment": null, "summary": "Object-oriented programs tend to be written using many common coding idioms, such as those captured by design patterns. While design patterns are useful, implementing them is often tedious and repetitive, requiring boilerplate code that distracts the programmer from more essential details. In this paper, we introduce Mason, a tool that synthesizes object-oriented programs from partial program pieces, and we apply it to automatically insert design patterns into programs. At the core of Mason is a novel technique we call type- and name-guided synthesis, in which an enumerative solver traverses a partial program to generate typing constraints; discharges constraints via program transformations guided by the names of constrained types and members; and backtracks when a constraint is violated or a candidate program fails unit tests. We also introduce two extensions to Mason: a non-local backtracking heuristic that uses execution traces, and a language of patterns that impose syntactic restrictions on missing names. We evaluate Mason on a suite of benchmarks to which Mason must add various well-known design patterns implemented as a library of program pieces. We find that Mason performs well when very few candidate programs satisfy its typing constraints and that our extensions can improve Mason's performance significantly when this is not the case. We believe that Mason takes an important step forward in synthesizing multi-class object-oriented programs using design patterns.", "AI": {"tldr": "Mason\u662f\u4e00\u79cd\u5de5\u5177\uff0c\u80fd\u591f\u901a\u8fc7\u90e8\u5206\u7a0b\u5e8f\u7247\u6bb5\u5408\u6210\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\uff0c\u5e76\u81ea\u52a8\u63d2\u5165\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u51cf\u5c11\u4e86\u7f16\u5199\u91cd\u590d\u4ee3\u7801\u7684\u9700\u6c42\u3002", "motivation": "\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\u8bbe\u8ba1\u5e38\u9700\u8981\u5927\u91cf\u91cd\u590d\u7684\u6837\u677f\u4ee3\u7801\u6765\u5b9e\u73b0\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u8fd9\u4e0d\u4ec5\u7e41\u7410\u8fd8\u5206\u6563\u4e86\u5f00\u53d1\u8005\u7684\u6ce8\u610f\u529b\u3002Mason\u7684\u76ee\u6807\u662f\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "Mason\u91c7\u7528\u4e86\u4e00\u79cd\u540d\u4e3a\"\u7c7b\u578b\u548c\u540d\u79f0\u5f15\u5bfc\u5408\u6210\"\u7684\u65b0\u6280\u672f\uff0c\u901a\u8fc7\u679a\u4e3e\u6c42\u89e3\u5668\u904d\u5386\u90e8\u5206\u7a0b\u5e8f\u751f\u6210\u7c7b\u578b\u7ea6\u675f\uff0c\u5e76\u5229\u7528\u7a0b\u5e8f\u8f6c\u6362\u6765\u6ee1\u8db3\u7ea6\u675f\u3002\u6b64\u5916\uff0cMason\u8fd8\u5f15\u5165\u4e86\u57fa\u4e8e\u6267\u884c\u8ddf\u8e2a\u7684\u975e\u5c40\u90e8\u56de\u6eaf\u542f\u53d1\u5f0f\u548c\u6a21\u5f0f\u8bed\u8a00\u3002", "result": "Mason\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5c24\u5176\u662f\u5728\u6ee1\u8db3\u7c7b\u578b\u7ea6\u675f\u7684\u5019\u9009\u7a0b\u5e8f\u8f83\u5c11\u65f6\u3002\u5176\u6269\u5c55\u529f\u80fd\u5728\u5019\u9009\u7a0b\u5e8f\u8f83\u591a\u65f6\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "Mason\u5728\u5229\u7528\u8bbe\u8ba1\u6a21\u5f0f\u5408\u6210\u591a\u7c7b\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\u65b9\u9762\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7b80\u5316\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.16928", "categories": ["cs.GT", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16928", "abs": "https://arxiv.org/abs/2602.16928", "authors": ["Zun Li", "John Schultz", "Daniel Hennes", "Marc Lanctot"], "title": "Discovering Multiagent Learning Algorithms with Large Language Models", "comment": null, "summary": "Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) rest on solid theoretical ground, the design of their most effective variants often relies on human intuition to navigate a vast algorithmic design space. In this work, we propose the use of AlphaEvolve, an evolutionary coding agent powered by large language models, to automatically discover new multiagent learning algorithms. We demonstrate the generality of this framework by evolving novel variants for two distinct paradigms of game-theoretic learning. First, in the domain of iterative regret minimization, we evolve the logic governing regret accumulation and policy derivation, discovering a new algorithm, Volatility-Adaptive Discounted (VAD-)CFR. VAD-CFR employs novel, non-intuitive mechanisms-including volatility-sensitive discounting, consistency-enforced optimism, and a hard warm-start policy accumulation schedule-to outperform state-of-the-art baselines like Discounted Predictive CFR+. Second, in the regime of population based training algorithms, we evolve training-time and evaluation-time meta strategy solvers for PSRO, discovering a new variant, Smoothed Hybrid Optimistic Regret (SHOR-)PSRO. SHOR-PSRO introduces a hybrid meta-solver that linearly blends Optimistic Regret Matching with a smoothed, temperature-controlled distribution over best pure strategies. By dynamically annealing this blending factor and diversity bonuses during training, the algorithm automates the transition from population diversity to rigorous equilibrium finding, yielding superior empirical convergence compared to standard static meta-solvers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAlphaEvolve\u7684\u8fdb\u5316\u7f16\u7801\u4ee3\u7406\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u53d1\u73b0\u65b0\u7684\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u535a\u5f08\u8bba\u5b66\u4e60\u7684\u4e24\u4e2a\u4e0d\u540c\u9886\u57df\uff0c\u5e76\u6f14\u5316\u51fa\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u57fa\u7ebf\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u975e\u5b8c\u7f8e\u4fe1\u606f\u535a\u5f08\u4e2d\u7684\u8fdb\u5c55\u4f9d\u8d56\u4eba\u5de5\u8fed\u4ee3\u6539\u8fdb\uff0c\u800c\u73b0\u6709\u57fa\u7840\u65b9\u6cd5\uff08\u5982CFR\u548cPSRO\uff09\u7684\u6709\u6548\u53d8\u4f53\u8bbe\u8ba1\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u76f4\u89c9\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7AlphaEvolve\u81ea\u52a8\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002", "method": "\u4f7f\u7528AlphaEvolve\u8fdb\u5316\u7f16\u7801\u4ee3\u7406\uff0c\u81ea\u52a8\u53d1\u73b0\u65b0\u7684\u7b97\u6cd5\u53d8\u4f53\u3002\u5206\u522b\u5728\u8fed\u4ee3\u9057\u61be\u6700\u5c0f\u5316\u548c\u57fa\u4e8e\u79cd\u7fa4\u8bad\u7ec3\u7684\u7b97\u6cd5\u8303\u5f0f\u4e2d\u6f14\u5316\u51fa\u65b0\u7b97\u6cd5VAD-CFR\u548cSHOR-PSRO\u3002", "result": "VAD-CFR\u901a\u8fc7\u6ce2\u52a8\u654f\u611f\u6298\u6263\u7b49\u673a\u5236\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u57fa\u7ebf\uff08\u5982Discounted Predictive CFR+\uff09\uff1bSHOR-PSRO\u901a\u8fc7\u6df7\u5408\u5143\u6c42\u89e3\u5668\u548c\u52a8\u6001\u9000\u706b\u6280\u672f\u8868\u73b0\u51fa\u4f18\u4e8e\u6807\u51c6\u9759\u6001\u5143\u6c42\u89e3\u5668\u7684\u6536\u655b\u6027\u3002", "conclusion": "AlphaEvolve\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u9ad8\u6027\u80fd\u7684\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\u53d8\u4f53\uff0c\u51cf\u5c11\u4e86\u5bf9\u4eba\u5de5\u8bbe\u8ba1\u7684\u4f9d\u8d56\uff0c\u5e76\u4e3a\u535a\u5f08\u8bba\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002"}}
{"id": "2602.16998", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.16998", "abs": "https://arxiv.org/abs/2602.16998", "authors": ["Arwa Alanqary", "Zakaria Baba", "Manxi Wu", "Alexandre M. Bayen"], "title": "Learning to Recommend in Unknown Games", "comment": null, "summary": "We study preference learning through recommendations in multi-agent game settings, where a moderator repeatedly interacts with agents whose utility functions are unknown. In each round, the moderator issues action recommendations and observes whether agents follow or deviate from them. We consider two canonical behavioral feedback models-best response and quantal response-and study how the information revealed by each model affects the learnability of agents' utilities. We show that under quantal-response feedback the game is learnable, up to a positive affine equivalence class, with logarithmic sample complexity in the desired precision, whereas best-response feedback can only identify a larger set of agents' utilities. We give a complete geometric characterization of this set. Moreover, we introduce a regret notion based on agents' incentives to deviate from recommendations and design an online algorithm with low regret under both feedback models, with bounds scaling linearly in the game dimension and logarithmically in time. Our results lay a theoretical foundation for AI recommendation systems in strategic multi-agent environments, where recommendation compliances are shaped by strategic interaction.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u591a\u667a\u80fd\u4f53\u6e38\u620f\u73af\u5883\u4e2d\u901a\u8fc7\u63a8\u8350\u5b66\u4e60\u504f\u597d\u7684\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u91cf\u5316\u54cd\u5e94\u53cd\u9988\u4e0b\u5982\u4f55\u4ee5\u5bf9\u6570\u6837\u672c\u590d\u6742\u5ea6\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u6548\u7528\u51fd\u6570\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4f4e\u540e\u6094\u7684\u5728\u7ebf\u7b97\u6cd5\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u667a\u80fd\u4f53\u7684\u6548\u7528\u51fd\u6570\u901a\u5e38\u672a\u77e5\uff0c\u5982\u4f55\u901a\u8fc7\u5b66\u4e60\u63a8\u8350\u884c\u4e3a\u7684\u53cd\u9988\u6765\u63a8\u65ad\u8fd9\u4e9b\u6548\u7528\u51fd\u6570\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8003\u8651\u4e86\u4e24\u79cd\u884c\u4e3a\u53cd\u9988\u6a21\u578b\uff08\u6700\u4f73\u54cd\u5e94\u548c\u91cf\u5316\u54cd\u5e94\uff09\uff0c\u5206\u6790\u5176\u5bf9\u6548\u7528\u51fd\u6570\u53ef\u5b66\u4e60\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5728\u7ebf\u7b97\u6cd5\u4ee5\u51cf\u5c11\u540e\u6094\u3002", "result": "\u91cf\u5316\u54cd\u5e94\u53cd\u9988\u4e0b\uff0c\u6e38\u620f\u80fd\u4ee5\u5bf9\u6570\u6837\u672c\u590d\u6742\u5ea6\u5b66\u4e60\u6548\u7528\u51fd\u6570\uff1b\u6700\u4f73\u54cd\u5e94\u53cd\u9988\u5219\u53ea\u80fd\u8bc6\u522b\u66f4\u5927\u7684\u6548\u7528\u51fd\u6570\u96c6\u3002\u5728\u7ebf\u7b97\u6cd5\u5728\u4e0d\u540c\u53cd\u9988\u6a21\u578b\u4e0b\u5747\u8868\u73b0\u51fa\u4f4e\u540e\u6094\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6218\u7565\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684AI\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u63a8\u8350\u884c\u4e3a\u5728\u6218\u7565\u4ea4\u4e92\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.17358", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.17358", "abs": "https://arxiv.org/abs/2602.17358", "authors": ["Johannes Br\u00fcstle", "Ilan Reuven Cohen", "Stefano Leonardi"], "title": "Prophet Inequality with Conservative Prediction", "comment": "32 pages", "summary": "Prophet inequalities compare online stopping strategies against an omniscient \"prophet\" using distributional knowledge. In this work, we augment this model with a conservative prediction of the maximum realized value. We quantify the quality of this prediction using a parameter $\u03b1\\in [0,1]$, ranging from inaccurate to perfect. Our goal is to improve performance when predictions are accurate (consistency) while maintaining theoretical guarantees when they are not (robustness). We propose a threshold-based strategy oblivious to $\u03b1$ (i.e., with $\u03b1$ unknown to the algorithm) that matches the classic competitive ratio of $1/2$ at $\u03b1=0$ and improves smoothly to $3/4$ at $\u03b1=1$. We further prove that simultaneously achieving better than $3/4$ at $\u03b1=1$ while maintaining $1/2$ at $\u03b1=0$ is impossible. Finally, when $\u03b1$ is known in advance, we present a strategy achieving a tight competitive ratio of $\\frac{1}{2-\u03b1}$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u7ecf\u5178\u7684\u5148\u77e5\u4e0d\u7b49\u5f0f\u6a21\u578b\u4e2d\u5f15\u5165\u4e86\u4e00\u4e2a\u4fdd\u5b88\u7684\u6700\u5927\u503c\u9884\u6d4b\uff0c\u901a\u8fc7\u53c2\u6570\u03b1\u91cf\u5316\u9884\u6d4b\u8d28\u91cf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9608\u503c\u7b56\u7565\uff0c\u80fd\u591f\u5728\u03b1\u672a\u77e5\u65f6\u5e73\u8861\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u03b1\u5df2\u77e5\u65f6\u8fbe\u5230\u6700\u4f18\u7ade\u4e89\u6bd4\u3002", "motivation": "\u4f20\u7edf\u5148\u77e5\u4e0d\u7b49\u5f0f\u6a21\u578b\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u4fe1\u606f\u7684\u5229\u7528\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u9884\u6d4b\u4fe1\u606f\u6765\u63d0\u9ad8\u5728\u7ebf\u505c\u6b62\u7b56\u7565\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u8bc1\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9608\u503c\u7684\u7b56\u7565\uff0c\u65e0\u9700\u77e5\u9053\u9884\u6d4b\u51c6\u786e\u5ea6\u03b1\uff0c\u540c\u65f6\u9488\u5bf9\u5df2\u77e5\u03b1\u7684\u60c5\u51b5\u8bbe\u8ba1\u4e86\u53e6\u4e00\u79cd\u7b56\u7565\uff0c\u7406\u8bba\u5206\u6790\u4e86\u4e0d\u540c\u7b56\u7565\u7684\u7ade\u4e89\u6bd4\u3002", "result": "\u5728\u03b1\u672a\u77e5\u65f6\uff0c\u7b56\u7565\u5728\u03b1=0\u65f6\u4fdd\u63011/2\u7684\u7ade\u4e89\u6bd4\uff0c\u03b1=1\u65f6\u63d0\u5347\u52303/4\uff1b\u5728\u03b1\u5df2\u77e5\u65f6\uff0c\u7b56\u7565\u8fbe\u5230\u6700\u4f18\u7ade\u4e89\u6bd41/(2\u2212\u03b1)\u3002\u7814\u7a76\u8fd8\u8bc1\u660e\u65e0\u6cd5\u540c\u65f6\u505a\u5230\u5728\u03b1=1\u65f6\u8d85\u8fc73/4\u4e14\u5728\u03b1=0\u65f6\u4fdd\u63011/2\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u9884\u6d4b\u4fe1\u606f\u6539\u8fdb\u4e86\u5148\u77e5\u4e0d\u7b49\u5f0f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u9608\u503c\u7b56\u7565\uff0c\u5e76\u786e\u5b9a\u4e86\u6027\u80fd\u7684\u7406\u8bba\u6781\u9650\u3002"}}
