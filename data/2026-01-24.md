<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SplatBus: A Gaussian Splatting Viewer Framework via GPU Interprocess Communication](https://arxiv.org/abs/2601.15431)
*Yinghan Xu,Théo Morales,John Dingliana*

Main category: cs.GR

TL;DR: 该论文提出了一种基于3D高斯泼溅的实时渲染方法，通过NVIDIA的IPC API实现与传统渲染管线的无缝集成，解决了现有方法难以整合的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管基于辐射场的渲染方法能实现高保真渲染，但其高耗时限制了实时应用。3D高斯泼溅虽解决了实时性问题，却难以与传统网格渲染管线集成，影响了其在交互式和艺术探索中的应用。

Method: 该软件解决方案利用NVIDIA的IPC API，实现了3D高斯泼溅渲染与外部客户端（如Unity、Blender等）的轻松集成。

Result: 该方法成功地将3D高斯泼溅渲染整合到传统渲染管线中，支持在多种外部客户端中实时查看渲染结果。

Conclusion: 论文提出的解决方案解决了3D高斯泼溅与传统渲染管线集成的难题，扩展了其在实时交互应用中的潜力。

Abstract: Radiance field-based rendering methods have attracted significant interest from the computer vision and computer graphics communities. They enable high-fidelity rendering with complex real-world lighting effects, but at the cost of high rendering time. 3D Gaussian Splatting solves this issue with a rasterisation-based approach for real-time rendering, enabling applications such as autonomous driving, robotics, virtual reality, and extended reality. However, current 3DGS implementations are difficult to integrate into traditional mesh-based rendering pipelines, which is a common use case for interactive applications and artistic exploration. To address this limitation, this software solution uses Nvidia's interprocess communication (IPC) APIs to easily integrate into implementations and allow the results to be viewed in external clients such as Unity, Blender, Unreal Engine, and OpenGL viewers. The code is available at https://github.com/RockyXu66/splatbus.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Remarks on Algebraic Reconstruction of Types and Effects](https://arxiv.org/abs/2601.15455)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 本文指出Jouvelot和Gifford在1991年提出的高阶多态语言的类型和效果重建算法中存在与变量绑定相关的细微错误。


<details>
  <summary>Details</summary>
Motivation: 原始的算法被认为是类型和效果系统的里程碑，但其在处理高阶多态语言的变量绑定方面存在未被发现的错误，需要重新审视。

Method: 重新审视了Jouvelot和Gifford的类型系统和重建算法，分析了其在高阶多态语言中的变量绑定处理方式。

Result: 发现了原始算法中与变量绑定相关的细微错误，并对这些问题进行了详细描述。

Conclusion: 尽管原始算法启发了大量后续研究，但其在高阶多态语言中的实现存在错误，需要通过进一步的修正来解决。

Abstract: In their 1991 paper "Algebraic Reconstruction of Types and Effects," Pierre Jouvelot and David Gifford presented a type-and-effect reconstruction algorithm based on an algebraic structure of effects. Their work is considered a milestone in the development of type-and-effect systems, and has inspired numerous subsequent works in the area of static analysis. However, unlike the later research it spawned, the original algorithm considered a language with higher-rank polymorphism, a feature which is challenging to implement correctly. In this note, we identify subtle bugs related to variable binding in their approach to this feature. We revisit their type system and reconstruction algorithm, and describe the discovered issues.

</details>


### [3] [Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking](https://arxiv.org/abs/2601.16008)
*Federico Bruzzone,Walter Cazzola,Luca Favini*

Main category: cs.PL

TL;DR: 该论文提出了一种基于编译器的方法RustyEx，通过中间表示提取、图数据结构构建、中心性度量排名和代码影响范围细化，优先处理Rust语言中的配置组合问题，有效生成高优先级配置。


<details>
  <summary>Details</summary>
Motivation: 现代编程语言（如Rust）的多样化配置组合导致程序分析、优化和测试的复杂性爆炸式增长，传统穷举方法难以应对。这促使研究如何优先处理配置空间以提高效率。

Method: 方法包括四个步骤：1. 从Rust编译器中提取中间表示；2. 构建两种图数据结构；3. 使用中心性度量对特征排名；4. 结合代码影响范围细化排名，最终通过SAT求解器验证配置。

Result: 实验评估表明，RustyEx在高排名开源Rust项目中高效生成了用户指定的配置集合，并在有限资源内确保了配置的正确性。

Conclusion: 中心性引导的配置优先方法有效探索了大配置空间，为未来配置感知的分析和优化研究奠定了基础。

Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Do people expect different behavior from large language models acting on their behalf? Evidence from norm elicitations in two canonical economic games](https://arxiv.org/abs/2601.15312)
*Paweł Niszczota,Elia Antoniou*

Main category: cs.GT

TL;DR: 研究表明，人们对于大型语言模型（LLM）代理任务的社会适宜性有不同的期望，特别是在资源分配和公平性监控方面。


<details>
  <summary>Details</summary>
Motivation: 探索人们对LLM作出决策时的社会适宜性期望，尤其是在资源分配和公平性监控任务中。

Method: 通过两项预先注册和有激励的实验研究，使用英国和美国的代表性样本，采用Krupka-Weber规范引出任务来检测社会适宜性评级的差异。

Result: 发现人们认为机器的提议在无需接受时比人类的提议更不合适，但在需要接受时，拒绝机器的提议更合适；机器拒绝提议的社会适宜性与人类相同。

Conclusion: 结果表明人们对机器分配资源有不同的规范要求，但并不反对机器执行规范，这表明机器的提议被视为了具有认知和情感双重成分。

Abstract: While delegating tasks to large language models (LLMs) can save people time, there is growing evidence that offloading tasks to such models produces social costs. We use behavior in two canonical economic games to study whether people have different expectations when decisions are made by LLMs acting on their behalf instead of themselves. More specifically, we study the social appropriateness of a spectrum of possible behaviors: when LLMs divide resources on our behalf (Dictator Game and Ultimatum Game) and when they monitor the fairness of splits of resources (Ultimatum Game). We use the Krupka-Weber norm elicitation task to detect shifts in social appropriateness ratings. Results of two pre-registered and incentivized experimental studies using representative samples from the UK and US (N = 2,658) show three key findings. First, people find that offers from machines - when no acceptance is necessary - are judged to be less appropriate than when they come from humans, although there is no shift in the modal response. Second - when acceptance is necessary - it is more appropriate for a person to reject offers from machines than from humans. Third, receiving a rejection of an offer from a machine is no less socially appropriate than receiving the same rejection from a human. Overall, these results suggest that people apply different norms for machines deciding on how to split resources but are not opposed to machines enforcing the norms. The findings are consistent with offers made by machines now being viewed as having both a cognitive and emotional component.

</details>


### [5] [On the closest balanced game](https://arxiv.org/abs/2601.15318)
*Pedro García-Segador,Michel Grabisch,Dylan Laplace Mermoud,Pedro Miranda*

Main category: cs.GT

TL;DR: 论文提出了一种快速算法，用于找到具有非空核心的最近平衡合作游戏，并证明随着玩家数量增加，最近游戏的单一核心概率趋近于1。


<details>
  <summary>Details</summary>
Motivation: 研究目标是解决核心为空的合作游戏中，如何找到最近的平衡游戏（即正交投影），以优化欧几里得距离。

Method: 提出了一种避免指数复杂度优化问题的快速算法，适用于最多20名玩家的游戏，并通过数学证明支持实验结果。

Result: 实验表明，随着玩家数量增加，最近游戏的单一核心概率趋近于1；数学证明进一步验证了这一发现。

Conclusion: 论文定义了一个新的解概念“最小平方核心”，并证明其在玩家数量增加时趋于点解的概率趋近于1。

Abstract: Cooperative games with nonempty core are called balanced, and the set of balanced games is a polyhedron. Given a game with empty core, we look for the closest balanced game, in the sense of the (weighted) Euclidean distance, i.e., the orthogonal projection of the game on the set of balanced games. Besides an analytical approach which becomes rapidly intractable, we propose a fast algorithm to find the closest balanced game, avoiding exponential complexity for the optimization problem, and being able to run up to 20 players. We show experimentally that the probability that the closest game has a core reduced to a singleton tends to 1 when the number of players grow. We provide a mathematical proof that the proportion of facets whose games have a non-singleton core tends to 0 when the number of players grow, by finding an expression of the aymptotic growth of the number of minimal balanced collections. This permits to prove mathematically the experimental result. Consequently, taking the core of the projected game defines a new solution concept, which we call least square core due to its analogy with the least core, and our result shows that the probability that this is a point solution tends to 1 when the number of players grow.

</details>


### [6] [Rules Create Unequal Rewards: Elite Tennis Players Allocate Resources Efficiently](https://arxiv.org/abs/2601.15327)
*Masatsugu Yoshizawa,Yuta Kawamoto,Daisuke Takeshita*

Main category: cs.GT

TL;DR: 在职业网球中，顶尖运动员通过根据比分动态调整努力程度，更高效地将得分转化为比赛胜利，体现了在规则创造的价值结构中适应的重要性。


<details>
  <summary>Details</summary>
Motivation: 在许多竞争性环境中，规则不均等地奖励努力，某些时刻因阈值（如比分临界点）变得尤为重要。然而，由于努力分配难以观察且反馈延迟，对这一现象的理解有限。网球比赛提供了一个理想的自然实验环境。

Method: 研究分析了职业网球比赛中得分依赖的得分概率，推导出每位运动员的帕累托前沿，即比赛获胜概率与每场预期得分之间的理论极限平衡。

Result: 顶尖运动员更接近帕累托前沿，尤其是在接发球局中，当比分大幅落后时会减少得分努力，这是一种理性的能量节约策略。

Conclusion: 精英表现反映了对规则创造的价值结构的高效适应，知道何时放弃可能与知道何时竞争同样重要。

Abstract: In many competitive settings, from education to politics, rules do not reward effort evenly, and thresholds (e.g., grade cutoffs or electoral majorities) make some moments disproportionately important. Success thus depends on efficiently allocating limited resources. However, empirical demonstration has been difficult because effort allocation is rarely observable and feedback is often delayed, limiting our understanding of expertise. Professional tennis provides an ideal natural experiment. Because each game resets after a player wins four points and points in a lost game are wasted, the value of a point varies sharply across scores. Efficient allocation should therefore win games without wasting points, conserving resources for future games. Such allocation manifests in score-dependent point-winning probabilities, from which we derive each player's Pareto frontier-the theoretical limit of the trade-off between game-winning probability and the expected points per game. Here, we show that top players operate closer to this frontier, converting points to game wins more efficiently. Optimal strategies reduce the probability of winning points when the player is far behind (e.g.,0-2, 0-3). This behavior is psychologically difficult-letting go of the current game-but represents a rational energy conservation strategy. Top players exhibit this pattern especially in return games, where winning points is harder than in service games, requiring them to drastically vary their efforts, consistent with game-theoretic predictions. These findings suggest that elite performance reflects efficient adaptation to rule-created value structures; knowing when to give up may be as fundamental to expertise as knowing when to compete.

</details>


### [7] [Equal-Pay Contracts](https://arxiv.org/abs/2601.15478)
*Michal Feldman,Yoav Gal-Tzur,Tomasz Ponitka,Maya Schlesinger*

Main category: cs.GT

TL;DR: 研究了多智能体合同设计中的等薪酬合同（equal-pay contracts）及其近似算法与硬度结果，量化了公平性带来的效用损失。


<details>
  <summary>Details</summary>
Motivation: 现实环境中许多场景限制了支付差异性，传统研究集中于非约束性合同的异质性支付，因此探索等薪酬合同的可行性与效果具有重要意义。

Method: 研究了等薪酬合同及近似等薪酬合同的算法设计与硬度分析，覆盖了二进制和组合动作模式下的多层次奖励函数。

Result: 设计了多项式时间的O(1)-近似算法，并证明了这些结果的紧性；量化了公平性带来的效用损失，给出了上界和下界。

Conclusion: 等薪酬合同在某些场景下可实现高效近似，但其公平性约束可能带来一定的效用损失，具体取决于奖励函数和动作模型的复杂性。

Abstract: We study multi-agent contract design, where a principal incentivizes a team of agents to take costly actions that jointly determine the project success via a combinatorial reward function. While prior work largely focuses on unconstrained contracts that allow heterogeneous payments across agents, many real-world environments limit payment dispersion. Motivated by this, we study equal-pay contracts, where all agents receive identical payments. Our results also extend to nearly-equal-pay contracts where any two payments are identical up to a constant factor.
  We provide both algorithmic and hardness results across a broad hierarchy of reward functions, under both binary and combinatorial action models. While we focus on equal-pay contracts, our analysis also yields new insights into unconstrained contract design, and resolves two important open problems. On the positive side, we design polynomial-time O(1)-approximation algorithms for (i) submodular rewards under combinatorial actions, and (ii) XOS rewards under binary actions. These guarantees are tight: We rule out the existence of (i) a PTAS for combinatorial actions, even for gross substitutes rewards (unless P = NP), and (ii) any O(1)-approximation for XOS rewards with combinatorial actions. Crucially, our hardness results hold even for unconstrained contracts, thereby settling the corresponding open problems in this setting.
  Finally, we quantify the loss induced by fairness via the price of equality, defined as the worst-case ratio between the optimal principal's utility achievable by unconstrained contracts and that achievable by equal-pay contracts. We obtain a bound of $Θ(\log n/ \log \log n)$, where $n$ is the number of agents. This gap is tight in a strong sense: the upper bound applies even for XOS rewards with combinatorial actions, while the lower bound arises already for additive rewards with binary actions.

</details>


### [8] [How to Tamper with a Parliament: Strategic Campaigns in Apportionment Elections](https://arxiv.org/abs/2601.15855)
*Robert Bredereck,Piotr Faliszewski,Michał Furdyna,Andrzej Kaczmarczyk,Joanna Kaczmarek,Martin Lackner,Christian Laußmann,Jörg Rothe,Tessa Seeger*

Main category: cs.GT

TL;DR: 该论文研究了如何通过说服有限数量的选民改变投票来影响选举结果，即增加或限制特定党派的影响力，称之为“战略竞选”。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是理解在多地区选举和选举门槛的背景下，改变选举结果的计算复杂性，并提出优化策略。

Method: 论文采用了计算复杂性分析（包括经典和参数化复杂性），并在真实选举数据上进行了大量实验，评估了战略竞选的有效性。

Result: 研究结果显示，战略竞选在改变选举结果方面具有一定的有效性，特别是在选举门槛和地区数量的影响下。

Conclusion: 论文提出了作为标准首选模式的替代方案的第二机会模式，并为该设置下的计算复杂性结果奠定了基础。

Abstract: In parliamentary elections, parties compete for a limited, typically fixed number of seats. Most parliaments are assembled using apportionment methods that distribute the seats based on the parties' vote counts. Common apportionment methods include divisor sequence methods (like D'Hondt or Sainte-Laguë), the largest-remainder method, and first-past-the-post. In many countries, an electoral threshold is implemented to prevent very small parties from entering the parliament. Further, several countries have apportionment systems that incorporate multiple districts. We study how computationally hard it is to change the election outcome (i.e., to increase or limit the influence of a distinguished party) by convincing a limited number of voters to change their vote. We refer to these bribery-style attacks as \emph{strategic campaigns} and study the corresponding problems in terms of their computational (both classical and parameterized) complexity. We also run extensive experiments on real-world election data and study the effectiveness of optimal campaigns, in particular as opposed to using heuristic bribing strategies and with respect to the influence of the threshold and the influence of the number of districts. For apportionment elections with threshold, finally, we propose -- as an alternative to the standard top-choice mode -- the second-chance mode where voters of parties below the threshold receive a second chance to vote for another party, and we establish computational complexity results also in this setting.

</details>


### [9] [Minimum Envy Graphical House Allocation Beyond Identical Valuations](https://arxiv.org/abs/2601.15864)
*Tanmay Inamdar,Pallavi Jain,Pranjal Pandey*

Main category: cs.GT

TL;DR: 研究非相同估值下的最小嫉妒图形房屋分配问题（ME-GHA），探索社会图和估值函数的结构限制以降低计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 图形房屋分配问题是公平分配领域中的经典问题，最小化嫉妒总和是关键。此前研究集中在相同估值情况下，而非相同估值情况尚未深入探索。

Method: 通过分析社会图和估值函数的结构限制，设计多项式时间算法和指数时间算法，以解决非相同估值下的ME-GHA问题。

Result: 提出了一种针对社会图最大度数不超过1且估值二元时的多项式时间算法，并设计了多种图类的指数时间算法。

Conclusion: 非相同估值下的ME-GHA问题在特定结构限制下具有计算可行性，为未来研究提供了新方向。

Abstract: House allocation is an extremely well-studied problem in the field of fair allocation, where the goal is to assign $n$ houses to $n$ agents while satisfying certain fairness criterion, e.g., envy-freeness. To model social interactions, the Graphical House Allocation framework introduces a social graph $G$, in which each vertex corresponds to an agent, and an edge $(u, v)$ corresponds to the potential of agent $u$ to envy the agent $v$, based on their allocations and valuations. In undirected social graphs, the potential for envy is in both the directions. In the Minimum Envy Graphical House Allocation (ME-GHA) problem, given a set of $n$ agents, $n$ houses, a social graph, and agent's valuation functions, the goal is to find an allocation that minimizes the total envy summed up over all the edges of $G$. Recent work, [Hosseini et al., AAMAS 2023, AAMAS 2024] studied ME-GHA in the regime of polynomial-time algorithms, and designed exact and approximation algorithms, for certain graph classes under identical agent valuations. We initiate the study of \gha with non-identical valuations, a setting that has so far remained unexplored. We investigate the multivariate (parameterized) complexity of \gha by identifying structural restrictions on the social graph and valuation functions that yield tractability. We also design moderately exponential-time algorithms for several graph classes, and a polynomial-time algorithm for {binary valuations that returns an allocation with envy at most one when the social graph has maximum degree at most one.

</details>
