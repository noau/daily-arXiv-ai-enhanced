<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.GT](#cs.GT) [Total: 1]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [AnimaMimic: Imitating 3D Animation from Video Priors](https://arxiv.org/abs/2512.14133)
*Tianyi Xie,Yunuo Chen,Yaowei Guo,Yin Yang,Bolei Zhou,Demetri Terzopoulos,Ying Jiang,Chenfanfu Jiang*

Main category: cs.GR

TL;DR: AnimaMimic 是一个利用视频扩散模型中的运动先验为静态 3D 网格生成动画的框架，通过单目动画视频合成、自动骨骼构建和物理模拟，实现逼真的、可编辑的运动序列。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 动画制作过程耗时且依赖专业技能，而视频扩散模型虽然能生成动态的 2D 运动，但缺乏 3D 结构，难以直接用于动画制作。AnimaMimic 旨在填补这一空白。

Method: AnimaMimic 从输入网格开始，合成单目动画视频，自动构建骨骼和蒙皮权重，并通过可微分渲染和视频监督优化关节参数，同时集成物理模拟以增强网格变形的真实感。

Result: AnimaMimic 能够生成物理合理、时间连贯且艺术家可编辑的运动序列，无缝集成到标准动画流程中。

Conclusion: AnimaMimic 成功结合了视频扩散的创造性和 3D 动画的结构控制，为 3D 动画制作提供了高效且逼真的解决方案。

Abstract: Creating realistic 3D animation remains a time-consuming and expertise-dependent process, requiring manual rigging, keyframing, and fine-tuning of complex motions. Meanwhile, video diffusion models have recently demonstrated remarkable motion imagination in 2D, generating dynamic and visually coherent motion from text or image prompts. However, their results lack explicit 3D structure and cannot be directly used for animation or simulation. We present AnimaMimic, a framework that animates static 3D meshes using motion priors learned from video diffusion models. Starting from an input mesh, AnimaMimic synthesizes a monocular animation video, automatically constructs a skeleton with skinning weights, and refines joint parameters through differentiable rendering and video-based supervision. To further enhance realism, we integrate a differentiable simulation module that refines mesh deformation through physically grounded soft-tissue dynamics. Our method bridges the creativity of video diffusion and the structural control of 3D rigged animation, producing physically plausible, temporally coherent, and artist-editable motion sequences that integrate seamlessly into standard animation pipelines. Our project page is at: https://xpandora.github.io/AnimaMimic/

</details>


### [2] [Establishing Stochastic Object Models from Noisy Data via Ambient Measurement-Integrated Diffusion](https://arxiv.org/abs/2512.14187)
*Jianwei Sun,Xiaoning Lei,Wenhao Cai,Xichen Xu,Yanshu Wang,Hu Gao*

Main category: cs.GR

TL;DR: AMID是一种无监督的环境测量集成扩散方法，通过噪声解耦直接从噪声测量中建立干净的随机对象模型（SOMs），在生成保真度和任务基于图像质量评估方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的随机对象模型（SOMs）无法捕捉真实的解剖结构，而数据驱动方法通常需要干净的临床数据，但现实中难以获得。因此，需要一种直接从噪声测量中学习干净SOMs的方法。

Method: 提出了AMID方法，通过环境测量集成扩散和噪声解耦，直接从噪声测量中建立干净的SOMs。该方法通过测量集成策略将测量噪声与扩散轨迹对齐，并明确建模测量和扩散噪声之间的耦合。

Result: 实验表明，AMID在真实CT和乳腺X光数据集上表现出色，生成保真度高，任务基于图像质量评估更可靠。

Conclusion: AMID展示了其在无监督医学图像分析中的潜力，能够直接从噪声数据中学习干净的SOMs，提升图像质量评估的可靠性。

Abstract: Task-based measures of image quality (IQ) are critical for evaluating medical imaging systems, which must account for randomness including anatomical variability. Stochastic object models (SOMs) provide a statistical description of such variability, but conventional mathematical SOMs fail to capture realistic anatomy, while data-driven approaches typically require clean data rarely available in clinical tasks. To address this challenge, we propose AMID, an unsupervised Ambient Measurement-Integrated Diffusion with noise decoupling, which establishes clean SOMs directly from noisy measurements. AMID introduces a measurement-integrated strategy aligning measurement noise with the diffusion trajectory, and explicitly models coupling between measurement and diffusion noise across steps, an ambient loss is thus designed base on it to learn clean SOMs. Experiments on real CT and mammography datasets show that AMID outperforms existing methods in generation fidelity and yields more reliable task-based IQ evaluation, demonstrating its potential for unsupervised medical imaging analysis.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [3] [The Impact Market to Save Conference Peer Review: Decoupling Dissemination and Credentialing](https://arxiv.org/abs/2512.14104)
*Karthikeyan Sankaralingam*

Main category: cs.GT

TL;DR: 该论文提出了Impact Market（IM）系统，通过三个阶段解耦论文发表与学术声望，解决顶级学术会议中‘等效类问题’和评审主观性问题。


<details>
  <summary>Details</summary>
Motivation: 当前顶级学术会议在快速传播研究成果和稀缺认证声望之间存在冲突，导致评审主观性和优秀论文被任意拒绝的问题。

Method: 提出IM系统，包括三阶段：1) PC评审接受所有严谨论文；2) 通过期货市场创建稀缺声望信号（NIS）；3) 3年后校准验证（MVIS），调整投资者影响力。

Result: 模拟结果显示，引入投资者代理和信心投注后，高影响力论文的检出率从28%提升至85%以上。

Conclusion: IM模型通过透明、数据驱动的市场机制，将即时认证与长期验证的学术影响力对齐，解决了现有评审系统的缺陷。

Abstract: Top-tier academic conferences are failing under the strain of two irreconcilable roles: (1) rapid dissemination of all sound research and (2) scarce credentialing for prestige and career advancement. This conflict has created a reviewer roulette and anonymous tribunal model - a zero-cost attack system - characterized by high-stakes subjectivity, turf wars, and the arbitrary rejection of sound research (the equivalence class problem). We propose the Impact Market (IM), a novel three-phase system that decouples publication from prestige. Phase 1 (Publication): All sound and rigorous papers are accepted via a PC review, solving the "equivalence class" problem. Phase 2 (Investment): An immediate, scarce prestige signal is created via a futures market. Senior community members invest tokens into published papers, creating a transparent, crowdsourced Net Invested Score (NIS). Phase 3 (Calibration): A 3-year lookback mechanism validates these investments against a manipulation-resistant Multi-Vector Impact Score (MVIS). This MVIS adjusts each investor's future influence (their Investor Rating), imposing a quantifiable cost on bad actors and rewarding accurate speculation. The IM model replaces a hidden, zero-cost attack system with a transparent, accountable, and data-driven market that aligns immediate credentialing with long-term, validated impact. Agent-based simulations demonstrate that while a passive market matches current protocols in low-skill environments, introducing investor agency and conviction betting increases the retrieval of high-impact papers from 28% to over 85% under identical conditions, confirming that incentivized self-selection is the mechanism required to scale peer review.

</details>
