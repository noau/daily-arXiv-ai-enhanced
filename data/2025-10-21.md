<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 10]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.GT](#cs.GT) [Total: 4]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Two-Stage Sketch-Based Smoke Illustration Generation using Stream Function](https://arxiv.org/abs/2510.15873)
*Hengyuan Chang,Xiaoxuan Xie,Syuhei Sato,Haoran Xie*

Main category: cs.GR

TL;DR: 本文提出了一种基于草图的烟雾插图生成框架，通过流函数和潜在扩散模型实现两阶段生成，草图用于指导流函数的生成，进而控制烟雾模拟的动态。


<details>
  <summary>Details</summary>
Motivation: 现有的烟雾生成方法难以准确捕捉用户草图表达的流动意图，尤其是连续变化和旋转流动的细节。

Method: 采用两阶段框架：首先使用草图指导流函数生成，流函数作为速度场生成器的控制条件；然后使用生成的速度场指导烟雾模拟，同时引入流线编码全局动态作为训练时的草图引导。

Result: 生成的烟雾动态能够更好地对齐用户的流动意图，流函数作为中间表示成功捕捉了草图中缺失的连续变化和旋转流动细节。

Conclusion: 所提出的框架有效解决了烟雾生成中对用户草图意图的精确捕捉问题，为基于草图的流体模拟提供了新方法。

Abstract: In this paper, we propose a two-stage sketch-based smoke illustration
generation framework using stream function and latent diffusion models (LDM).
The user sketch is used to guide the generation of the stream function, which
serves as the control condition for the velocity field generator. The generated
velocity field can be used to guide the smoke simulation to align with the
intended flow. We adopt streamlines to encode global flow dynamics as sketch
guidance during training. The stream function constitutes the intermediate
representation that captures continuous variation and rotational flow details
absent from sketches.

</details>


### [2] [Sketch-based Fluid Video Generation Using Motion-Guided Diffusion Models in Still Landscape Images](https://arxiv.org/abs/2510.15874)
*Hao Jin,Haoran Xie*

Main category: cs.GR

TL;DR: 本文提出了一种通过运动草图指导静画中流体动画的框架，结合条件潜扩散模型和运动适配器，解决了现有方法在流体平滑和时间一致性运动方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 流体元素的动态特性在视觉计算中难以建模和控制，现有的物理方法和潜扩散模型在边界条件和时间一致性方面存在问题。

Method: 采用微调的条件潜扩散模型生成运动场，并通过运动适配器将其整合到潜视频扩散模型中，以精确控制流体运动。

Result: 提出的框架能够生成高质量且时间一致的流体动画，解决了现有方法的局限性。

Conclusion: 该框架为静画中的流体动画提供了一种高效且可控的解决方案，增强了视觉表现力和沉浸感。

Abstract: Integrating motion into static images not only enhances visual expressiveness
but also creates a sense of immersion and temporal depth, establishing it as a
longstanding and impactful theme in artistic expression. Fluid elements such as
waterfall, river, and oceans are common features in landscape, but their
complex dynamic characteristics pose significant challenges in modeling and
controlling their motion within visual computing. Physics-based methods are
often used in fluid animation to track particle movement. However, they are
easily affected by boundary conditions. Recently, latent diffusion models have
been applied to video generation tasks, demonstrating impressive capabilities
in producing high-quality and temporally coherent results. However, it is
challenging for the existing methods to animate fluid smooth and temporally
consistent motion. To solve these issues, this paper introduces a framework for
generating landscape videos by animating fluid in still images under the
guidance of motion sketches. We propose a finetuned conditional latent
diffusion model for generating motion field from user-provided sketches, which
are subsequently integrated into a latent video diffusion model via a motion
adapter to precisely control the fluid movement.

</details>


### [3] [Adaptive Frameless Rendering](https://arxiv.org/abs/2510.15876)
*Abhinav Dayal,Cliff Woolley,Benjamin Watson,David Luebke*

Main category: cs.GR

TL;DR: 提出了一种自适应无框架渲染方法，显著提升渲染速度，相较于传统交互式渲染方法，能更好地适应时空颜色变化。


<details>
  <summary>Details</summary>
Motivation: 传统的渲染方法受限于固定的采样模式，无法灵活适应图像中的时空颜色变化。本文旨在通过自适应采样和重建，显著提升渲染效率和图像质量。

Method: 采用闭环反馈机制引导采样朝向图像边缘或运动区域，使用基于GPU的重建技术，结合采样密度和时空颜色梯度。同时利用样本重投影改进重建质量和采样精度。

Result: 在模拟中，无框架渲染器所需样本量比传统渲染少一个数量级，且视觉质量相近（以RMS误差衡量），额外计算开销仅为15%。

Conclusion: 自适应无框架渲染方法在提升渲染速度和适应动态场景方面表现出色，为交互式渲染提供了新的解决方案。

Abstract: We propose an adaptive form of frameless rendering with the potential to
dramatically increase rendering speed over conventional interactive rendering
approaches. Without the rigid sampling patterns of framed renderers, sampling
and reconstruction can adapt with very fine granularity to spatio-temporal
color change. A sampler uses closed-loop feedback to guide sampling toward
edges or motion in the image. Temporally deep buffers store all the samples
created over a short time interval for use in reconstruction and as sampler
feedback. GPU-based reconstruction responds both to sampling density and
space-time color gradients. Where the displayed scene is static, spatial color
change dominates and older samples are given significant weight in
reconstruction, resulting in sharper and eventually antialiased images. Where
the scene is dynamic, more recent samples are emphasized, resulting in less
sharp but more up-to-date images. We also use sample reprojection to improve
reconstruction and guide sampling toward occlusion edges, undersampled regions,
and specular highlights. In simulation our frameless renderer requires an order
of magnitude fewer samples than traditional rendering of similar visual quality
(as measured by RMS error), while introducing overhead amounting to 15% of
computation time.

</details>


### [4] [Procedural modeling of urban land use](https://arxiv.org/abs/2510.15877)
*Thomas Lechner,Ben Watson,Uri Wilenski,Seth Tisue,Martin Felsen,Andy Moddrell,Pin Ren,Craig Brozefsky*

Main category: cs.GR

TL;DR: 提出了一种程序化生成城市土地利用方法，帮助艺术家自动放置建筑和道路。


<details>
  <summary>Details</summary>
Motivation: 城市是数字制作的重要内容元素，但其复杂性和规模使得建模极具挑战性，亟需工具支持。

Method: 采用程序化生成技术，自动生成城市中建筑和道路的现实分布模式。

Result: 提出了一种能够为艺术家自动化生成城市内容的工具。

Conclusion: 该方法能够满足对高质量内容的需求，同时节省制作成本。

Abstract: Cities are important elements of content in digital productions, but their
complexity and size make them very challenging to model. Few tools exist that
can help artists with this work, even as rapid improvements in graphics
hardware create demand for richer content without matching increases in
production cost. We propose a method for procedurally generating realistic
patterns of land use in cities, automating placement of buildings and roads for
artists.

</details>


### [5] [Structural Tree Extraction from 3D Surfaces](https://arxiv.org/abs/2510.15886)
*Diogo de Andrade,Nuno Fachada*

Main category: cs.GR

TL;DR: 提出了一种从3D非结构化多边形数据中提取层次树表示的方法，通过生成图表示和Steiner树优化连接，并结合视线约束减少冗余。该方法直接作用于表面，适用于导航感知的几何分析。


<details>
  <summary>Details</summary>
Motivation: 传统骨架化方法通常基于体积解释，而本研究提出了一种直接作用于表面的方法，以支持导航感知的几何分析和应用。

Method: 方法包括提取表面的图表示作为结构分析基础，生成Steiner树优化终端点连接，并通过视线约束进一步优化结构。

Result: 验证了两个用例：用于程序化内容生成的瓦片元素结构表示提取，以及自动关卡分析中的关键点和结构度量识别。结果表明其能够生成简化和连贯的表示。

Conclusion: 该方法能够有效支持程序化生成、空间推理和地图分析等应用，提供了一种不同于传统骨架化的新思路。

Abstract: This paper introduces a method to extract a hierarchical tree representation
from 3D unorganized polygonal data. The proposed approach first extracts a
graph representation of the surface, which serves as the foundation for
structural analysis. A Steiner tree is then generated to establish an optimized
connection between key terminal points, defined according to
application-specific criteria. The structure can be further refined by
leveraging line-of-sight constraints, reducing redundancy while preserving
essential connectivity. Unlike traditional skeletonization techniques, which
often assume volumetric interpretations, this method operates directly on the
surface, ensuring that the resulting representation remains relevant for
navigation-aware geometric analysis. The method is validated through two use
cases: extracting structural representations from tile-based elements for
procedural content generation, and identifying key points and structural
metrics for automated level analysis. Results demonstrate its ability to
produce simplified, coherent representations, supporting applications in
procedural generation, spatial reasoning, and map analysis.

</details>


### [6] [Procedural Scene Programs for Open-Universe Scene Generation: LLM-Free Error Correction via Program Search](https://arxiv.org/abs/2510.16147)
*Maxim Gumin,Do Heon Han,Seung Jean Yoo,Aditya Ganeshan,R. Kenny Jones,Kailiang Fu,Rio Aguina-Kang,Stewart Morris,Daniel Ritchie*

Main category: cs.GR

TL;DR: 该论文探讨了一种基于LLM的指令式方法，用于从开放性词汇文本描述中生成3D场景布局，优于传统的声明式方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景生成方法主要采用声明式范式，存在场景规格语言复杂且难以处理多样化场景的问题。

Method: 提出了一种指令式范式，通过LLM迭代放置对象，并为每个对象的位置和方向计算函数。

Result: 在感知研究中，参与者在82%和94%的情况下更偏好指令式方法生成的布局。

Conclusion: 指令式方法在3D场景布局生成中表现更优，并提出了一种与人类偏好一致的自动化评估指标。

Abstract: Synthesizing 3D scenes from open-vocabulary text descriptions is a
challenging, important, and recently-popular application. One of its critical
subproblems is layout generation: given a set of objects, lay them out to
produce a scene matching the input description. Nearly all recent work adopts a
declarative paradigm for this problem: using an LLM to generate a specification
of constraints between objects, then solving those constraints to produce the
final layout. In contrast, we explore an alternative imperative paradigm, in
which an LLM iteratively places objects, with each object's position and
orientation computed as a function of previously-placed objects. The imperative
approach allows for a simpler scene specification language while also handling
a wider variety and larger complexity of scenes. We further improve the
robustness of our imperative scheme by developing an error correction mechanism
that iteratively improves the scene's validity while staying as close as
possible to the original layout generated by the LLM. In forced-choice
perceptual studies, participants preferred layouts generated by our imperative
approach 82% and 94% of the time when compared against two declarative layout
generation methods. We also present a simple, automated evaluation metric for
3D scene layout generation that aligns well with human preferences.

</details>


### [7] [Region-Aware Wasserstein Distances of Persistence Diagrams and Merge Trees](https://arxiv.org/abs/2510.16486)
*Mathieu Pont,Christoph Garth*

Main category: cs.GR

TL;DR: 本文提出了一种针对持久图和合并树的Wasserstein距离的泛化方法，通过利用其在输入域中的拓扑特征的区域，定义了一种更为区分性的度量方法。


<details>
  <summary>Details</summary>
Motivation: 传统的Wasserstein距离在分析持久图和合并树时缺乏对拓扑特征区域的充分利用，限制了其区分性和实用性。

Method: 通过重新定义拓扑特征的比较方式，利用其极值对齐区域的值来定义距离，并通过输入参数调整区域属性的影响。此外，还提出了两种策略来控制计算时间和内存使用。

Result: 实验结果表明该方法效率高，平均运行时间在分钟级别。应用案例包括追踪拓扑特征的演化和用于降维的距离矩阵计算。

Conclusion: 该方法不仅在理论上扩展了Wasserstein距离，还通过实际应用展示了其在时间变化集成和可视化分析中的实用性，并提供了开源实现。

Abstract: This paper presents a generalization of the Wasserstein distance for both
persistence diagrams and merge trees [20], [66] that takes advantage of the
regions of their topological features in the input domain. Specifically, we
redefine the comparison of topological features as a distance between the
values of their extrema-aligned regions. It results in a more discriminative
metric than the classical Wasserstein distance and generalizes it through an
input parameter adjusting the impact of the region properties in the distance.
We present two strategies to control both computation time and memory storage
of our method by respectively enabling the use of subsets of the regions in the
computation, and by compressing the regions' properties to obtain low-memory
representations. Extensive experiments on openly available ensemble data
demonstrate the efficiency of our method, with running times on the orders of
minutes on average. We show the utility of our contributions with two
applications. First, we use the assignments between topological features
provided by our method to track their evolution in time-varying ensembles and
propose the temporal persistence curves to facilitate the understanding of how
these features appear, disappear and change over time. Second, our method
allows to compute a distance matrix of an ensemble that can be used for
dimensionality reduction purposes and visually represent in 2D all its members,
we show that such distance matrices also allow to detect key phases in the
ensemble. Finally, we provide a C++ implementation that can be used to
reproduce our results.

</details>


### [8] [Filtering of Small Components for Isosurface Generation](https://arxiv.org/abs/2510.16684)
*Devin Zhao,Rephael Wenger*

Main category: cs.GR

TL;DR: 该论文探讨了从扫描数据（如CT或MRI）构建的等值面中去除极小分量的过滤方法及其效果。


<details>
  <summary>Details</summary>
Motivation: 等值面中常包含极小的干扰分量，这些分量对可视化无益且不构成任何几何模型的一部分。

Method: 通过简单的数据预过滤方法去除极小分量，同时不影响构成可视化主体的较大分量。

Result: 展示了此类过滤方法的实验结果，证明了其有效性。

Conclusion: 预过滤能有效去除等值面中的极小干扰分量，提升可视化质量。

Abstract: Let $f: \mathbb{R}^3 \rightarrow \mathbb{R}$ be a scalar field. An isosurface
is a piecewise linear approximation of a level set $f^{-1}(\sigma)$ for some
$\sigma \in \mathbb{R}$ built from some regular grid sampling of $f$.
Isosurfaces constructed from scanned data such as CT scans or MRIs often
contain extremely small components that distract from the visualization and do
not form part of any geometric model produced from the data. Simple
prefiltering of the data can remove such small components while having no
effect on the large components that form the body of the visualization. We
present experimental results on such filtering.

</details>


### [9] [A Scalable In Transit Solution for Comprehensive Exploration of Simulation Data](https://arxiv.org/abs/2510.16966)
*Paascal Grosset,James Ahrens*

Main category: cs.GR

TL;DR: SeerX是一种轻量级、可扩展的in-transit原位服务，支持动态资源分配和3D模拟数据的有损压缩，解决了模拟数据存储和分析的资源需求未知问题。


<details>
  <summary>Details</summary>
Motivation: 由于超级计算器上模拟产生的数据量超过可用磁盘空间，需通过原位分析与可视化减少存储数据量，但现有方法因缺乏先验知识与动态资源分配受限。

Method: 提出SeerX服务，支持动态资源分配和有损压缩，允许多个模拟共享弹性服务基础设施，无需MPI同步。

Result: SeerX有效解决了模拟数据分析中资源需求未知和动态资源分配的问题，实现了数据的高效压缩与分析。

Conclusion: SeerX作为一种轻量级、可扩展的in-transit原位服务，为解决模拟数据存储和分析的动态资源需求提供了有效方案。

Abstract: As simulations produce more data than available disk space on supercomputers,
many simulations are employing in situ analysis and visualization to reduce the
amount of data that needs to be stored. While in situ visualization offers
potential for substantial data reduction, its efficacy is hindered by the need
for a priori knowledge. First, we need to know what visualization parameters to
use to highlight features of interest. Second, we do not know ahead of time how
much resources will be needed to run the in situ workflows, e.g. how many
compute nodes will be needed for in situ work. In this work, we present SeerX,
a lightweight, scalable in-transit in situ service that supports dynamic
resource allocation and lossy compression of 3D simulation data. SeerX enables
multiple simulations to offload analysis to a shared, elastic service
infrastructure without MPI synchronization.

</details>


### [10] [Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors](https://arxiv.org/abs/2510.17101)
*Lu Yin,Ziying Shi,Yinghao Wu,Xinyu Yi,Feng Xu,Shihui Guo*

Main category: cs.GR

TL;DR: SAIP是一种考虑体形差异的稀疏惯性运动捕捉方法，通过分解传感器测量中的体形和姿态信息，并结合回归模型和物理优化策略，实现了对不同体形个体的运动捕捉。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖模板成人体形建模训练数据，难以泛化到体形差异大的个体（如儿童）。SAIP旨在填补这一空白，考虑体形差异对IMU测量加速度的影响。

Method: SAIP通过回归模型将真实体形的IMU测量加速度转换为模板体形，再利用先进的运动捕捉方法估计姿态，最后通过回归模型和物理优化策略将姿态映射回真实体形。同时设计了MLP网络实现体形估计。

Result: 实验结果显示，SAIP能有效处理不同体形的运动捕捉任务。作者还发布了首个包含不同体形的IMU运动捕捉数据集，验证了方法的有效性。

Conclusion: SAIP是首个考虑体形差异的稀疏惯性运动捕捉方法，通过体形感知建模和优化策略，显著提升了运动捕捉的泛化能力，适用于多样化体形。

Abstract: Human motion capture with sparse inertial sensors has gained significant
attention recently. However, existing methods almost exclusively rely on a
template adult body shape to model the training data, which poses challenges
when generalizing to individuals with largely different body shapes (such as a
child). This is primarily due to the variation in IMU-measured acceleration
caused by changes in body shape. To fill this gap, we propose Shape-aware
Inertial Poser (SAIP), the first solution considering body shape differences in
sparse inertial-based motion capture. Specifically, we decompose the sensor
measurements related to shape and pose in order to effectively model their
joint correlations. Firstly, we train a regression model to transfer the
IMU-measured accelerations of a real body to match the template adult body
model, compensating for the shape-related sensor measurements. Then, we can
easily follow the state-of-the-art methods to estimate the full body motions of
the template-shaped body. Finally, we utilize a second regression model to map
the joint velocities back to the real body, combined with a shape-aware
physical optimization strategy to calculate global motions on the subject.
Furthermore, our method relies on body shape awareness, introducing the first
inertial shape estimation scheme. This is accomplished by modeling the
shape-conditioned IMU-pose correlation using an MLP-based network. To validate
the effectiveness of SAIP, we also present the first IMU motion capture dataset
containing individuals of different body sizes. This dataset features 10
children and 10 adults, with heights ranging from 110 cm to 190 cm, and a total
of 400 minutes of paired IMU-Motion samples. Extensive experimental results
demonstrate that SAIP can effectively handle motion capture tasks for diverse
body shapes. The code and dataset are available at
https://github.com/yinlu5942/SAIP.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [11] [Latency Based Tiling](https://arxiv.org/abs/2510.15912)
*Jack Cashman*

Main category: cs.PL

TL;DR: Latency Based Tiling 是一种基于延迟的系统方法，用于快速生成近似分块解决方案，以最大化局部性并减少编译时间。该方法通过三角循环和缓存未命中率缩放，估算系统的 L1、L2 和 L3 缓存大小，实现硬件无关的优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统自动调优方法（auto tuning）编译时间长的问题，并实现快速且高效的缓存分块优化，特别是在多进程共享缓存的环境中。

Method: 使用三角循环分析缓存未命中率缩放，通过数据访问延迟的变化确定缓存层级的大小（L1、L2、L3）。结合硬件无关的 Rust 实现，提供了一种便携且内存安全的解决方案。

Result: 该方法能够快速估算缓存层级大小，生成高效的分块策略，同时避免传统自动调优的高编译时间开销。在多种硬件平台上均表现良好。

Conclusion: Latency Based Tiling 提供了一种高效、快速的缓存分块优化方法，适用于多进程共享缓存的场景，并具有广泛的硬件兼容性。

Abstract: Latency Based Tiling provides a systems based approach to deriving
approximate tiling solution that maximizes locality while maintaining a fast
compile time. The method uses triangular loops to characterize miss ratio
scaling of a machine avoiding prefetcher distortion. Miss ratio scaling
captures the relationship between data access latency and working set size with
sharp increases in latency indicating the data footprint exceeds capacity from
a cache level. Through these noticeable increases in latency we can determine
an approximate location for L1, L2, and L3 memory sizes. These sizes are
expected to be under approximations of a systems true memory sizes which is in
line with our expectations given the shared nature of cache in a multi process
system as described in defensive loop tiling. Unlike auto tuning, which can be
effective but prohibitively slow, Latency Based Tiling achieves negligible
compile time overhead. The implementation in Rust enables a hardware agnostic
approach which combined with a cache timing based techniques, yields a
portable, memory safe system running wherever Rust is supported. The tiling
strategy is applied to a subset of the polyhedral model, where loop nestings
are tiled based on both the derived memory hierarchy and the observed data
footprint per iteration.

</details>


### [12] [Typing Strictness (Extended Version)](https://arxiv.org/abs/2510.16133)
*Daniel Sainati,Joseph W. Cutler,Benjamin C. Pierce,Stephanie Weirich*

Main category: cs.PL

TL;DR: 论文提出了一种新的严格性定义，改进了传统定义，通过类型系统更精确地描述变量的使用，并在不同的评估策略下验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 非严格评估语言的实现效率问题需要通过严格性分析来解决，但现有的严格性定义在源代码层面不够直观和准确。

Method: 作者提出了新的严格性定义，并在按名调用和按值推送调用的评估策略下建立了类型理论基础，还提供了类型系统间的翻译。

Result: 通过逻辑关系证明，类型系统计算的严格性属性能准确描述运行时变量使用，所有结果在Rocq中进行了机械化验证。

Conclusion: 论文的新定义和理论框架有效地改进了严格性分析的精确性和适用性，为非严格语言的实现提供了更好的理论基础。

Abstract: Strictness analysis is critical to efficient implementation of languages with
non-strict evaluation, mitigating much of the performance overhead of laziness.
However, reasoning about strictness at the source level can be challenging and
unintuitive. We propose a new definition of strictness that refines the
traditional one by describing variable usage more precisely. We lay
type-theoretic foundations for this definition in both call-by-name and
call-by-push-value settings, drawing inspiration from the literature on type
systems tracking effects and coeffects. We prove via a logical relation that
the strictness attributes computed by our type systems accurately describe the
use of variables at runtime, and we offer a strictness-annotation-preserving
translation from the call-by-name system to the call-by-push-value one. All our
results are mechanized in Rocq.

</details>


### [13] [SimpliPy: A Source-Tracking Notional Machine for Simplified Python](https://arxiv.org/abs/2510.16594)
*Moida Praneeth Jain,Venkatesh Choppella*

Main category: cs.PL

TL;DR: SimplePy 是一个为初学者设计的轻量级 Python 子集概念机，通过明确的语义和静态分析帮助学生理解程序执行和控制流，并提供交互式调试工具。


<details>
  <summary>Details</summary>
Motivation: 许多初学者对程序执行存在误解，因此需要一种工具来澄清核心控制流和作用域的概念。

Method: SimplePy 基于精确的操作语义，动态跟踪源代码行号，并结合静态分析生成控制流图（CFG）和识别词法作用域。此外，提供了一个基于这些原则的交互式网络调试器。

Result: SimplePy 通过集成形式化语义、程序分析和可视化技术，提供了教学方法和实际应用形式化方法的工具。

Conclusion: SimplePy 不仅是一种教学方法，也是形式化方法应用于程序理解的实践演示。

Abstract: Misconceptions about program execution hinder many novice programmers. We
introduce SimpliPy, a notional machine designed around a carefully chosen
Python subset to clarify core control flow and scoping concepts. Its foundation
is a precise operational semantics that explicitly tracks source code line
numbers for each execution step, making the link between code and behavior
unambiguous. Complementing the dynamic semantics, SimpliPy uses static analysis
to generate Control Flow Graphs (CFGs) and identify lexical scopes, helping
students build a structural understanding before tracing. We also present an
interactive web-based debugger built on these principles. This tool embodies
the formal techniques, visualizing the operational state (environments, stack)
and using the static CFG to animate control flow directly on the graph during
step-by-step execution. SimpliPy thus integrates formal semantics, program
analysis, and visualization to offer both a pedagogical approach and a
practical demonstration of applying formal methods to program understanding.

</details>


### [14] [JAX Autodiff from a Linear Logic Perspective (Extended Version)](https://arxiv.org/abs/2510.16883)
*Giulia Giusti,Michele Pagani*

Main category: cs.PL

TL;DR: 本文提出了一种将Autodiff编码到线性$\\lambda$-演算的方法，证明了其定性（扩展等价）和定量（工作成本保留）的正确性。


<details>
  <summary>Details</summary>
Motivation: 尽管Radul等人的线性类型化演算能表达Autodiff的主要程序变换，但其类型系统是否自成一派尚不明确。

Method: 通过线性$\\lambda$-演算实现Autodiff的编码，并与Girard的线性逻辑建立Curry-Howard对应。

Result: 证明了编码的定性（扩展等价）和定量（工作成本保留）正确性，同时发现反向传播中的unzipping是可选的。

Conclusion: 该编码不仅保留了Autodiff的功能特性，还揭示了unzipping的非必要性。

Abstract: Autodiff refers to the core of the automatic differentiation systems
developed in projects like JAX and Dex. Autodiff has recently been formalised
in a linear typed calculus by Radul et al in arXiv:2204.10923. Although this
formalisation suffices to express the main program transformations of Autodiff,
the calculus is very specific to this task, and it is not clear whether the
type system yields a substructural logic that has interest on its own.
  We propose an encoding of Autodiff into a linear $\lambda$-calculus that
enjoys a Curry-Howard correspondence with Girard's linear logic. We prove that
the encoding is sound both qualitatively (the encoded terms are extensionally
equivalent to the original ones) and quantitatively (the encoding preserves the
original work cost as described in arXiv:2204.10923). As a byproduct, we show
that unzipping, one of the transformations used to implement backpropagation in
Autodiff, is, in fact, optional.

</details>


### [15] [Introducing Linear Implication Types to $λ_{GT}$ for Computing With Incomplete Graphs](https://arxiv.org/abs/2510.17429)
*Jin Sano,Naoki Yamamoto,Kazunori Ueda*

Main category: cs.PL

TL;DR: 该论文提出了一种新的类型系统，解决了$\lambda_{GT}$语言在处理不完整图和动态类型检查方面的两个关键问题。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够直观且安全操作数据结构的编程语言是一个重要挑战。传统的内存操作复杂且易错，现有的类型系统（如仿射类型和形状类型）部分解决了堆和指针的安全操作问题，但高层次的声明性语言设计仍然是一个开放问题。$\lambda_{GT}$语言通过将数据抽象为图结构来实现声明式操作，但其类型系统存在不支持不完整图和依赖动态类型检查的问题。

Method: 该研究通过在线性类型的$\lambda_{GT}$类型系统中引入线性蕴涵和新约束，解决了不完整图和动态类型检查的问题。

Result: 新的类型系统支持不完整图的处理，并通过静态类型检查确保操作的安全性。

Conclusion: 这项研究不仅扩展了$\lambda_{GT}$语言的功能，还为高层次的声明性编程语言设计提供了新的方向。

Abstract: Designing programming languages that enable intuitive and safe manipulation
of data structures is a critical research challenge. Conventional destructive
memory operations using pointers are complex and prone to errors. Existing type
systems, such as affine types and shape types, address this problem towards
safe manipulation of heaps and pointers, but design of high-level declarative
languages that allow us to manipulate complex pointer data structures at a
higher level of abstraction is largely an open problem. The $\lambda_{GT}$
language, a purely functional programming language that treats hypergraphs
(hereafter referred to as graphs) as primary data structures, addresses some of
these challenges. By abstracting data with shared references and cycles as
graphs, it enables declarative operations through pattern matching and
leverages its type system to guarantee safety of these operations.
Nevertheless, the previously proposed type system of $\lambda_{GT}$ leaves two
significant open challenges. First, the type system does not support
\emph{incomplete graphs}, that is, graphs in which some elements are missing
from the graphs of user-defined types. Second, the type system relies on
dynamic type checking during pattern matching. This study addresses these two
challenges by incorporating linear implication into the $\lambda_{GT}$ type
system, while introducing new constraints to ensure its soundness.

</details>


### [16] [Insum: Sparse GPU Kernels Simplified and Optimized with Indirect Einsums](https://arxiv.org/abs/2510.17505)
*Jaeyeon Won,Willow Ahrens,Joel S. Emer,Saman Amarasinghe*

Main category: cs.PL

TL;DR: 提出了一种新的稀疏计算表达方法，通过间接索引将稀疏数据映射到密集张量操作，并使用Insum编译器生成高效的GPU代码。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏编译器设计主要用于CPU，且在处理稀疏与密集混合计算时优化不足。

Method: 从格式无关的稀疏张量Einsums重写为格式敏感的间接Einsums，并通过Insum编译器生成GPU代码。

Result: 该方法在稀疏GPU应用上实现了1.14x至3.81x的加速，代码量减少了202x至4491x。

Conclusion: 提出的间接Einsums和编译器能有效提升稀疏GPU计算的性能和开发效率。

Abstract: Programming high-performance sparse GPU kernels is notoriously difficult,
requiring both substantial effort and deep expertise. Sparse compilers aim to
simplify this process, but existing systems fall short in two key ways. First,
they are primarily designed for CPUs and rarely produce high-performance GPU
code. Second, when computations involve both sparse and dense regions, these
compilers often fail to optimize the dense portions effectively. In this paper,
we propose a new approach for expressing sparse computations. We start from
format-agnostic Einsums over sparse tensors and rewrite them into
format-conscious indirect Einsums, which explicitly encode format information
by mapping sparse data and metadata onto dense tensor operations through
indirect indexing. To execute indirect Einsums, we introduce the Insum
compiler, which generates efficient GPU code for these Einsums by lowering to
the PyTorch compiler, extended to better support Tensor Core-enabled indirect
Einsums. We also present two fixed-length sparse formats, GroupCOO and
BlockGroupCOO, designed to fit naturally with indirect Einsums. Our approach
achieves 1.14x to 3.81x speedups across a range of sparse GPU applications
while reducing lines of code by 202x to 4491x compared to hand-written
implementations.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [17] [The Strongly Stable Roommates Problem and Linear Programming](https://arxiv.org/abs/2510.16385)
*Naoyuki Kamiyama*

Main category: cs.GT

TL;DR: 本文提出了一种新的多项式时间算法，用于解决带有条件的稳定室友问题中的强稳定匹配存在性问题。


<details>
  <summary>Details</summary>
Motivation: 研究带有条件的稳定室友问题中的强稳定匹配存在性问题，填补现有方法的空白。

Method: 扩展了Abeledo和Blum的线性规划方法，将其从严格偏好的稳定室友问题扩展到带有条件的稳定室友问题。

Result: 提出了一种新的多项式时间算法，能够有效检查强稳定匹配的存在性。

Conclusion: 该方法为解决带有条件的稳定室友问题中的强稳定匹配提供了一种有效的算法支持。

Abstract: The stable roommates problem is a non-bipartite version of the stable
matching problem in a bipartite graph. In this paper, we consider the stable
roommates problem with ties. In particular, we focus on strong stability, which
is one of the main stability concepts in the stable roommates problem with
ties. We propose a new polynomial-time algorithm for the problem of checking
the existence of a strongly stable matching in the stable roommates problem
with ties. More concretely, we extend the linear programming approach of
Abeledo and Blum to the stable roommates problem with strict preferences to our
problem.

</details>


### [18] [No-Regret Online Autobidding Algorithms in First-price Auctions](https://arxiv.org/abs/2510.16869)
*Yuan Deng,Yilin Li,Wei Tang,Hanrui Zhang*

Main category: cs.GT

TL;DR: 本文提出了一种针对重复第一价格拍卖的在线竞价算法，通过ROI约束优化在线广告竞标，并在完全反馈和部分反馈设置下实现了近乎最优的遗憾边界。


<details>
  <summary>Details</summary>
Motivation: 在线广告竞标中的ROI约束和预算约束是常见的挑战，而现有研究多集中在真实拍卖或较弱的基准上。本文旨在填补这一空白，提出更高效的算法。

Method: 本文设计了在线竞价算法，用于重复第一价格拍卖场景，并在完全反馈（观察所有竞争出价）和部分反馈（仅观察是否获胜）两种设置下进行分析。

Result: 在完全反馈设置下，算法实现了接近最优的遗憾边界$\widetilde{O}(\sqrt{T})$；在部分反馈设置下，遗憾边界为$\widetilde{O}(T^{3/4})$。

Conclusion: 本文提出的算法在ROI约束下显著提高了在线广告竞标的效率，并在不同反馈机制下表现出近乎最优的性能。

Abstract: Automated bidding to optimize online advertising with various constraints,
e.g. ROI constraints and budget constraints, is widely adopted by advertisers.
A key challenge lies in designing algorithms for non-truthful mechanisms with
ROI constraints. While prior work has addressed truthful auctions or
non-truthful auctions with weaker benchmarks, this paper provides a significant
improvement: We develop online bidding algorithms for repeated first-price
auctions with ROI constraints, benchmarking against the optimal randomized
strategy in hindsight. In the full feedback setting, where the maximum
competing bid is observed, our algorithm achieves a near-optimal
$\widetilde{O}(\sqrt{T})$ regret bound, and in the bandit feedback setting
(where the bidder only observes whether the bidder wins each auction), our
algorithm attains $\widetilde{O}(T^{3/4})$ regret bound.

</details>


### [19] [Convergence of Regret Matching in Potential Games and Constrained Optimization](https://arxiv.org/abs/2510.17067)
*Ioannis Anagnostides,Emanuel Tewolde,Brian Hu Zhang,Ioannis Panageas,Vincent Conitzer,Tuomas Sandholm*

Main category: cs.GT

TL;DR: 论文研究了遗憾匹配（RM）及其变体在现代AI中的应用，证明了交替RM$^+$在约束优化问题中的高效收敛性，并揭示了RM与RM$^+$之间的理论差异。


<details>
  <summary>Details</summary>
Motivation: 遗憾匹配及其变体在解决零和游戏中表现突出，但其在更广泛游戏或优化问题中的收敛性缺乏理论支持。论文旨在填补这一空白，特别是潜在游戏中的纳什均衡收敛问题。

Method: 论文通过交替RM$^+$方法，分析了其收敛到$ϵ$-KKT点的迭代次数，并探讨了KKT差与累积遗憾的关系。

Result: 结果表明，交替RM$^+$在$O_ϵ(1/ϵ^4)$次迭代内收敛，而RM在某些情况下可能需要指数时间。

Conclusion: RM$^+$在约束优化问题中是一种高效的一阶优化器，而其与RM的收敛速度差异揭示了潜在游戏中均衡收敛的理论分界。

Abstract: Regret matching (RM} -- and its modern variants -- is a foundational online
algorithm that has been at the heart of many AI breakthrough results in solving
benchmark zero-sum games, such as poker. Yet, surprisingly little is known so
far in theory about its convergence beyond two-player zero-sum games. For
example, whether regret matching converges to Nash equilibria in potential
games has been an open problem for two decades. Even beyond games, one could
try to use RM variants for general constrained optimization problems. Recent
empirical evidence suggests that they -- particularly regret matching$^+$
(RM$^+$) -- attain strong performance on benchmark constrained optimization
problems, outperforming traditional gradient descent-type algorithms.
  We show that alternating RM$^+$ converges to an $\epsilon$-KKT point after
$O_\epsilon(1/\epsilon^4)$ iterations, establishing for the first time that it
is a sound and fast first-order optimizer. Our argument relates the KKT gap to
the accumulated regret, two quantities that are entirely disparate in general
but interact in an intriguing way in our setting, so much so that when regrets
are bounded, our complexity bound improves all the way to
$O_\epsilon(1/\epsilon^2)$. From a technical standpoint, while RM$^+$ does not
have the usual one-step improvement property in general, we show that it does
in a certain region that the algorithm will quickly reach and remain in
thereafter. In sharp contrast, our second main result establishes a lower
bound: RM, with or without alternation, can take an exponential number of
iterations to reach a crude approximate solution even in two-player potential
games. This represents the first worst-case separation between RM and RM$^+$.
Our lower bound shows that convergence to coarse correlated equilibria in
potential games is exponentially faster than convergence to Nash equilibria.

</details>


### [20] [Eliciting Truthful Feedback for Preference-Based Learning via the VCG Mechanism](https://arxiv.org/abs/2510.17285)
*Leo Landolt,Anna Maddux,Andreas Schlaginhaufen,Saurabh Vaishampayan,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 该论文提出一种结合偏好学习和VCG支付的算法，用于战略代理的资源分配问题，以近似真实、个体合理且高效的方式解决成本报告的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究资源分配问题，代理人的成本函数可能未知或难以明确指定，且可能策略性虚报成本，导致社会成本最小化的挑战。

Method: 算法结合D-optimal设计的选择查询、最大似然估计成本参数，以及基于VCG的分配和支付。

Result: 在一次性设置中，算法近似真实、个体合理且高效；在线设置中，这些保证以亚线性遗憾率渐进成立，并在电力市场需求响应案例中验证了效果。

Conclusion: 论文提出的方法有效解决了战略代理资源分配中的主要挑战，并为实际应用提供了理论支持和实证验证。

Abstract: We study resource allocation problems in which a central planner allocates
resources among strategic agents with private cost functions in order to
minimize a social cost, defined as an aggregate of the agents' costs. This
setting poses two main challenges: (i) the agents' cost functions may be
unknown to them or difficult to specify explicitly, and (ii) agents may
misreport their costs strategically. To address these challenges, we propose an
algorithm that combines preference-based learning with Vickrey-Clarke-Groves
(VCG) payments to incentivize truthful reporting. Our algorithm selects
informative preference queries via D-optimal design, estimates cost parameters
through maximum likelihood, and computes VCG allocations and payments based on
these estimates. In a one-shot setting, we prove that the mechanism is
approximately truthful, individually rational, and efficient up to an error of
$\tilde{\mathcal O}(K^{-1/2})$ for $K$ preference queries per agent. In an
online setting, these guarantees hold asymptotically with sublinear regret at a
rate of $\tilde{\mathcal O}(T^{2/3})$ after $T$ rounds. Finally, we validate
our approach through a numerical case study on demand response in local
electricity markets.

</details>
