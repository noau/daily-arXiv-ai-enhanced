{"id": "2601.14543", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.14543", "abs": "https://arxiv.org/abs/2601.14543", "authors": ["Zhuofan Jia", "Jian Pei"], "title": "Shapley Value on Uncertain Data", "comment": null, "summary": "The Shapley value provides a principled framework for fairly distributing rewards among participants according to their individual contributions. While prior work has applied this concept to data valuation in machine learning, existing formulations overwhelmingly assume that each participant contributes a fixed, deterministic dataset. In practice, however, data owners often provide samples drawn from underlying probabilistic distributions, introducing stochasticity into their marginal contributions and rendering the Shapley value itself a random variable. This work addresses this gap by proposing a framework for the Shapley value of probabilistic data distributions that quantifies both the expected contribution and the variance of each participant, thereby capturing uncertainty induced by random sampling. We develop theoretical and empirical methodologies for estimating these quantities: on the theoretical side, we derive unbiased estimators for the expectation and variance of the probabilistic Shapley value and analyze their statistical properties; on the empirical side, we introduce three Monte Carlo-based estimation algorithms - a baseline estimator using independent samples, a pooled estimator that improves efficiency through sample reuse, and a stratified pooled estimator that adaptively allocates sampling budget based on player-specific variability. Experiments on synthetic and real datasets demonstrate that these methods achieve strong accuracy-efficiency trade-offs, with the stratified pooled approach attaining substantial variance reduction at minimal additional cost. By extending Shapley value analysis from deterministic datasets to probabilistic data distributions, this work provides both theoretical rigor and practical tools for fair and reliable data valuation in modern stochastic data-sharing environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u6982\u7387\u6570\u636e\u5206\u5e03\u7684Shapley\u503c\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u6bcf\u4e2a\u53c2\u4e0e\u8005\u7684\u671f\u671b\u8d21\u732e\u548c\u65b9\u5dee\uff0c\u4ece\u800c\u6355\u83b7\u968f\u673a\u91c7\u6837\u5f15\u5165\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5047\u8bbe\u53c2\u4e0e\u8005\u63d0\u4f9b\u56fa\u5b9a\u4e14\u786e\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u800c\u5b9e\u8df5\u4e2d\u6570\u636e\u6240\u6709\u8005\u901a\u5e38\u63d0\u4f9b\u4ece\u6982\u7387\u5206\u5e03\u4e2d\u62bd\u53d6\u7684\u6837\u672c\uff0c\u5bfc\u81f4\u8fb9\u9645\u8d21\u732e\u5177\u6709\u968f\u673a\u6027\uff0cShapley\u503c\u672c\u8eab\u4e5f\u6210\u4e3a\u968f\u673a\u53d8\u91cf\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u6982\u7387Shapley\u503c\u7684\u671f\u671b\u548c\u65b9\u5dee\u7684\u65e0\u504f\u4f30\u8ba1\u91cf\uff0c\u5e76\u5206\u6790\u4e86\u5176\u7edf\u8ba1\u6027\u8d28\uff1b\u540c\u65f6\u63d0\u51fa\u4e86\u4e09\u79cd\u8499\u7279\u5361\u7f57\u4f30\u8ba1\u7b97\u6cd5\uff08\u57fa\u7ebf\u4f30\u8ba1\u5668\u3001\u6c60\u5316\u4f30\u8ba1\u5668\u548c\u5206\u5c42\u6c60\u5316\u4f30\u8ba1\u5668\uff09\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u5176\u4e2d\u5206\u5c42\u6c60\u5316\u65b9\u6cd5\u4ee5\u6700\u5c0f\u7684\u989d\u5916\u6210\u672c\u5b9e\u73b0\u4e86\u663e\u8457\u65b9\u5dee\u51cf\u5c11\u3002", "conclusion": "\u901a\u8fc7\u5c06Shapley\u503c\u5206\u6790\u4ece\u786e\u5b9a\u6027\u6570\u636e\u96c6\u6269\u5c55\u5230\u6982\u7387\u6570\u636e\u5206\u5e03\uff0c\u8be5\u7814\u7a76\u4e3a\u73b0\u4ee3\u968f\u673a\u6570\u636e\u5171\u4eab\u73af\u5883\u4e2d\u7684\u516c\u5e73\u53ef\u9760\u6570\u636e\u4f30\u503c\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u6027\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.15148", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.15148", "abs": "https://arxiv.org/abs/2601.15148", "authors": ["Vipin Ravindran Vijayalakshmi", "Marc Schroder", "Tami Tamir"], "title": "Interval Scheduling Games", "comment": null, "summary": "We consider a game-theoretic variant of an interval scheduling problem. Every job is associated with a length, a weight, and a color. Each player controls all the jobs of a specific color, and needs to decide on a processing interval for each of its jobs. Jobs of the same color can be processed simultaneously by the machine. A job is covered if the machine is configured to its color during its whole processing interval. The goal of the machine is to maximize the sum of weights of all covered jobs, and the goal of each player is to place its jobs such that the sum of weights of covered jobs from its color is maximized. The study of this game is motivated by several applications like antenna scheduling for wireless networks.\n  We first show that given a strategy profile of the players, the machine scheduling problem can be solved in polynomial time. We then study the game from the players' point of view. We analyze the existence of Nash equilibria, its computation, and inefficiency. We distinguish between instances of the classical interval scheduling problem, in which every player controls a single job, and instances in which color sets may include multiple jobs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\u7684\u535a\u5f08\u8bba\u53d8\u4f53\uff0c\u6d89\u53ca\u4f5c\u4e1a\u7684\u957f\u5ea6\u3001\u6743\u91cd\u548c\u989c\u8272\uff0c\u73a9\u5bb6\u901a\u8fc7\u7b56\u7565\u6700\u5927\u5316\u81ea\u8eab\u989c\u8272\u7684\u8986\u76d6\u4f5c\u4e1a\u6743\u91cd\u603b\u548c\uff0c\u673a\u5668\u5219\u6700\u5927\u5316\u6240\u6709\u8986\u76d6\u4f5c\u4e1a\u7684\u603b\u6743\u91cd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u81ea\u65e0\u7ebf\u7f51\u7edc\u5929\u7ebf\u8c03\u5ea6\u7b49\u5b9e\u9645\u5e94\u7528\u95ee\u9898\uff0c\u63a2\u8ba8\u591a\u73a9\u5bb6\u535a\u5f08\u73af\u5883\u4e0b\u7684\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\u3002", "method": "\u9996\u5148\u8bc1\u660e\u73a9\u5bb6\u7b56\u7565\u4e0b\u673a\u5668\u8c03\u5ea6\u95ee\u9898\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u7136\u540e\u4ece\u73a9\u5bb6\u89c6\u89d2\u5206\u6790\u7eb3\u4ec0\u5747\u8861\u7684\u5b58\u5728\u6027\u3001\u8ba1\u7b97\u548c\u6548\u7387\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u8868\u660e\u673a\u5668\u8c03\u5ea6\u95ee\u9898\u5728\u7ed9\u5b9a\u7b56\u7565\u4e0b\u53ef\u9ad8\u6548\u89e3\u51b3\uff0c\u540c\u65f6\u533a\u5206\u4e86\u5355\u4f5c\u4e1a\u548c\u591a\u4f5c\u4e1a\u73a9\u5bb6\u7684\u4e0d\u540c\u535a\u5f08\u573a\u666f\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u535a\u5f08\u8bba\u65b9\u6cd5\u5206\u6790\u4e86\u533a\u95f4\u8c03\u5ea6\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u591a\u73a9\u5bb6\u8c03\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2601.15211", "categories": ["cs.GT", "cs.HC", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.15211", "abs": "https://arxiv.org/abs/2601.15211", "authors": ["Mayada Oudah", "John Wooders"], "title": "Real-time Facial Communication Restores Cooperation After Defection in Social Dilemmas", "comment": "16 pages, 12 figures. Includes Supplementary Information (18 pages, 17 figures)", "summary": "Facial expressions are central to human interaction, yet their role in strategic decision-making has received limited attention. We investigate how real-time facial communication influences cooperation in repeated social dilemmas. In a laboratory experiment, participants play a repeated Prisoner's Dilemma game under two conditions: in one, they observe their counterpart's facial expressions via gender-neutral avatars, and in the other no facial cues are available. Using state-of-the-art biometric technology to capture and display emotions in real-time, we find that facial communication significantly increases overall cooperation and, notably, promotes cooperation following defection. This restorative effect suggests that facial expressions help participants interpret defections less harshly, fostering forgiveness and the resumption of cooperation. While past actions remain the strongest predictor of behavior, our findings highlight the communicative power of facial expressions in shaping strategic outcomes. These results offer practical insights for designing emotionally responsive virtual agents and digital platforms that sustain cooperation in the absence of physical presence.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b9e\u65f6\u9762\u90e8\u8868\u60c5\u6c9f\u901a\u5728\u91cd\u590d\u56da\u5f92\u56f0\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u6574\u4f53\u5408\u4f5c\u7387\uff0c\u5e76\u4fc3\u8fdb\u80cc\u53db\u540e\u7684\u5408\u4f5c\u6062\u590d\uff0c\u663e\u793a\u9762\u90e8\u8868\u60c5\u6709\u52a9\u4e8e\u51cf\u5c11\u5bf9\u80cc\u53db\u7684\u8d1f\u9762\u89e3\u8bfb\u3002", "motivation": "\u9762\u90e8\u8868\u60c5\u5728\u4eba\u7c7b\u4e92\u52a8\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5728\u6218\u7565\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u9c9c\u6709\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5b9e\u65f6\u9762\u90e8\u8868\u60c5\u6c9f\u901a\u5982\u4f55\u5f71\u54cd\u91cd\u590d\u793e\u4f1a\u56f0\u5883\u4e2d\u7684\u5408\u4f5c\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u53c2\u4e0e\u8005\u5206\u522b\u5728\u6709\u9762\u90e8\u8868\u60c5\u6c9f\u901a\uff08\u901a\u8fc7\u6027\u522b\u4e2d\u7acb\u865a\u62df\u5f62\u8c61\uff09\u548c\u65e0\u9762\u90e8\u8868\u60c5\u6c9f\u901a\u7684\u6761\u4ef6\u4e0b\u73a9\u91cd\u590d\u56da\u5f92\u56f0\u5883\u6e38\u620f\u3002\u7814\u7a76\u4f7f\u7528\u5148\u8fdb\u7684\u751f\u7269\u8bc6\u522b\u6280\u672f\u5b9e\u65f6\u6355\u6349\u548c\u663e\u793a\u60c5\u7eea\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u9762\u90e8\u8868\u60c5\u6c9f\u901a\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u5408\u4f5c\u7387\uff0c\u5e76\u7279\u522b\u4fc3\u8fdb\u4e86\u80cc\u53db\u540e\u7684\u5408\u4f5c\u6062\u590d\uff0c\u8868\u660e\u9762\u90e8\u8868\u60c5\u6709\u52a9\u4e8e\u51cf\u8f7b\u5bf9\u80cc\u53db\u7684\u8d1f\u9762\u89e3\u8bfb\uff0c\u4fc3\u8fdb\u5bbd\u6055\u548c\u5408\u4f5c\u7ee7\u7eed\u3002", "conclusion": "\u9762\u90e8\u8868\u60c5\u5bf9\u6218\u7565\u7ed3\u679c\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u865a\u62df\u73af\u5883\u4e2d\u4fc3\u8fdb\u5408\u4f5c\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u60c5\u611f\u54cd\u5e94\u5f0f\u865a\u62df\u4ee3\u7406\u548c\u6570\u5b57\u5e73\u53f0\u63d0\u4f9b\u4e86\u5b9e\u8df5\u542f\u793a\uff0c\u4ee5\u5728\u7269\u7406\u7f3a\u5e2d\u7684\u60c5\u51b5\u4e0b\u7ef4\u6301\u5408\u4f5c\u3002"}}
{"id": "2601.15258", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.15258", "abs": "https://arxiv.org/abs/2601.15258", "authors": ["Argyrios Deligkas", "Panagiotis Kanellopoulos", "Alexandros A. Voudouris"], "title": "Distributed Agent-Constrained Truthful Facility Location", "comment": null, "summary": "We study a distributed facility location problem in which a set of agents, each with a private position on the real line, is partitioned into a collection of fixed, disjoint groups. The goal is to open $k$ facilities at locations chosen from the set of positions reported by the agents. This decision is made by mechanisms that operate in two phases. In Phase 1, each group selects the position of one of its agents to serve as the group's representative location. In Phase 2, $k$ representatives are chosen as facility locations. Once the facility locations are determined, each agent incurs an individual cost, defined either as the sum of its distances to all facilities (sum-variant) or as the distance to its farthest facility (max-variant). We focus on the class of strategyproof mechanisms, which preclude the agents from benefiting through strategic misreporting, and establish tight bounds on the approximation ratio with respect to the social cost (the total individual agent cost) in both variants.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u5206\u5e03\u5f0f\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\uff0c\u5176\u4e2d\u4e00\u7ec4\u4ee3\u7406\u4eba\u5728\u5b9e\u7ebf\u4e0a\u5206\u5e03\uff0c\u5e76\u88ab\u5212\u5206\u4e3a\u56fa\u5b9a\u4e14\u4e0d\u76f8\u4ea4\u7684\u7fa4\u4f53\u3002\u76ee\u6807\u662f\u9009\u62e9\u4ee3\u7406\u4eba\u62a5\u544a\u7684k\u4e2a\u4f4d\u7f6e\u4f5c\u4e3a\u8bbe\u65bd\u70b9\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u673a\u5236\u5b9e\u73b0\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u4ee3\u7406\u4eba\u5206\u5e03\u4e14\u5206\u7ec4\u7684\u573a\u666f\u4e0b\uff0c\u516c\u5e73\u4e14\u9ad8\u6548\u5730\u9009\u62e9\u8bbe\u65bd\u4f4d\u7f6e\uff0c\u540c\u65f6\u9632\u6b62\u4ee3\u7406\u4eba\u901a\u8fc7\u7b56\u7565\u6027\u62a5\u544a\u4f4d\u7f6e\u83b7\u76ca\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u673a\u5236\uff1a\u7b2c\u4e00\u9636\u6bb5\u6bcf\u7ec4\u9009\u62e9\u4e00\u4e2a\u4ee3\u7406\u4eba\u4f4d\u7f6e\u4f5c\u4e3a\u4ee3\u8868\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4ece\u6240\u6709\u4ee3\u8868\u4e2d\u9009\u62e9k\u4e2a\u4f4d\u7f6e\u4f5c\u4e3a\u8bbe\u65bd\u70b9\u3002", "result": "\u9488\u5bf9\u4e24\u79cd\u4e2a\u4f53\u6210\u672c\u5b9a\u4e49\uff08\u603b\u548c\u53d8\u4f53\u548c\u6700\u5927\u503c\u53d8\u4f53\uff09\uff0c\u5efa\u7acb\u4e86\u7b56\u7565\u8bc1\u660e\u673a\u5236\u5728\u793e\u4f1a\u6210\u672c\u4e0a\u7684\u7d27\u754c\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5206\u5e03\u5f0f\u8bbe\u65bd\u4f4d\u7f6e\u95ee\u9898\u63d0\u4f9b\u4e86\u7b56\u7565\u8bc1\u660e\u673a\u5236\u7684\u7d27\u754c\u8fd1\u4f3c\u6bd4\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2601.14766", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.14766", "abs": "https://arxiv.org/abs/2601.14766", "authors": ["Chun Chen", "Minseok Chae", "Seung-Woo Nam", "Myeong-Ho Choi", "Minseong Kim", "Eunbi Lee", "Yoonchan Jeong", "Jae-Hyeung Park"], "title": "PAColorHolo: A Perceptually-Aware Color Management Framework for Holographic Displays", "comment": "Preprint (accepted to ACM TOG), 34 pages, 32 figures", "summary": "Holographic displays offer significant potential for augmented and virtual reality applications by reconstructing wavefronts that enable continuous depth cues and natural parallax without vergence-accommodation conflict. However, despite advances in pixel-level image quality, current systems struggle to achieve perceptually accurate color reproduction--an essential component of visual realism. These challenges arise from complex system-level distortions caused by coherent laser illumination, spatial light modulator imperfections, chromatic aberrations, and camera-induced color biases. In this work, we propose a perceptually-aware color management framework for holographic displays that jointly addresses input-output color inconsistencies through color space transformation, adaptive illumination control, and neural network-based perceptual modeling of the camera's color response. We validate the effectiveness of our approach through numerical simulations, optical experiments, and a controlled user study. The results demonstrate substantial improvements in perceptual color fidelity, laying the groundwork for perceptually driven holographic rendering in future systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u611f\u77e5\u9a71\u52a8\u7684\u989c\u8272\u7ba1\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5168\u606f\u663e\u793a\u4e2d\u989c\u8272\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u771f\u5b9e\u611f\u3002", "motivation": "\u5168\u606f\u663e\u793a\u5728\u589e\u5f3a\u548c\u865a\u62df\u73b0\u5b9e\u5e94\u7528\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5f53\u524d\u7cfb\u7edf\u5728\u989c\u8272\u518d\u73b0\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u5f71\u54cd\u4e86\u89c6\u89c9\u771f\u5b9e\u611f\u3002", "method": "\u901a\u8fc7\u8272\u5f69\u7a7a\u95f4\u53d8\u6362\u3001\u81ea\u9002\u5e94\u7167\u660e\u63a7\u5236\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u76f8\u673a\u989c\u8272\u54cd\u5e94\u5efa\u6a21\uff0c\u8054\u5408\u89e3\u51b3\u8f93\u5165\u8f93\u51fa\u989c\u8272\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "result": "\u6570\u503c\u6a21\u62df\u3001\u5149\u5b66\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u611f\u77e5\u989c\u8272\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u7cfb\u7edf\u7684\u611f\u77e5\u9a71\u52a8\u5168\u606f\u6e32\u67d3\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.15167", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15167", "abs": "https://arxiv.org/abs/2601.15167", "authors": ["Francesca Randone", "Romina Doz", "Mirco Tribastone", "Luca Bortolussi"], "title": "DeGAS: Gradient-Based Optimization of Probabilistic Programs without Sampling", "comment": null, "summary": "We present DeGAS, a differentiable Gaussian approximate semantics for loopless probabilistic programs that enables sample-free, gradient-based optimization in models with both continuous and discrete components. DeGAS evaluates programs under a Gaussian-mixture semantics and replaces measure-zero predicates and discrete branches with a vanishing smoothing, yielding closed-form expressions for posterior and path probabilities. We prove differentiability of these quantities with respect to program parameters, enabling end-to-end optimization via standard automatic differentiation, without Monte Carlo estimators. On thirteen benchmark programs, DeGAS achieves accuracy and runtime competitive with variational inference and MCMC. Importantly, it reliably tackles optimization problems where sampling-based baselines fail to converge due to conditioning involving continuous variables.", "AI": {"tldr": "DeGAS\u662f\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u9ad8\u65af\u8fd1\u4f3c\u8bed\u4e49\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u65e0\u5faa\u73af\u6982\u7387\u7a0b\u5e8f\uff0c\u652f\u6301\u5bf9\u5305\u542b\u8fde\u7eed\u548c\u79bb\u6563\u7ec4\u4ef6\u7684\u6a21\u578b\u8fdb\u884c\u65e0\u91c7\u6837\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u3002", "motivation": "\u6982\u7387\u7a0b\u5e8f\u4e2d\u5305\u542b\u8fde\u7eed\u548c\u79bb\u6563\u53d8\u91cf\u65f6\uff0c\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\uff08\u5982MCMC\uff09\u53ef\u80fd\u5728\u4f18\u5316\u95ee\u9898\u65f6\u96be\u4ee5\u6536\u655b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u91c7\u6837\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "DeGAS\u91c7\u7528\u9ad8\u65af\u6df7\u5408\u8bed\u4e49\u8bc4\u4f30\u7a0b\u5e8f\uff0c\u5e76\u4f7f\u7528\u5e73\u6ed1\u6280\u672f\u66ff\u4ee3\u96f6\u6d4b\u5ea6\u8c13\u8bcd\u548c\u79bb\u6563\u5206\u652f\uff0c\u4ece\u800c\u5f97\u5230\u540e\u9a8c\u548c\u8def\u5f84\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u7a0b\u5e8f\u4e0a\uff0cDeGAS\u7684\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u8868\u73b0\u4e0e\u53d8\u5206\u63a8\u65ad\u548cMCMC\u76f8\u5f53\uff0c\u5e76\u5728\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u5931\u8d25\u7684\u4f18\u5316\u95ee\u9898\u4e0a\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "DeGAS\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u9ad8\u65af\u8fd1\u4f3c\u8bed\u4e49\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65e0\u5faa\u73af\u6982\u7387\u7a0b\u5e8f\u7684\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u57fa\u4e8e\u91c7\u6837\u65b9\u6cd5\u5728\u6d89\u53ca\u8fde\u7eed\u53d8\u91cf\u65f6\u7684\u6536\u655b\u95ee\u9898\u3002"}}
{"id": "2601.14844", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14844", "abs": "https://arxiv.org/abs/2601.14844", "authors": ["Zhe Chang", "Haodong Jin", "Yan Song", "Hui Yu"], "title": "CAG-Avatar: Cross-Attention Guided Gaussian Avatars for High-Fidelity Head Reconstruction", "comment": null, "summary": "Creating high-fidelity, real-time drivable 3D head avatars is a core challenge in digital animation. While 3D Gaussian Splashing (3D-GS) offers unprecedented rendering speed and quality, current animation techniques often rely on a \"one-size-fits-all\" global tuning approach, where all Gaussian primitives are uniformly driven by a single expression code. This simplistic approach fails to unravel the distinct dynamics of different facial regions, such as deformable skin versus rigid teeth, leading to significant blurring and distortion artifacts. We introduce Conditionally-Adaptive Gaussian Avatars (CAG-Avatar), a framework that resolves this key limitation. At its core is a Conditionally Adaptive Fusion Module built on cross-attention. This mechanism empowers each 3D Gaussian to act as a query, adaptively extracting relevant driving signals from the global expression code based on its canonical position. This \"tailor-made\" conditioning strategy drastically enhances the modeling of fine-grained, localized dynamics. Our experiments confirm a significant improvement in reconstruction fidelity, particularly for challenging regions such as teeth, while preserving real-time rendering performance.", "AI": {"tldr": "CAG-Avatar\u6846\u67b6\u901a\u8fc7\u6761\u4ef6\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\u89e3\u51b3\u4e86\u73b0\u67093D\u9ad8\u65af\u55b7\u6d12\u6280\u672f\u4e2d\u5168\u5c40\u8c03\u8c10\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5934\u50cf\u7684\u7cbe\u7ec6\u52a8\u6001\u5efa\u6a21\u548c\u91cd\u5efa\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u76843D\u9ad8\u65af\u55b7\u6d12\u6280\u672f\u5728\u9a71\u52a83D\u5934\u50cf\u52a8\u753b\u65f6\uff0c\u91c7\u7528\u5168\u5c40\u7edf\u4e00\u7684\u8868\u8fbe\u4ee3\u7801\uff0c\u672a\u80fd\u8003\u8651\u9762\u90e8\u4e0d\u540c\u533a\u57df\u7684\u52a8\u6001\u5dee\u5f02\uff0c\u5bfc\u81f4\u6a21\u7cca\u548c\u5931\u771f\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u6761\u4ef6\u81ea\u9002\u5e94\u9ad8\u65af\u5934\u50cf\uff08CAG-Avatar\uff09\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u4e00\u4e2a\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u6761\u4ef6\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\uff0c\u4f7f\u6bcf\u4e2a\u9ad8\u65af\u67e5\u8be2\u80fd\u591f\u6839\u636e\u5176\u89c4\u8303\u4f4d\u7f6e\u81ea\u9002\u5e94\u63d0\u53d6\u9a71\u52a8\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u7279\u522b\u662f\u5728\u7259\u9f7f\u7b49\u6311\u6218\u6027\u533a\u57df\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b9e\u65f6\u6e32\u67d3\u6027\u80fd\u3002", "conclusion": "CAG-Avatar\u6846\u67b6\u901a\u8fc7\u6761\u4ef6\u81ea\u9002\u5e94\u9a71\u52a8\u4fe1\u53f7\u7684\u63d0\u53d6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u9ad8\u4fdd\u771f\u3001\u5b9e\u65f6\u9a71\u52a8\u76843D\u5934\u50cf\u52a8\u753b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.15180", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.15180", "abs": "https://arxiv.org/abs/2601.15180", "authors": ["Pedro \u00c2ngelo", "Atsushi Igarashi", "Yuito Murase", "Vasco T. Vasconcelos"], "title": "Contextual Metaprogramming for Session Types", "comment": "36 pages, 14 figures, ESOP 2026", "summary": "We propose the integration of staged metaprogramming into a session-typed message passing functional language. We build on a model of contextual modal type theory with multi-level contexts, where contextual values, closing arbitrary terms over a series of variables, may be boxed and transmitted in messages. Once received, one such value may then be unboxed and locally applied before being run. To motivate this integration, we present examples of real-world use cases, for which our system would be suitable, such as servers preparing and shipping code on demand via session typed messages. We present a type system that distinguishes linear (used exactly once) from unrestricted (used an unbounded number of times) resources, and further define a type checker, suitable for a concrete implementation. We show type preservation, a progress result for sequential computations and absence of runtime errors for the concurrent runtime environment, as well as the correctness of the type checker.", "AI": {"tldr": "\u5c06\u5206\u9636\u6bb5\u5143\u7f16\u7a0b\u6574\u5408\u5230\u4f1a\u8bdd\u7c7b\u578b\u7684\u6d88\u606f\u4f20\u9012\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u7ea7\u4e0a\u4e0b\u6587\u7684\u4e0a\u4e0b\u6587\u6a21\u6001\u7c7b\u578b\u7406\u8bba\u6a21\u578b\uff0c\u652f\u6301\u5c06\u4e0a\u4e0b\u6587\u503c\u88c5\u7bb1\u5e76\u5728\u6d88\u606f\u4e2d\u4f20\u8f93\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u670d\u52a1\u5668\u6309\u9700\u51c6\u5907\u548c\u53d1\u9001\u4ee3\u7801\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\u7684\u9700\u6c42\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u652f\u6301\u7ebf\u6027\u4e0e\u65e0\u9650\u5236\u8d44\u6e90\u533a\u5206\u7684\u7c7b\u578b\u7cfb\u7edf\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u7ea7\u4e0a\u4e0b\u6587\u7684\u4e0a\u4e0b\u6587\u6a21\u6001\u7c7b\u578b\u7406\u8bba\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e86\u7c7b\u578b\u68c0\u67e5\u5668\uff0c\u5e76\u533a\u5206\u4e86\u7ebf\u6027\u548c\u65e0\u9650\u5236\u8d44\u6e90\u3002", "result": "\u5c55\u793a\u4e86\u7c7b\u578b\u4fdd\u7559\u6027\u3001\u987a\u5e8f\u8ba1\u7b97\u7684\u8fdb\u5c55\u6027\u4ee5\u53ca\u5e76\u53d1\u8fd0\u884c\u65f6\u73af\u5883\u7684\u65e0\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u7c7b\u578b\u68c0\u67e5\u5668\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u5904\u7406\u590d\u6742\u7684\u4ee3\u7801\u4f20\u8f93\u548c\u8fd0\u884c\u573a\u666f\u3002"}}
