{"id": "2507.00409", "categories": ["cs.FL", "46H05 (Primary) 06E15, 08A62 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.00409", "abs": "https://arxiv.org/abs/2507.00409", "authors": ["Jorge Almeida", "Ondřej Klíma"], "title": "Eilenberg correspondence for Stone recognition", "comment": null, "summary": "We develop and explore the idea of recognition of languages (in the general\nsense of subsets of topological algebras) as preimages of clopen sets under\ncontinuous homomorphisms into Stone topological algebras. We obtain an\nEilenberg correspondence between varieties of languages and varieties of\nordered Stone topological algebras and a Birkhoff/Reiterman-type theorem\nshowing that the latter may me defined by certain pseudo-inequalities. In the\ncase of classical formal languages, of words over a finite alphabet, we also\nshow how this extended framework goes beyond the class of regular languages by\nworking with Stone completions of minimal automata, viewed as unary algebras.\nThis leads to a general method for showing that a language does not belong to a\nvariety of languages, expressed in terms of sequences of pairs of words, which\nis illustrated when the class consists of all finite intersections of\ncontext-free languages."}
{"id": "2507.00976", "categories": ["cs.MS", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.00976", "abs": "https://arxiv.org/abs/2507.00976", "authors": ["Maksim Melnichenko", "Riley Murray", "William Killian", "James Demmel", "Michael W. Mahoney", "Piotr Luszczek", "Mark Gates"], "title": "Anatomy of High-Performance Column-Pivoted QR Decomposition", "comment": "v1: 33 pages in the body, 7 pages in the appendices, 17 figures", "summary": "We introduce an algorithmic framework for performing QR factorization with\ncolumn pivoting (QRCP) on general matrices. The framework enables the design of\npractical QRCP algorithms through user-controlled choices for the core\nsubroutines. We provide a comprehensive overview of how to navigate these\nchoices on modern hardware platforms, offering detailed descriptions of\nalternative methods for both CPUs and GPUs. The practical QRCP algorithms\ndeveloped within this framework are implemented as part of the open-source\nRandLAPACK library. Our empirical evaluation demonstrates that, on a dual AMD\nEPYC 9734 system, the proposed method achieves performance improvements of up\nto two orders of magnitude over LAPACK's standard QRCP routine and greatly\nsurpasses the performance of the current state-of-the-art randomized QRCP\nalgorithm. Additionally, on an NVIDIA H100 GPU, our method attains\napproximately 65 percent of the performance of cuSOLVER's unpivoted QR\nfactorization."}
{"id": "2507.00465", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.00465", "abs": "https://arxiv.org/abs/2507.00465", "authors": ["Sohei Ito", "Makoto Tatsuta"], "title": "Encoding Peano Arithmetic in a Minimal Fragment of Separation Logic", "comment": null, "summary": "This paper investigates the expressive power of a minimal fragment of\nseparation logic extended with natural numbers. Specifically, it demonstrates\nthat the fragment consisting solely of the intuitionistic points-to predicate,\nthe constant 0, and the successor function is sufficient to encode all\n$\\Pi^0_1$ formulas of Peano Arithmetic (PA). The authors construct a\ntranslation from PA into this fragment, showing that a $\\Pi^0_1$ formula is\nvalid in the standard model of arithmetic if and only if its translation is\nvalid in the standard interpretation of the separation logic fragment. This\nresult implies the undecidability of validity in the fragment, despite its\nsyntactic simplicity. The translation leverages a heap-based encoding of\narithmetic operations - addition, multiplication, and inequality - using\nstructured memory cells. The paper also explores the boundaries of this\nencoding, showing that the translation does not preserve validity for\n$\\Sigma^0_1$ formulas. Additionally, an alternative undecidability proof is\npresented via a reduction from finite model theory. Finally, the paper\nestablishes that the validity problem for this fragment is $\\Pi^0_1$-complete,\nhighlighting its theoretical significance in the landscape of logic and program\nverification."}
{"id": "2507.00349", "categories": ["math.RT", "math.QA", "math.RA", "17B10, 17B20, 17B65, 17B66, 17B68"], "pdf": "https://arxiv.org/pdf/2507.00349", "abs": "https://arxiv.org/abs/2507.00349", "authors": ["Rencai Lü", "Xizhou You", "Kaiming Zhao"], "title": "$(d,σ)$-twisted Affine-Virasoro superalgebras", "comment": "31 pages", "summary": "For any finite dimensional Lie superalgebra $\\dot{\\mathfrak{g}}$ (maybe a Lie\nalgebra) with an even derivation $d$ and a finite order automorphism $\\sigma$\nthat commutes with $d$, we introduce the $(d,\\sigma)$-twisted Affine-Virasoro\nsuperalgebra $\\mathfrak{L}=\\mathfrak{L}(\\dot{\\mathfrak{g}},d,\\sigma)$ and\ndetermine its universal central extension\n$\\hat{\\mathfrak{L}}=\\hat{\\mathfrak{L}}(\\dot{\\mathfrak{g}},d,\\sigma)$. This is a\nhuge class of infinite-dimensional Lie superalgebras. Such Lie superalgebras\nconsist of many new and well-known Lie algebras and superalgebras, including\nthe Affine-Virasoro superalgebras, the twisted Heisenberg-Virasoro algebra, the\nmirror Heisenberg-Virasoro algebra, the W-algebra $W(2,2)$, the gap-$p$\nVirasoro algebras, the Fermion-Virasoro algebra, the $N=1$ BMS superalgebra,\nthe planar Galilean conformal algebra. Then we give the classification of\ncuspidal $A\\mathfrak{L}$-modules by using the weighting functor from\n$U(\\mathfrak{h})$-free modules to weight modules. Consequently, we give the\nclassification of simple cuspidal $\\mathfrak{L}$-modules by using the $A$-cover\nmethod. Finally, all simple quasi-finite modules over $\\mathfrak{L}$ and\n$\\hat{\\mathfrak{L}}$ are classified. Our results recover many known Lie\nsuperalgebra results from mathematics and mathematical physics, and give many\nnew Lie superalgebras."}
{"id": "2507.00955", "categories": ["math.LO"], "pdf": "https://arxiv.org/pdf/2507.00955", "abs": "https://arxiv.org/abs/2507.00955", "authors": ["Taishi Kurahashi"], "title": "Refinements of provability and consistency principles for the second incompleteness theorem", "comment": "24 pages", "summary": "This paper continues the author's previous study \\cite{Kura20}, showing that\nseveral weak principles inspired by non-normal modal logic suffice to derive\nvarious refined forms of the second incompleteness theorem. Among the main\nresults of the present paper, we show that the set $\\{\\mathbf{E},\\mathbf{C},\n\\mathbf{D3}\\}$ suffices to establish the unprovability of the consistency\nstatement $\\neg\\, \\mathrm{Pr}_T(\\ulcorner 0=1 \\urcorner)$. We also prove that\nthe set $\\{\\mathbf{E}^{\\mathrm{U}}, \\mathbf{CB_{\\exists}}\\}$ yields formalized\n$\\Sigma_1$-completeness."}
{"id": "2507.00047", "categories": ["cs.DM", "econ.TH", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.00047", "abs": "https://arxiv.org/abs/2507.00047", "authors": ["Seongbeom Park"], "title": "Reducing Profile-Based Matching to the Maximum Weight Matching Problem", "comment": "8 pages, in English; 9 pages, in Korean;", "summary": "The profile-based matching problem is the problem of finding a matching that\noptimizes profile from an instance $(G, r, \\langle u_1, \\dots, u_r \\rangle)$,\nwhere $G$ is a bipartite graph $(A \\cup B, E)$, $r$ is the number of utility\nfunctions, and $u_i: E \\to \\{ 0, 1, \\dots, U_i \\}$ is utility functions for $1\n\\le i \\le r$. A matching is optimal if the matching maximizes the sum of the\n1st utility, subject to this, maximizes the sum of the 2nd utility, and so on.\nThe profile-based matching can express rank-maximal matching\n\\cite{irving2006rank}, fair matching \\cite{huang2016fair}, and weight-maximal\nmatching \\cite{huang2012weight}. These problems can be reduced to maximum\nweight matching problems, but the reduction is known to be inefficient due to\nthe huge weights.\n  This paper presents the condition for a weight function to find an optimal\nmatching by reducing profile-based matching to the maximum weight matching\nproblem. It is shown that a weight function which represents utilities as a\nmixed-radix numeric system with base-$(2U_i+1)$ can be used, so the complexity\nof the problem is $O(m\\sqrt{n}(\\log{n} + \\sum_{i=1}^{r}\\log{U_i}))$ for $n =\n|V|$, $m = |E|$. In addition, it is demonstrated that the weight lower bound\nfor rank-maximal/fair/weight-maximal matching, better computational complexity\nfor fair/weight-maximal matching, and an algorithm to verify a maximum weight\nmatching can be reduced to rank-maximal matching. Finally, the effectiveness of\nthe profile-based algorithm is evaluated with real data for school choice\nlottery."}
{"id": "2507.00006", "categories": ["cs.GR", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.00006", "abs": "https://arxiv.org/abs/2507.00006", "authors": ["Xianghui Xie", "Chuhang Zou", "Meher Gitika Karumuri", "Jan Eric Lenssen", "Gerard Pons-Moll"], "title": "MVGBench: Comprehensive Benchmark for Multi-view Generation Models", "comment": "17 pages, 11 figures, 9 tables, project page:\n  https://virtualhumans.mpi-inf.mpg.de/MVGBench/", "summary": "We propose MVGBench, a comprehensive benchmark for multi-view image\ngeneration models (MVGs) that evaluates 3D consistency in geometry and texture,\nimage quality, and semantics (using vision language models). Recently, MVGs\nhave been the main driving force in 3D object creation. However, existing\nmetrics compare generated images against ground truth target views, which is\nnot suitable for generative tasks where multiple solutions exist while\ndiffering from ground truth. Furthermore, different MVGs are trained on\ndifferent view angles, synthetic data and specific lightings -- robustness to\nthese factors and generalization to real data are rarely evaluated thoroughly.\nWithout a rigorous evaluation protocol, it is also unclear what design choices\ncontribute to the progress of MVGs. MVGBench evaluates three different aspects:\nbest setup performance, generalization to real data and robustness. Instead of\ncomparing against ground truth, we introduce a novel 3D self-consistency metric\nwhich compares 3D reconstructions from disjoint generated multi-views. We\nsystematically compare 12 existing MVGs on 4 different curated real and\nsynthetic datasets. With our analysis, we identify important limitations of\nexisting methods specially in terms of robustness and generalization, and we\nfind the most critical design choices. Using the discovered best practices, we\npropose ViFiGen, a method that outperforms all evaluated MVGs on 3D\nconsistency. Our code, model, and benchmark suite will be publicly released."}
{"id": "2507.00009", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.00009", "abs": "https://arxiv.org/abs/2507.00009", "authors": ["Sergio Scarlatti"], "title": "A note on D-functions and P-covariances on Hilbert spaces and related inequalities", "comment": null, "summary": "In this note we first review the concept of D-function, closely connected\nwith Cauchy-Schwarz inequality, and then introduce the notion of P-covariance\non a Hilbert space, where $P$ is an orthogonal projection. We show that when P\nis specialized to be one-dimensional many well-known inequalities such as\nBuzano, Richard and Walker inequalities are simple consequences of P-covariance\ninequalities and their relation with D-functions. By means of these concepts\nenhancements of the previous mentioned inequalities are also established with\nminimum effort. A more thorough analysis of Walker inequality is presented\njointly with some novel financial considerations as well as a new refinement of\nHolder inequality."}
{"id": "2507.00057", "categories": ["cs.PL", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.00057", "abs": "https://arxiv.org/abs/2507.00057", "authors": ["Thomas Valentin", "Ardi Madadi", "Gaetano Sapia", "Marcel Böhme"], "title": "Estimating Correctness Without Oracles in LLM-Based Code Generation", "comment": "8 pages + refs and appendix", "summary": "Generating code from natural language specifications is one of the most\nsuccessful applications of Large Language Models (LLMs). Yet, they hallucinate:\nLLMs produce outputs that may be grammatically correct but are factually\nincorrect. Without an existing, correct implementation (i.e., an oracle), can\nwe quantify how likely the generated program is correct?\n  In this paper, we propose a measure of incorrectness, called incoherence,\nthat can be estimated efficiently in the absence of an oracle and provides a\nlower bound on the error, i.e., the probability that the LLM-generated program\nfor that specification is incorrect. Our experiments demonstrate an\nextraordinary effectiveness. For the average code generation task, our\nincoherence-based methodology can automatically identify about two-thirds of\nincorrect programs without reports of false positives. In fact, an oracle-based\nevaluation of LLMs can be reliably replaced by an incoherence-based evaluation.\nIn particular, we find a very strong agreement between the ranking of LLMs by\nthe number of programs deemed correct via an oracle (pass@1) and the ranking of\nLLMs by the number of programs deemed correct via our incoherence."}
{"id": "2507.00196", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.00196", "abs": "https://arxiv.org/abs/2507.00196", "authors": ["Nick Fischer", "Melvin Kallmayer", "Leo Wennmann"], "title": "A Simple Algorithm for Trimmed Multipoint Evaluation", "comment": "To appear at ESA 25", "summary": "Evaluating a polynomial on a set of points is a fundamental task in computer\nalgebra. In this work, we revisit a particular variant called trimmed\nmultipoint evaluation: given an $n$-variate polynomial with bounded individual\ndegree $d$ and total degree $D$, the goal is to evaluate it on a natural class\nof input points. This problem arises as a key subroutine in recent algorithmic\nresults [Dinur; SODA '21], [Dell, Haak, Kallmayer, Wennmann; SODA '25]. It is\nknown that trimmed multipoint evaluation can be solved in near-linear time [van\nder Hoeven, Schost; AAECC '13] by a clever yet somewhat involved algorithm. We\ngive a simple recursive algorithm that avoids heavy computer-algebraic\nmachinery, and can be readily understood by researchers without specialized\nbackground."}
{"id": "2507.00146", "categories": ["math.CT", "math.AT", "math.CO", "18N20, 18N65, 18N40, 55U10"], "pdf": "https://arxiv.org/pdf/2507.00146", "abs": "https://arxiv.org/abs/2507.00146", "authors": ["Clémence Chanavat", "Amar Hadzihasanovic"], "title": "Semi-strictification of $(\\infty, n)$-categories", "comment": "104 pages", "summary": "We prove the first equivalence between a weak non-algebraic model and a\nsemi-strict algebraic model of $(\\infty, n)$-categories. This takes the form of\na natural semi-strictification, whereby a weak $(\\infty, n)$-category is\nembedded into a semi-strict one through an acyclic cofibration, in such a way\nthat weak functors lift to semi-strict functors; this constitutes the derived\nunit of a Quillen equivalence between weak model categories whose fibrant\nobjects are, respectively, the weak $(\\infty, n)$-categories and (up to an\nacyclic fibration) the semi-strict ones. The semi-strict model has algebraic\nunits and composition of round pasting diagrams, satisfying a strict form of\nassociativity and interchange as in Henry's regular version of Simpson's weak\nunits conjecture; semi-strict functors strictly preserve round composition, but\nonly weakly preserve units. Globular composition operations are obtained from a\ncombination of units and round composition. Since the models satisfy the\nhomotopy hypothesis in the case $n = 0$, this result also exhibits the first\nsemi-strict model of the classical homotopy types that has algebraic units and\ncomposition. The constructions are based on the combinatorics of regular\ndirected complexes and are entirely explicit and combinatorial, in the spirit\nof Mac Lane's strictification of bicategories."}
{"id": "2507.00384", "categories": ["math.RT", "hep-th", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.00384", "abs": "https://arxiv.org/abs/2507.00384", "authors": ["Mark D. Gould", "Phillip S. Isaac", "Ian Marquette", "Jorgen Rasmussen"], "title": "Finite-dimensional $\\mathbb{Z}$-graded Lie algebras", "comment": "38 pages", "summary": "We investigate the structure and representation theory of finite-dimensional\n$\\mathbb{Z}$-graded Lie algebras, including the corresponding root systems and\nVerma, irreducible, and Harish-Chandra modules. This extends the familiar\ntheory for finite-dimensional semisimple Lie algebras to a much wider class of\nLie algebras, and opens up for advances and applications in areas relying on\nad-hoc approaches. Physically relevant examples are afforded by the Heisenberg\nand conformal Galilei algebras, including the Schr\\\"odinger algebras, whose\n$\\mathbb{Z}$-graded structures are yet to be fully exploited."}
{"id": "2507.00059", "categories": ["cs.DM", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.00059", "abs": "https://arxiv.org/abs/2507.00059", "authors": ["Ranjan N Naik"], "title": "Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31", "comment": "This is a result an improvement over by Mariusz Meszka for all primes\n  up to 23 (included) with the aid of a computer", "summary": "The BHR (Buratti-Horak-Rosa) Conjecture (2006) proposes that for every p and\na multiset L of (p-1) positive integers modulo p, there exists a Hamiltonian\npath in the Complete Graph Kp with consecutive edge lengths given by the\nelements of L. In this article, we outline an approach to the conjecture based\non frequency partitions and local/global adjustment operations and\nbacktracking. We describe the mathematical strategy, experimental evidence, and\nimplementation in a Python Program to explore valid Hamiltonian paths p < 37.\nThis is a result an improvement over by Mariusz Meszka for all primes up to 23\n(included) with the aid of a computer."}
{"id": "2507.00412", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.00412", "abs": "https://arxiv.org/abs/2507.00412", "authors": ["Meenakshi Krishnan", "Ramani Duraiswami"], "title": "ViscoReg: Neural Signed Distance Functions via Viscosity Solutions", "comment": "14 pages, 6 figures", "summary": "Implicit Neural Representations (INRs) that learn a Signed Distance Function\n(SDF) are a powerful tool for continuous 3D scene reconstruction. These models\nare trained by enforcing the Eikonal equation. We demonstrate theoretically\nthat despite the ill-posedness of the Eikonal equation, generalization error\nestimates may be obtained for Neural SDFs in terms of the training error.\nHowever, training with the Eikonal loss can lead to unstable gradient flows,\nnecessitating alternate stabilization techniques. Traditional numerical solvers\nfor the equation have relied on viscosity approaches for regularization. We\nenhance Neural SDF training using this well-developed theory, and introduce a\nnew loss formulation we call ViscoReg. We theoretically demonstrate the\nstability of the gradient flow equation of our proposed loss term. Empirically,\nViscoReg outperforms state-of-the-art approaches such as SIREN, DiGS, and StEik\nwithout adding significant computational cost."}
{"id": "2507.00010", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.00010", "abs": "https://arxiv.org/abs/2507.00010", "authors": ["Jia-Yin Peng", "Bing-Zhao Li"], "title": "The 2p order Heisenberg-Pauli-Weyl uncertainty principles related to the offset linear canonical transform", "comment": "19 pages, 3 figures", "summary": "The uncertainty principle is one of the fundamental tools for time-frequency\nanalysis in harmonic analysis, revealing the intrinsic trade-off between time\nand frequency resolutions. With the continuous development of various advanced\ntime-frequency analysis methods based on the Fourier transform, investigating\nuncertainty principles associated with these methods has become one of the most\ninteresting topics. This paper studies the uncertainty principles related to\nthe offset linear canonical transform, including the\nPlancherel-Parseval-Rayleigh identity, the $2p$ order Heisenberg-Pauli-Weyl\nuncertainty principle and the sharpened Heisenberg-Pauli-Weyl uncertainty\nprinciple. Numerical simulations are also proposed to validate the derived\nresults."}
{"id": "2507.00264", "categories": ["cs.PL", "cs.DC", "cs.PF", "cs.SE", "D.2.13; D.2.8; D.3.3; B.8"], "pdf": "https://arxiv.org/pdf/2507.00264", "abs": "https://arxiv.org/abs/2507.00264", "authors": ["Isabella Basso do Amaral", "Renato Cordeiro Ferreira", "Alfredo Goldman"], "title": "Rust vs. C for Python Libraries: Evaluating Rust-Compatible Bindings Toolchains", "comment": "10 pages, 27 figures (1 diagram, 4 graphs, 9 tables, 13 code\n  listings), submitted to SBAC-PAD 2025", "summary": "The Python programming language is best known for its syntax and scientific\nlibraries, but it is also notorious for its slow interpreter. Optimizing\ncritical sections in Python entails special knowledge of the binary\ninteractions between programming languages, and can be cumbersome to interface\nmanually, with implementers often resorting to convoluted third-party\nlibraries. This comparative study evaluates the performance and ease of use of\nthe PyO3 Python bindings toolchain for Rust against ctypes and cffi. By using\nRust tooling developed for Python, we can achieve state-of-the-art performance\nwith no concern for API compatibility."}
{"id": "2507.00277", "categories": ["cs.DS", "cs.DB"], "pdf": "https://arxiv.org/pdf/2507.00277", "abs": "https://arxiv.org/abs/2507.00277", "authors": ["Casper Moldrup Rysgaard", "Sebastian Wild"], "title": "Lazy B-Trees", "comment": "MFCS 2025", "summary": "Lazy search trees (Sandlund & Wild FOCS 2020, Sandlund & Zhang SODA 2022) are\nsorted dictionaries whose update and query performance smoothly interpolates\nbetween that of efficient priority queues and binary search trees -\nautomatically, depending on actual use; no adjustments are necessary to the\ndata structure to realize the cost savings. In this paper, we design lazy\nB-trees, a variant of lazy search trees suitable for external memory that\ngeneralizes the speedup of B-trees over binary search trees wrt. input/output\noperations to the same smooth interpolation regime.\n  A key technical difficulty to overcome is the lack of a (fully satisfactory)\nexternal variant of biased search trees, on which lazy search trees crucially\nrely. We give a construction for a subset of performance guarantees sufficient\nto realize external-memory lazy search trees, which we deem of independent\ninterest.\n  As one special case, lazy B-trees can be used as an external-memory priority\nqueue, in which case they are competitive with some tailor-made heaps; indeed,\nthey offer faster decrease-key and insert operations than known data\nstructures."}
{"id": "2507.00212", "categories": ["math.CT", "18D99, 18A25"], "pdf": "https://arxiv.org/pdf/2507.00212", "abs": "https://arxiv.org/abs/2507.00212", "authors": ["Suddhasattwa Das"], "title": "The concept of nullity in general spaces and contexts", "comment": null, "summary": "The notion of nullity is present in all discourses of mathematics. The two\nmost familiar notions of nullity are \"almost-every\" and \"almost none\". A notion\nof nullity corresponds to a choice of subsets that one interprets as null or\nnon-empty. The rationale behind this choice depends on the context, such as\nTopology or Measure theory. One also expects that the morphisms or\ntransformations within the contexts preserve the nullity structures. Extending\nthis idea, a generalized notion of nullity is presented as a functor between\ncategories. A constructive procedure is presented for extending the notion of\nnullity to categories with richer structure. Thus nullity in a category, such\nas that of general vector spaces, can be provided a recursive definition. Thus\nnullity is an arbitrary construct, which can be extended to broader contexts\nusing well defined rules. These rules are succinctly expressed by right and\nleft Kan extensions."}
{"id": "2507.00580", "categories": ["math.RT", "math.CO", "05E10, 05E16, 05E18"], "pdf": "https://arxiv.org/pdf/2507.00580", "abs": "https://arxiv.org/abs/2507.00580", "authors": ["M. Parvathi", "A. Tamilselvi", "D. Hepsi"], "title": "Study of $p$-Young tableaux, Robinson-Schensted correspondence and the lacunary Cauchy identity of group algebras $KG_{r}$ and $KSG_{r}$", "comment": "21 pages, 4 figures", "summary": "In this paper, we develop the Robinson-Schensted correspondence between the\nelements of the groups $G_{r}$ $(\\mathbb{Z}_{p^{r}}\\rtimes\n\\mathbb{Z}^{*}_{p^{r}})$ and $SG_{r}$ $(\\mathbb{Z}_{p^{r-1}}\\rtimes\n\\mathbb{Z}^{*}_{p^{r}})$, along with a pair of the standard $p$-Young tableaux.\nThis approach differs from the classical method, and ours is based on matrix\nunits arising from orthogonal primitive idempotents computed for every group\nalgebra. Some classical properties of the Robinson-Schensted correspondence are\ndiscussed. As a by-product, we also extend the Cauchy identity to our setup,\nwhich we refer to as the lacunary Cauchy identity. This study offers new\ninsights into the representation theory of these groups and their combinatorial\nstructures."}
{"id": "2507.00093", "categories": ["cs.DM", "cs.AI", "cs.DS", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.00093", "abs": "https://arxiv.org/abs/2507.00093", "authors": ["Binghua Yao", "Joris M. Mooij"], "title": "$σ$-Maximal Ancestral Graphs", "comment": "It has beee accepted by the 41st Conference on Uncertainty in\n  Artificial Intelligence (UAI)", "summary": "Maximal Ancestral Graphs (MAGs) provide an abstract representation of\nDirected Acyclic Graphs (DAGs) with latent (selection) variables. These\ngraphical objects encode information about ancestral relations and\nd-separations of the DAGs they represent. This abstract representation has been\nused amongst others to prove the soundness and completeness of the FCI\nalgorithm for causal discovery, and to derive a do-calculus for its output. One\nsignificant inherent limitation of MAGs is that they rule out the possibility\nof cyclic causal relationships. In this work, we address that limitation. We\nintroduce and study a class of graphical objects that we coin\n''$\\sigma$-Maximal Ancestral Graphs'' (''$\\sigma$-MAGs''). We show how these\ngraphs provide an abstract representation of (possibly cyclic) Directed Graphs\n(DGs) with latent (selection) variables, analogously to how MAGs represent\nDAGs. We study the properties of these objects and provide a characterization\nof their Markov equivalence classes."}
{"id": "2507.00476", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.00476", "abs": "https://arxiv.org/abs/2507.00476", "authors": ["Chenliang Zhou", "Zheyuan Hu", "Cengiz Oztireli"], "title": "FreNBRDF: A Frequency-Rectified Neural Material Representation", "comment": null, "summary": "Accurate material modeling is crucial for achieving photorealistic rendering,\nbridging the gap between computer-generated imagery and real-world photographs.\nWhile traditional approaches rely on tabulated BRDF data, recent work has\nshifted towards implicit neural representations, which offer compact and\nflexible frameworks for a range of tasks. However, their behavior in the\nfrequency domain remains poorly understood. To address this, we introduce\nFreNBRDF, a frequency-rectified neural material representation. By leveraging\nspherical harmonics, we integrate frequency-domain considerations into neural\nBRDF modeling. We propose a novel frequency-rectified loss, derived from a\nfrequency analysis of neural materials, and incorporate it into a generalizable\nand adaptive reconstruction and editing pipeline. This framework enhances\nfidelity, adaptability, and efficiency. Extensive experiments demonstrate that\n\\ours improves the accuracy and robustness of material appearance\nreconstruction and editing compared to state-of-the-art baselines, enabling\nmore structured and interpretable downstream tasks and applications."}
{"id": "2507.00017", "categories": ["math.GM", "34B16, 34A08, 34K37, 26A33"], "pdf": "https://arxiv.org/pdf/2507.00017", "abs": "https://arxiv.org/abs/2507.00017", "authors": ["Lok Nath Kannaujiya", "Narendra Kumar", "Amit K. Verma"], "title": "On a class of coupled fractional nonlinear singular boundary value problems arising in dusty fluid models", "comment": null, "summary": "In this article, we introduce a new class of coupled fractional Lane-Emden\nboundary value problems. We employ a novel approach, the fractional Haar\nwavelet collocation method with the Newton-Raphson method. We analyze the\nconditions in two cases to present numerical experiments related to the defined\nsystem of fractional differential equations. To validate the accuracy of the\nproposed method we present the convergence of the method, and we demonstrate\nthe method's effectiveness through five numerical experiments, highlighting\nreal-world applications of fractional differential equations. Using figures and\ntables, we show that the residual error decreases as we increase the value of\nthe maximum level of resolution $J$ while keeping the order of derivatives\nfixed, and similar trends also observe when $J$ is fixed and vary the order of\nfractional derivatives. We demonstrate that Mathematica software can be used\neffectively to solve such nonlinear singular fractional boundary value\nproblems."}
{"id": "2507.00488", "categories": ["cs.PL", "D.3.3; D.2"], "pdf": "https://arxiv.org/pdf/2507.00488", "abs": "https://arxiv.org/abs/2507.00488", "authors": ["Lloyd Allison"], "title": "Have Object-Oriented Languages Missed a Trick with Class Function and its Subclasses?", "comment": null, "summary": "Compared to functions in mathematics, functions in programming languages seem\nto be under classified. Functional programming languages based on the lambda\ncalculus famously treat functions as first-class values. Object-oriented\nlanguages have adopted ``lambdas'', notably for call-back routines in\nevent-based programming. Typically a programming language has functions, a\nfunction has a type, and some functions act on other functions and/or return\nfunctions but there is generally a lack of (i) ``class Function'' in the OO\nsense of the word class and particularly (ii) subclasses of Function for\nfunctions having specific properties. Some such classes are presented here and\nprogrammed in some popular programming languages as an experimental\ninvestigation into OO languages missing this opportunity."}
{"id": "2507.00708", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.00708", "abs": "https://arxiv.org/abs/2507.00708", "authors": ["Davide Bilò", "Giodano Colli", "Luca Forlizzi", "Stefano Leucci"], "title": "On the (In)Approximability of the Monitoring Edge Geodetic Set Problem", "comment": "arXiv admin note: text overlap with arXiv:2405.13875", "summary": "We study the minimum \\emph{Monitoring Edge Geodetic Set} (\\megset) problem\nintroduced in [Foucaud et al., CALDAM'23]: given a graph $G$, we say that an\nedge is monitored by a pair $u,v$ of vertices if \\emph{all} shortest paths\nbetween $u$ and $v$ traverse $e$; the goal of the problem consists in finding a\nsubset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at\nleast one pair of vertices in $M$, and $|M|$ is minimized.\n  In this paper, we prove that all polynomial-time approximation algorithms for\nthe minimum \\megset problem must have an approximation ratio of $\\Omega(\\log\nn)$, unless \\p = \\np. To the best of our knowledge, this is the first\nnon-constant inapproximability result known for this problem. We also\nstrengthen the known \\np-hardness of the problem on $2$-apex graphs by showing\nthat the same result holds for $1$-apex graphs. This leaves open the problem of\ndetermining whether the problem remains \\np-hard on planar (i.e., $0$-apex)\ngraphs.\n  On the positive side, we design an algorithm that computes good approximate\nsolutions for hereditary graph classes that admit efficiently computable\nbalanced separators of truly sublinear size. This immediately results in\npolynomial-time approximation algorithms achieving an approximation ratio of\n$O(n^{\\frac{1}{4}} \\sqrt{\\log n})$ on planar graphs, graphs with bounded genus,\nand $k$-apex graphs with $k=O(n^{\\frac{1}{4}})$. On graphs with bounded\ntreewidth, we obtain an approximation ratio of $O(\\log^{3/2} n)$ for any\nconstant $\\varepsilon > 0$. This compares favorably with the best-known\napproximation algorithm for general graphs, which achieves an approximation\nratio of $O(\\sqrt{n \\log n})$ via a simple reduction to the \\textsc{Set Cover}\nproblem."}
{"id": "2507.00730", "categories": ["math.RT", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.00730", "abs": "https://arxiv.org/abs/2507.00730", "authors": ["Wan Keng Cheong", "Ngau Lam"], "title": "Dualities of Gaudin models with irregular singularities for general linear Lie (super)algebras", "comment": null, "summary": "We prove an equivalence between the actions of the Gaudin algebras with\nirregular singularities for $\\mathfrak{gl}_d$ and $\\mathfrak{gl}_{p+m|q+n}$ on\nthe Fock space of $d(p+m)$ bosonic and $d(q+n)$ fermionic oscillators. This\nestablishes a duality of $(\\mathfrak{gl}_d, \\mathfrak{gl}_{p+m|q+n})$ for\nGaudin models. As an application, we show that the Gaudin algebra with\nirregular singularities for $\\mathfrak{gl}_{p+m|q+n}$ acts cyclically on each\nweight space of a certain class of infinite-dimensional modules over a direct\nsum of Takiff superalgebras over $\\mathfrak{gl}_{p+m|q+n}$ and that the action\nis diagonalizable with a simple spectrum under a generic condition. We also\nstudy the classical versions of Gaudin algebras with irregular singularities\nand demonstrate a duality of $(\\mathfrak{gl}_d, \\mathfrak{gl}_{p+m|q+n})$ for\nclassical Gaudin models."}
{"id": "2507.00564", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.00564", "abs": "https://arxiv.org/abs/2507.00564", "authors": ["Jan Bok", "Jiří Fiala", "Nikola Jedličková", "Jan Kratochvíl"], "title": "Computational complexity of covering regular trees", "comment": "19 pages, accepted to MFCS 2025", "summary": "A graph covering projection, also referred to as a locally bijective\nhomomorphism, is a mapping between the vertices and edges of two graphs that\npreserves incidences and is a local bijection. This concept originates in\ntopological graph theory but has also found applications in combinatorics and\ntheoretical computer science. In this paper we consider undirected graphs in\nthe most general setting -- graphs may contain multiple edges, loops, and\nsemi-edges. This is in line with recent trends in topological graph theory and\nmathematical physics.\n  We advance the study of the computational complexity of the {\\sc $H$-Cover}\nproblem, which asks whether an input graph allows a covering projection onto a\nparameter graph $H$. The quest for a complete characterization started in\n1990's. Several results for simple graphs or graphs without semi-edges have\nbeen known, the role of semi-edges in the complexity setting has started to be\ninvestigated only recently. One of the most general known NP-hardness results\nstates that {\\sc $H$}-Cover is NP-complete for every simple connected regular\ngraph of valency greater than two. We complement this result by considering\nregular graphs $H$ arising from connected acyclic graphs by adding semi-edges.\nNamely, we prove that any graph obtained by adding semi-edges to the vertices\nof a tree making it a $d$-regular graph with $d \\geq 3$, defines an NP-complete\ngraph covering problem. In line with the so called Strong Dichotomy Conjecture,\nwe prove that the NP-hardness holds even for simple graphs on input."}
{"id": "2507.00725", "categories": ["cs.GR", "cs.CG", "I.3.5"], "pdf": "https://arxiv.org/pdf/2507.00725", "abs": "https://arxiv.org/abs/2507.00725", "authors": ["Amritendu Dhar", "Apratim Chakraborty", "Vijay Natarajan"], "title": "Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory", "comment": null, "summary": "Morse-Cerf theory considers a one-parameter family of smooth functions\ndefined on a manifold and studies the evolution of their critical points with\nthe parameter. This paper presents an adaptation of Morse-Cerf theory to a\nfamily of piecewise-linear (PL) functions. The vertex diagram and Cerf diagram\nare introduced as representations of the evolution of critical points of the PL\nfunction. The characterization of a crossing in the vertex diagram based on the\nhomology of the lower links of vertices leads to the definition of a\ntopological descriptor for time-varying scalar fields. An algorithm for\ncomputing the Cerf diagram and a measure for comparing two Cerf diagrams are\nalso described together with experimental results on time-varying scalar\nfields."}
{"id": "2507.00021", "categories": ["math.GM", "34A12, 34A08, 74B05, 74A10"], "pdf": "https://arxiv.org/pdf/2507.00021", "abs": "https://arxiv.org/abs/2507.00021", "authors": ["José Villa-Morales", "Manuel Ramírez-Aranda"], "title": "An Application of Fractional Calculus to Column Theory", "comment": "15 pages", "summary": "In this article, we employ a fractional version of the radius of curvature in\nEuler's equation for column buckling, enabling us to derive a fractional\ndifferential equation in the Caputo sense. We solve this equation and\ndemonstrate that for certain values of the fractional parameter, there exists a\ncritical buckling force. Additionally, we provide a numerical scheme for\naccurately approximating this critical force."}
{"id": "2507.00930", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.00930", "abs": "https://arxiv.org/abs/2507.00930", "authors": ["Kristóf íBérczi", "Lydia Mirabel Mendoza-Cadena", "José Soto"], "title": "Inverse matroid optimization under subset constraints", "comment": "20 pages", "summary": "In the Inverse Matroid problem, we are given a matroid, a fixed basis $B$,\nand an initial weight function, and the goal is to minimally modify the weights\n-- measured by some function -- so that $B$ becomes a maximum-weight basis. The\nproblem arises naturally in settings where one wishes to explain or enforce a\ngiven solution by minimally perturbing the input.\n  We extend this classical problem by replacing the fixed basis with a subset\n$S_0$ of the ground set and imposing various structural constraints on the set\nof maximum-weight bases relative to $S_0$. Specifically, we study six variants:\n(A) Inverse Matroid Exists, where $S_0$ must contain at least one\nmaximum-weight basis; (B) Inverse Matroid All, where all bases contained in\n$S_0$ are maximum-weight; and (C) Inverse Matroid Only, where $S_0$ contains\nexactly the maximum-weight bases, along with their natural negated\ncounterparts.\n  For all variants, we develop combinatorial polynomial-time algorithms under\nthe $\\ell_\\infty$-norm. A key ingredient is a refined min-max theorem for\nInverse Matroid under the $\\ell_\\infty$-norm, which enables simpler and faster\nalgorithms than previous approaches and may be of independent combinatorial\ninterest. Our work significantly broadens the range of inverse optimization\nproblems on matroids that can be solved efficiently, especially those that\nconstrain the structure of optimal solutions through subset inclusion or\nexclusion."}
{"id": "2507.00631", "categories": ["cs.GT", "cs.AI", "cs.MA", "I.2.11; F.2.2"], "pdf": "https://arxiv.org/pdf/2507.00631", "abs": "https://arxiv.org/abs/2507.00631", "authors": ["David Shi", "Kevin Joo"], "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "comment": "9 pages, 1 figure", "summary": "Correctness is an emergent property of systems where exposing error is\ncheaper than committing it. In dynamic, low-trust environments, autonomous AI\nagents benefit from delegating work to sub-agents, yet correctness cannot be\nassured through upfront specification or centralized oversight. We propose a\nprotocol that enforces correctness through collateralized claims in a recursive\nverification game. Tasks are published as intents, and solvers compete to\nfulfill them. Selected solvers carry out tasks under risk, with correctness\nchecked post hoc by verifiers. Any challenger can challenge a result by staking\nagainst it to trigger the verification process. Incorrect agents are slashed\nand correct opposition is rewarded, with an escalation path that penalizes\nerroneous verifiers themselves. When incentives are aligned across solvers,\nchallengers, and verifiers, falsification conditions make correctness the Nash\nequilibrium."}
{"id": "2507.00728", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.00728", "abs": "https://arxiv.org/abs/2507.00728", "authors": ["Timothée Corsini", "Jessica Enright", "Laura Larios-Jones", "Kitty Meeks"], "title": "Temporal Orienteering with Changing Fuel Costs", "comment": "23 pages, 2 figures", "summary": "The problem Orienteering asks whether there exists a walk which visits a\nnumber of sites without exceeding some fuel budget. In the variant of the\nproblem we consider, the cost of each edge in the walk is dependent on the time\nwe depart one endpoint and the time we arrive at the other endpoint. This\nmirrors applications such as travel between orbiting objects where fuel costs\nare dependent on both the departure time and the length of time spent\ntravelling. In defining this problem, we introduce a natural generalisation of\nthe standard notion of temporal graphs: the pair consisting of the graph of the\nsites and a cost function, in which costs as well as shortest travel times\nbetween pairs of objects change over time. We believe this model is likely to\nbe of independent interest. The problem of deciding whether a stated goal is\nfeasible is easily seen to be NP-complete; we investigate three different ways\nto restrict the input which lead to efficient algorithms. These include the\nnumber of times an edge can be used, an analogue of vertex-interval-membership\nwidth, and the number of sites to be visited."}
{"id": "2507.00027", "categories": ["math.GM"], "pdf": "https://arxiv.org/pdf/2507.00027", "abs": "https://arxiv.org/abs/2507.00027", "authors": ["Nikos Mantzakouras", "Carlos López Zapata", "Nid Na Ratch"], "title": "Conditions for solving polynomial equations using algebraic and hypergeometric functions", "comment": "53 pages", "summary": "In this paper, we focus on clarifying the concept of solving equations of\ndegree greater than six using continuous functions or hypergeometric functions\nand providing another proof of the non-existence of algebraic solutions for\nequations of degree greater than four. According to the Kolmogorov-Arnold\ntheorem, we will prove that equations of degree greater than five cannot be\nsolved without special conditions between their coefficients using\nhypergeometric functions. However, we prove that trinomial equations of general\nform can in general be solved using hypergeometric functions."}
{"id": "2507.00059", "categories": ["cs.DM", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.00059", "abs": "https://arxiv.org/abs/2507.00059", "authors": ["Ranjan N Naik"], "title": "Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31", "comment": "This is a result an improvement over by Mariusz Meszka for all primes\n  up to 23 (included) with the aid of a computer", "summary": "The BHR (Buratti-Horak-Rosa) Conjecture (2006) proposes that for every p and\na multiset L of (p-1) positive integers modulo p, there exists a Hamiltonian\npath in the Complete Graph Kp with consecutive edge lengths given by the\nelements of L. In this article, we outline an approach to the conjecture based\non frequency partitions and local/global adjustment operations and\nbacktracking. We describe the mathematical strategy, experimental evidence, and\nimplementation in a Python Program to explore valid Hamiltonian paths p < 37.\nThis is a result an improvement over by Mariusz Meszka for all primes up to 23\n(included) with the aid of a computer."}
{"id": "2507.00930", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.00930", "abs": "https://arxiv.org/abs/2507.00930", "authors": ["Kristóf íBérczi", "Lydia Mirabel Mendoza-Cadena", "José Soto"], "title": "Inverse matroid optimization under subset constraints", "comment": "20 pages", "summary": "In the Inverse Matroid problem, we are given a matroid, a fixed basis $B$,\nand an initial weight function, and the goal is to minimally modify the weights\n-- measured by some function -- so that $B$ becomes a maximum-weight basis. The\nproblem arises naturally in settings where one wishes to explain or enforce a\ngiven solution by minimally perturbing the input.\n  We extend this classical problem by replacing the fixed basis with a subset\n$S_0$ of the ground set and imposing various structural constraints on the set\nof maximum-weight bases relative to $S_0$. Specifically, we study six variants:\n(A) Inverse Matroid Exists, where $S_0$ must contain at least one\nmaximum-weight basis; (B) Inverse Matroid All, where all bases contained in\n$S_0$ are maximum-weight; and (C) Inverse Matroid Only, where $S_0$ contains\nexactly the maximum-weight bases, along with their natural negated\ncounterparts.\n  For all variants, we develop combinatorial polynomial-time algorithms under\nthe $\\ell_\\infty$-norm. A key ingredient is a refined min-max theorem for\nInverse Matroid under the $\\ell_\\infty$-norm, which enables simpler and faster\nalgorithms than previous approaches and may be of independent combinatorial\ninterest. Our work significantly broadens the range of inverse optimization\nproblems on matroids that can be solved efficiently, especially those that\nconstrain the structure of optimal solutions through subset inclusion or\nexclusion."}
{"id": "2507.00035", "categories": ["math.GM", "47H10, 54H25"], "pdf": "https://arxiv.org/pdf/2507.00035", "abs": "https://arxiv.org/abs/2507.00035", "authors": ["Alemayehu Negash", "Meaza Bogale"], "title": "Weakly Compatible Mappings and Common Fixed Points Under Generalized Contractive Conditions", "comment": "16 pages", "summary": "This paper establishes new common fixed point theorems for weakly compatible\nmappings in metric spaces, relaxing traditional requirements such as\ncontinuity, compatibility, and reciprocal continuity. We present a unified\nframework for three self-mappings $T$, $f$, and $g$ with a contractive\ncondition involving a control function $\\psi$, along with corollaries extending\nresults to pairs of mappings and upper semi-continuous control functions.\nFurther generalizations include iterated mappings and sequences of mappings.\nRigorous examples demonstrate the necessity of hypotheses and show our results\nstrictly generalize theorems by Al-Thagafi \\emph{et. al.}\n\\cite{Al-Thagafi2006}, Babu \\emph{et. al.} \\cite{Babu2007}, Jungck\n\\cite{Jungck1976,Jungck1986}, Singh \\cite{Singh1986,Singh1997a}, Som\n\\cite{Som2003}, Song \\cite{Song2007} and Zhang \\emph{et. al.} \\cite{Zhang2008}.\nKey advancements include eliminating completeness assumptions on the entire\nspace and relaxing mapping compatibility conditions."}
{"id": "2507.00093", "categories": ["cs.DM", "cs.AI", "cs.DS", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2507.00093", "abs": "https://arxiv.org/abs/2507.00093", "authors": ["Binghua Yao", "Joris M. Mooij"], "title": "$σ$-Maximal Ancestral Graphs", "comment": "It has beee accepted by the 41st Conference on Uncertainty in\n  Artificial Intelligence (UAI)", "summary": "Maximal Ancestral Graphs (MAGs) provide an abstract representation of\nDirected Acyclic Graphs (DAGs) with latent (selection) variables. These\ngraphical objects encode information about ancestral relations and\nd-separations of the DAGs they represent. This abstract representation has been\nused amongst others to prove the soundness and completeness of the FCI\nalgorithm for causal discovery, and to derive a do-calculus for its output. One\nsignificant inherent limitation of MAGs is that they rule out the possibility\nof cyclic causal relationships. In this work, we address that limitation. We\nintroduce and study a class of graphical objects that we coin\n''$\\sigma$-Maximal Ancestral Graphs'' (''$\\sigma$-MAGs''). We show how these\ngraphs provide an abstract representation of (possibly cyclic) Directed Graphs\n(DGs) with latent (selection) variables, analogously to how MAGs represent\nDAGs. We study the properties of these objects and provide a characterization\nof their Markov equivalence classes."}
{"id": "2507.00040", "categories": ["math.GM", "40A25, 33B30, 11M35"], "pdf": "https://arxiv.org/pdf/2507.00040", "abs": "https://arxiv.org/abs/2507.00040", "authors": ["Segun Olofin Akerele"], "title": "An Addendum to Plouffe's Ramanujan Identities", "comment": "12 pages", "summary": "We introduce a new class of polylogarithm sums closely related to a family\nstudied by L. Vep\\v{s}tas in 2010. These generalized sums depend on two free\nparameters and yield closed-form expressions involving the Dirichlet eta\nfunction. Additionally, we present an alternative proof for a hyperbolic sum\noriginally discussed by Ramanujan."}
{"id": "2507.00317", "categories": ["math.GM", "11B37"], "pdf": "https://arxiv.org/pdf/2507.00317", "abs": "https://arxiv.org/abs/2507.00317", "authors": ["Yunier Bello-Cruz", "Roy Quintero-Contreras"], "title": "Fixed Points of the Josephus Function via Fractional Base Expansions", "comment": null, "summary": "In this paper, we investigated some interesting properties of the fixed\npoints of the Josephus function $J_3$. First, we establish a connection between\nthis sequence and the Chinese Remainder Theorem. Next, we observed a clear\nnumerical pattern in the fixed points sequence when the terms are written in\nbase $3/2$ using modular arithmetic, which allows us to develop a recursive\nprocedure to determine the digits of their base $3/2$ expansions."}
