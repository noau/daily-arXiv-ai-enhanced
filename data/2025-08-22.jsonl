{"id": "2508.15109", "categories": ["cs.PL", "D.3.0; F.3.1"], "pdf": "https://arxiv.org/pdf/2508.15109", "abs": "https://arxiv.org/abs/2508.15109", "authors": ["Ziteng Wang", "Ruijie Fang", "Linus Zheng", "Dixin Tang", "Isil Dillig"], "title": "Homomorphism Calculus for User-Defined Aggregations", "comment": null, "summary": "Data processing frameworks like Apache Spark and Flink provide built-in\nsupport for user-defined aggregation functions (UDAFs), enabling the\nintegration of domain-specific logic. However, for these frameworks to support\n\\emph{efficient} UDAF execution, the function needs to satisfy a\n\\emph{homomorphism property}, which ensures that partial results from\nindependent computations can be merged correctly. Motivated by this problem,\nthis paper introduces a novel \\emph{homomorphism calculus} that can both verify\nand refute whether a UDAF is a dataframe homomorphism. If so, our calculus also\nenables the construction of a corresponding merge operator which can be used\nfor incremental computation and parallel execution. We have implemented an\nalgorithm based on our proposed calculus and evaluate it on real-world UDAFs,\ndemonstrating that our approach significantly outperforms two leading\nsynthesizers."}
{"id": "2508.15137", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.15137", "abs": "https://arxiv.org/abs/2508.15137", "authors": ["Ruijie Fang", "Zachary Kincaid", "Thomas Reps"], "title": "Software Model Checking via Summary-Guided Search (Extended Version)", "comment": "Preliminary manuscript of extended version of paper that will appear\n  in OOPSLA 2025. 36 pages", "summary": "In this work, we describe a new software model-checking algorithm called GPS.\nGPS treats the task of model checking a program as a directed search of the\nprogram states, guided by a compositional, summary-based static analysis. The\nsummaries produced by static analysis are used both to prune away infeasible\npaths and to drive test generation to reach new, unexplored program states. GPS\ncan find both proofs of safety and counter-examples to safety (i.e., inputs\nthat trigger bugs), and features a novel two-layered search strategy that\nrenders it particularly efficient at finding bugs in programs featuring long,\ninput-dependent error paths. To make GPS refutationally complete (in the sense\nthat it will find an error if one exists, if it is allotted enough time), we\nintroduce an instrumentation technique and show that it helps GPS achieve\nrefutation-completeness without sacrificing overall performance. We benchmarked\nGPS on a suite of benchmarks including both programs from the Software\nVerification Competition (SV-COMP) and from prior literature, and found that\nour implementation of GPS outperforms state-of-the-art software model checkers\n(including the top performers in SV-COMP ReachSafety-Loops category), both in\nterms of the number of benchmarks solved and in terms of running time."}
{"id": "2508.15157", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15157", "abs": "https://arxiv.org/abs/2508.15157", "authors": ["David M Kahn", "Jan Hoffmann", "Runming Li"], "title": "Big-Stop Semantics: A Simple Way to Get the Benefits of Small-Step Semantics in a Big-Step Judgment", "comment": "26 pages, 27 figures", "summary": "As evident in the programming language literature, many practitioners favor\nspecifying dynamic program behavior using big-step over small-step semantics.\nUnlike small-step semantics, which must dwell on every intermediate program\nstate, big-step semantics conveniently jump directly to the ever-important\nresult of the computation. Big-step semantics also typically involve fewer\ninference rules than their small-step counterparts. However, in exchange for\nergonomics, big-step semantics give up power: Small-step semantics describes\nprogram behaviors that are outside the grasp of big-step semantics, notably\ndivergence. This work presents a little-known extension of big-step semantics\nwith inductive definitions that captures diverging computations without\nintroducing error states. This big-stop semantics is illustrated for typed,\nuntyped, and effectful variants of PCF, as well as a while-loop-based\nimperative language. Big-stop semantics extends the standard big-step inference\nrules with a few additional rules to define an evaluation judgment that is\nequivalent to the reflexive-transitive closure of small-step transitions. This\nsimple extension contrasts with other solutions in the literature which\nsacrifice ergonomics by introducing many additional inference rules, global\nstate, and/or less-commonly-understood reasoning principles like coinduction."}
{"id": "2508.15166", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15166", "abs": "https://arxiv.org/abs/2508.15166", "authors": ["Jingbo Wang", "Shashin Halalingaiah", "Weiyi Chen", "Chao Wang", "Isil Dillig"], "title": "Probabilistic Inference for Datalog with Correlated Inputs", "comment": "Accepted for publication at OOPSLA 2025 (R2)", "summary": "Probabilistic extensions of logic programming languages, such as ProbLog,\nintegrate logical reasoning with probabilistic inference to evaluate\nprobabilities of output relations; however, prior work does not account for\npotential statistical correlations among input facts. This paper introduces\nPraline, a new extension to Datalog designed for precise probabilistic\ninference in the presence of (partially known) input correlations. We formulate\nthe inference task as a constrained optimization problem, where the solution\nyields sound and precise probability bounds for output facts. However, due to\nthe complexity of the resulting optimization problem, this approach alone often\ndoes not scale to large programs. To address scalability, we propose a more\nefficient $\\delta$-exact inference algorithm that leverages constraint solving,\nstatic analysis, and iterative refinement. Our empirical evaluation on\nchallenging real-world benchmarks, including side-channel analysis,\ndemonstrates that our method not only scales effectively but also delivers\ntight probability bounds."}
{"id": "2508.14930", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.14930", "abs": "https://arxiv.org/abs/2508.14930", "authors": ["Hanwen Zhao", "John Akers", "Baback Elmieh", "Ira Kemelmacher-Shlizerman"], "title": "Hybrelighter: Combining Deep Anisotropic Diffusion and Scene Reconstruction for On-device Real-time Relighting in Mixed Reality", "comment": null, "summary": "Mixed Reality scene relighting, where virtual changes to lighting conditions\nrealistically interact with physical objects, producing authentic illumination\nand shadows, can be used in a variety of applications. One such application in\nreal estate could be visualizing a room at different times of day and placing\nvirtual light fixtures. Existing deep learning-based relighting techniques\ntypically exceed the real-time performance capabilities of current MR devices.\nOn the other hand, scene understanding methods, such as on-device scene\nreconstruction, often yield inaccurate results due to scanning limitations, in\nturn affecting relighting quality. Finally, simpler 2D image filter-based\napproaches cannot represent complex geometry and shadows. We introduce a novel\nmethod to integrate image segmentation, with lighting propagation via\nanisotropic diffusion on top of basic scene understanding, and the\ncomputational simplicity of filter-based techniques. Our approach corrects\non-device scanning inaccuracies, delivering visually appealing and accurate\nrelighting effects in real-time on edge devices, achieving speeds as high as\n100 fps. We show a direct comparison between our method and the industry\nstandard, and present a practical demonstration of our method in the\naforementioned real estate example."}
{"id": "2508.14927", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14927", "abs": "https://arxiv.org/abs/2508.14927", "authors": ["Vojtech Kovarik", "Eric Olav Chen", "Sami Petersen", "Alexis Ghersengorin", "Vincent Conitzer"], "title": "AI Testing Should Account for Sophisticated Strategic Behaviour", "comment": null, "summary": "This position paper argues for two claims regarding AI testing and\nevaluation. First, to remain informative about deployment behaviour,\nevaluations need account for the possibility that AI systems understand their\ncircumstances and reason strategically. Second, game-theoretic analysis can\ninform evaluation design by formalising and scrutinising the reasoning in\nevaluation-based safety cases. Drawing on examples from existing AI systems, a\nreview of relevant research, and formal strategic analysis of a stylised\nevaluation scenario, we present evidence for these claims and motivate several\nresearch directions."}
{"id": "2508.15264", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15264", "abs": "https://arxiv.org/abs/2508.15264", "authors": ["Patrick Redmond", "Jonathan Castello", "José Manuel Calderón Trilla", "Lindsey Kuper"], "title": "Exploring the Theory and Practice of Concurrency in the Entity-Component-System Pattern", "comment": "This is an extended version (with appendices) of the OOPSLA 2025\n  paper", "summary": "The Entity-Component-System (ECS) software design pattern, long used in game\ndevelopment, encourages a clean separation of identity (entities), data\nproperties (components), and computational behaviors (systems). Programs\nwritten using the ECS pattern are naturally concurrent, and the pattern offers\nmodularity, flexibility, and performance benefits that have led to a\nproliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known\nand not well understood outside of a few domains. Existing explanations of the\nECS pattern tend to be mired in the concrete details of particular ECS\nframeworks, or they explain the pattern in terms of imperfect metaphors or in\nterms of what it is not. We seek a rigorous understanding of the ECS pattern\nvia the design of a formal model, Core ECS, that abstracts away the details of\nspecific implementations to reveal the essence of software using the ECS\npattern. We identify a class of Core ECS programs that behave deterministically\nregardless of scheduling, enabling use of the ECS pattern as a\ndeterministic-by-construction concurrent programming model. With Core ECS as a\npoint of comparison, we then survey several real-world ECS frameworks and find\nthat they all leave opportunities for deterministic concurrency unexploited.\nOur findings point out a space for new ECS implementation techniques that\nbetter leverage such opportunities."}
{"id": "2508.14933", "categories": ["cs.GR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14933", "abs": "https://arxiv.org/abs/2508.14933", "authors": ["Lucas S. Kupssinskü", "Marco N. Bochernitsan", "Jordan Kopper", "Otávio Parraga", "Rodrigo C. Barros"], "title": "Inference Time Debiasing Concepts in Diffusion Models", "comment": null, "summary": "We propose DeCoDi, a debiasing procedure for text-to-image diffusion-based\nmodels that changes the inference procedure, does not significantly change\nimage quality, has negligible compute overhead, and can be applied in any\ndiffusion-based image generation model. DeCoDi changes the diffusion process to\navoid latent dimension regions of biased concepts. While most deep learning\ndebiasing methods require complex or compute-intensive interventions, our\nmethod is designed to change only the inference procedure. Therefore, it is\nmore accessible to a wide range of practitioners. We show the effectiveness of\nthe method by debiasing for gender, ethnicity, and age for the concepts of\nnurse, firefighter, and CEO. Two distinct human evaluators manually inspect\n1,200 generated images. Their evaluation results provide evidence that our\nmethod is effective in mitigating biases based on gender, ethnicity, and age.\nWe also show that an automatic bias evaluation performed by the GPT4o is not\nsignificantly statistically distinct from a human evaluation. Our evaluation\nshows promising results, with reliable levels of agreement between evaluators\nand more coverage of protected attributes. Our method has the potential to\nsignificantly improve the diversity of images it generates by diffusion-based\ntext-to-image generative models."}
{"id": "2508.15296", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.15296", "abs": "https://arxiv.org/abs/2508.15296", "authors": ["Ryota Takeshima", "Kei Kimura", "Ayumu Kuroki", "Temma Wakasugi", "Makoto Yokoo"], "title": "A New Relaxation of Fairness in Two-Sided Matching Respecting Acquaintance Relationships", "comment": "To appear in Proceedings of ECAI-25", "summary": "Two-sided matching, such as matching between students and schools, has been\napplied to various aspects of real life and has been the subject of much\nresearch, however, it has been plagued by the fact that efficiency and fairness\nare incompatible. In particular, Pareto efficiency and justified-envy-freeness\nare known to be incompatible even in the simplest one-to-one matching, i.e.,\nthe stable marriage problem. In previous research, the primary approach to\nimproving efficiency in matchings has been to tolerate students' envy, thereby\nrelaxing fairness constraints. In this study, we take a different approach to\nrelaxing fairness. Specifically, it focuses on addressing only the envy that\nstudents may experience or prioritize more highly and seeks matchings without\nsuch envy. More specifically, this study assumes that envy towards students who\nare not acquaintances has less impact compared to envy towards students who are\nacquaintances. Accordingly, we assume that the students know each other or not,\nrepresented by an undirected graph, and define a local envy as a justified envy\ntoward an acquaintance or a neighbor in the graph. We then propose the property\nthat there is no local envy as a new relaxed concept of fairness, called local\nenvy-freeness. We analyze whether Pareto-efficient matching can be achieved\nwhile maintaining local envy-freeness by meaningfully restricting the graph\nstructure and the school's preferences. To analyze in detail the fairness that\ncan achieve Pareto-efficient matching, we introduce a local version of the\nrelaxed fairness recently proposed by Cho et al. (AAMAS 2024), which\nparameterizes the level of local envy-freeness by nonnegative integers. We then\nclarify the level of local envy-freeness that can be achieved by\nPareto-efficient mechanisms for graphs that are ``close'' to trees and\nsingle-peaked preferences on the graphs."}
{"id": "2508.15333", "categories": ["cs.PL", "F.3.3"], "pdf": "https://arxiv.org/pdf/2508.15333", "abs": "https://arxiv.org/abs/2508.15333", "authors": ["Francesco Dagnino", "Paola Giannini", "Violet Ka I Pun", "Ulises Torrella"], "title": "Fair Termination for Resource-Aware Active Objects", "comment": "18 pages, 12 pages of appendix, 12 figures, APLAS 2025", "summary": "Active object systems are a model of distributed computation that has been\nadopted for modelling distributed systems and business process workflows. This\nfield of modelling is, in essence, concurrent and resource-aware, motivating\nthe development of resource-aware formalisations on the active object model.\nThe contributions of this work are the development of a core calculus for\nresource-aware active objects together with a type system ensuring that\nwell-typed programs are fairly terminating, i.e., they can always eventually\nterminate. To achieve this, we combine techniques from graded semantics and\ntype systems, which are quite well understood for sequential programs, with\nthose for fair termination, which have been developed for synchronous~sessions."}
{"id": "2508.15356", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.15356", "abs": "https://arxiv.org/abs/2508.15356", "authors": ["Ali Asadi", "Léonard Brice", "Krishnendu Chatterjee", "K. S. Thejaswini"], "title": "ε-Stationary Nash Equilibria in Multi-player Stochastic Graph Games", "comment": null, "summary": "A strategy profile in a multi-player game is a Nash equilibrium if no player\ncan unilaterally deviate to achieve a strictly better payoff. A profile is an\n$\\epsilon$-Nash equilibrium if no player can gain more than $\\epsilon$ by\nunilaterally deviating from their strategy. In this work, we use\n$\\epsilon$-Nash equilibria to approximate the computation of Nash equilibria.\nSpecifically, we focus on turn-based, multiplayer stochastic games played on\ngraphs, where players are restricted to stationary strategies -- strategies\nthat use randomness but not memory.\n  The problem of deciding the constrained existence of stationary Nash\nequilibria -- where each player's payoff must lie within a given interval -- is\nknown to be $\\exists\\mathbb{R}$-complete in such a setting (Hansen and\nS{\\o}lvsten, 2020). We extend this line of work to stationary $\\epsilon$-Nash\nequilibria and present an algorithm that solves the following promise problem:\ngiven a game with a Nash equilibrium satisfying the constraints, compute an\n$\\epsilon$-Nash equilibrium that $\\epsilon$-satisfies those same constraints --\nsatisfies the constraints up to an $\\epsilon$ additive error. Our algorithm\nruns in FNP^NP time.\n  To achieve this, we first show that if a constrained Nash equilibrium exists,\nthen one exists where the non-zero probabilities are at least an inverse of a\ndouble-exponential in the input. We further prove that such a strategy can be\nencoded using floating-point representations, as in the work of Frederiksen and\nMiltersen (2013), which finally gives us our FNP^NP algorithm.\n  We further show that the decision version of the promise problem is NP-hard.\nFinally, we show a partial tightness result by proving a lower bound for such\ntechniques: if a constrained Nash equilibrium exists, then there must be one\nthat where the probabilities in the strategies are double-exponentially small."}
{"id": "2508.15576", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15576", "abs": "https://arxiv.org/abs/2508.15576", "authors": ["Andreas Lööw", "Seung Hoon Park", "Daniele Nantes-Sobrinho", "Sacha-Élie Ayoun", "Opale Sjöstedt", "Philippa Gardner"], "title": "Compositional Symbolic Execution for the Next 700 Memory Models (Extended Version)", "comment": null, "summary": "Multiple successful compositional symbolic execution (CSE) tools and\nplatforms exploit separation logic (SL) for compositional verification and/or\nincorrectness separation logic (ISL) for compositional bug-finding, including\nVeriFast, Viper, Gillian, CN, and Infer-Pulse. Previous work on the Gillian\nplatform, the only CSE platform that is parametric on the memory model, meaning\nthat it can be instantiated to different memory models, suggests that the\nability to use custom memory models allows for more flexibility in supporting\nanalysis of a wide range of programming languages, for implementing custom\nautomation, and for improving performance. However, the literature lacks a\nsatisfactory formal foundation for memory-model-parametric CSE platforms.\n  In this paper, inspired by Gillian, we provide a new formal foundation for\nmemory-model-parametric CSE platforms. Our foundation advances the state of the\nart in four ways. First, we mechanise our foundation (in the interactive\ntheorem prover Rocq). Second, we validate our foundation by instantiating it to\na broad range of memory models, including models for C and CHERI. Third,\nwhereas previous memory-model-parametric work has only covered SL analyses, we\ncover both SL and ISL analyses. Fourth, our foundation is based on standard\ndefinitions of SL and ISL (including definitions of function specification\nvalidity, to ensure sound interoperation with other tools and platforms also\nbased on standard definitions)."}
{"id": "2508.15380", "categories": ["cs.GT", "cs.DS", "91B32, 91B10, 68W25"], "pdf": "https://arxiv.org/pdf/2508.15380", "abs": "https://arxiv.org/abs/2508.15380", "authors": ["Vishwa Prakash HV", "Ruta Mehta", "Prajakta Nimbhorkar"], "title": "Almost and Approximate EFX for Few Types of Agents", "comment": null, "summary": "We study the problem of fair allocation of a set of indivisible goods among\n$n$ agents with $k$ distinct additive valuations, with the goal of achieving\napproximate envy-freeness up to any good ($\\alpha-\\mathrm{EFX}$).\n  It is known that EFX allocations exist for $n$ agents when there are at most\nthree distinct valuations due to HV et al. Furthermore, Amanatidis et al.\nshowed that a $\\frac{2}{3}-\\mathrm{EFX}$ allocation is guaranteed to exist when\nnumber of agents is at most seven. In this paper, we show that a\n$\\frac{2}{3}-\\mathrm{EFX}$ allocation exists for any number of agents when\nthere are at most four distinct valuations.\n  Secondly, we consider a relaxation called $\\mathrm{EFX}$ with charity, where\nsome goods remain unallocated such that no agent envies the set of unallocated\ngoods. Akrami et al. showed that for $n$ agents and any $\\varepsilon \\in\n\\left(0, \\frac{1}{2}\\right]$, there exists a $(1-\\varepsilon)-\\mathrm{EFX}$\nallocation with at most $\\tilde{\\mathcal{O}}((n/\\varepsilon)^{\\frac{1}{2}})$\ngoods to charity. In this paper, we show that a $(1-\\varepsilon)-\\mathrm{EFX}$\nallocation with a $\\tilde{\\mathcal{O}}(k/\\varepsilon)^{\\frac{1}{2}}$ charity\nexists for any number of agents when there are at most $k$ distinct valuations."}
{"id": "2508.15750", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15750", "abs": "https://arxiv.org/abs/2508.15750", "authors": ["Celeste Barnaby", "Qiaochu Chen", "Ramya Ramalingam", "Osbert Bastani", "Isil Dillig"], "title": "Active Learning for Neurosymbolic Program Synthesis", "comment": null, "summary": "The goal of active learning for program synthesis is to synthesize the\ndesired program by asking targeted questions that minimize user interaction.\nWhile prior work has explored active learning in the purely symbolic setting,\nsuch techniques are inadequate for the increasingly popular paradigm of\nneurosymbolic program synthesis, where the synthesized program incorporates\nneural components. When applied to the neurosymbolic setting, such techniques\ncan -- and, in practice, do -- return an unintended program due to\nmispredictions of neural components. This paper proposes a new active learning\ntechnique that can handle the unique challenges posed by neural network\nmispredictions. Our approach is based upon a new evaluation strategy called\nconstrained conformal evaluation (CCE), which accounts for neural\nmispredictions while taking into account user-provided feedback. Our proposed\nmethod iteratively makes CCE more precise until all remaining programs are\nguaranteed to be observationally equivalent. We have implemented this method in\na tool called SmartLabel and experimentally evaluated it on three neurosymbolic\ndomains. Our results demonstrate that SmartLabel identifies the ground truth\nprogram for 98% of the benchmarks, requiring under 5 rounds of user interaction\non average. In contrast, prior techniques for active learning are only able to\nconverge to the ground truth program for at most 65% of the benchmarks."}
