<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.GT](#cs.GT) [Total: 13]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Detail Enhanced Gaussian Splatting for Large-Scale Volumetric Capture](https://arxiv.org/abs/2511.21697)
*Julien Philip,Li Ma,Pascal Clausen,Wenqi Xian,Ahmet Levent Taşel,Mingming He,Xueming Yu,David M. George,Ning Yu,Oliver Pilarski,Paul Debevec*

Main category: cs.GR

TL;DR: 本文提出了一种用于大规模、多表演者、高分辨率4D体积捕捉的独特系统，通过动态高斯泼溅和基于扩散的细节增强技术，实现了高质量的自由视点视频。


<details>
  <summary>Details</summary>
Motivation: 为了满足高端媒体制作的需求，该系统旨在解决大规模捕捉设备无法直接达到4K制作质量标准的问题，尤其是面部特写的细节要求。

Method: 采用了两种捕捉设备：场景捕捉设备和面部捕捉设备。首先使用4D高斯泼溅技术从场景捕捉设备中重建动态表演，然后通过基于扩散的细节增强模型，结合面部捕捉设备的高保真数据，实现高质量的图像渲染。

Result: 实验结果表明，该方法成功地在大规模捕捉设备的可扩展性和电影制作所需的高分辨率标准之间架起了桥梁。

Conclusion: 该系统提供了一种有效的解决方案，能够在满足高质量媒体制作需求的同时，实现大规模表演的高效捕捉和渲染。

Abstract: We present a unique system for large-scale, multi-performer, high resolution 4D volumetric capture providing realistic free-viewpoint video up to and including 4K resolution facial closeups. To achieve this, we employ a novel volumetric capture, reconstruction and rendering pipeline based on Dynamic Gaussian Splatting and Diffusion-based Detail Enhancement. We design our pipeline specifically to meet the demands of high-end media production. We employ two capture rigs: the Scene Rig, which captures multi-actor performances at a resolution which falls short of 4K production quality, and the Face Rig, which records high-fidelity single-actor facial detail to serve as a reference for detail enhancement. We first reconstruct dynamic performances from the Scene Rig using 4D Gaussian Splatting, incorporating new model designs and training strategies to improve reconstruction, dynamic range, and rendering quality. Then to render high-quality images for facial closeups, we introduce a diffusion-based detail enhancement model. This model is fine-tuned with high-fidelity data from the same actors recorded in the Face Rig. We train on paired data generated from low- and high-quality Gaussian Splatting (GS) models, using the low-quality input to match the quality of the Scene Rig, with the high-quality GS as ground truth. Our results demonstrate the effectiveness of this pipeline in bridging the gap between the scalable performance capture of a large-scale rig and the high-resolution standards required for film and media production.

</details>


### [2] [Improving Sparse IMU-based Motion Capture with Motion Label Smoothing](https://arxiv.org/abs/2511.22288)
*Zhaorui Meng,Lu Yin,Yangqing Hou,Anjun Chen,Shihui Guo,Yipeng Qin*

Main category: cs.GR

TL;DR: 该论文提出了一种称为运动标签平滑的新方法，用于稀疏惯性测量单元（IMU）基于人体运动捕捉任务，通过提高标签熵并满足运动的三个关键属性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在稀疏IMU人体运动捕捉的流水线和架构设计上，而对正则化方法的关注较少。本文旨在填补这一空白，提出一种更全面的AI工具包。

Method: 论文提出了运动标签平滑方法，通过分析人体运动标签的三个关键属性（时间平滑性、关节相关性和低频主导性），设计了基于骨架的Perlin噪声进行平滑。

Result: 在四个真实IMU数据集上的广泛实验表明，该方法对三种最先进方法的性能提升具有有效性和鲁棒的泛化能力。

Conclusion: 运动标签平滑方法通过提高标签熵并满足运动的关键属性，为稀疏IMU运动捕捉任务提供了一种有效的正则化工具。

Abstract: Sparse Inertial Measurement Units (IMUs) based human motion capture has gained significant momentum, driven by the adaptation of fundamental AI tools such as recurrent neural networks (RNNs) and transformers that are tailored for temporal and spatial modeling. Despite these achievements, current research predominantly focuses on pipeline and architectural designs, with comparatively little attention given to regularization methods, highlighting a critical gap in developing a comprehensive AI toolkit for this task. To bridge this gap, we propose motion label smoothing, a novel method that adapts the classic label smoothing strategy from classification to the sparse IMU-based motion capture task. Specifically, we first demonstrate that a naive adaptation of label smoothing, including simply blending a uniform vector or a ``uniform'' motion representation (e.g., dataset-average motion or a canonical T-pose), is suboptimal; and argue that a proper adaptation requires increasing the entropy of the smoothed labels. Second, we conduct a thorough analysis of human motion labels, identifying three critical properties: 1) Temporal Smoothness, 2) Joint Correlation, and 3) Low-Frequency Dominance, and show that conventional approaches to entropy enhancement (e.g., blending Gaussian noise) are ineffective as they disrupt these properties. Finally, we propose the blend of a novel skeleton-based Perlin noise for motion label smoothing, designed to raise label entropy while satisfying motion properties. Extensive experiments applying our motion label smoothing to three state-of-the-art methods across four real-world IMU datasets demonstrate its effectiveness and robust generalization (plug-and-play) capability.

</details>


### [3] [Geodiffussr: Generative Terrain Texturing with Elevation Fidelity](https://arxiv.org/abs/2511.23029)
*Tai Inui,Alexander Matsumura,Edgar Simo-Serra*

Main category: cs.GR

TL;DR: Geodiffussr是一种基于流匹配的管道，用于生成文本引导的纹理地图，并严格遵循提供的数字高程地图（DEM），通过多尺度内容聚合（MCA）显著提升了视觉保真度和高度-外观耦合。


<details>
  <summary>Details</summary>
Motivation: 大规模地形生成在计算机图形学中仍然是一项劳动密集型任务。本文旨在通过Geodiffussr解决这一问题，实现可控的2.5D景观生成，为粗粒度构思和预览提供支持。

Method: Geodiffussr采用流匹配管道和多尺度内容聚合（MCA）机制，将预训练编码器的DEM特征注入UNet模块的不同分辨率中，以强制全局到局部的高程一致性。

Result: 与非MCA基线相比，MCA显著提高了视觉保真度（FID下降49.16%，LPIPS下降32.33%，ΔdCor降至0.0016）。数据集使用了全球分布、按生物群落和气候分层的DEM与Sentinel-2图像配对。

Conclusion: Geodiffussr为可控的2.5D景观生成提供了强有力的基线，可与基于物理的地形和生态系统模拟器互补，适用于粗粒度构思和预览。

Abstract: Large-scale terrain generation remains a labor-intensive task in computer graphics. We introduce Geodiffussr, a flow-matching pipeline that synthesizes text-guided texture maps while strictly adhering to a supplied Digital Elevation Map (DEM). The core mechanism is multi-scale content aggregation (MCA): DEM features from a pretrained encoder are injected into UNet blocks at multiple resolutions to enforce global-to-local elevation consistency. Compared with a non-MCA baseline, MCA markedly improves visual fidelity and strengthens height-appearance coupling (FID $\downarrow$ 49.16%, LPIPS $\downarrow$ 32.33%, $Δ$dCor $\downarrow$ to 0.0016). To train and evaluate Geodiffussr, we assemble a globally distributed, biome- and climate-stratified corpus of triplets pairing SRTM-derived DEMs with Sentinel-2 imagery and vision-grounded natural-language captions that describe visible land cover. We position Geodiffussr as a strong baseline and step toward controllable 2.5D landscape generation for coarse-scale ideation and previz, complementary to physically based terrain and ecosystem simulators.

</details>


### [4] [Towards Generalized Position-Based Dynamics](https://arxiv.org/abs/2511.23131)
*Manas Chaudhary,Chandradeep Pokhariya,Rahul Narain*

Main category: cs.GR

TL;DR: 提出了一种广义的位置动力学方法，适用于任意非线性力模型，扩展了PBD算法的应用范围。


<details>
  <summary>Details</summary>
Motivation: 传统的PBD算法仅适用于线性力约束，限制了其在非线性力模型中的应用。为了克服这一限制，本文探索了一种适用于任意非线性力模型的PBD扩展方法。

Method: 通过将隐式时间积分方程重新表示为系统中各力的形式，并应用高斯-赛德尔迭代，开发了一种PBD类型的算法。

Result: 该方法成功应用于数据驱动的布料模型和高分辨率网格的模拟，性能优于基线牛顿求解器，并展示了其在不允许反转的体积Neo-Hookean弹性中的应用。

Conclusion: 广义PBD方法能够处理复杂的非线性力模型，为实时模拟提供了更灵活的工具。

Abstract: The position-based dynamics (PBD) algorithm is a popular and versatile technique for real-time simulation of deformable bodies, but is only applicable to forces that can be expressed as linearly compliant constraints. In this work, we explore a generalization of PBD that is applicable to arbitrary nonlinear force models. We do this by reformulating the implicit time integration equations in terms of the individual forces in the system, to which applying Gauss-Seidel iterations naturally leads to a PBD-type algorithm. As we demonstrate, our method allows simulation of data-driven cloth models [Sperl et al. 2020] that cannot be represented by existing variations of position-based dynamics, enabling performance improvements over the baseline Newton-based solver for high mesh resolutions. We also show our method's applicability to volumetric neo-Hookean elasticity with an inversion barrier.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Expanding Specification Capabilities of a Gradual Verifier with Pure Functions](https://arxiv.org/abs/2511.22075)
*Doruk Alp Mutlu*

Main category: cs.PL

TL;DR: 渐进验证结合静态和动态检查，提供了一种逐步验证软件的增量方法。


<details>
  <summary>Details</summary>
Motivation: 现有渐进验证工具Gradual C0虽然在支持递归堆数据结构方面表现出色，但其规范语言在复杂表达式方面的能力有限，本研究旨在通过引入纯函数扩展其功能。

Method: 本研究扩展了Gradual C0的设计，引入纯函数这一常见构造，解决了不精确规范下纯函数公理化带来的技术挑战。

Result: 通过纯函数的引入，Gradual C0的规范能力和编码观测方法的便利性均得到提升。

Conclusion: 扩展Gradual C0的设计以支持纯函数，有效提升了其规范能力和实用性。

Abstract: Gradual verification soundly combines static checking and dynamic checking to provide an incremental approach for software verification. With gradual verification, programs can be partially specified first, and then the full specification of a program can be achieved in incremental steps. The first and only practicable gradual verifier based on symbolic execution, Gradual C0, supports recursive heap data structures. Despite recent efforts to improve the expressivity of Gradual C0's specification language, Gradual C0's specification language is still limited in its capabilities for complex expressions. This work explores an extension to Gradual C0's design with a common construct supported by many static verification tools, pure functions, which both extend the specification capabilities of Gradual C0 and increase the ease of encoding observer methods in Gradual C0. Our approach addresses the technical challenges related to the axiomatisation of pure functions with imprecise specifications.

</details>


### [6] [On Circuit Description Languages, Indexed Monads, and Resource Analysis](https://arxiv.org/abs/2511.22419)
*Ken Sakayori,Andrea Colledan,Ugo Dal Lago*

Main category: cs.PL

TL;DR: 该论文引入了基于单子的指称模型,并被证明适用于Proto-Quipper家族的计算模型,这些模型是Quipper编程语言的理想化版本。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过单子方法分离项的值和其副作用产生的电路,以实现对电路大小的控制,并通过新颖的电路代数概念验证丰富的类型系统。

Method: 采用了基于单子的指称模型,引入电路代数概念,支持对电路生成的副作用进行量化分析。

Result: 模型能够控制电路的大小,并通过电路代数提出了效应类型化的新形式,保证了优化后的电路定量性质。

Conclusion: 提出的语义框架通过电路代数,为优化后的电路提供了新的量化性质保证,丰富了类型系统的验证方法。

Abstract: In this paper, a monad-based denotational model is introduced and shown adequate for the Proto-Quipper family of calculi, themselves being idealized versions of the Quipper programming language. The use of a monadic approach allows us to separate the value to which a term reduces from the circuit that the term itself produces as a side effect. In turn, this enables the denotational interpretation and validation of rich type systems in which the size of the produced circuit can be controlled. Notably, the proposed semantic framework, through the novel concept of circuit algebra, suggests forms of effect typing guaranteeing quantitative properties about the resulting circuit, even in presence of optimizations.

</details>


### [7] [A Synthetic Reconstruction of Multiparty Session Types (with Appendix)](https://arxiv.org/abs/2511.22692)
*David Castro-Perez,Francisco Ferreira,Sung-Shik Jongmans*

Main category: cs.PL

TL;DR: 本文提出了一种新的多议会话类型（MPST）方法，称为合成方法，既具有表达能力又具有组合性，避免了传统方法中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有MPST方法在表达能力和组合性之间难以权衡，经典方法虽组合性强但表达能力有限，而新方法虽表达能力高但组合性差且扩展性不佳。

Method: 通过一种新的类型系统，直接验证每个进程是否符合全局协议规范，避免了中间局部类型和投影的需求，并以标记转换系统（LTS）表示全局类型。

Result: 该方法支持一系列具有挑战性的协议，超越现有组合技术的局限，且可验证任何"行为良好"的LTS规范，覆盖标准全局类型语法无法表达的协议。

Conclusion: 合成方法在保持概念简洁的同时，显著提升了MPST的表达能力和组合性，已在Agda中形式化并实现为VS Code的扩展原型。

Abstract: Multiparty session types (MPST) provide a rigorous foundation for verifying the safety and liveness of concurrent systems. However, existing approaches often force a difficult trade-off: classical, projection-based techniques are compositional but limited in expressiveness, while more recent techniques achieve higher expressiveness by relying on non-compositional, whole-system model checking, which scales poorly.
  This paper introduces a new approach to MPST that delivers both expressiveness and compositionality, called the synthetic approach. Our key innovation is a type system that verifies each process directly against a global protocol specification, represented as a labelled transition system (LTS) in general, with global types as a special case. This approach uniquely avoids the need for intermediate local types and projection.
  We demonstrate that our approach, while conceptually simpler, supports a benchmark of challenging protocols that were previously beyond the reach of compositional techniques in the MPST literature. We generalise our type system, showing that it can validate processes against any specification that constitutes a "well-behaved" LTS, supporting protocols not expressible with the standard global type syntax. The entire framework, including all theorems and many examples, has been formalised and mechanised in Agda, and we have developed a prototype implementation as an extension to VS Code.

</details>


### [8] [All for One and One for All: Program Logics for Exploiting Internal Determinism in Parallel Programs](https://arxiv.org/abs/2511.23283)
*Alexandre Moine,Sam Westrick,Joseph Tassarotti*

Main category: cs.PL

TL;DR: 本文提出了一种称为Musketeer的分离逻辑，用于验证调度无关安全性，并进一步利用Angelic逻辑简化对内部确定性程序的验证。


<details>
  <summary>Details</summary>
Motivation: 尽管内部确定性并行编程简化了程序的推理过程，但缺乏验证框架来利用这一特性。本文旨在填补这一空白，通过定义调度无关安全性并提出相应的验证逻辑。

Method: 本文定义了调度无关安全性，并提出Musketeer分离逻辑来验证该属性。随后，使用Angelic逻辑动态选择和验证程序的顺序执行。应用这些方法验证了MiniDet类型系统的正确性。

Result: 通过Musketeer和Angelic逻辑，成功验证了MiniDet类型系统的合理性及其支持的内部确定性编程原语。所有结果均已在Rocq中使用Iris分离逻辑框架验证。

Conclusion: 本文提出的Musketeer和Angelic逻辑为内部确定性程序的验证提供了有效框架，简化了此类程序的推理过程。

Abstract: Nondeterminism makes parallel programs challenging to write and reason about. To avoid these challenges, researchers have developed techniques for internally deterministic parallel programming, in which the steps of a parallel computation proceed in a deterministic way. Internal determinism is useful because it lets a programmer reason about a program as if it executed in a sequential order. However, no verification framework exists to exploit this property and simplify formal reasoning about internally deterministic programs.
  To capture the essence of why internally deterministic programs should be easier to reason about, this paper defines a property called schedule-independent safety. A program satisfies schedule-independent safety, if, to show that the program is safe across all orderings, it suffices to show that one terminating execution of the program is safe. We then present a separation logic called Musketeer for proving that a program satisfies schedule-independent safety. Once a parallel program has been shown to satisfy schedule-independent safety, we can verify it with a new logic called Angelic, which allows one to dynamically select and verify just one sequential ordering of the program.
  Using Musketeer, we prove the soundness of MiniDet, an affine type system for enforcing internal determinism. MiniDet supports several core algorithmic primitives for internally deterministic programming that have been identified in the research literature, including a deterministic version of a concurrent hash set. Because any syntactically well-typed MiniDet program satisfies schedule-independent safety, we can apply Angelic to verify such programs.
  All results in this paper have been verified in Rocq using the Iris separation logic framework.

</details>


### [9] [TypeDis: A Type System for Disentanglement](https://arxiv.org/abs/2511.23358)
*Alexandre Moine,Stephanie Balzer,Alex Xu,Sam Westrick*

Main category: cs.PL

TL;DR: 论文提出了一种名为TypeDis的类型系统，用于自动验证并行程序的解耦性，减轻程序员手动证明的负担。


<details>
  <summary>Details</summary>
Motivation: 现有的解耦性验证方法（如DisLog）需要大量专业知识和手动证明，TypeDis旨在通过类型系统自动验证解耦性。

Method: TypeDis是一种基于时间戳的区域类型系统，支持iso递归类型和多态性，允许时间戳在类型检查过程中动态变化。

Result: TypeDis成功验证了解耦性，并通过Rocq证明助手验证了其正确性。

Conclusion: TypeDis提供了一种高效且自动化的解耦性验证方法，显著减少了程序员的负担。

Abstract: Disentanglement is a runtime property of parallel programs guaranteeing that parallel tasks remain oblivious to each other's allocations. As demonstrated in the MaPLe compiler and run-time system, disentanglement can be exploited for fast automatic memory management, especially task-local garbage collection with no synchronization between parallel tasks. However, as a low-level property, disentanglement can be difficult to reason about for programmers. The only means of statically verifying disentanglement so far has been DisLog, an Iris-fueled variant of separation logic, mechanized in the Rocq proof assistant. DisLog is a fully-featured program logic, allowing for proof of functional correctness as well as verification of disentanglement. Yet its employment requires significant expertise and per-program proof effort.
  This paper explores the route of automatic verification via a type system, ensuring that any well-typed program is disentangled and lifting the burden of carrying out manual proofs from the programmer. It contributes TypeDis, a type system inspired by region types, where each type is annotated with a timestamp, identifying the task that allocated it. TypeDis supports iso-recursive types as well as polymorphism over both types and timestamps. Crucially, timestamps are allowed to change during type-checking, at join points as well as via a form of subtyping, dubbed subtiming. The paper illustrates TypeDis and its features on a range of examples. The soundness of TypeDis and the examples are mechanized in the Rocq proof assistant, using an improved version of DisLog, dubbed DisLog2.

</details>


### [10] [RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing](https://arxiv.org/abs/2511.23472)
*Yusuke Matsushita,Kengo Hirata,Ryo Wakizaka,Emanuele D'Osualdo*

Main category: cs.PL

TL;DR: 本文提出了RapunSL，一种新颖的量子分离逻辑，通过引入线性组合和混合连接词，显著提高了量子程序推理的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 量子分离逻辑（QSL）作为一种工具，旨在提高量子程序演绎推理的可扩展性。然而，量子领域中存在两种独特的局部性概念，需要通过新的逻辑来解决。

Method: 作者构建了RapunSL，引入了线性组合和混合两种连接词，并结合分离操作，实现了对叠加态和测量导致的混合态的纯态推理。

Result: 通过一系列具有挑战性的案例研究，证明了RapunSL在推理可扩展性方面的显著改进。

Conclusion: RapunSL通过结合线性组合、混合和分离操作，为量子程序的推理提供了一种更高效和可扩展的方法。

Abstract: Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [Tacit Bidder-Side Collusion: Artificial Intelligence in Dynamic Auctions](https://arxiv.org/abs/2511.21802)
*Sriram Tolety*

Main category: cs.GT

TL;DR: 研究大型语言模型作为自主投标人是否能在不接受平台支付的情况下通过协调在荷兰拍卖中默示共谋，并在控制模拟中观察到超竞争价格。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型作为投标人时是否能在重复拍卖中默示共谋，以及市场结构如何影响这种共谋行为。

Method: 采用最小化重复拍卖模型，提出激励相容条件和共谋可持续性阈值，并在控制实验中模拟多个语言模型的行为。

Result: 在小型拍卖场景中观察到系统性的超竞争价格，随着投标人数增加，行为逐渐回归竞争；语言模型使用了多种机制（如焦点接受时间或耐心策略）促进默示协调。

Conclusion: 研究表明语言模型能够在拍卖中默示共谋，市场结构调整比能力限制更能有效缓解这种共谋行为。

Abstract: We study whether large language models acting as autonomous bidders can tacitly collude by coordinating when to accept platform posted payouts in repeated Dutch auctions, without any communication. We present a minimal repeated auction model that yields a simple incentive compatibility condition and a closed form threshold for sustainable collusion for subgame-perfect Nash equilibria. In controlled simulations with multiple language models, we observe systematic supra-competitive prices in small auction settings and a return to competitive behavior as the number of bidders in the market increases, consistent with the theoretical model. We also find LLMs use various mechanisms to facilitate tacit coordination, such as focal point acceptance timing versus patient strategies that track the theoretical incentives. The results provide, to our knowledge, the first evidence of bidder side tacit collusion by LLMs and show that market structure levers can be more effective than capability limits for mitigation.

</details>


### [12] [The Evolution of Trust under Institutional Moral Hazard](https://arxiv.org/abs/2511.21875)
*Hiroaki Chiba-Okabe,Joshua B. Plotkin*

Main category: cs.GT

TL;DR: 研究营利性平台通过广播声誉来促进市场参与者信任的行为，揭示平台存在声誉信号通胀的动机，同时为了维持市场信任而自我限制失真程度。


<details>
  <summary>Details</summary>
Motivation: 探讨营利性平台在维护声誉系统时的动机及其对社会效用的影响。

Method: 建立理论模型，分析平台、买家和卖家之间的动态互动，考察声誉信号的准确性与其对市场行为的影响。

Result: 平台倾向于声誉信号通胀以增加佣金收入，但也需自我限制失真程度以维持市场信任；当平台可自由设置佣金时，可能投资高精度声誉系统。

Conclusion: 平台的激励与其为社会参与者带来的效用之间存在复杂张力，最优策略可能涉及平衡声誉系统的准确性与盈利能力。

Abstract: We study the behavior of for-profit institutions that broadcast reputations to foster trust among market participants. We develop a theoretical model in which buyers and sellers are matched on a platform to engage in transactions involving a moral hazard: sellers can either faithfully deliver goods after receiving payment, or not. Although the buyer does not know a seller's true type, the platform maintains a reputation system that probabilistically assigns binary reputation signals. Buyers make purchase decisions based on reputation signals, which influence the payoffs to sellers who then adapt their type over time. These market dynamics ultimately shape the platform's profit from commissions on sales. Our analysis reveals that platforms inherently have an incentive for rating inflation, driven by the desire to increase commission. This introduces a second layer of moral hazard: the platform's incentive to distort reputations for its own profit. Such distortion is self-limited by the platform's need to maintain enough accuracy that trustworthy sellers remain in the market, without which rational buyers would refrain from purchases altogether. Nonetheless, the optimal strategy for the platform can be to invest in order to reduce signal accuracy. When the platform can freely set commission fees, however, maximum profit may be achieved by costly investment in an accurate reputation system. These findings highlight the intricate tensions between platform incentives and resulting social utility for marketplace participants.

</details>


### [13] [Aligning with Human Values to Enhance Interaction: An eHMI-Mediated Lane-Changing Negotiation Strategy Using Bayesian Inference](https://arxiv.org/abs/2511.22061)
*Boyao Peng,Linkun Liu*

Main category: cs.GT

TL;DR: 研究提出了一种基于博弈论的模型，结合贝叶斯推断分析车道变换场景中人类信任的动态变化，揭示善意欺骗在59.4%的情境中提升交互效率，52.7%的情境中提升安全性，但也可能引发36.9%驾驶员的信任崩溃。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，确保其稳定性和安全性需与人类价值观一致。现有研究忽视善意欺骗的潜在优势，本研究旨在填补这一空白。

Method: 研究采用博弈论模型分析车道变换场景，结合贝叶斯推断捕捉eHMI披露信息下人类信任的动态变化。

Result: 善意欺骗在59.4%场景中提升了交互效率，52.7%场景中提升了安全性，但也会导致36.9%驾驶员的信任崩溃。

Conclusion: 研究表明，有条件地使用善意欺骗可优化人机交互，但信任崩溃风险是未来自动驾驶系统开发中亟待解决的伦理漏洞。

Abstract: As autonomous driving technology evolves, ensuring the stability and safety of Autonomous Driving Systems (ADS) through alignment with human values becomes increasingly crucial. While existing research emphasizes the adherence of AI to honest ethical principles, it overlooks the potential benefits of benevolent deception, which maximize overall payoffs. This study proposes a game-theoretic model for lane-changing scenarios, incorporating Bayesian inference to capture dynamic changes in human trust during interactions under external Human-Machine Interface (eHMI) disclosed information. Case studies reveal that benevolent deception can enhance the efficiency of interaction in up to 59.4% of scenarios and improve safety in up to 52.7%. However, in the most pronounced cases, deception also led to trust collapse in up to 36.9% of drivers, exposing a critical vulnerability in the ethical design of ADS. The findings suggest that aligning ADS with comprehensive human ethical values, including the conditional use of benevolent deception, can enhance human-machine interaction. Additionally, the risk of trust collapse remains a major ethical loophole that must be addressed in future ADS development.

</details>


### [14] [On Computing the Shapley Value in Bankruptcy Games -llustrated by Rectified Linear Function Game-](https://arxiv.org/abs/2511.22208)
*Shunta Yamazaki,Tomomi Matsui*

Main category: cs.GT

TL;DR: 本文讨论了破产游戏中计算Shapley值的问题，证明其为NP完全问题，并提出递归算法和动态规划技术，以及基于蒙特卡洛采样的高效近似方法FPRAS。


<details>
  <summary>Details</summary>
Motivation: 研究破产游戏中Shapley值的计算问题，探索其与加权投票游戏中Shapley-Shubik指数的关系，并提出高效计算方法。

Method: 结合动态规划技术、递归算法（包括O'Neill的递归完成法和新的对偶博弈公式）以及FPRAS蒙特卡洛采样方法。

Result: 证明了破产游戏中Shapley值的计算是NP完全问题，递归算法和FPRAS提供了高效的计算和近似方案。

Conclusion: 破产游戏中Shapley值的计算复杂，但通过递归算法和蒙特卡洛采样方法可实现高效和近似求解。

Abstract: In this research, we discuss a problem of calculating the Shapley value in bankruptcy games. We show that the decision problem of computing the Shapley value in bankruptcy games is NP-complete. We also investigate the relationship between the Shapley value of bankruptcy games and the Shapley-Shubik index in weighted voting games. The relation naturally implies a dynamic programming technique for calculating the Shapley value. We also present two recursive algorithms for computing the Shapley value: the first is the recursive completion method originally proposed by O'Neill, and the second is our novel contribution based on the dual game formulation. These recursive approaches offer conceptual clarity and computational efficiency, especially when combined with memoisation technique. Finally, we propose a Fully Polynomial-Time Randomized Approximation Scheme (FPRAS) based on Monte Carlo sampling, providing an efficient approximation method for large-scale instances.

</details>


### [15] [Mechanism Design under Unawareness -- Extended Abstract](https://arxiv.org/abs/2511.22369)
*Kym Pram,Burkhard C. Schipper*

Main category: cs.GT

TL;DR: 研究如何在不对称认知和信息条件下设计机制，通过动态版本的Vickrey-Clarke-Groves机制实现社会选择功能的最优效率，同时考虑预算平衡和参与约束。


<details>
  <summary>Details</summary>
Motivation: 探讨机制设计在不对称认知和信息环境下的可行性，致力于在无需完全预知的情况下实现社会选择功能的最优效率。

Method: 采用准线性效用和私有价值假设，开发动态版本的Vickrey-Clarke-Groves机制，揭示真实类型并在更高认知层次上逐步完善。

Result: 证明可以在不对称认知条件下实现社会选择功能的最优效率，预算平衡和参与约束不受事前未知因素的影响。

Conclusion: 动态机制能够有效处理不对称认知问题，提出了一种预算平衡的动态反向第二价格拍卖模型用于复杂项目的采购。

Abstract: We study the design of mechanisms under asymmetric awareness and information. While the mechanism designer cannot necessarily commit to a particular social choice function in the face of unawareness, she can at least commit to properties of social choice functions such as efficiency given ex post awareness. Assuming quasi-linear utilities and private values, we show that we can implement in conditional dominant strategies a social choice function that is utilitarian ex post efficient under pooled awareness without the need of the social planner being fully aware ex ante. To this end, we develop novel dynamic versions of Vickrey-Clarke-Groves mechanisms in which true types are revealed and subsequently elaborated at endogenous higher awareness levels. We explore how asymmetric awareness affects budget balance and participation constraints. We show that ex ante unforeseen contingencies are no excuse for deficits. Finally, we propose a dynamic elaboration reverse second price auction for efficient procurement of complex incompletely specified projects with budget balance and participation constraints.

</details>


### [16] [Solving Four Open Problems about Core Stability in Altruistic Hedonic Games](https://arxiv.org/abs/2511.22370)
*Jörg Rothe,Ildikó Schlotter*

Main category: cs.GT

TL;DR: 本文解决了四种变体的利他主义享乐博弈中核心稳定性验证问题的复杂性，证明这些问题均为coNP完全问题。


<details>
  <summary>Details</summary>
Motivation: 享乐博弈是合作博弈理论与计算社会选择的交叉研究领域。Kerkmann等人引入了利他主义享乐博弈，其中玩家的效用不仅依赖于自身对联盟的评价，还依赖于朋友的评价。然而，四种变体的利他主义享乐博弈中核心稳定性验证问题的复杂性尚未解决。

Method: 通过构建复杂的网络朋友关系中的精巧装置，作者对四种变体的利他主义享乐博弈（基于平均和最小值的“平等待遇”和“利他待遇”偏好）进行了研究。

Result: 研究证明，这四种变体的核心稳定性验证问题均为coNP完全问题。

Conclusion: 本文填补了利他主义享乐博弈中核心稳定性验证问题的复杂性空白，表明这些问题均具有较高的计算复杂性。

Abstract: Hedonic games -- at the interface of cooperative game theory and computational social choice -- are coalition formation games in which the players have preferences over the coalitions they can join. Kerkmann et al. [13] introduced altruistic hedonic games where the players' utilities depend not only on their own but also on their friends' valuations of coalitions. The complexity of the verification problem for core stability has remained open in four variants of altruistic hedonic games: namely, for the variants with average- and minimum-based "equal-treatment" and "altruistic-treatment" preferences. We solve these four open questions by proving the corresponding problems coNP-complete; our reductions rely on rather intricate gadgets in the related networks of friends.

</details>


### [17] [Common $p$-Belief with Plausibility Measures: Extended Abstract](https://arxiv.org/abs/2511.22372)
*Eric Pacuit,Leo Yang*

Main category: cs.GT

TL;DR: 该论文将Aumann的“同意不同意”定理和Monderer-Samet-Neeman的广义共识定理从经典概率测度扩展到更一般的似然测度框架，并提供了新的证明和应用。


<details>
  <summary>Details</summary>
Motivation: 动机在于将广义共识定理从经典概率测度推广到Halpern提出的似然测度框架，以统一多种非经典信念模型。

Method: 方法包括在经典设置下提供Monderer-Samet-Neeman定理的新证明，并基于原有证明和新证明，提出两种针对似然测度结构的广义定理。

Result: 结果表明，这些广义结果适用于多种非经典信念模型（如条件概率结构和词典概率结构），并且当广义定理不适用时，原定理也会失效。

Conclusion: 结论是论文成功识别了满足Monderer-Samet-Neeman共识定理的信念模型的最小条件。

Abstract: Aumann's famous Agreeing to Disagree Theorem states that if a group of agents share a common prior, update their beliefs by Bayesian conditioning based on private information, and have common knowledge of their posterior beliefs regarding some event, these posteriors must be identical. There is an elegant generalization of this theorem by Monderer and Samet, later refined by Neeman: if a group of agents share a common prior, update their beliefs using Bayesian conditioning on private information, and have common p-belief of their posteriors, these posteriors must be close (i.e., they cannot differ by more than 1 - p). Here, common p-belief generalizes the concept of common knowledge to probabilistic beliefs: agents commonly p-believe an event E if everyone believes E to at least degree p, everyone believes to at least degree p that everyone believes E to at least degree p, and so on.
  This paper further extends the Monderer-Samet-Neeman Agreement Theorem from classical probability measures to plausibility measures -- a very general framework introduced by Halpern that unifies many formal models of belief. To facilitate this extension, we provide a new proof of the Monderer-Samet-Neeman theorem in the classical setting. Building upon both the original proof and our new proof, we offer two different generalizations of the theorem to plausibility-based structures.
  We then apply these generalized results to several non-classical belief models, including conditional probability structures and lexicographic probability structures. Moreover, we show that whenever our generalized theorems do not apply, the Monderer-Samet-Neeman Agreement Theorem fails. These findings suggest that our results successfully identify the minimal conditions required for a belief model to satisfy the Monderer-Samet-Neeman Agreement Theorem.

</details>


### [18] [Skating System Unveiled: Exploring Preference Aggregation in Ballroom Tournaments](https://arxiv.org/abs/2511.22384)
*Laryssa Horn,Paul Nüsken,Jörg Rothe,Tessa Seeger*

Main category: cs.GT

TL;DR: 该论文介绍了源自舞蹈比赛评审系统的Skating System Single (SkS)投票系统，并将其纳入计算社会选择框架中。通过分析SkS的数学特性和易受操控性，论文比较了SkS与Bucklin投票系统的异同，并揭示了其优势和局限。


<details>
  <summary>Details</summary>
Motivation: SkS系统源自舞蹈比赛评审系统，但其作为投票系统的特性尚未被深入研究。论文旨在填补这一空白，系统分析SkS的性质及其在选举中的表现，特别是在操控和选举控制方面的表现。

Method: 论文通过对SkS的数学公理化分析，评估其满足或不满足的选举理论准则（如多数准则、Condorcet准则等），并研究了其在操控和选举控制问题中的表现，包括NP完全性和多项式时间可解性分析。

Result: 研究发现，SkS满足非独裁性、多数准则、正响应性等性质，但违反Condorcet准则、一致性等；操控问题中的联盟加权操控是NP完全的，而破坏性操控可在多项式时间内解决。选举控制问题中，删除候选人或增加选民的构造性控制是NP完全的，破坏性控制则可在多项式时间内解决。

Conclusion: SkS作为一种新的投票系统，在理论上具有独特的性质和局限性。其易受操控性和选举控制问题的复杂性为其在实际应用中提供了重要的权衡点，也为未来研究提供了方向。

Abstract: The Skating System, which originated from the scrutineering system in dance sport tournaments, can be formulated as a voting system: We introduce and formalize the Skating System Single (SkS, for short), a new voting system embedded into the framework of computational social choice. Although SkS has similarities with Bucklin voting, it differs from it because it is subject to additional constraints when determining the election winners. Through an analysis of the axiomatic properties of SkS and of its vulnerability to manipulative and electoral control attacks, we compare SkS with Bucklin voting and provide insights into its potential strengths and weaknesses. In particular, we show that SkS satisfies nondictatorship as well as the majority criterion, positive responsiveness, monotonicity, and citizens' sovereignty but violates the Condorcet criterion, strong monotonicity, independence of clones, consistency, participation, resoluteness, and strategy-proofness. Further, we study manipulation, i.e., where (groups of) voters vote strategically to improve the outcome of an election in their favor, showing that the constructive coalitional weighted manipulation problem for SkS is NP-complete, while the destructive variant can be solved in polynomial time. Lastly, we initiate the study of electoral control, where an external agent attempts to change the election outcome by interfering with the structure of the election. Here, we show NP-completeness for constructive and destructive control by deleting candidates as well as for constructive control by adding voters, whereas we show that the problem of destructive control by adding voters can be solved in polynomial time.

</details>


### [19] [Prudent Rationalizability and the Best Rationalization Principle](https://arxiv.org/abs/2511.22388)
*Nicodemo De Vito*

Main category: cs.GT

TL;DR: 本文研究了具有完美记忆的有限顺序博弈中的谨慎推理，提出了谨慎合理性（prudent rationalizability）的定义，并展示了其与标准概率表示的条件信念等价性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是针对有限顺序博弈中的谨慎推理，提出一种新的谨慎合理性定义，以改进现有的理性化方法。

Method: 通过条件非标准概率测度表示玩家的信念，并引入c-强信念（c-strong belief）的概念，将谨慎合理性定义为信念的迭代约简过程。

Result: 研究表明，提出的谨慎合理性定义与标准概率表示的条件信念等价，且可以通过迭代可接受性算法化地表征。此外，该定义还能扩展到具有无意识的顺序博弈中。

Conclusion: 本文成功定义了谨慎合理性，并证明了其在顺序博弈中的应用潜力，包括对无意识情形的适应性。

Abstract: We study cautious reasoning in finite sequential games played by agents with perfect recall. Our contribution lies in formulating a definition of prudent rationalizability (Heifetz et al. 2021, BEJTE) as an iterative reduction procedure of beliefs. To this end, we represent the players' beliefs by systems of conditional non-standard probability measures. The key novelty is the notion of c-strong belief, a non-standard, "cautious" version of strong belief (Battigalli and Siniscalchi 2002, JET). Our formulation of prudent rationalizability embodies a "best rationalization principle" similar to the one that underlies the solution concept of strong rationalizability. The main results show the equivalence between the proposed definition with the one originally put forth by Heifetz et al. (2021) in terms of conditional beliefs represented by standard probabilities. In particular, it is shown that prudent rationalizability can be algorithmically characterized by iterated admissibility. Finally, our formulation can be extended to sequential games with unawareness.

</details>


### [20] [Beyond Last-Click: An Optimal Mechanism for Ad Attribution](https://arxiv.org/abs/2511.22918)
*Nan An,Weian Li,Qi Qi,Changyuan Yu,Liang Zhang*

Main category: cs.GT

TL;DR: 该论文提出了一种新的广告归因理论模型，设计了最优的DSIC机制PVM，并在准确性和公平性上优于LCM。


<details>
  <summary>Details</summary>
Motivation: 现有广告归因方法（如LCM）依赖启发式方法，缺乏理论保障，需要在准确性上引入更优的模型。

Method: 提出Peer-Validated Mechanism (PVM)作为DSIC机制，通过仅依赖其他平台的报告来确定归因，并在同质和异质环境下验证其准确性。

Result: PVM在同质环境下是最优DSIC机制，实验表明其在准确性和公平性上一致优于LCM。

Conclusion: PVM作为一种理论驱动的广告归因机制，提供了优于传统方法的表现，尤其在DSIC和准确性方面。

Abstract: Accurate attribution for multiple platforms is critical for evaluating performance-based advertising. However, existing attribution methods rely heavily on the heuristic methods, e.g., Last-Click Mechanism (LCM) which always allocates the attribution to the platform with the latest report, lacking theoretical guarantees for attribution accuracy. In this work, we propose a novel theoretical model for the advertising attribution problem, in which we aim to design the optimal dominant strategy incentive compatible (DSIC) mechanisms and evaluate their performance. We first show that LCM is not DSIC and performs poorly in terms of accuracy and fairness. To address this limitation, we introduce the Peer-Validated Mechanism (PVM), a DSIC mechanism in which a platform's attribution depends solely on the reports of other platforms. We then examine the accuracy of PVM across both homogeneous and heterogeneous settings, and provide provable accuracy bounds for each case. Notably, we show that PVM is the optimal DSIC mechanism in the homogeneous setting. Finally, numerical experiments are conducted to show that PVM consistently outperforms LCM in terms of attribution accuracy and fairness.

</details>


### [21] [Merging Mechanisms for Ads and Organic Items in E-commerce Platforms](https://arxiv.org/abs/2511.22925)
*Nan An,Weian Li,Qi Qi,Liang Zhang*

Main category: cs.GT

TL;DR: 本文提出了一种满足激励相容、个体理性、多槽位适应、不可分割候选集成和避免广告与有机项目重复曝光等所有理想属性的电商平台合并机制。


<details>
  <summary>Details</summary>
Motivation: 在电商平台中，广告项目和有机项目的优化目标不同，现有研究未能同时满足多个理想属性，本文旨在解决这一问题。

Method: 提出了广义固定机制和广义变化机制两种简单有效的合并机制，并通过理论分析证明了其在最优机制下的近似比。

Result: 理论证明了两种机制在简单和一般设置下均具有优于最优机制的近似比保证。

Conclusion: 本文设计的合并机制满足了所有理想属性，为电商平台的搜索结果页合并提供了有效解决方案。

Abstract: In contemporary e-commerce platforms, search result pages display two types of items: ad items and organic items. Ad items are determined through an advertising auction system, while organic items are selected by a recommendation system. These systems have distinct optimization objectives, creating the challenge of effectively merging these two components. Recent research has explored merging mechanisms for e-commerce platforms, but none have simultaneously achieved all desirable properties: incentive compatibility, individual rationality, adaptability to multiple slots, integration of inseparable candidates, and avoidance of repeated exposure for ads and organic items. This paper addresses the design of a merging mechanism that satisfies all these properties. We first provide the necessary conditions for the optimal merging mechanisms. Next, we introduce two simple and effective mechanisms, termed the generalized fix mechanism and the generalized change mechanism. Finally, we theoretically prove that both mechanisms offer guaranteed approximation ratios compared to the optimal mechanism in both simplest and general settings.

</details>


### [22] [Fairness in the Multi-Secretary Problem](https://arxiv.org/abs/2511.23097)
*Georgios Papasotiropoulos,Zein Pishbin*

Main category: cs.GT

TL;DR: 本文结合社会选择的公平视角与在线决策的多秘书问题研究，探讨多赢家选举，并提出一种结合在线算法与社会选择规则的机制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在弥补扩展合理代表(EJR)概念在线领域的局限性，探索多秘书问题和多赢家选举的结合视角。

Method: 提出了一系列机制，融合了在线算法与社会选择规则（如平等份额法和纳什规则），并进行了理论分析和实验评估。

Result: 提出的机制在理论和实验中都表现出了显著的有效性。

Conclusion: 通过结合在线算法与社会选择规则，研究为多秘书问题和多赢家选举提供了新的解决方案。

Abstract: This paper bridges two perspectives: it studies the multi-secretary problem through the fairness lens of social choice, and examines multi-winner elections from the viewpoint of online decision making. After identifying the limitations of the prominent proportionality notion of Extended Justified Representation (EJR) in the online domain, the work proposes a set of mechanisms that merge techniques from online algorithms with rules from social choice -- such as the Method of Equal Shares and the Nash Rule -- and supports them through both theoretical analysis and extensive experimental evaluation.

</details>


### [23] [Designing Rules for Choosing a Winner in a Debate](https://arxiv.org/abs/2511.23454)
*Alexander Heckett,Vincent Conitzer*

Main category: cs.GT

TL;DR: 本文研究了一个无知的委托人如何在两个知情代理人之间制定规则以选择更好的行动，提供了一个正式框架并分析了其性质和计算问题。


<details>
  <summary>Details</summary>
Motivation: 探讨在信息不对称的情况下，委托人如何设计规则以便在两个代理人中选择最佳行动方案。

Method: 通过形式化框架分析代理人的策略行为，研究了评估和优化委托人策略的计算问题。

Result: 展示了该框架的基本性质，并提供了关键的错误界限。

Conclusion: 本文提供了一种方法，帮助委托人在信息不对称的环境中设计更有效的决策规则。

Abstract: We consider settings where an uninformed principal must hear arguments from two better-informed agents, corresponding to two possible courses of action that they argue for. The arguments are verifiable in the sense that the true state of the world restricts the arguments that can be made by the agents. Each agent simply wants to be chosen as the winner and does so strategically based on the rule set by the principal. How should the principal design the rule to choose the better action? We provide a formal framework for answering this question, exhibit some basic properties of it, study the computational problems of evaluating and optimizing the principal's policy, and provide key error bounds.

</details>
