<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 8]
- [cs.GT](#cs.GT) [Total: 4]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Hybrelighter: Combining Deep Anisotropic Diffusion and Scene Reconstruction for On-device Real-time Relighting in Mixed Reality](https://arxiv.org/abs/2508.14930)
*Hanwen Zhao,John Akers,Baback Elmieh,Ira Kemelmacher-Shlizerman*

Main category: cs.GR

TL;DR: 提出了一种新的混合现实场景重新照明方法，通过整合图像分割、光线传播和基于滤波的技术，在边缘设备上实时实现高质量的照明效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法无法满足混合现实设备的实时性能需求，而场景理解方法因扫描限制导致结果不准确，2D图像滤波方法无法处理复杂几何和阴影。因此需要一种新方法来解决这些问题。

Method: 整合图像分割、通过各向异性扩散的光线传播和基于滤波的技术，在基本场景理解的基础上进行校正，以实现实时高质量的重新照明效果。

Result: 该方法纠正了设备扫描的不准确性，在边缘设备上实现了高达100帧每秒的实时重新照明效果，并通过与行业标准的直接比较和实际应用案例展示了其有效性。

Conclusion: 该方法在混合现实场景重新照明中表现出色，能够实时且准确地生成视觉上吸引人的照明效果，适用于如房地产等实际应用场景。

Abstract: Mixed Reality scene relighting, where virtual changes to lighting conditions
realistically interact with physical objects, producing authentic illumination
and shadows, can be used in a variety of applications. One such application in
real estate could be visualizing a room at different times of day and placing
virtual light fixtures. Existing deep learning-based relighting techniques
typically exceed the real-time performance capabilities of current MR devices.
On the other hand, scene understanding methods, such as on-device scene
reconstruction, often yield inaccurate results due to scanning limitations, in
turn affecting relighting quality. Finally, simpler 2D image filter-based
approaches cannot represent complex geometry and shadows. We introduce a novel
method to integrate image segmentation, with lighting propagation via
anisotropic diffusion on top of basic scene understanding, and the
computational simplicity of filter-based techniques. Our approach corrects
on-device scanning inaccuracies, delivering visually appealing and accurate
relighting effects in real-time on edge devices, achieving speeds as high as
100 fps. We show a direct comparison between our method and the industry
standard, and present a practical demonstration of our method in the
aforementioned real estate example.

</details>


### [2] [Inference Time Debiasing Concepts in Diffusion Models](https://arxiv.org/abs/2508.14933)
*Lucas S. Kupssinskü,Marco N. Bochernitsan,Jordan Kopper,Otávio Parraga,Rodrigo C. Barros*

Main category: cs.GR

TL;DR: 提出了一种名为DeCoDi的去偏方法，用于基于扩散的文本生成图像模型。该方法通过改变推理过程避免潜在维度中的偏见概念，不显著影响图像质量且计算开销低。实验证明其在性别、种族和年龄方面的去偏效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的去偏方法通常复杂且计算密集，因此需要一种更简单且高效的方法，能够在推理过程中直接减少偏见概念的影响。

Method: DeCoDi通过调整扩散过程，避免潜在维度中的偏见区域，实现去偏。该方法仅需调整推理过程，无需复杂的训练干预。

Result: 通过人类评估者对1,200张生成图像的评估，DeCoDi在性别、种族和年龄方面的去偏效果显著，且自动评估与人工评估结果一致。

Conclusion: DeCoDi是一种高效且易于应用的去偏方法，能够显著提升基于扩散模型的图像生成多样性，覆盖更多受保护属性。

Abstract: We propose DeCoDi, a debiasing procedure for text-to-image diffusion-based
models that changes the inference procedure, does not significantly change
image quality, has negligible compute overhead, and can be applied in any
diffusion-based image generation model. DeCoDi changes the diffusion process to
avoid latent dimension regions of biased concepts. While most deep learning
debiasing methods require complex or compute-intensive interventions, our
method is designed to change only the inference procedure. Therefore, it is
more accessible to a wide range of practitioners. We show the effectiveness of
the method by debiasing for gender, ethnicity, and age for the concepts of
nurse, firefighter, and CEO. Two distinct human evaluators manually inspect
1,200 generated images. Their evaluation results provide evidence that our
method is effective in mitigating biases based on gender, ethnicity, and age.
We also show that an automatic bias evaluation performed by the GPT4o is not
significantly statistically distinct from a human evaluation. Our evaluation
shows promising results, with reliable levels of agreement between evaluators
and more coverage of protected attributes. Our method has the potential to
significantly improve the diversity of images it generates by diffusion-based
text-to-image generative models.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Homomorphism Calculus for User-Defined Aggregations](https://arxiv.org/abs/2508.15109)
*Ziteng Wang,Ruijie Fang,Linus Zheng,Dixin Tang,Isil Dillig*

Main category: cs.PL

TL;DR: 本文提出了一个新的同态演算方法，用于验证和反驳用户定义聚合函数（UDAF）是否满足同态性质，从而提高框架的执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有数据处理框架（如Apache Spark和Flink）需要UDAF满足同态性质以实现高效执行，但缺乏有效的验证方法。

Method: 通过引入同态演算方法，既能验证UDAF的同态性质，又能构建对应的合并运算符以支持增量计算和并行执行。

Result: 实验证明，基于该演算的算法在真实UDAF上显著优于现有的两种合成器。

Conclusion: 本文提出的同态演算方法有效解决了UDAF同态性质的验证问题，为框架的高效执行提供了支持。

Abstract: Data processing frameworks like Apache Spark and Flink provide built-in
support for user-defined aggregation functions (UDAFs), enabling the
integration of domain-specific logic. However, for these frameworks to support
\emph{efficient} UDAF execution, the function needs to satisfy a
\emph{homomorphism property}, which ensures that partial results from
independent computations can be merged correctly. Motivated by this problem,
this paper introduces a novel \emph{homomorphism calculus} that can both verify
and refute whether a UDAF is a dataframe homomorphism. If so, our calculus also
enables the construction of a corresponding merge operator which can be used
for incremental computation and parallel execution. We have implemented an
algorithm based on our proposed calculus and evaluate it on real-world UDAFs,
demonstrating that our approach significantly outperforms two leading
synthesizers.

</details>


### [4] [Software Model Checking via Summary-Guided Search (Extended Version)](https://arxiv.org/abs/2508.15137)
*Ruijie Fang,Zachary Kincaid,Thomas Reps*

Main category: cs.PL

TL;DR: GPS是一种新型的软件模型检测算法，通过组合式静态分析和双层搜索策略高效检测程序中的错误，并在性能上优于现有最先进的模型检测工具。


<details>
  <summary>Details</summary>
Motivation: 现有的软件模型检测方法在处理长且输入依赖的错误路径时效率不高，因此需要一种更高效的算法来改进这一问题。

Method: GPS采用了组合式静态分析生成摘要，并利用双层搜索策略指导程序状态的搜索，同时通过插装技术确保其能够找到所有潜在的错误。

Result: GPS在包括SV-COMP和文献基准测试的多个程序中表现出色，优于现有最先进的模型检测工具，解决了更多问题且运行时间更短。

Conclusion: GPS通过其创新的静态分析和搜索策略，成为了一种高效且全面的软件模型检测工具，尤其适用于复杂程序中的错误检测。

Abstract: In this work, we describe a new software model-checking algorithm called GPS.
GPS treats the task of model checking a program as a directed search of the
program states, guided by a compositional, summary-based static analysis. The
summaries produced by static analysis are used both to prune away infeasible
paths and to drive test generation to reach new, unexplored program states. GPS
can find both proofs of safety and counter-examples to safety (i.e., inputs
that trigger bugs), and features a novel two-layered search strategy that
renders it particularly efficient at finding bugs in programs featuring long,
input-dependent error paths. To make GPS refutationally complete (in the sense
that it will find an error if one exists, if it is allotted enough time), we
introduce an instrumentation technique and show that it helps GPS achieve
refutation-completeness without sacrificing overall performance. We benchmarked
GPS on a suite of benchmarks including both programs from the Software
Verification Competition (SV-COMP) and from prior literature, and found that
our implementation of GPS outperforms state-of-the-art software model checkers
(including the top performers in SV-COMP ReachSafety-Loops category), both in
terms of the number of benchmarks solved and in terms of running time.

</details>


### [5] [Big-Stop Semantics: A Simple Way to Get the Benefits of Small-Step Semantics in a Big-Step Judgment](https://arxiv.org/abs/2508.15157)
*David M Kahn,Jan Hoffmann,Runming Li*

Main category: cs.PL

TL;DR: 本文提出了一种扩展的大步语义（big-step semantics）方法，通过归纳定义捕获程序的分歧行为，而无需引入错误状态。


<details>
  <summary>Details</summary>
Motivation: 大步语义在实践中因其简便性备受青睐，但它无法描述某些程序行为（如分歧）。本文旨在保留大步语义的便捷性的同时，扩展其能力以覆盖这些行为。

Method: 作者扩展了标准大步语义的推断规则，通过少量的额外规则定义了与小步语义（small-step semantics）的反射-传递闭包等效的评估判断。

Result: 该方法成功应用于类型化、非类型化、带效果的PCF以及基于while循环的命令式语言，展示了其通用性。

Conclusion: 扩展的大步语义（称为big-stop semantics）在保持简洁的同时，解决了传统大步语义无法处理的问题，为程序语义的描述提供了新的视角。

Abstract: As evident in the programming language literature, many practitioners favor
specifying dynamic program behavior using big-step over small-step semantics.
Unlike small-step semantics, which must dwell on every intermediate program
state, big-step semantics conveniently jump directly to the ever-important
result of the computation. Big-step semantics also typically involve fewer
inference rules than their small-step counterparts. However, in exchange for
ergonomics, big-step semantics give up power: Small-step semantics describes
program behaviors that are outside the grasp of big-step semantics, notably
divergence. This work presents a little-known extension of big-step semantics
with inductive definitions that captures diverging computations without
introducing error states. This big-stop semantics is illustrated for typed,
untyped, and effectful variants of PCF, as well as a while-loop-based
imperative language. Big-stop semantics extends the standard big-step inference
rules with a few additional rules to define an evaluation judgment that is
equivalent to the reflexive-transitive closure of small-step transitions. This
simple extension contrasts with other solutions in the literature which
sacrifice ergonomics by introducing many additional inference rules, global
state, and/or less-commonly-understood reasoning principles like coinduction.

</details>


### [6] [Probabilistic Inference for Datalog with Correlated Inputs](https://arxiv.org/abs/2508.15166)
*Jingbo Wang,Shashin Halalingaiah,Weiyi Chen,Chao Wang,Isil Dillig*

Main category: cs.PL

TL;DR: 本文介绍了一种名为Praline的Datalog扩展方法，用于在存在输入相关性时进行精确的概率推理，通过优化问题和高效算法解决可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有概率逻辑编程语言（如ProbLog）未考虑输入事实之间的统计相关性，导致推理结果不够精确。

Method: 提出Praline方法，将推理任务建模为约束优化问题，并通过δ-精确推理算法结合约束求解、静态分析和迭代优化提升可扩展性。

Result: 实验结果表明，Praline不仅能够高效扩展，还能提供紧致的概率边界。

Conclusion: Praline为存在输入相关性的概率推理提供了一种高效且精确的解决方案。

Abstract: Probabilistic extensions of logic programming languages, such as ProbLog,
integrate logical reasoning with probabilistic inference to evaluate
probabilities of output relations; however, prior work does not account for
potential statistical correlations among input facts. This paper introduces
Praline, a new extension to Datalog designed for precise probabilistic
inference in the presence of (partially known) input correlations. We formulate
the inference task as a constrained optimization problem, where the solution
yields sound and precise probability bounds for output facts. However, due to
the complexity of the resulting optimization problem, this approach alone often
does not scale to large programs. To address scalability, we propose a more
efficient $\delta$-exact inference algorithm that leverages constraint solving,
static analysis, and iterative refinement. Our empirical evaluation on
challenging real-world benchmarks, including side-channel analysis,
demonstrates that our method not only scales effectively but also delivers
tight probability bounds.

</details>


### [7] [Exploring the Theory and Practice of Concurrency in the Entity-Component-System Pattern](https://arxiv.org/abs/2508.15264)
*Patrick Redmond,Jonathan Castello,José Manuel Calderón Trilla,Lindsey Kuper*

Main category: cs.PL

TL;DR: 论文提出了一种名为Core ECS的正式模型，来抽象地理解实体-组件-系统（ECS）软件设计模式的本质，并探讨了其作为确定性并发编程模型的潜力。


<details>
  <summary>Details</summary>
Motivation: ECS模式在游戏开发中被广泛应用，但其在其他领域的认知度较低，且现有解释多局限于具体框架或不完善的比喻。作者希望通过建立Core ECS模型，揭示ECS模式的本质。

Method: 设计了Core ECS这一正式模型，抽象实现细节以揭示ECS模式的核心特性。通过识别一类确定性行为的Core ECS程序，探究其作为确定性并发编程模型的潜力。

Result: 研究发现，现有的ECS框架未能充分利用确定性并发的机会。Core ECS模型揭示了ECS模式作为确定性并发编程工具的潜力，为新型实现技术提供了空间。

Conclusion: 论文通过Core ECS模型揭示了ECS模式的本质，并指出了其在确定性并发编程中的应用潜力，为未来的ECS框架设计提供了新的方向。

Abstract: The Entity-Component-System (ECS) software design pattern, long used in game
development, encourages a clean separation of identity (entities), data
properties (components), and computational behaviors (systems). Programs
written using the ECS pattern are naturally concurrent, and the pattern offers
modularity, flexibility, and performance benefits that have led to a
proliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known
and not well understood outside of a few domains. Existing explanations of the
ECS pattern tend to be mired in the concrete details of particular ECS
frameworks, or they explain the pattern in terms of imperfect metaphors or in
terms of what it is not. We seek a rigorous understanding of the ECS pattern
via the design of a formal model, Core ECS, that abstracts away the details of
specific implementations to reveal the essence of software using the ECS
pattern. We identify a class of Core ECS programs that behave deterministically
regardless of scheduling, enabling use of the ECS pattern as a
deterministic-by-construction concurrent programming model. With Core ECS as a
point of comparison, we then survey several real-world ECS frameworks and find
that they all leave opportunities for deterministic concurrency unexploited.
Our findings point out a space for new ECS implementation techniques that
better leverage such opportunities.

</details>


### [8] [Fair Termination for Resource-Aware Active Objects](https://arxiv.org/abs/2508.15333)
*Francesco Dagnino,Paola Giannini,Violet Ka I Pun,Ulises Torrella*

Main category: cs.PL

TL;DR: 该论文提出了一个用于资源感知的主动对象模型的核心演算和类型系统，确保良好类型的程序能够公平终止。


<details>
  <summary>Details</summary>
Motivation: 主动对象系统用于建模分布式系统和业务流程工作流，具有并发性和资源感知性，因此需要开发资源感知的形式化模型。

Method: 结合了用于顺序程序的分级语义和类型系统技术，以及用于同步会话的公平终止技术，开发了一个核心演算和类型系统。

Result: 提出的类型系统确保良好类型的程序能够公平终止，即程序最终可以终止。

Conclusion: 该研究为资源感知的主动对象模型提供了形式化基础，并通过类型系统确保了程序的公平终止性。

Abstract: Active object systems are a model of distributed computation that has been
adopted for modelling distributed systems and business process workflows. This
field of modelling is, in essence, concurrent and resource-aware, motivating
the development of resource-aware formalisations on the active object model.
The contributions of this work are the development of a core calculus for
resource-aware active objects together with a type system ensuring that
well-typed programs are fairly terminating, i.e., they can always eventually
terminate. To achieve this, we combine techniques from graded semantics and
type systems, which are quite well understood for sequential programs, with
those for fair termination, which have been developed for synchronous~sessions.

</details>


### [9] [Compositional Symbolic Execution for the Next 700 Memory Models (Extended Version)](https://arxiv.org/abs/2508.15576)
*Andreas Lööw,Seung Hoon Park,Daniele Nantes-Sobrinho,Sacha-Élie Ayoun,Opale Sjöstedt,Philippa Gardner*

Main category: cs.PL

TL;DR: 本文提出了一种基于Gillian平台的新型内存模型参数化CSE平台的形式化基础，支持分离逻辑（SL）和不正确性分离逻辑（ISL）分析，并覆盖了多种内存模型。


<details>
  <summary>Details</summary>
Motivation: 现有的CSE工具和平台虽然利用了SL和ISL进行组合验证和错误查找，但缺乏对内存模型参数化的形式化基础，限制了其灵活性和适用范围。

Method: 受Gillian平台启发，本文在Rocq交互式定理证明器中提出了新的形式化基础，覆盖了SL和ISL分析，并实例化为多种内存模型（如C和CHERI）。

Result: 提出的形式化基础不仅机械化了理论，还通过广泛的内存模型实例进行了验证，同时扩展了SL和ISL的分析能力。

Conclusion: 本文为内存模型参数化CSE平台提供了新的形式化基础，支持更灵活的应用场景和更广泛的语言支持，同时确保了与其他基于标准定义的工具的互操作性。

Abstract: Multiple successful compositional symbolic execution (CSE) tools and
platforms exploit separation logic (SL) for compositional verification and/or
incorrectness separation logic (ISL) for compositional bug-finding, including
VeriFast, Viper, Gillian, CN, and Infer-Pulse. Previous work on the Gillian
platform, the only CSE platform that is parametric on the memory model, meaning
that it can be instantiated to different memory models, suggests that the
ability to use custom memory models allows for more flexibility in supporting
analysis of a wide range of programming languages, for implementing custom
automation, and for improving performance. However, the literature lacks a
satisfactory formal foundation for memory-model-parametric CSE platforms.
  In this paper, inspired by Gillian, we provide a new formal foundation for
memory-model-parametric CSE platforms. Our foundation advances the state of the
art in four ways. First, we mechanise our foundation (in the interactive
theorem prover Rocq). Second, we validate our foundation by instantiating it to
a broad range of memory models, including models for C and CHERI. Third,
whereas previous memory-model-parametric work has only covered SL analyses, we
cover both SL and ISL analyses. Fourth, our foundation is based on standard
definitions of SL and ISL (including definitions of function specification
validity, to ensure sound interoperation with other tools and platforms also
based on standard definitions).

</details>


### [10] [Active Learning for Neurosymbolic Program Synthesis](https://arxiv.org/abs/2508.15750)
*Celeste Barnaby,Qiaochu Chen,Ramya Ramalingam,Osbert Bastani,Isil Dillig*

Main category: cs.PL

TL;DR: 提出一种新的主动学习技术SmartLabel，用于处理神经符号程序合成中的神经网络误预测问题，通过受限一致性评估（CCE）策略提高精度，实验表明其在98%的基准测试中找到真实程序。


<details>
  <summary>Details</summary>
Motivation: 传统的主动学习技术在纯符号设置下有效，但在神经符号程序合成中由于神经组件误预测导致无法准确合成目标程序。本文旨在解决这一问题。

Method: 提出受限一致性评估（CCE）策略，结合用户反馈迭代优化，确保所有剩余程序在观测上等价，并实现为工具SmartLabel。

Result: SmartLabel在98%的基准测试中准确识别真实程序，平均用户交互次数少于5轮，传统方法仅能解决65%的基准。

Conclusion: SmartLabel有效解决了神经符号程序合成中的误预测问题，显著优于传统方法。

Abstract: The goal of active learning for program synthesis is to synthesize the
desired program by asking targeted questions that minimize user interaction.
While prior work has explored active learning in the purely symbolic setting,
such techniques are inadequate for the increasingly popular paradigm of
neurosymbolic program synthesis, where the synthesized program incorporates
neural components. When applied to the neurosymbolic setting, such techniques
can -- and, in practice, do -- return an unintended program due to
mispredictions of neural components. This paper proposes a new active learning
technique that can handle the unique challenges posed by neural network
mispredictions. Our approach is based upon a new evaluation strategy called
constrained conformal evaluation (CCE), which accounts for neural
mispredictions while taking into account user-provided feedback. Our proposed
method iteratively makes CCE more precise until all remaining programs are
guaranteed to be observationally equivalent. We have implemented this method in
a tool called SmartLabel and experimentally evaluated it on three neurosymbolic
domains. Our results demonstrate that SmartLabel identifies the ground truth
program for 98% of the benchmarks, requiring under 5 rounds of user interaction
on average. In contrast, prior techniques for active learning are only able to
converge to the ground truth program for at most 65% of the benchmarks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [AI Testing Should Account for Sophisticated Strategic Behaviour](https://arxiv.org/abs/2508.14927)
*Vojtech Kovarik,Eric Olav Chen,Sami Petersen,Alexis Ghersengorin,Vincent Conitzer*

Main category: cs.GT

TL;DR: 本文主张AI测试与评估需考虑系统是否能理解环境并进行策略性推理，并认为博弈论分析可优化评估设计。


<details>
  <summary>Details</summary>
Motivation: 为了确保AI系统在实际部署中的行为可预测与安全，需要改进评估方法以涵盖系统的策略性推理能力。

Method: 通过分析现有AI系统的实例、梳理相关研究并对典型评估场景进行形式化策略分析，支持提出的主张。

Result: 研究表明，博弈论分析可提升评估设计的有效性，并提供了一些研究方向。

Conclusion: AI评估需融入策略性推理考量，博弈论是提升评估设计的有力工具，亟需进一步研究。

Abstract: This position paper argues for two claims regarding AI testing and
evaluation. First, to remain informative about deployment behaviour,
evaluations need account for the possibility that AI systems understand their
circumstances and reason strategically. Second, game-theoretic analysis can
inform evaluation design by formalising and scrutinising the reasoning in
evaluation-based safety cases. Drawing on examples from existing AI systems, a
review of relevant research, and formal strategic analysis of a stylised
evaluation scenario, we present evidence for these claims and motivate several
research directions.

</details>


### [12] [A New Relaxation of Fairness in Two-Sided Matching Respecting Acquaintance Relationships](https://arxiv.org/abs/2508.15296)
*Ryota Takeshima,Kei Kimura,Ayumu Kuroki,Temma Wakasugi,Makoto Yokoo*

Main category: cs.GT

TL;DR: 该研究通过引入‘局部无嫉妒’的新公平性概念，探索在学生与学校匹配中实现帕累托效率与局部公平性的兼容性，重点关注学生之间的熟人关系。


<details>
  <summary>Details</summary>
Motivation: 传统双边匹配中效率与公平性的不兼容性，特别是帕累托效率与无嫉妒性之间的冲突，促使研究者提出新的公平性放松方法，以减少学生对非熟人的嫉妒。

Method: 通过无向图表示学生之间的熟人关系，定义‘局部嫉妒’为学生对熟人的嫉妒，并提出‘局部无嫉妒’作为新的公平性概念。研究在不同图结构和学校偏好下，分析帕累托效率与局部公平性的兼容性。

Result: 研究发现，通过限制图结构和学校偏好，可以实现帕累托效率与局部无嫉妒性的兼容，并引入局部版本的放松公平性来参数化嫉妒程度。

Conclusion: 研究证明了局部无嫉妒性是一种有效的公平性放松方法，为实际匹配问题中实现效率与公平性的平衡提供了新的理论支持。

Abstract: Two-sided matching, such as matching between students and schools, has been
applied to various aspects of real life and has been the subject of much
research, however, it has been plagued by the fact that efficiency and fairness
are incompatible. In particular, Pareto efficiency and justified-envy-freeness
are known to be incompatible even in the simplest one-to-one matching, i.e.,
the stable marriage problem. In previous research, the primary approach to
improving efficiency in matchings has been to tolerate students' envy, thereby
relaxing fairness constraints. In this study, we take a different approach to
relaxing fairness. Specifically, it focuses on addressing only the envy that
students may experience or prioritize more highly and seeks matchings without
such envy. More specifically, this study assumes that envy towards students who
are not acquaintances has less impact compared to envy towards students who are
acquaintances. Accordingly, we assume that the students know each other or not,
represented by an undirected graph, and define a local envy as a justified envy
toward an acquaintance or a neighbor in the graph. We then propose the property
that there is no local envy as a new relaxed concept of fairness, called local
envy-freeness. We analyze whether Pareto-efficient matching can be achieved
while maintaining local envy-freeness by meaningfully restricting the graph
structure and the school's preferences. To analyze in detail the fairness that
can achieve Pareto-efficient matching, we introduce a local version of the
relaxed fairness recently proposed by Cho et al. (AAMAS 2024), which
parameterizes the level of local envy-freeness by nonnegative integers. We then
clarify the level of local envy-freeness that can be achieved by
Pareto-efficient mechanisms for graphs that are ``close'' to trees and
single-peaked preferences on the graphs.

</details>


### [13] [ε-Stationary Nash Equilibria in Multi-player Stochastic Graph Games](https://arxiv.org/abs/2508.15356)
*Ali Asadi,Léonard Brice,Krishnendu Chatterjee,K. S. Thejaswini*

Main category: cs.GT

TL;DR: 本文研究如何在有限制的多人随机图上游戏中，通过计算ε-Nash均衡来近似Nash均衡，并提出一种FNP^NP时间算法来解决这一承诺问题。


<details>
  <summary>Details</summary>
Motivation: Nash均衡在多人游戏中的计算复杂度高，而ε-Nash均衡作为一种近似方法，可以更高效地计算。本文旨在扩展这一方法，针对有限制的多人随机图上游戏进行研究。

Method: 通过证明在存在约束Nash均衡的情况下，存在一个概率至少为输入的双指数倒数的策略，并利用浮点表示编码这些策略，最终提出一种FNP^NP时间算法来解决承诺问题。

Result: 提出的算法能够在给定存在满足约束的Nash均衡的游戏情况下，计算出一个ε-满足相同约束的ε-Nash均衡。同时证明了该承诺问题的决策版本是NP-hard的。

Conclusion: 本文不仅扩展了ε-Nash均衡在受限多人游戏中的应用，还展示了相关技术的部分紧下界，证明了某些策略中的概率必须为双指数小。

Abstract: A strategy profile in a multi-player game is a Nash equilibrium if no player
can unilaterally deviate to achieve a strictly better payoff. A profile is an
$\epsilon$-Nash equilibrium if no player can gain more than $\epsilon$ by
unilaterally deviating from their strategy. In this work, we use
$\epsilon$-Nash equilibria to approximate the computation of Nash equilibria.
Specifically, we focus on turn-based, multiplayer stochastic games played on
graphs, where players are restricted to stationary strategies -- strategies
that use randomness but not memory.
  The problem of deciding the constrained existence of stationary Nash
equilibria -- where each player's payoff must lie within a given interval -- is
known to be $\exists\mathbb{R}$-complete in such a setting (Hansen and
S{\o}lvsten, 2020). We extend this line of work to stationary $\epsilon$-Nash
equilibria and present an algorithm that solves the following promise problem:
given a game with a Nash equilibrium satisfying the constraints, compute an
$\epsilon$-Nash equilibrium that $\epsilon$-satisfies those same constraints --
satisfies the constraints up to an $\epsilon$ additive error. Our algorithm
runs in FNP^NP time.
  To achieve this, we first show that if a constrained Nash equilibrium exists,
then one exists where the non-zero probabilities are at least an inverse of a
double-exponential in the input. We further prove that such a strategy can be
encoded using floating-point representations, as in the work of Frederiksen and
Miltersen (2013), which finally gives us our FNP^NP algorithm.
  We further show that the decision version of the promise problem is NP-hard.
Finally, we show a partial tightness result by proving a lower bound for such
techniques: if a constrained Nash equilibrium exists, then there must be one
that where the probabilities in the strategies are double-exponentially small.

</details>


### [14] [Almost and Approximate EFX for Few Types of Agents](https://arxiv.org/abs/2508.15380)
*Vishwa Prakash HV,Ruta Mehta,Prajakta Nimbhorkar*

Main category: cs.GT

TL;DR: 本研究探讨了不可分物品的公平分配问题，证明了在不超过四种不同估值时存在2/3-EFX分配，并提出了在不超过k种估值时存在(1-ε)-EFX分配且慈善物品数量为O(k/ε)^1/2的结果。


<details>
  <summary>Details</summary>
Motivation: 解决在多代理系统中不可分物品的公平分配问题，特别是在不同估值情况下的近似无嫉妒性质（EFX）及其放松变体（EFX with charity），是计算经济学和社会选择理论中的重要课题。

Method: 通过数学证明和算法分析，研究了在不同估值情况下如何实现近似EFX分配以及EFX with charity分配。

Result: 证明了在不超过四种不同估值时存在2/3-EFX分配；同时在不超过k种估值时，存在(1-ε)-EFX分配且慈善物品数量为O((k/ε)^1/2)。

Conclusion: 本研究扩展了对EFX分配的理解，为不同估值情况下的公平分配提供了新的理论保证。

Abstract: We study the problem of fair allocation of a set of indivisible goods among
$n$ agents with $k$ distinct additive valuations, with the goal of achieving
approximate envy-freeness up to any good ($\alpha-\mathrm{EFX}$).
  It is known that EFX allocations exist for $n$ agents when there are at most
three distinct valuations due to HV et al. Furthermore, Amanatidis et al.
showed that a $\frac{2}{3}-\mathrm{EFX}$ allocation is guaranteed to exist when
number of agents is at most seven. In this paper, we show that a
$\frac{2}{3}-\mathrm{EFX}$ allocation exists for any number of agents when
there are at most four distinct valuations.
  Secondly, we consider a relaxation called $\mathrm{EFX}$ with charity, where
some goods remain unallocated such that no agent envies the set of unallocated
goods. Akrami et al. showed that for $n$ agents and any $\varepsilon \in
\left(0, \frac{1}{2}\right]$, there exists a $(1-\varepsilon)-\mathrm{EFX}$
allocation with at most $\tilde{\mathcal{O}}((n/\varepsilon)^{\frac{1}{2}})$
goods to charity. In this paper, we show that a $(1-\varepsilon)-\mathrm{EFX}$
allocation with a $\tilde{\mathcal{O}}(k/\varepsilon)^{\frac{1}{2}}$ charity
exists for any number of agents when there are at most $k$ distinct valuations.

</details>
