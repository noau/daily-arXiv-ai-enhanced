<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields](https://arxiv.org/abs/2507.08285)
*Gwanhyeong Koo,Sunjae Yoon,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: FlowDrag通过结合几何信息和用户定义的点，提出了一种更准确和一致的物体编辑方法，解决了现有方法中几何不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的拖拽编辑方法仅关注匹配用户定义的点，忽视了更广泛的几何结构，导致编辑时出现伪影或不稳定的结果，因此需要一种更准确的方法。

Method: FlowDrag通过从图像构建3D网格，并使用能量函数指导基于用户定义点的网格变形，然后将位移投影到2D并引入UNet去噪过程，以实现精确的编辑。

Result: FlowDrag在VFD Bench和DragBench上优于现有的拖拽编辑方法，且提出的VFD基准数据集提供了真实的编辑基准。

Conclusion: FlowDrag通过利用几何信息改进了拖拽编辑的准确性，并通过VFD基准数据集填补了评估空白，为未来的研究提供了方向。

Abstract: Drag-based editing allows precise object manipulation through point-based
control, offering user convenience. However, current methods often suffer from
a geometric inconsistency problem by focusing exclusively on matching
user-defined points, neglecting the broader geometry and leading to artifacts
or unstable edits. We propose FlowDrag, which leverages geometric information
for more accurate and coherent transformations. Our approach constructs a 3D
mesh from the image, using an energy function to guide mesh deformation based
on user-defined drag points. The resulting mesh displacements are projected
into 2D and incorporated into a UNet denoising process, enabling precise
handle-to-target point alignment while preserving structural integrity.
Additionally, existing drag-editing benchmarks provide no ground truth, making
it difficult to assess how accurately the edits match the intended
transformations. To address this, we present VFD (VidFrameDrag) benchmark
dataset, which provides ground-truth frames using consecutive shots in a video
dataset. FlowDrag outperforms existing drag-based editing methods on both VFD
Bench and DragBench.

</details>


### [2] [Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation](https://arxiv.org/abs/2507.08513)
*Liu He,Xiao Zeng,Yizhi Song,Albert Y. C. Chen,Lu Xia,Shashwat Verma,Sankalp Dayal,Min Sun,Cheng-Hao Kuo,Daniel Aliaga*

Main category: cs.GR

TL;DR: 为了解决多模态大语言模型（MLLMs）在捕捉相机-物体关系方面的不足，研究人员提出了一种合成生成流水线来创建大规模3D视觉指令数据集，显著提升了模型在相关任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在准确捕捉相机-物体关系（如物体方向、相机视角和拍摄角度）方面表现不佳，主要是因为训练数据中缺乏多样化的相机-物体关系和相应的文本描述。

Method: 研究人员提出了一种合成生成流水线，使用3D资产作为输入，通过渲染和基于扩散的图像生成模型创建保留精确相机-物体关系的逼真图像，同时利用大型语言模型（LLMs）生成文本提示以指导视觉指令调整和控制图像生成。

Result: 构建的Ultimate3D数据集包含24万个视觉问答（VQA）样本，具有精确的相机-物体关系标注。实验表明，基于该数据集微调的MLLMs在相机-物体关系识别任务上的平均准确率提升了33.4%，显著优于商业模型。

Conclusion: 该研究通过创建高质量的合成数据集，显著提升了MLLMs在相机-物体关系任务上的性能，其代码、数据集和基准将为多模态大语言模型的广泛应用做出贡献。

Abstract: Multimodal Large Language Models (MLLMs) struggle with accurately capturing
camera-object relations, especially for object orientation, camera viewpoint,
and camera shots. This stems from the fact that existing MLLMs are trained on
images with limited diverse camera-object relations and corresponding textual
descriptions. To address this, we propose a synthetic generation pipeline to
create large-scale 3D visual instruction datasets. Our framework takes 3D
assets as input and uses rendering and diffusion-based image generation models
to create photorealistic images preserving precise camera-object relations.
Additionally, large language models (LLMs) are used to generate text prompts
for guiding visual instruction tuning and controlling image generation. We
create Ultimate3D, a dataset of 240K VQAs with precise camera-object
annotations, and corresponding benchmark. MLLMs fine-tuned on our proposed
dataset outperform commercial models by a large margin, achieving an average
accuracy improvement of 33.4% on camera-object relation recognition tasks. Our
code, dataset, and benchmark will contribute to broad MLLM applications.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Dependent Multiplicities in Dependent Linear Type Theory](https://arxiv.org/abs/2507.08759)
*Maximilian Doré*

Main category: cs.PL

TL;DR: 我们提出了一种新颖的依赖线性类型理论，其中变量的多重性（即变量在程序中可以被使用的次数）可以依赖于其他变量。这使我们能够为许多在现有系统中无法充分类型化的高阶函数提供精确的资源注释。


<details>
  <summary>Details</summary>
Motivation: 现有系统中无法为某些高阶函数提供精确的资源注释，因此需要一种能够支持依赖多重性的类型理论。

Method: 通过将线性逻辑嵌入依赖类型理论，并指定嵌入逻辑与宿主理论的交互方式，我们设计了一种新的类型规则。利用标准的自然数类型，我们实现了一个具有依赖多重性的定量类型系统。

Result: 我们的理论结合了依赖类型理论和线性逻辑的标准模型，并提供了一个在Agda中实现的示例。

Conclusion: 该依赖线性类型理论为高阶函数的资源管理提供了一种有效的解决方案，并可集成到任何依赖类型语言中。

Abstract: We present a novel dependent linear type theory in which the multiplicity of
some variable - i.e., the number of times the variable can be used in a program
- can depend on other variables. This allows us to give precise resource
annotations to many higher-order functions that cannot be adequately typed in
any other system. Inspired by the Dialectica translation, our typing discipline
is obtained by embedding linear logic into dependent type theory and specifying
how the embedded logic interacts with the host theory. We can then use a
standard natural numbers type to obtain a quantitative typing system with
dependent multiplicities. We characterise the semantics for our theory as a
combination of standard models of dependent type theory and linear logic. Our
system can be added to any dependently typed language, which we demonstrate
with an implementation in Agda.

</details>


### [4] [Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists](https://arxiv.org/abs/2507.08796)
*Owen Lewis,Neil Ghani,Andrew Dudzik,Christos Perivolaropoulos,Razvan Pascanu,Petar Veličković*

Main category: cs.PL

TL;DR: 该论文提出了一种新的函数语义类别——滤波器等变函数，并通过几何解释和算法展示了其在列表函数中的预测行为。


<details>
  <summary>Details</summary>
Motivation: 研究如何定义在已知输入/输出示例之外具有良好推断能力的函数，尤其是遵循某些规则的函数。

Method: 引入滤波器等变函数的概念，通过滤波器函数表达元素移除操作，并研究其性质及其与映射等变函数的关系。

Result: 证明了滤波器等变函数类的有趣示例和基本定理，提出了几何解释，并开发了完美推断的合并算法。

Conclusion: 滤波器等变函数为函数推断提供了一个有吸引力的规则遵循标准，且在理论和算法上均具有实用性。

Abstract: What should a function that extrapolates beyond known input/output examples
look like? This is a tricky question to answer in general, as any function
matching the outputs on those examples can in principle be a correct
extrapolant. We argue that a "good" extrapolant should follow certain kinds of
rules, and here we study a particularly appealing criterion for rule-following
in list functions: that the function should behave predictably even when
certain elements are removed. In functional programming, a standard way to
express such removal operations is by using a filter function. Accordingly, our
paper introduces a new semantic class of functions -- the filter equivariant
functions. We show that this class contains interesting examples, prove some
basic theorems about it, and relate it to the well-known class of map
equivariant functions. We also present a geometric account of filter
equivariants, showing how they correspond naturally to certain simplicial
structures. Our highlight result is the amalgamation algorithm, which
constructs any filter-equivariant function's output by first studying how it
behaves on sublists of the input, in a way that extrapolates perfectly.

</details>
