<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Cyclotron: Compilation of Recurrences to Distributed and Systolic Architectures](https://arxiv.org/abs/2511.09987)
*Shiv Sundram,Akhilesh Balasingam,Nathan Zhang,Kunle Olukotun,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: Cyclotron是一个用于表达流式数据流算法的框架和编译器，通过递归方程将其可移植地编译到分布式拓扑的互连处理器中。


<details>
  <summary>Details</summary>
Motivation: 现有的流式数据流算法表达和分布式实现通常缺乏灵活性和可移植性，Cyclotron旨在解决这一问题。

Method: Cyclotron提供了一种基于逻辑张量的递归输入语言，逐步降级为逻辑迭代空间的递归中间语言，最终生成针对每个处理器的发送、接收和计算操作程序。

Result: Cyclotron能够生成优化的程序，减少外部内存交互，并通过调度语言实现分布式拓扑中的流水线执行。其生成的实现在某些应用中与ScaLAPACK竞争。

Conclusion: Cyclotron展示了在分布式处理器和可重构硬件上高效实现流式数据流算法的潜力，适用于多种应用场景。

Abstract: We present Cyclotron, a framework and compiler for using recurrence equations to express streaming dataflow algorithms, which then get portably compiled to distributed topologies of interlinked processors. Our framework provides an input language of recurrences over logical tensors, which then gets lowered into an intermediate language of recurrences over logical iteration spaces, and finally into programs of send, receive, and computation operations specific to each individual processor. In Cyclotron's IR, programs are optimized such that external memory interactions are confined to the boundaries of the iteration space. Within inner iteration spaces, all data accesses become local: data accesses target values residing in local fast memory or on neighboring processing units, avoiding costly memory movement. We provide a scheduling language allowing users to define how data gets streamed and broadcasted between processors, enabling pipelined execution of computation kernels over distributed topologies of processing elements. We demonstrate the portability of our approach by compiling our IR to a reconfigurable simulator of systolic arrays and chiplet style distributed hardware, as well as to distributed-memory CPU clusters. In the simulated reconfigurable setting, we use our compiler for hardware design space exploration in which link costs and latencies can be specified. In the distributed CPU setting, we show how to use recurrences and our scheduling language to express various matrix multiplication routines (Cannon, SUMMA, PUMMA, weight stationary) and solvers (Triangular solve and Cholesky). For matrix multiplication and the triangular solve, we generate distributed implementations competitive with ScaLAPACK.

</details>


### [2] [Omnidirectional type inference for ML: principality any way](https://arxiv.org/abs/2511.10343)
*Alistair O'Brien,Didier Rémy,Gabriel Scherer*

Main category: cs.PL

TL;DR: 该论文提出了一种称为“全向类型推断”的新方法，通过在动态顺序中流动类型信息来恢复ML类型系统中的主属性，解决了现有方法因静态推断顺序导致的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的ML类型系统及其扩展（如GADTs和高级多态性）由于引入脆弱构造而破坏了主属性，导致推断不可预测。现有方法通过固定顺序传播类型信息来恢复主属性，但这种静态顺序经常导致程序被错误拒绝。

Method: 作者提出了“全向类型推断”，类型信息可以在动态顺序中流动，约束可以在任意顺序中解决，并使用“暂停匹配约束”来恢复进展。为了适应ML中的let泛化，引入了“增量实例化”机制。

Result: 该方法成功应用于OCaml的两个不同特性：记录标签和数据构造器的静态重载以及半显式多态性，实现了比现有OCaml类型检查器更具表达性的主类型推断算法。

Conclusion: 全向类型推断提供了一个通用框架，能够在脆弱特性存在的情况下恢复主属性，显著提升了类型推断的表达性和灵活性。

Abstract: The Damas-Hindley-Milner (ML) type system owes its success to principality, the property that every well-typed expression has a unique most general type. This makes inference predictable and efficient. Unfortunately, many extensions of ML (GADTs, higher-rank polymorphism, and static overloading) endanger princpality by introducing _fragile_ constructs that resist principal inference. Existing approaches recover principality through directional inference algorithms, which propagate _known_ type information in a fixed (or static) order (e.g. as in bidirectional typing) to disambiguate such constructs. However, the rigidity of a static inference order often causes otherwise well-typed programs to be rejected.
  We propose _omnidirectional_ type inference, where type information flows in a dynamic order. Typing constraints may be solved in any order, suspending when progress requires known type information and resuming once it becomes available, using _suspended match constraints_. This approach is straightforward for simply typed systems, but extending it to ML is challenging due to let-generalization. Existing ML inference algorithms type let-bindings (let x = e1 in e2) in a fixed order: type e1, generalize its type, and then type e2. To overcome this, we introduce _incremental instantiation_, allowing partially solved type schemes containing suspended constraints to be instantiated, with a mechanism to incrementally update instances as the scheme is refined.
  Omnidirectionality provides a general framework for restoring principality in the presence of fragile features. We demonstrate its versatility on two fundamentally different features of OCaml: static overloading of record labels and datatype constructors and semi-explicit first-class polymorphism. In both cases, we obtain a principal type inference algorithm that is more expressive than OCaml's current typechecker.

</details>


### [3] [Lazy Linearity for a Core Functional Language](https://arxiv.org/abs/2511.10361)
*Rodrigo Mesquita,Bernardo Toninho*

Main category: cs.PL

TL;DR: 介绍了Linear Core系统，该系统在惰性语言中静态地接受线性资源的惰性语义，并证明其正确性。


<details>
  <summary>Details</summary>
Motivation: 在惰性求值的背景下，传统的线性资源管理方式无法完全捕获语义上的线性性，因此需要新的系统来解决这一问题。

Method: 提出了Linear Core系统，该系统在惰性语言（如Haskell的Core中间语言）中静态地捕获线性资源的惰性语义，并通过编译器插件实现验证。

Result: 实验证明，Linear Core能够保证线性资源的使用正确性，并在优化转换中保持线性性。

Conclusion: Linear Core为惰性语言中的线性资源管理提供了有效的解决方案，并通过实现验证了其可行性和优势。

Abstract: Traditionally, in linearly typed languages, consuming a linear resource is synonymous with its syntactic occurrence in the program. However, under the lens of non-strict evaluation, linearity can be further understood semantically, where a syntactic occurrence of a resource does not necessarily entail using that resource when the program is executed. While this distinction has been largely unexplored, it turns out to be inescapable in Haskell's optimising compiler, which heavily rewrites the source program in ways that break syntactic linearity but preserve the program's semantics. We introduce Linear Core, a novel system which accepts the lazy semantics of linearity statically and is suitable for lazy languages such as the Core intermediate language of the Glasgow Haskell Compiler. We prove that Linear Core is sound, guaranteeing linear resource usage, and that multiple optimising transformations preserve linearity in Linear Core while failing to do so in Core. We have implemented Linear Core as a compiler plugin to validate the system against linearity-heavy libraries, including linear-base.

</details>


### [4] [Modeling Layout Abstractions Using Integer Set Relations](https://arxiv.org/abs/2511.10374)
*Somashekaracharya G Bhaskaracharya,Aravind Acharya,Bastian Hagedorn,Vinod Grover*

Main category: cs.PL

TL;DR: 通过引入整数集库（ISL）的统一数学表示，解决了CuTe布局和Triton线性布局之间缺乏统一分析的问题，支持形式化分析和跨系统优化。


<details>
  <summary>Details</summary>
Motivation: 现有的CuTe布局和Triton线性布局由于数学基础不同，无法进行统一的形式化分析和跨系统推理，限制了优化潜力。

Method: 使用ISL创建统一的整数集关系表示，模拟CuTe的基于步长的多维坐标转换和Triton的二进制向量空间转换。

Result: 实现了完整的布局操作算法，验证了其能够处理从简单到复杂的布局变体，包括复杂步长配置和swizzle模式。

Conclusion: 该方法成功地为不同布局范式提供了统一的数学建模，为未来的形式化分析和跨系统优化奠定了基础。

Abstract: Modern deep learning compilers rely on layout abstractions to manage the complex mapping between logical tensor structures and physical memory arrangements. CuTe layouts and Triton linear layouts are widely adopted industry standards. However, these layout systems operate independently with distinct mathematical underpinnings, preventing unified formal analysis and cross-system reasoning. We bridge this gap by introducing a novel approach that leverages the Integer Set Library (ISL) to create a unified mathematical representation for both layout systems through integer set relations, thereby enabling rigorous formal analysis, correctness verification, and the foundation for future cross-system optimization strategies. Our approach models CuTe layouts through integer set relations that encode the transformation from multi-dimensional coordinates to linear indices using stride-based calculations, including sophisticated swizzle operations that perform bit-level manipulations for enhanced memory access patterns. For Triton linear layouts, we construct integer set relations that model the binary vector space transformations where arithmetic operations follow finite field F_2 rules. We implement a complete suite of layout manipulation algorithms for composition, inversion, complement using built-in operations in ISL to ensure mathematical correctness and preserve layout semantics. Experimental evaluation shows that the system handles the full spectrum of layout complexity, from elementary identity transformations to sophisticated multi-dimensional tensor arrangements with complex stride configurations and swizzle patterns, validating the mathematical modeling approach across different layout paradigms.

</details>


### [5] [zkStruDul: Programming zkSNARKs with Structural Duality](https://arxiv.org/abs/2511.10565)
*Rahul Krishnan,Ashley Samuelson,Emily Yao,Ethan Cecchetti*

Main category: cs.PL

TL;DR: zkStruDul是一种语言，将输入转换和谓词定义统一为一个抽象层，解决了现有NIZK工具中逻辑重复和安全漏洞的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的NIZK工具在实现输入转换和谓词定义时存在逻辑重复和潜在的安全风险。

Method: 通过zkStruDul语言，将输入转换和谓词定义统一为一个抽象层，编译器可以从这一层投影出两个过程，消除重复代码和不匹配问题。

Result: zkStruDul不仅消除了重复逻辑和安全漏洞，还支持递归证明等功能。

Conclusion: zkStruDul提供了一个高效且安全的解决方案，提升了NIZK技术的应用效率和安全性。

Abstract: Non-Interactive Zero Knowledge (NIZK) proofs, such as zkSNARKS, let one prove knowledge of private data without revealing it or interacting with a verifier. While existing tooling focuses on specifying the predicate to be proven, real-world applications optimize predicate definitions to minimize proof generation overhead, but must correspondingly transform predicate inputs. Implementing these two steps separately duplicates logic that must precisely match to avoid catastrophic security flaws. We address this shortcoming with zkStruDul, a language that unifies input transformations and predicate definitions into a single combined abstraction from which a compiler can project both procedures, eliminating duplicate code and problematic mismatches. zkStruDul provides a high-level abstraction to layer on top of existing NIZK technology and supports important features like recursive proofs. We provide a source-level semantics and prove its behavior is identical to the projected semantics, allowing straightforward standard reasoning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Truth, Justice, and Secrecy: Cake Cutting Under Privacy Constraints](https://arxiv.org/abs/2511.09882)
*Yaron Salman,Tamir Tassa,Omer Lev,Roie Zivan*

Main category: cs.GT

TL;DR: 本文扩展了Chen等人的策略性公平蛋糕切割算法，引入了隐私保护维度，首次提出了一种隐私保护的蛋糕切割协议，并确保其无嫉妒性和策略性。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋糕切割算法虽然在公平性和策略性上有所进步，但忽视了隐私保护的重要性。由于隐私顾虑，即使没有策略性激励，代理人仍可能不愿透露真实偏好。

Method: 通过将集中式计算替换为新型的密码学技术，实现了隐私保护，不损害公平性或策略性。

Result: 提出的协议不仅保持了无嫉妒性和策略性，还首次实现了隐私保护，鼓励代理人真实报告偏好。

Conclusion: 本研究填补了蛋糕切割算法中隐私保护的空白，为解决实际问题提供了更全面的解决方案。

Abstract: Cake-cutting algorithms, which aim to fairly allocate a continuous resource based on individual agent preferences, have seen significant progress over the past two decades. Much of the research has concentrated on fairness, with comparatively less attention given to other important aspects. Chen et al. (2010) introduced an algorithm that, in addition to ensuring fairness, was strategyproof -- meaning agents had no incentive to misreport their valuations. However, even in the absence of strategic incentives to misreport, agents may still hesitate to reveal their true preferences due to privacy concerns (e.g., when allocating advertising time between firms, revealing preferences could inadvertently expose planned marketing strategies or product launch timelines). In this work, we extend the strategyproof algorithm of Chen et al. by introducing a privacy-preserving dimension. To the best of our knowledge, we present the first private cake-cutting protocol, and, in addition, this protocol is also envy-free and strategyproof. Our approach replaces the algorithm's centralized computation with a novel adaptation of cryptographic techniques, enabling privacy without compromising fairness or strategyproofness. Thus, our protocol encourages agents to report their true preferences not only because they are not incentivized to lie, but also because they are protected from having their preferences exposed.

</details>


### [7] [Robust Resource Allocation via Competitive Subsidies](https://arxiv.org/abs/2511.09934)
*David X. Lin,Giannis Fikioris,Siddhartha Banerjee,Éva Tardos*

Main category: cs.GT

TL;DR: 本研究提出了一种新的0.625-稳健机制，打破了0.6的第一价格障碍，几乎接近非战略稳健性边界0.63。通过简单的拍卖机制和竞争补贴的新方法实现。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配中，如何在对称代理人的情况下，为每个代理人提供接近理想效用的稳健保证是一个重要问题。尽管已有研究表明可以实现1/2-稳健性，但仍存在提升空间。

Method: 提出一种简单拍卖机制，代理人在每轮决定是否请求物品，并从中随机分配。关键创新是引入竞争补贴，即根据竞标人数调整获胜者的信用支付。

Result: 新的机制实现了0.625-稳健性，接近非战略边界0.63。进一步调整后，在均衡策略下也能获得0.61的稳健性。

Conclusion: 该机制在拍卖类方法中达到了最优边界，几乎完全填补了战略与非战略稳健性之间的差距。

Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.

</details>


### [8] [Facility Location for Congesting Commuters and Generalizing the Cost-Distance Problem](https://arxiv.org/abs/2511.10228)
*Thanasis Lianeas,Marios Mertzanidis,Aikaterini Nikolidaki*

Main category: cs.GT

TL;DR: 本文提出了一种新的设施选址问题，考虑代理人（自私的通勤者）与设施之间的拥堵依赖性连接成本，并展示了如何在成本函数不同变化趋势下推导近似解。


<details>
  <summary>Details</summary>
Motivation: 传统设施选址问题忽略了代理人连接设施的拥堵依赖性成本。本文旨在填补这一空白，研究在拥堵条件下的设施选址问题，以更贴近实际应用场景。

Method: 对于成本函数为非递减的情况，创新性地应用Caratheodory定理的近似版本推导问题的近似解；对于非递增成本函数，通过推广Cost-Distance问题并提供算法达到相同近似保证。

Result: 证明了在非递减成本函数下可以推导出问题的近似解，并在非递增成本函数下推广了Cost-Distance问题，提供了算法保证近似性能。

Conclusion: 本文为解决拥堵依赖性成本的设施选址问题提供了理论框架和算法，扩展了现有设施选址问题的研究范围。

Abstract: In Facility Location problems there are agents that should be connected to facilities and locations where facilities may be opened so that agents can connect to them. We depart from Uncapacitated Facility Location and by assuming that the connection costs of agents to facilities are congestion dependent, we define a novel problem, namely, Facility Location for Congesting (Selfish) Commuters. The connection costs of agents to facilities come as a result of how the agents commute to reach the facilities in an underlying network with cost functions on the edges. Inapproximability results follow from the related literature and thus approximate solutions is all we can hope for. For when the cost functions are nondecreasing we employ in a novel way an approximate version of Caratheodory's Theorem [5] to show how approximate solutions for different versions of the problem can be derived. For when the cost functions are nonincreasing we show how this problem generalizes the Cost-Distance problem [38] and provide an algorithm that for this more general case achieves the same approximation guarantees.

</details>
