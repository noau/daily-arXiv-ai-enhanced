<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 7]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Controllable Video Generation: A Survey](https://arxiv.org/abs/2507.16869)
*Yue Ma,Kunyu Feng,Zhongyuan Hu,Xinyu Wang,Yucheng Wang,Mingzhe Zheng,Xuanhua He,Chenyang Zhu,Hongyu Liu,Yingqing He,Zeyu Wang,Zhifeng Li,Xiu Li,Wei Liu,Dan Xu,Linfeng Zhang,Qifeng Chen*

Main category: cs.GR

TL;DR: 论文综述了可控视频生成领域，重点介绍了如何通过多模态条件（如相机运动、深度图和人体姿态）增强预训练模型的生成控制能力。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC的发展，现有的文本到视频生成模型无法满足用户对复杂、多模态和精细控制的需求，因此需要研究更灵活的控制方法。

Method: 文章系统回顾了可控视频生成的理论基础和最新进展，重点分析了如何在去噪过程中整合不同类型的控制信号（如单条件、多条件和通用可控生成）。

Result: 论文提出了一种分类方法，根据控制信号类型对现有方法进行分类，并总结了如何通过附加条件增强视频生成模型的实用性。

Conclusion: 可控视频生成是AIGC的重要发展方向，未来的研究应关注如何进一步优化多模态条件下的生成质量与控制精度。

Abstract: With the rapid development of AI-generated content (AIGC), video generation
has emerged as one of its most dynamic and impactful subfields. In particular,
the advancement of video generation foundation models has led to growing demand
for controllable video generation methods that can more accurately reflect user
intent. Most existing foundation models are designed for text-to-video
generation, where text prompts alone are often insufficient to express complex,
multi-modal, and fine-grained user requirements. This limitation makes it
challenging for users to generate videos with precise control using current
models. To address this issue, recent research has explored the integration of
additional non-textual conditions, such as camera motion, depth maps, and human
pose, to extend pretrained video generation models and enable more controllable
video synthesis. These approaches aim to enhance the flexibility and practical
applicability of AIGC-driven video generation systems. In this survey, we
provide a systematic review of controllable video generation, covering both
theoretical foundations and recent advances in the field. We begin by
introducing the key concepts and commonly used open-source video generation
models. We then focus on control mechanisms in video diffusion models,
analyzing how different types of conditions can be incorporated into the
denoising process to guide generation. Finally, we categorize existing methods
based on the types of control signals they leverage, including single-condition
generation, multi-condition generation, and universal controllable generation.
For a complete list of the literature on controllable video generation
reviewed, please visit our curated repository at
https://github.com/mayuelala/Awesome-Controllable-Video-Generation.

</details>


### [2] [StreamME: Simplify 3D Gaussian Avatar within Live Stream](https://arxiv.org/abs/2507.17029)
*Luchuan Song,Yang Zhou,Zhan Xu,Yi Zhou,Deepali Aneja,Chenliang Xu*

Main category: cs.GR

TL;DR: StreamME是一种快速3D头像重建方法，通过实时视频流同步记录和重建头像，无需预缓存数据，支持下游应用的无缝集成。


<details>
  <summary>Details</summary>
Motivation: 为了在实时视频流中快速重建3D头像并优化下游应用的集成，同时保护隐私和降低通信带宽需求。

Method: 基于3D高斯散射（3DGS）的改进方法，摆脱了对MLPs的依赖，仅依赖几何结构，并通过主点简化策略优化点云分布。

Result: StreamME显著提高了面部表情的适应速度，同时保持了渲染质量，并成功应用于VR系统、在线会议、动画等下游场景。

Conclusion: StreamME通过实时训练和高效率的几何优化，为3D头像重建提供了快速、隐私保护的解决方案，适用于多种下游应用。

Abstract: We propose StreamME, a method focuses on fast 3D avatar reconstruction. The
StreamME synchronously records and reconstructs a head avatar from live video
streams without any pre-cached data, enabling seamless integration of the
reconstructed appearance into downstream applications. This exceptionally fast
training strategy, which we refer to as on-the-fly training, is central to our
approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating
the reliance on MLPs in deformable 3DGS and relying solely on geometry, which
significantly improves the adaptation speed to facial expression. To further
ensure high efficiency in on-the-fly training, we introduced a simplification
strategy based on primary points, which distributes the point clouds more
sparsely across the facial surface, optimizing points number while maintaining
rendering quality. Leveraging the on-the-fly training capabilities, our method
protects the facial privacy and reduces communication bandwidth in VR system or
online conference. Additionally, it can be directly applied to downstream
application such as animation, toonify, and relighting. Please refer to our
project page for more details: https://songluchuan.github.io/StreamME/.

</details>


### [3] [GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP](https://arxiv.org/abs/2507.17174)
*Myeongwon Jung,Takanori Fujiwara,Jaemin Jo*

Main category: cs.GR

TL;DR: 论文研究了UMAP随机优化过程对结果的影响，提出了(r,d)-稳定性框架以分析数据点在投影空间中的随机定位，并通过“幽灵”方法评估随机性对结果的影响。


<details>
  <summary>Details</summary>
Motivation: UMAP的随机优化过程导致结果不稳定，数据点的投影更多地取决于随机性而非邻近结构。论文旨在解决这一问题。

Method: 引入(r,d)-稳定性框架和“幽灵”方法，通过计算数据点在投影空间中的位置变化来分析随机性影响，并开发自适应丢弃方案以优化运行时间。

Result: 提出的方法在减少时间复杂度60%的同时保持了约90%的不稳定点识别能力，并提供了可视化工具支持交互式探索。

Conclusion: 论文证明了(r,d)-稳定性框架的有效性，并为UMAP的实际使用提供了指导。

Abstract: Despite the widespread use of Uniform Manifold Approximation and Projection
(UMAP), the impact of its stochastic optimization process on the results
remains underexplored. We observed that it often produces unstable results
where the projections of data points are determined mostly by chance rather
than reflecting neighboring structures. To address this limitation, we
introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic
positioning of data points in the projection space. To assess how stochastic
elements, specifically initial projection positions and negative sampling,
impact UMAP results, we introduce "ghosts", or duplicates of data points
representing potential positional variations due to stochasticity. We define a
data point's projection as (r,d)-stable if its ghosts perturbed within a circle
of radius r in the initial projection remain confined within a circle of radius
d for their final positions. To efficiently compute the ghost projections, we
develop an adaptive dropping scheme that reduces a runtime up to 60% compared
to an unoptimized baseline while maintaining approximately 90% of unstable
points. We also present a visualization tool that supports the interactive
exploration of the (r,d)-stability of data points. Finally, we demonstrate the
effectiveness of our framework by examining the stability of projections of
real-world datasets and present usage guidelines for the effective use of our
framework.

</details>


### [4] [A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis](https://arxiv.org/abs/2507.17184)
*Hui Zhao*

Main category: cs.GR

TL;DR: 本文提出了一种全新的研究方向，研究超结构化四边形网格的整体全局排列结构对有限元计算收敛性和精度的影响，以减少当前对"经验"的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前工业界和学术界在有限元计算中，网格生成的方法和质量对收敛性和精度有重要影响。然而，现有研究多关注局部质量，缺乏对整体全局排列结构的研究，导致模拟中严重依赖"经验"。

Method: 通过引入现代二维和三维几何拓扑理论（如模空间、Teichmüller空间、调和叶理、动力系统、曲面映射、亚纯二次微分等），设计和生成可控整体排列结构的超结构化四边形网格。

Result: 研究表明，整体全局排列结构对有限元计算的收敛性和精度有显著影响，为网格生成提供了更科学的依据。

Conclusion: 本文为网格生成提供了新的研究方向，明确了哪些全局排列结构可以确保有限元计算的收敛性，减少了对"经验"的依赖。

Abstract: In the current practices of both industry and academia, the convergence and
accuracy of finite element calculations are closely related to the methods and
quality of mesh generation. For years, the research on high-quality mesh
generation in the domestic academic field has mainly referred to the local
quality of quadrilaterals and hexahedrons approximating that of squares and
cubes. The main contribution of this paper is to propose a brand-new research
direction and content: it is necessary to explore and study the influence of
the overall global arrangement structure and pattern of super structured
quadrilateral meshes on the convergence and calculation accuracy of finite
element calculations. Through the research in this new field, it can help solve
the non-rigorous state of serious reliance on "experience" in the mesh
generation stage during simulation in the current industry and academia, and
make clear judgments on which global arrangements of mesh generation can ensure
the convergence of finite element calculations. In order to generate and design
super-structured quadrilateral meshes with controllable overall arrangement
structures, a large number of modern two-dimensional and three-dimensional
geometric topology theories are required, such as moduli space, Teichm\"uller
space, harmonic foliations, dynamical systems, surface mappings, meromorphic
quadratic differentials, surface mappings, etc.

</details>


### [5] [Visualization-Driven Illumination for Density Plots](https://arxiv.org/abs/2507.17265)
*Xin Chen,Yunhai Wang,Huaiwei Bao,Kecheng Lu,Jaemin Jo,Chi-Wing Fu,Jean-Daniel Fekete*

Main category: cs.GR

TL;DR: 提出了一种新颖的可视化驱动光照模型，用于增强密度图，有效揭示高密度和中等密度区域的细节结构以及低密度区域的异常值，同时避免颜色失真。


<details>
  <summary>Details</summary>
Motivation: 解决散点图和点密度图在可视化大量离散点样本时因重叠问题导致的细节丢失，以及现有光照模型在密度图中可能引起的颜色失真和低密度区域细节隐藏的问题。

Method: 提出了一种可视化驱动的光照模型，支持密度图特定的分析任务，并开发了一种新的图像合成技术以减少图像阴影与颜色编码密度值之间的干扰。

Result: 通过定量研究、对照实验和两个案例研究，验证了该技术在12个数据集（最多包含200万个数据点样本）中的有效性。

Conclusion: 该技术显著提升了密度图在高密度和中等密度区域的细节表现，同时避免了颜色失真，为数据可视化提供了一种有效的解决方案。

Abstract: We present a novel visualization-driven illumination model for density plots,
a new technique to enhance density plots by effectively revealing the detailed
structures in high- and medium-density regions and outliers in low-density
regions, while avoiding artifacts in the density field's colors. When
visualizing large and dense discrete point samples, scatterplots and dot
density maps often suffer from overplotting, and density plots are commonly
employed to provide aggregated views while revealing underlying structures.
Yet, in such density plots, existing illumination models may produce color
distortion and hide details in low-density regions, making it challenging to
look up density values, compare them, and find outliers. The key novelty in
this work includes (i) a visualization-driven illumination model that
inherently supports density-plot-specific analysis tasks and (ii) a new image
composition technique to reduce the interference between the image shading and
the color-encoded density values. To demonstrate the effectiveness of our
technique, we conducted a quantitative study, an empirical evaluation of our
technique in a controlled study, and two case studies, exploring twelve
datasets with up to two million data point samples.

</details>


### [6] [Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian Splatting](https://arxiv.org/abs/2507.17336)
*Hyeongmin Lee,Kyungjune Baek*

Main category: cs.GR

TL;DR: 论文提出了一种针对4D高斯泼溅（4DGS）的端到端RD优化压缩框架，显著提升了存储效率和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 当前4DGS在存储、处理和数据传输方面面临巨大挑战，主要是由于高斯数量多、时间冗余大以及缺乏熵感知压缩框架。

Method: 采用小波变换替代独立的点运动轨迹存储，利用实际世界的平滑性先验知识，显著提高存储效率，并在压缩效率和渲染质量之间实现用户可控的平衡。

Result: 实验表明，该方法实现了高达91倍的压缩比，同时保持了高视觉保真度。

Conclusion: 该框架适用于从资源受限的边缘设备到高性能环境的实时动态场景渲染，具有广泛的应用潜力。

Abstract: Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed
rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric
videos. However, the large number of Gaussians, substantial temporal
redundancies, and especially the absence of an entropy-aware compression
framework result in large storage requirements. Consequently, this poses
significant challenges for practical deployment, efficient edge-device
processing, and data transmission. In this paper, we introduce a novel
end-to-end RD-optimized compression framework tailored for 4DGS, aiming to
enable flexible, high-fidelity rendering across varied computational platforms.
Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the
state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS
compression methods for compatibility while effectively addressing additional
challenges introduced by the temporal axis. In particular, instead of storing
motion trajectories independently per point, we employ a wavelet transform to
reflect the real-world smoothness prior, significantly enhancing storage
efficiency. This approach yields significantly improved compression ratios and
provides a user-controlled balance between compression efficiency and rendering
quality. Extensive experiments demonstrate the effectiveness of our method,
achieving up to 91x compression compared to the original Ex4DGS model while
maintaining high visual fidelity. These results highlight the applicability of
our framework for real-time dynamic scene rendering in diverse scenarios, from
resource-constrained edge devices to high-performance environments.

</details>


### [7] [Parametric Integration with Neural Integral Operators](https://arxiv.org/abs/2507.17440)
*Christoph Schied,Alexander Keller*

Main category: cs.GR

TL;DR: 论文提出了一种在材质着色前进行去噪的方法，通过神经网络近似光传输积分算子，实现实时、单帧数据的材质无关去噪（MAD），并与现有去噪器和时间抗锯齿技术无缝集成。


<details>
  <summary>Details</summary>
Motivation: 实时渲染中，光传输模拟的采样预算有限，常导致图像噪声。尽管现有去噪器可通过滤波生成无噪图像，但研究者希望通过在材质着色前去除噪声，进一步提升图像质量。

Method: 利用神经网络近似光传输积分算子，实现参数化积分。该方法在材质着色前进行去噪（MAD），仅需单帧数据，支持实时运行，且易于训练。同时，可与现有去噪器和时间抗锯齿技术无缝集成。

Result: 方法能够高效去除噪声，生成高质量的图像，且无需依赖多帧数据。其与物理渲染算法的兼容性良好，并提升了实时渲染的整体表现。

Conclusion: 论文提出的材质无关去噪方法（MAD）通过神经算子实现了高效去噪，适用于实时渲染，并在图像质量和计算效率上表现出色。

Abstract: Real-time rendering imposes strict limitations on the sampling budget for
light transport simulation, often resulting in noisy images. However, denoisers
have demonstrated that it is possible to produce noise-free images through
filtering. We enhance image quality by removing noise before material shading,
rather than filtering already shaded noisy images. This approach allows for
material-agnostic denoising (MAD) and leverages machine learning by
approximating the light transport integral operator with a neural network,
effectively performing parametric integration with neural operators. Our method
operates in real-time, requires data from only a single frame, seamlessly
integrates with existing denoisers and temporal anti-aliasing techniques, and
is efficient to train. Additionally, it is straightforward to incorporate with
physically based rendering algorithms.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [8] [Hiord: An Approach to the Specification and Verification of Higher-Order (C)LP Programs](https://arxiv.org/abs/2507.17233)
*Marco Ciccalè,Daniel Jurjo-Rivas,Jose F. Morales,Pedro López-García,Manuel V. Hermenegildo*

Main category: cs.PL

TL;DR: 提出了一种静态验证高阶(C)LP程序与高阶断言的新方法，基于抽象解释的技术，并通过原型实现验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 高阶程序中的断言验证在运行时已有研究，但编译时验证相对较少，本文旨在填补这一空白。

Method: 通过使用谓词属性描述高阶参数，基于语义序关系提出抽象判断准则，并将其降阶为一阶属性进行静态分析。

Result: 原型实现通过Ciao系统中的多种示例验证了方法的有效性。

Conclusion: 本文提出的方法具有通用性，适用于类似高阶程序与断言的静态验证场景。

Abstract: Higher-order constructs enable more expressive and concise code by allowing
procedures to be parameterized by other procedures. Assertions allow expressing
partial program specifications, which can be verified either at compile time
(statically) or run time (dynamically). In higher-order programs, assertions
can also describe higher-order arguments. While in the context of (C)LP,
run-time verification of higher-order assertions has received some attention,
compile-time verification remains relatively unexplored. We propose a novel
approach for statically verifying higher-order (C)LP programs with higher-order
assertions. Although we use the Ciao assertion language for illustration, our
approach is quite general and we believe is applicable to similar contexts.
Higher-order arguments are described using predicate properties -- a special
kind of property which exploits the (Ciao) assertion language. We refine the
syntax and semantics of these properties and introduce an abstract criterion to
determine conformance to a predicate property at compile time, based on a
semantic order relation comparing the predicate property with the predicate
assertions. We then show how to handle these properties using an abstract
interpretation-based static analyzer for programs with first-order assertions
by reducing predicate properties to first-order properties. Finally, we report
on a prototype implementation and evaluate it through various examples within
the Ciao system.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Regret Minimization in Population Network Games: Vanishing Heterogeneity and Convergence to Equilibria](https://arxiv.org/abs/2507.17183)
*Die Hu,Shuyue Hu,Chunjiang Mu,Shiqi Fan,Chen Chu,Jinzhuo Liu,Zhen Wang*

Main category: cs.GT

TL;DR: 论文探讨了通过平滑遗憾匹配（smooth regret-matching）如何驱动大量异构代理在博弈中达成统一行为，揭示了多样性消失和共识形成的现象，并在理论和实践上推进了多代理学习的研究。


<details>
  <summary>Details</summary>
Motivation: 理解并预测大规模多代理在博弈中的行为是多代理系统研究中的核心挑战。本文旨在探讨异质性在均衡形成中的作用，特别是在多样化的初始策略下，如何通过平滑遗憾匹配实现代理行为的统一。

Method: 通过将系统状态建模为遗憾的概率分布，并利用连续性方程分析其演化过程，研究了多样多代理设置中遗憾分布的方差随时间减小的现象，进而驱动代理达成共识。

Result: 研究结果显示，异质性随时间消失，代理之间达成共识。这一普遍现象使得在竞争和合作的多代理设置中均能证明其收敛于量化响应均衡（quantal response equilibria）。

Conclusion: 论文不仅深化了对多代理学习的理论理解，还为多样博弈论场景中的均衡选择提供了新的视角。

Abstract: Understanding and predicting the behavior of large-scale multi-agents in
games remains a fundamental challenge in multi-agent systems. This paper
examines the role of heterogeneity in equilibrium formation by analyzing how
smooth regret-matching drives a large number of heterogeneous agents with
diverse initial policies toward unified behavior. By modeling the system state
as a probability distribution of regrets and analyzing its evolution through
the continuity equation, we uncover a key phenomenon in diverse multi-agent
settings: the variance of the regret distribution diminishes over time, leading
to the disappearance of heterogeneity and the emergence of consensus among
agents. This universal result enables us to prove convergence to quantal
response equilibria in both competitive and cooperative multi-agent settings.
Our work advances the theoretical understanding of multi-agent learning and
offers a novel perspective on equilibrium selection in diverse game-theoretic
scenarios.

</details>
