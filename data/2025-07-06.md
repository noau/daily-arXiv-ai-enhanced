<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Gbake: Baking 3D Gaussian Splats into Reflection Probes](https://arxiv.org/abs/2507.02257)
*Stephen Pasch,Joel K. Salzman,Changxi Zheng*

Main category: cs.GR

TL;DR: GBake是一款专用工具，用于从高斯散射场景中烘焙反射探头，使Unity游戏引擎中的传统3D网格能够实现逼真的反射映射。


<details>
  <summary>Details</summary>
Motivation: 随着3D高斯散射的普及，需要将传统计算机图形技术（如网格）集成到高斯散射环境中。由于3D高斯基元将光照和几何信息编码为外观，直接插入网格会导致不正确的光照效果。

Method: 引入了GBake工具，专门用于从高斯散射场景中烘焙反射探头，以在Unity游戏引擎中实现传统3D网格的逼真反射映射。

Result: GBake能够解决高斯散射环境中网格光照不正确的问题，使其能够自然地融入场景。

Conclusion: GBake提供了一种有效的方法，将传统3D网格与高斯散射场景无缝结合，提升了视觉效果的真实感。

Abstract: The growing popularity of 3D Gaussian Splatting has created the need to
integrate traditional computer graphics techniques and assets in splatted
environments. Since 3D Gaussian primitives encode lighting and geometry jointly
as appearance, meshes are relit improperly when inserted directly in a mixture
of 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a
specialized tool for baking reflection probes from Gaussian-splatted scenes
that enables realistic reflection mapping of traditional 3D meshes in the Unity
game engine.

</details>


### [2] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
*Tom Kneiphof,Reinhard Klein*

Main category: cs.GR

TL;DR: 提出了一种高效的图像光照近似方法，用于实时渲染具有闪亮或闪烁外观的材料，支持动态材料属性和环境贴图。


<details>
  <summary>Details</summary>
Motivation: 基于图像的光照技术被广泛应用于重建真实世界光照条件下的阴影，但在处理具有离散微表面结构的闪亮材料时存在挑战。

Method: 采用实时区域光照下的闪亮渲染技术和标准环境贴图滤波方法，通过分层采样多模态分布和双门高斯近似来高效处理环境贴图。

Result: 实验验证了该方法在多种材料属性和光照条件下接近真实渲染效果，性能稳定且额外开销低，仅需两倍于平滑材料渲染的内存。

Conclusion: 该方法为实时渲染闪亮材料提供了一种高效且接近真实的解决方案，适用于动态环境和材料属性的场景。

Abstract: Image-based lighting is a widely used technique to reproduce shading under
real-world lighting conditions, especially in real-time rendering applications.
A particularly challenging scenario involves materials exhibiting a sparkling
or glittering appearance, caused by discrete microfacets scattered across their
surface. In this paper, we propose an efficient approximation for image-based
lighting of glints, enabling fully dynamic material properties and environment
maps. Our novel approach is grounded in real-time glint rendering under area
light illumination and employs standard environment map filtering techniques.
Crucially, our environment map filtering process is sufficiently fast to be
executed on a per-frame basis. Our method assumes that the environment map is
partitioned into few homogeneous regions of constant radiance. By filtering the
corresponding indicator functions with the normal distribution function, we
obtain the probabilities for individual microfacets to reflect light from each
region. During shading, these probabilities are utilized to hierarchically
sample a multinomial distribution, facilitated by our novel dual-gated Gaussian
approximation of binomial distributions. We validate that our real-time
approximation is close to ground-truth renderings for a range of material
properties and lighting conditions, and demonstrate robust and stable
performance, with little overhead over rendering glints from a single
directional light. Compared to rendering smooth materials without glints, our
approach requires twice as much memory to store the prefiltered environment
map.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
*Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 论文提出了DecoRTL，一种针对RTL代码生成的新型运行时解码策略，通过自一致性采样和语法感知温度调整，显著提高了语法有效性、功能正确性和输出多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM解码策略在生成RTL代码时常常无法满足结构和语义需求，导致生成的代码存在幻觉、重复或无效的问题。论文旨在通过分析这些问题的根源并提出解决方案。

Method: 论文提出了DecoRTL，包含两个组件：自一致性采样（生成多个候选并基于标记级一致性重新排序）和语法感知温度调整（根据标记的语法和功能角色调整采样温度）。

Result: 在VerilogEval基准测试中，DecoRTL在多个开源LLM上显著提高了语法有效性、功能正确性和输出多样性，且运行时开销几乎不可感知。

Conclusion: DecoRTL在不增加模型微调的情况下，通过运行时策略优化，显著提升了RTL代码生成的质量和多样性。

Abstract: As one of their many applications, large language models (LLMs) have recently
shown promise in automating register transfer level (RTL) code generation.
However, conventional LLM decoding strategies, originally designed for natural
language, often fail to meet the structural and semantic demands of RTL,
leading to hallucinated, repetitive, or invalid code outputs. In this paper, we
first investigate the root causes of these decoding failures through an
empirical analysis of token-level entropy during RTL generation. Our findings
reveal that LLMs exhibit low confidence in regions of structural ambiguity or
semantic complexity, showing that standard decoding strategies fail to
differentiate between regions requiring determinism (syntax-critical regions)
and those that benefit from creative exploratory variability (design-critical
regions). Then, to overcome this, we introduce DecoRTL, a novel run-time
decoding strategy, that is both syntax-aware and contrastive for RTL code
generation. DecoRTL integrates two complementary components: (i)
self-consistency sampling, which generates multiple candidates and re-ranks
them based on token-level agreement to promote correctness while maintaining
diversity; and (ii) syntax-aware temperature adaptation, which classifies
tokens by their syntactical and functional roles and adjusts the sampling
temperature accordingly, enforcing low temperature for syntax-critical tokens
and higher temperature for exploratory ones. Our approach operates entirely at
inference time without requiring any additional model fine-tuning. Through
evaluations on multiple open-source LLMs using the VerilogEval benchmark, we
demonstrate significant improvements in syntactic validity, functional
correctness, and output diversity, while the execution overhead (performance
overhead) is imperceptible.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems](https://arxiv.org/abs/2507.02464)
*Craig S Wright*

Main category: cs.GT

TL;DR: 论文通过引入自动机理论和经济学框架，将CAP定理的权衡问题转化为约束优化问题，证明了在有限范围内可同时保持可用性和一致性。


<details>
  <summary>Details</summary>
Motivation: CAP定理指出了在分布式系统中一致性、可用性和分区容错性之间的三难问题，作者希望通过经济学和自动机理论重新定义这一权衡。

Method: 将分布式系统建模为分区感知状态机，并嵌入经济激励层，通过博弈论机制定义全局转换语义，证明收敛性、活性和正确性的界限。

Result: 结果表明，在有限的ε范围内，可用性和一致性可以同时保持，从而通过形式化的经济控制扩展了经典CAP定理的界限。

Conclusion: 论文通过经济激励和自动机理论提供了一种新的方法，扩展了CAP定理的适用性，为分布式系统的设计提供了新的理论基础。

Abstract: The CAP theorem asserts a trilemma between consistency, availability, and
partition tolerance. This paper introduces a rigorous automata-theoretic and
economically grounded framework that reframes the CAP trade-off as a constraint
optimization problem. We model distributed systems as partition-aware state
machines and embed economic incentive layers to stabilize consensus behavior
across adversarially partitioned networks. By incorporating game-theoretic
mechanisms into the global transition semantics, we define provable bounds on
convergence, liveness, and correctness. Our results demonstrate that
availability and consistency can be simultaneously preserved within bounded
epsilon margins, effectively extending the classical CAP limits through formal
economic control.

</details>


### [5] [TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games](https://arxiv.org/abs/2507.02675)
*Zhaoqilin Yang,Xin Wang,Ruichen Zhang,Chanchan Li,Youliang Tian*

Main category: cs.GT

TL;DR: TUC-PPO是一个新的深度强化学习框架，通过整合团队福利目标扩展了PPO，旨在解决空间公共物品游戏中的合作问题。


<details>
  <summary>Details</summary>
Motivation: 传统的深度强化学习方法通过间接的个体奖励促发合作，而TUC-PPO直接优化了整合策略梯度和团队效用约束的双层目标，以更显式地纳入集体收益阈值。

Method: TUC-PPO保留了PPO的策略梯度核心，并通过自适应拉格朗日乘子引入约束优化，使分散的代理动态平衡自私和合作的激励。

Result: 相比未修改的PPO和进化博弈论基线，TUC-PPO在收敛速度和稳定性上表现更优，能更快达到合作均衡并抵御叛逃者的入侵。

Conclusion: TUC-PPO将团队目标正式整合到策略更新中，为多智能体深度强化学习和进化博弈论研究提供了新的计算工具。

Abstract: We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO),
a new deep reinforcement learning framework. It extends Proximal Policy
Optimization (PPO) by integrating team welfare objectives specifically for
spatial public goods games. Unlike conventional approaches where cooperation
emerges indirectly from individual rewards, TUC-PPO instead optimizes a
bi-level objective integrating policy gradients and team utility constraints.
Consequently, all policy updates explicitly incorporate collective payoff
thresholds. The framework preserves PPO's policy gradient core while
incorporating constrained optimization through adaptive Lagrangian multipliers.
Therefore, decentralized agents dynamically balance selfish and cooperative
incentives. The comparative analysis demonstrates superior performance of this
constrained deep reinforcement learning approach compared to unmodified PPO and
evolutionary game theory baselines. It achieves faster convergence to
cooperative equilibria and greater stability against invasion by defectors. The
framework formally integrates team objectives into policy updates. This work
advances multi-agent deep reinforcement learning for social dilemmas while
providing new computational tools for evolutionary game theory research.

</details>


### [6] [Learning to Coordinate Bidders in Non-Truthful Auctions](https://arxiv.org/abs/2507.02801)
*Hu Fu,Tao Lin*

Main category: cs.GT

TL;DR: 研究了在非真实性拍卖中学习贝叶斯相关均衡（BCE）的样本复杂度问题，证明了在一大类拍卖中（包括第一价格拍卖和全支付拍卖），可以用多项式数量的样本学习BCE。


<details>
  <summary>Details</summary>
Motivation: 在非真实性拍卖中，独立策略行为（贝叶斯纳什均衡）难以表征且可能导致不良结果。通过引入协调机制（BCE）可以改善拍卖系统，但BCE的实现需要投标人私有估值的分布知识，而这通常是未知的。

Method: 通过减少样本估计投标人期望效用的问题，并结合对投标人所有单调投标策略类别的伪维分析，研究学习BCE的样本复杂度。

Result: 证明在一大类非真实性拍卖中，可以用多项式数量$	ilde O(\frac{n}{\varepsilon^2})$的样本学习BCE。

Conclusion: 研究表明，通过适当的样本复杂度分析，可以在非真实性拍卖中有效学习和实现贝叶斯相关均衡（BCE）。

Abstract: In non-truthful auctions such as first-price and all-pay auctions, the
independent strategic behaviors of bidders, with the corresponding equilibrium
notion -- Bayes Nash equilibria -- are notoriously difficult to characterize
and can cause undesirable outcomes. An alternative approach to designing better
auction systems is to coordinate the bidders: let a mediator make
incentive-compatible recommendations of correlated bidding strategies to the
bidders, namely, implementing a Bayes correlated equilibrium (BCE). The
implementation of BCE, however, requires knowledge of the distribution of
bidders' private valuations, which is often unavailable. We initiate the study
of the sample complexity of learning Bayes correlated equilibria in
non-truthful auctions. We prove that the BCEs in a large class of non-truthful
auctions, including first-price and all-pay auctions, can be learned with a
polynomial number $\tilde O(\frac{n}{\varepsilon^2})$ of samples from the
bidders' value distributions. Our technique is a reduction to the problem of
estimating bidders' expected utility from samples, combined with an analysis of
the pseudo-dimension of the class of all monotone bidding strategies of
bidders.

</details>
