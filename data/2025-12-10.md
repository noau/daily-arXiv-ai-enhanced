<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Learning to Control Physically-simulated 3D Characters via Generating and Mimicking 2D Motions](https://arxiv.org/abs/2512.08500)
*Jianan Li,Xiao Chen,Tao Huang,Tien-Tsin Wong*

Main category: cs.GR

TL;DR: Mimic2DM框架通过学习2D关键点轨迹直接训练控制策略，无需依赖3D数据，实现了多样化的物理合理运动合成。


<details>
  <summary>Details</summary>
Motivation: 视频数据比动作捕捉数据成本更低，但直接从视频合成真实多样的3D行为仍具挑战性，现有方法依赖3D重建技术且通用性较差。

Method: 提出Mimic2DM框架，通过最小化重投影误差训练单视角2D运动跟踪策略，并结合基于Transformer的自回归2D运动生成器。

Result: 该方法无需依赖显式3D数据，即可在舞蹈、足球运球和动物运动等领域合成物理合理且多样的运动。

Conclusion: Mimic2DM证明了直接从2D视频数据学习控制策略的可行性，为广泛的应用场景提供了解决方案。

Abstract: Video data is more cost-effective than motion capture data for learning 3D character motion controllers, yet synthesizing realistic and diverse behaviors directly from videos remains challenging. Previous approaches typically rely on off-the-shelf motion reconstruction techniques to obtain 3D trajectories for physics-based imitation. These reconstruction methods struggle with generalizability, as they either require 3D training data (potentially scarce) or fail to produce physically plausible poses, hindering their application to challenging scenarios like human-object interaction (HOI) or non-human characters. We tackle this challenge by introducing Mimic2DM, a novel motion imitation framework that learns the control policy directly and solely from widely available 2D keypoint trajectories extracted from videos. By minimizing the reprojection error, we train a general single-view 2D motion tracking policy capable of following arbitrary 2D reference motions in physics simulation, using only 2D motion data. The policy, when trained on diverse 2D motions captured from different or slightly different viewpoints, can further acquire 3D motion tracking capabilities by aggregating multiple views. Moreover, we develop a transformer-based autoregressive 2D motion generator and integrate it into a hierarchical control framework, where the generator produces high-quality 2D reference trajectories to guide the tracking policy. We show that the proposed approach is versatile and can effectively learn to synthesize physically plausible and diverse motions across a range of domains, including dancing, soccer dribbling, and animal movements, without any reliance on explicit 3D motion data. Project Website: https://jiann-li.github.io/mimic2dm/

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [2] [The Theory of Strategic Evolution: Games with Endogenous Players and Strategic Replicators](https://arxiv.org/abs/2512.07901)
*Kevin Vallier*

Main category: cs.GT

TL;DR: 本文提出了一个通用的‘战略进化理论’，扩展了复制动态理论，涵盖了内生玩家、多层次选择、创新和制度变迁，并通过‘Poiesis堆栈’这一数学模型实现了全局稳定性分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于建立一个统一的数学模型，以描述玩家、策略和制度规则共同演化的复杂系统，填补了现有进化博弈理论在多层次动态和创新机制方面的空白。

Method: 方法上，采用‘Poiesis堆栈’这一层次化数学模型，结合交叉级增益矩阵和Lyapunov函数，分析了小增益条件下的全局稳定性和随机稳定性。

Result: 结果表明，该系统在小增益条件下具有全局Lyapunov函数，支持选择、跟踪和随机稳定性，并通过闭包定理证明了高层次不会引入新动态。

Conclusion: 结论指出，该理论统一了进化博弈、制度设计、创新动态和政治经济学的研究成果，为长期战略适应性提供了一个通用的数学模型。

Abstract: This paper develops the Theory of Strategic Evolution, a general model for systems in which the population of players, strategies, and institutional rules evolve together. The theory extends replicator dynamics to settings with endogenous players, multi level selection, innovation, constitutional change, and meta governance. The central mathematical object is a Poiesis stack: a hierarchy of strategic layers linked by cross level gain matrices. Under small gain conditions, the system admits a global Lyapunov function and satisfies selection, tracking, and stochastic stability results at every finite depth. We prove that the class is closed under block extension, innovation events, heterogeneous utilities, continuous strategy spaces, and constitutional evolution. The closure theorem shows that no new dynamics arise at higher levels and that unrestricted self modification cannot preserve Lyapunov structure. The theory unifies results from evolutionary game theory, institutional design, innovation dynamics, and constitutional political economy, providing a general mathematical model of long run strategic adaptation.

</details>


### [3] [Selling Privacy in Blockchain Transactions](https://arxiv.org/abs/2512.08096)
*Georgios Chionas,Olga Gorelkina,Piotr Krysta,Rida Laraki*

Main category: cs.GT

TL;DR: 该论文从经济学角度研究了如何增强区块链交易的隐私性，分析了隐私意识用户的激励机制，包括最优拍卖和荷兰拍卖变体，并提出了一个隐私市场的双边市场机制，以保证社会福利的最优近似。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是基于隐私意识用户的需求，研究如何在区块链交易中通过经济学方法增强隐私性，同时平衡用户的经济效用和隐私暴露的风险。

Method: 论文采用了拍卖理论的分析方法，研究了两种拍卖设定：订单流拍卖和荷兰拍卖变体。此外，还提出了一个双边市场（隐私市场）的定价机制，确保激励兼容和预算平衡。

Result: 研究发现，最优拍卖是一种密封竞价拍卖。荷兰拍卖变体的收入与通信轮数相关。双边市场的定价机制能够实现社会福利的最优近似，并保持激励兼容和预算平衡。

Conclusion: 论文得出结论，通过经济学方法和加密技术的结合，可以有效提升区块链交易的隐私性和经济效率，尤其是在隐私市场和拍卖设定中表现优异。

Abstract: We study methods to enhance privacy in blockchain transactions from an economic angle. We consider mechanisms for privacy-aware users whose utility depends not only on the outcome of the mechanism but also negatively on the exposure of their economic preferences. Specifically, we study two auction-theoretic settings with privacy-aware users. First, we analyze an order flow auction, where a user auctions off to specialized agents, called searchers, the right to execute her transaction while maintaining a degree of privacy. We examine how the degree of privacy affects the revenue of the auction and, broadly, the net utility of the privacy-aware user. In this new setting, we describe the optimal auction, which is a sealed-bid auction. Subsequently, we analyze a variant of a Dutch auction in which the user gradually decreases the price and the degree of privacy until the transaction is sold. We compare the revenue of this auction to that of the optimal one as a function of the number of communication rounds. Then, we introduce a two-sided market - a privacy marketplace - with multiple users selling their transactions under their privacy preferences to multiple searchers. We propose a posted-price mechanism for the two-sided market that guarantees constant approximation of the optimal social welfare while maintaining incentive compatibility (from both sides of the market) and budget balance. This work builds on the emerging line of research that attempts to improve the performance of economic mechanisms by appending cryptographic primitives to them.

</details>


### [4] [Beyond Revenue and Welfare: Counterfactual Analysis of Spectrum Auctions with Application to Canada's 3800MHz Allocation](https://arxiv.org/abs/2512.08106)
*Sara Jalili Shani,Kris Joseph,Michael B. McNally,James R. Wright*

Main category: cs.GT

TL;DR: 本文提出了一种简化的频谱拍卖行为模型，通过模拟加拿大2023年3800 MHz频谱许可拍卖的竞价过程，验证了模型的有效性，并通过线性规划框架估算投标者的估值。


<details>
  <summary>Details</summary>
Motivation: 传统频谱拍卖模型依赖强均衡假设，而本文旨在探讨一种更简洁的行为模型，以预测拍卖结果并支持政策制定。

Method: 采用线性编程框架估计投标者的估值，模拟竞价过程，并验证模型是否能重现观察到的分配和价格演变特征。

Result: 模型成功预测了加拿大3800 MHz频谱拍卖的结果，并通过反事实模拟展示了替代机制如何提高农村和偏远地区的覆盖范围。

Conclusion: 研究表明，这一简洁的行为模型能够可靠地生成反事实预测，为政策制定者评估替代拍卖设计的影响提供了实用工具。

Abstract: Spectrum auctions are the primary mechanism through which governments allocate scarce radio frequencies, with outcomes that shape competition, coverage, and innovation in telecommunications markets. While traditional models of spectrum auctions often rely on strong equilibrium assumptions, we take a more parsimonious approach by modeling bidders as myopic and straightforward: in each round, firms simply demand the bundle that maximizes their utility given current prices. Despite its simplicity, this model proves effective in predicting the outcomes of Canada's 2023 auction of 3800 MHz spectrum licenses. Using detailed round-by-round bidding data, we estimate bidders' valuations through a linear programming framework and validate that our model reproduces key features of the observed allocation and price evolution. We then use these estimated valuations to simulate a counterfactual auction under an alternative mechanism that incentivizes deployment in rural and remote regions, aligning with one of the key objectives set out in the Canadian Telecommunications Act. The results show that the proposed mechanism substantially improves population coverage in underserved areas. These findings demonstrate that a behavioral model with minimal assumptions is sufficient to generate reliable counterfactual predictions, making it a practical tool for policymakers to evaluate how alternative auction designs may influence future outcomes. In particular, our study demonstrates a method for counterfactual mechanism design, providing a framework to evaluate how alternative auction rules could advance policy goals such as equitable deployment across Canada.

</details>


### [5] [Multi-agent learning under uncertainty: Recurrence vs. concentration](https://arxiv.org/abs/2512.08132)
*Kyriakos Lotidis,Panayotis Mertikopoulos,Nicholas Bambos,Jose Blanchet*

Main category: cs.GT

TL;DR: 本文研究了不确定性下多智能体学习的收敛情况，重点关注了连续博弈中两种随机正则化学习模型的长期行为，发现其动态一般不会收敛，但在强单调博弈中，动态会频繁返回均衡附近。


<details>
  <summary>Details</summary>
Motivation: 探讨在多智能体学习中的不确定性环境下，正则化学习模型的长期行为及其收敛特性，揭示随机性与确定性模型的不同表现。

Method: 分析了连续和离散时间下的两种随机正则化学习模型，研究了它们在强单调博弈中的动态行为。

Result: 发现在强单调博弈中，动态会频繁返回均衡邻近区域，但在非强单调博弈中，这一特性可能失效，突显了正则化学习的局限性。

Conclusion: 研究表明，正则化学习在强单调博弈中具有良好的局部收敛性，但在非强单调博弈中受限于随机性和不确定性。

Abstract: In this paper, we examine the convergence landscape of multi-agent learning under uncertainty. Specifically, we analyze two stochastic models of regularized learning in continuous games -- one in continuous and one in discrete time with the aim of characterizing the long-run behavior of the induced sequence of play. In stark contrast to deterministic, full-information models of learning (or models with a vanishing learning rate), we show that the resulting dynamics do not converge in general. In lieu of this, we ask instead which actions are played more often in the long run, and by how much. We show that, in strongly monotone games, the dynamics of regularized learning may wander away from equilibrium infinitely often, but they always return to its vicinity in finite time (which we estimate), and their long-run distribution is sharply concentrated around a neighborhood thereof. We quantify the degree of this concentration, and we show that these favorable properties may all break down if the underlying game is not strongly monotone -- underscoring in this way the limits of regularized learning in the presence of persistent randomness and uncertainty.

</details>


### [6] [Robust equilibria in continuous games: From strategic to dynamic robustness](https://arxiv.org/abs/2512.08138)
*Kyriakos Lotidis,Panayotis Mertikopoulos,Nicholas Bambos,Jose Blanchet*

Main category: cs.GT

TL;DR: 本文研究了连续博弈中纳什均衡在战略和动态不确定性下的稳健性，提出了两种稳健性概念及其几何特征，并证明了它们之间的结构对应关系。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探讨纳什均衡在战略和动态不确定性下的稳健性，以确保均衡在扰动和不确定性下的不变性。

Method: 通过引入稳健均衡的概念，分析其在博弈收益结构小扰动下的不变性，并研究FTRL动态中的稳定极限点。

Result: 证明了战略稳健性和动态稳健性之间的结构对应关系，并展示了熵正则化学习在仿射约束动作空间中的几何收敛速率。

Conclusion: 战略稳健性和动态稳健性之间存在紧密联系，熵正则化学习在特定条件下展现了高效的收敛性能。

Abstract: In this paper, we examine the robustness of Nash equilibria in continuous games, under both strategic and dynamic uncertainty. Starting with the former, we introduce the notion of a robust equilibrium as those equilibria that remain invariant to small -- but otherwise arbitrary -- perturbations to the game's payoff structure, and we provide a crisp geometric characterization thereof. Subsequently, we turn to the question of dynamic robustness, and we examine which equilibria may arise as stable limit points of the dynamics of "follow the regularized leader" (FTRL) in the presence of randomness and uncertainty. Despite their very distinct origins, we establish a structural correspondence between these two notions of robustness: strategic robustness implies dynamic robustness, and, conversely, the requirement of strategic robustness cannot be relaxed if dynamic robustness is to be maintained. Finally, we examine the rate of convergence to robust equilibria as a function of the underlying regularizer, and we show that entropically regularized learning converges at a geometric rate in games with affinely constrained action spaces.

</details>
