<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
*Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman*

Main category: cs.GR

TL;DR: 提出了一个完全零样本的框架，用于在文本到视频模型中实现动态概念的个性化，无需实例微调，提升了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的动态概念个性化方法大多需要针对每个实例进行微调，这限制了方法的可扩展性。

Method: 该方法利用结构化的2x2视频网格，通过训练轻量级的Grid-LoRA适配器，实现对这些网格内的视频内容进行编辑和组合。推断时，专用的Grid Fill模块完成部分观察到的布局，生成时间相干且保持身份一致性的输出。

Result: 实验表明，该方法能够生成高质量且一致的结果，适用于多种未训练过的动态概念和编辑场景。

Conclusion: 提出的框架在单次前向传播中完成所有操作，无需测试时优化，展示了在动态概念个性化领域的强大扩展性和通用性。

Abstract: Recent advances in text-to-video generation have enabled high-quality
synthesis from text and image prompts. While the personalization of dynamic
concepts, which capture subject-specific appearance and motion from a single
video, is now feasible, most existing methods require per-instance fine-tuning,
limiting scalability. We introduce a fully zero-shot framework for dynamic
concept personalization in text-to-video models. Our method leverages
structured 2x2 video grids that spatially organize input and output pairs,
enabling the training of lightweight Grid-LoRA adapters for editing and
composition within these grids. At inference, a dedicated Grid Fill module
completes partially observed layouts, producing temporally coherent and
identity preserving outputs. Once trained, the entire system operates in a
single forward pass, generalizing to previously unseen dynamic concepts without
any test-time optimization. Extensive experiments demonstrate high-quality and
consistent results across a wide range of subjects beyond trained concepts and
editing scenarios.

</details>


### [2] [DanceGraph: A Complementary Architecture for Synchronous Dancing Online](https://arxiv.org/abs/2507.18052)
*David Sinclair,Ademyemi Ademola,Babis Koniaris,Kenny Mitchell*

Main category: cs.GR

TL;DR: DanceGraph是一种架构，用于解决在线同步跳舞中的网络延迟问题，通过高效的实时带宽架构减少滞后，并结合参数化风格化方法优化舞蹈动作。


<details>
  <summary>Details</summary>
Motivation: 在线同步跳舞面临网络延迟和身体姿势共享的挑战，需要一种高效的方法来最小化滞后并实现与音乐节奏的同步。

Method: 开发了一种实时带宽高效架构以减少延迟，并引入参数化风格化方法，通过在线舞蹈修正优化舞蹈动作的节奏感。

Result: DanceGraph成功减少了运动预测的时间范围，实现了高效的在线舞蹈同步，并通过风格化方法提升了舞蹈的表现力。

Conclusion: DanceGraph为在线同步跳舞提供了有效的解决方案，通过高效架构和风格化方法克服了网络延迟问题，优化了舞蹈体验。

Abstract: DanceGraph is an architecture for synchronized online dancing overcoming the
latency of networked body pose sharing. We break down this challenge by
developing a real-time bandwidth-efficient architecture to minimize lag and
reduce the timeframe of required motion prediction for synchronization with the
music's rhythm. In addition, we show an interactive method for the
parameterized stylization of dance motions for rhythmic dance using online
dance correctives.

</details>


### [3] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
*SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park*

Main category: cs.GR

TL;DR: GeoAvatar提出了一种自适应几何高斯抛射框架，通过无监督方法分割高斯区域，并结合嘴部结构和部分变形策略，提升了3D头部头像的生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前3D头部头像生成方法在身份保持和新姿势/表情动画之间存在平衡问题，高斯方法难以适应面部区域的不同几何偏差。

Method: GeoAvatar采用自适应预分配阶段（APS）分割高斯区域，提出嘴部结构和部分变形策略，并引入正则化损失用于精确绑定。

Result: 实验表明，GeoAvatar在重建和新动画场景中优于现有方法，并发布了高表现力的DynamicFace视频数据集。

Conclusion: GeoAvatar通过自适应几何高斯抛射和嘴部增强策略，显著提升了3D头部头像生成的质量和动画保真度。

Abstract: Despite recent progress in 3D head avatar generation, balancing identity
preservation, i.e., reconstruction, with novel poses and expressions, i.e.,
animation, remains a challenge. Existing methods struggle to adapt Gaussians to
varying geometrical deviations across facial regions, resulting in suboptimal
quality. To address this, we propose GeoAvatar, a framework for adaptive
geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation
Stage (APS), an unsupervised method that segments Gaussians into rigid and
flexible sets for adaptive offset regularization. Then, based on mouth anatomy
and dynamics, we introduce a novel mouth structure and the part-wise
deformation strategy to enhance the animation fidelity of the mouth. Finally,
we propose a regularization loss for precise rigging between Gaussians and 3DMM
faces. Moreover, we release DynamicFace, a video dataset with highly expressive
facial motions. Extensive experiments show the superiority of GeoAvatar
compared to state-of-the-art methods in reconstruction and novel animation
scenarios.

</details>


### [4] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
*Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng*

Main category: cs.GR

TL;DR: 该论文提出了一种名为PS-GS的方法，将逆渲染与多视图光度立体（MVPS）结合，高效联合估计几何、材质和光照，并通过正则化和多视图多光源图像缓解逆渲染的病态问题。


<details>
  <summary>Details</summary>
Motivation: 传统逆渲染方法依赖固定环境光照，导致3D重建准确性不足。而MVPS虽能提高重建精度，但高效逆渲染仍具挑战性。

Method: PS-GS方法首先重建2D高斯泼溅模型作为初始几何，随后通过包含光照计算多层感知器的完整渲染方程进行延迟逆渲染，并利用未校准光度立体估计的法线图正则化渲染法线图。此外，提出2D高斯光线追踪以细化入射光照。

Result: 实验表明，该方法在合成和真实数据集上的重建精度和计算效率均优于先前工作。

Conclusion: PS-GS方法通过多视图和多光源图像的正则化，成功解决了逆渲染的病态问题，为新颖视角合成、重光照及材质和形状编辑提供了高效准确的解决方案。

Abstract: Integrating inverse rendering with multi-view photometric stereo (MVPS)
yields more accurate 3D reconstructions than the inverse rendering approaches
that rely on fixed environment illumination. However, efficient inverse
rendering with MVPS remains challenging. To fill this gap, we introduce the
Gaussian Splatting for Multi-view Photometric Stereo (PS-GS), which efficiently
and jointly estimates the geometry, materials, and lighting of the object that
is illuminated by diverse directional lights (multi-light). Our method first
reconstructs a standard 2D Gaussian splatting model as the initial geometry.
Based on the initialization model, it then proceeds with the deferred inverse
rendering by the full rendering equation containing a lighting-computing
multi-layer perceptron. During the whole optimization, we regularize the
rendered normal maps by the uncalibrated photometric stereo estimated normals.
We also propose the 2D Gaussian ray-tracing for single directional light to
refine the incident lighting. The regularizations and the use of multi-view and
multi-light images mitigate the ill-posed problem of inverse rendering. After
optimization, the reconstructed object can be used for novel-view synthesis,
relighting, and material and shape editing. Experiments on both synthetic and
real datasets demonstrate that our method outperforms prior works in terms of
reconstruction accuracy and computational efficiency.

</details>


### [5] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
*Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage*

Main category: cs.GR

TL;DR: 论文通过混合知识蒸馏和伪标签技术，开发了一种轻量级的语音驱动3D面部动画模型，适用于设备上的实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的语音驱动3D面部动画模型由于依赖大型预训练语音编码器，导致模型过大且仅适用于离线推理。为了支持游戏开发中的实时应用，需要开发轻量级的模型。

Method: 通过混合知识蒸馏和伪标签技术，使用高性能教师模型训练仅包含卷积和全连接层的小型学生模型，减少了模型的计算和存储需求。

Result: 实验表明，模型的内存占用可降至3.4 MB，所需音频上下文时间降至81毫秒，同时保持高质量的动画效果。

Conclusion: 该研究为设备上的实时推理提供了可能，是实现逼真、模型驱动的数字角色的重要一步。

Abstract: The training of high-quality, robust machine learning models for
speech-driven 3D facial animation requires a large, diverse dataset of
high-quality audio-animation pairs. To overcome the lack of such a dataset,
recent work has introduced large pre-trained speech encoders that are robust to
variations in the input audio and, therefore, enable the facial animation model
to generalize across speakers, audio quality, and languages. However, the
resulting facial animation models are prohibitively large and lend themselves
only to offline inference on a dedicated machine. In this work, we explore
on-device, real-time facial animation models in the context of game
development. We overcome the lack of large datasets by using hybrid knowledge
distillation with pseudo-labeling. Given a large audio dataset, we employ a
high-performing teacher model to train very small student models. In contrast
to the pre-trained speech encoders, our student models only consist of
convolutional and fully-connected layers, removing the need for attention
context or recurrent updates. In our experiments, we demonstrate that we can
reduce the memory footprint to up to 3.4 MB and required future audio context
to up to 81 ms while maintaining high-quality animations. This paves the way
for on-device inference, an important step towards realistic, model-driven
digital characters.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 论文提出了一种统一的范畴方法来扩展Howe's方法，用于证明高阶语言中行为一致性的程序同余性。


<details>
  <summary>Details</summary>
Motivation: 随着具有定量特征（如概率性）的高阶语言的兴起，需要扩展共归纳方法以适应更精细的行为一致性概念，如行为距离。

Method: 通过抽象的范畴方法（称为AHOS）和纤维化模型来统一处理Howe's方法，使其适应不同语言和行为一致性概念。

Result: 在满足自然条件下，AHOS模型中最广义的行为一致性可以形成同余关系，并应用于概率高阶语言的同余性证明。

Conclusion: 该研究为高阶语言的行为一致性提供了统一的范畴框架，可用于证明多种行为概念的同余性。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [$k$-Approval Veto: A Spectrum of Voting Rules Balancing Metric Distortion and Minority Protection](https://arxiv.org/abs/2507.17981)
*Fatih Erdem Kizilkaya,David Kempe*

Main category: cs.GT

TL;DR: 论文研究了单候选人排名选择选举中的多数原则与少数原则之间的权衡，提出了$k$-Approval Veto投票规则，以在不同目标下实现社会福祉与少数群体保护的平衡。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决民主选举中的两个核心问题：最大化社会福利（多数原则）和保护少数群体免受不利结果（少数原则）。

Method: 使用度量扭曲框架衡量社会福利，并引入$\ell$-mutual minority准则评估少数群体保护。分析$k$-Approval Veto投票规则在不同目标（功利主义、百分位数和平均主义）下的表现。

Result: $k$-Approval Veto在少数群体保护方面至少满足$k$的水平，但社会福祉会降低。在功利主义目标下，度量扭曲随$k$线性增加；在$\alpha$-百分位数目标下，度量扭曲在$\alpha \ge k/(k+1)$时为5，否则无界；在平均主义目标下，度量扭曲始终为3。

Conclusion: $k$-Approval Veto提供了一种灵活的投票规则，允许根据不同需求调整多数原则与少数原则之间的权衡，但其社会福祉代价需权衡考虑。

Abstract: In the context of single-winner ranked-choice elections between $m$
candidates, we explore the tradeoff between two competing goals in every
democratic system: the majority principle (maximizing the social welfare) and
the minority principle (safeguarding minority groups from overly bad
outcomes).To measure the social welfare, we use the well-established framework
of metric distortion subject to various objectives: utilitarian (i.e., total
cost), $\alpha$-percentile (e.g., median cost for $\alpha = 1/2$), and
egalitarian (i.e., max cost). To measure the protection of minorities, we
introduce the $\ell$-mutual minority criterion, which requires that if a
sufficiently large (parametrized by $\ell$) coalition $T$ of voters ranks all
candidates in $S$ lower than all other candidates, then none of the candidates
in $S$ should win. The highest $\ell$ for which the criterion is satisfied
provides a well-defined measure of mutual minority protection (ranging from 1
to $m$).
  Our main contribution is the analysis of a recently proposed class of voting
rules called $k$-Approval Veto, offering a comprehensive range of trade-offs
between the two principles. This class spans between Plurality Veto (for $k=1$)
- a simple voting rule achieving optimal metric distortion - and Vote By Veto
(for $k=m$) which picks a candidate from the proportional veto core. We show
that $k$-Approval Veto has minority protection at least $k$, and thus, it
accommodates any desired level of minority protection. However, this comes at
the price of lower social welfare. For the utilitarian objective, the metric
distortion increases linearly in $k$. For the $\alpha$-percentile objective,
the metric distortion is the optimal value of 5 for $\alpha \ge k/(k+1)$ and
unbounded for $\alpha < k/(k+1)$. For the egalitarian objective, the metric
distortion is the optimal value of 3 for all values of $k$.

</details>


### [8] [On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities](https://arxiv.org/abs/2507.18251)
*Jiarong Jin,Biaoshuai Tao*

Main category: cs.GT

TL;DR: 本文研究了在个性化双值效用下分配不可分割物品的公平分割问题，给出了帕累托最优分配的刻画，并证明了在整数价值比率下判别帕累托最优性的多项式时间算法，而在一般情况（分数价值比率）下该问题是coNP完全的。此外，展示了EFX分配的存在性和可计算性。


<details>
  <summary>Details</summary>
Motivation: 研究在个性化双值效用模型下公平分配不可分割物品的问题，填补现有研究在判别帕累托最优性和EFX分配存在性方面的空白。

Method: 通过刻画帕累托最优分配的条件，设计多项式时间算法判别整数价值比率下的帕累托最优性，并证明分数价值比率下该问题的coNP完全性。进一步证明了EFX分配的存在性及其多项式时间可计算性。

Result: 在整数价值比率下，判别帕累托最优性是多项式时间可解的；在分数价值比率下，该问题是coNP完全的。EFX分配在个性化双值效用下总是存在且可多项式时间计算。

Conclusion: 本文扩展了双值效用下的公平分配研究，提出了EFX与帕累托最优分配是否总能存在并可高效计算的开问题。

Abstract: We study the fair division problem of allocating $m$ indivisible goods to $n$
agents with additive personalized bi-valued utilities. Specifically, each agent
$i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating
that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For
convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.
  We give a characterization to all the Pareto-optimal allocations. Our
characterization implies a polynomial-time algorithm to decide if a given
allocation is Pareto-optimal in the case each $r_i$ is an integer. For the
general case (where $r_i$ may be fractional), we show that this decision
problem is coNP-complete. Our result complements the existing results: this
decision problem is coNP-complete for tri-valued utilities (where each agent's
value for each good belongs to $\{a,b,c\}$ for some prescribed $a>b>c\geq0$),
and this decision problem belongs to P for bi-valued utilities (where $r_i$ in
our model is the same for each agent).
  We further show that an EFX allocation always exists and can be computed in
polynomial time under the personalized bi-valued utilities setting, which
extends the previous result on bi-valued utilities. We propose the open problem
of whether an EFX and Pareto-optimal allocation always exists (and can be
computed in polynomial time).

</details>
