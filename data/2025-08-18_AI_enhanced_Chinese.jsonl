{"id": "2508.11297", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.11297", "abs": "https://arxiv.org/abs/2508.11297", "authors": ["Casper Bach"], "title": "Generic Reduction-Based Interpreters (Extended Version)", "comment": null, "summary": "Reduction-based interpreters are traditionally defined in terms of a one-step\nreduction function which systematically decomposes a term into a potential\nredex and context, contracts the redex, and recomposes it to construct the new\nterm to be further reduced. While implementing such interpreters follows a\nsystematic recipe, they often require interpreter engineers to write a\nsubstantial amount of code -- much of it boilerplate. In this paper, we apply\nwell-known techniques from generic programming to reduce boilerplate code in\nreduction-based interpreters.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\u51cf\u5c11\u57fa\u4e8e\u5f52\u7ea6\u7684\u89e3\u91ca\u5668\u4e2d\u7684\u6837\u677f\u4ee3\u7801\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5f52\u7ea6\u7684\u89e3\u91ca\u5668\u7f16\u5199\u9700\u8981\u5927\u91cf\u91cd\u590d\u4ee3\u7801\uff0c\u5e0c\u671b\u901a\u8fc7\u6cdb\u578b\u7f16\u7a0b\u51cf\u5c11\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\uff0c\u4f18\u5316\u89e3\u91ca\u5668\u7684\u5f52\u7ea6\u8fc7\u7a0b\u8bbe\u8ba1\u3002", "result": "\u5b9e\u73b0\u4e86\u51cf\u5c11\u6837\u677f\u4ee3\u7801\u7684\u76ee\u6807\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "\u6cdb\u578b\u7f16\u7a0b\u53ef\u6709\u6548\u7b80\u5316\u57fa\u4e8e\u5f52\u7ea6\u7684\u89e3\u91ca\u5668\u5b9e\u73b0\uff0c\u51cf\u5c11\u91cd\u590d\u5de5\u4f5c\u3002"}}
{"id": "2508.11443", "categories": ["cs.PL", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.11443", "abs": "https://arxiv.org/abs/2508.11443", "authors": ["William Henrich Due", "Martin Elsman", "Troels Henriksen"], "title": "Towards Efficient Hash Maps in Functional Array Languages", "comment": null, "summary": "We present a systematic derivation of a data-parallel implementation of\ntwo-level, static and collision-free hash maps, by giving a functional\nformulation of the Fredman et al. construction, and then flattening it. We\ndiscuss the challenges of providing a flexible, polymorphic, and abstract\ninterface to hash maps in a functional array language, with particular\nattention paid to the problem of dynamically sized keys, which we address by\nassociating each hash map with an arbitrary context. The algorithm is\nimplemented in Futhark, and the achieved GPU execution performance is compared\non simple benchmark problems. We find that our hash maps outperform\nconventional tree/search-based approaches. Furthermore, our implementation is\ncompared against the state-of-the-art cuCollections library, which is\nsignificantly faster for hash map construction, and to a lesser degree for\nlookups. We explain to which extent the performance difference is due to\nlow-level code generation limitation in the Futhark compiler, and to which\nextent it can be attributed to the data-parallel programming vocabulary not\nproviding the constructs necessary to express the equivalent of the algorithms\nused by cuCollections. We end by reflecting to which extent the functional\narray language programming model could, or should, be extended to address these\nweaknesses.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u5e76\u884c\u5b9e\u73b0\u7684\u4e24\u5c42\u9759\u6001\u65e0\u51b2\u7a81\u54c8\u5e0c\u6620\u5c04\uff0c\u901a\u8fc7\u529f\u80fd\u5316Fredman\u7b49\u4eba\u6784\u9020\u5e76\u5c06\u5176\u6241\u5e73\u5316\u3002\u5728\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u4e2d\u63d0\u4f9b\u7075\u6d3b\u3001\u591a\u6001\u548c\u62bd\u8c61\u7684\u54c8\u5e0c\u6620\u5c04\u63a5\u53e3\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u52a8\u6001\u5927\u5c0f\u952e\u7684\u95ee\u9898\u3002\u7b97\u6cd5\u5728Futhark\u4e2d\u5b9e\u73b0\uff0cGPU\u6267\u884c\u6027\u80fd\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u4f20\u7edf\u7684\u6811/\u641c\u7d22\u65b9\u6cd5\u3002\u4e0ecuCollections\u5e93\u76f8\u6bd4\uff0c\u6784\u9020\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u67e5\u627e\u7a0d\u6162\u3002\u5206\u6790\u4e86\u6027\u80fd\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u5e76\u63a2\u8ba8\u4e86\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\u53ef\u80fd\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5728\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u54c8\u5e0c\u6620\u5c04\u63a5\u53e3\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5904\u7406\u52a8\u6001\u5927\u5c0f\u952e\u7684\u95ee\u9898\u3002\u540c\u65f6\uff0c\u63a2\u7d22\u6570\u636e\u5e76\u884c\u7f16\u7a0b\u6a21\u578b\u7684\u5c40\u9650\u6027\u53ca\u5176\u6539\u8fdb\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u529f\u80fd\u5316Fredman\u7b49\u4eba\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u6241\u5e73\u5316\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u5e76\u884c\u7684\u4e24\u5c42\u9759\u6001\u65e0\u51b2\u7a81\u54c8\u5e0c\u6620\u5c04\u3002\u7b97\u6cd5\u5728Futhark\u4e2d\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u6027\u80fd\u3002", "result": "\u5728GPU\u4e0a\u7684\u6267\u884c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u7684\u6811/\u641c\u7d22\u65b9\u6cd5\u3002\u4e0ecuCollections\u5e93\u76f8\u6bd4\uff0c\u54c8\u5e0c\u6620\u5c04\u6784\u9020\u901f\u5ea6\u663e\u8457\u66f4\u5feb\uff0c\u4f46\u67e5\u627e\u6027\u80fd\u7565\u4f4e\u3002\u6027\u80fd\u5dee\u5f02\u90e8\u5206\u5f52\u56e0\u4e8eFuthark\u7f16\u8bd1\u5668\u7684\u4ee3\u7801\u751f\u6210\u9650\u5236\u548c\u6570\u636e\u5e76\u884c\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u8bba\u6587\u5206\u6790\u4e86\u529f\u80fd\u6570\u7ec4\u8bed\u8a00\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u662f\u5426\u53ca\u5982\u4f55\u6269\u5c55\u8be5\u6a21\u578b\u4ee5\u89e3\u51b3\u6027\u80fd\u95ee\u9898\u3002\u672a\u6765\u7814\u7a76\u53ef\u80fd\u96c6\u4e2d\u5728\u6539\u8fdb\u7f16\u8bd1\u5668\u6216\u6269\u5c55\u7f16\u7a0b\u6a21\u578b\u7684\u529f\u80fd\u6027\u3002"}}
{"id": "2508.11359", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.11359", "abs": "https://arxiv.org/abs/2508.11359", "authors": ["Jiejun Hu-Bolz", "James Stovold"], "title": "Can We Tell if ChatGPT is a Parasite? Studying Human-AI Symbiosis with Game Theory", "comment": "8 pages, 6 figures, accepted in ALife 2025", "summary": "This work asks whether a human interacting with a generative AI system can\nmerge into a single individual through iterative, information-driven\ninteractions. We model the interactions between a human, a generative AI\nsystem, and the human's wider environment as a three-player stochastic game. We\nuse information-theoretic measures (entropy, mutual information, and transfer\nentropy) to show that our modelled human and generative AI are able to form an\naggregate individual in the sense of Krakauer et al. (2020). The model we\npresent is able to answer interesting questions around the symbiotic nature of\nhumans and AI systems, including whether LLM-driven chatbots are acting as\nparasites, feeding on the information provided by humans.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4eba\u7c7b\u4e0e\u751f\u6210AI\u7cfb\u7edf\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u8fed\u4ee3\u7684\u4fe1\u606f\u9a71\u52a8\u4ea4\u4e92\u878d\u5408\u4e3a\u4e00\u4e2a\u6574\u4f53\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u8bba\u5de5\u5177\u5c55\u793a\u4e86\u8fd9\u79cd\u878d\u5408\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u4eba\u7c7b\u4e0e\u751f\u6210AI\u7cfb\u7edf\u4e4b\u95f4\u7684\u4ea4\u4e92\u662f\u5426\u80fd\u5f62\u6210\u5171\u751f\u5173\u7cfb\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5173\u7cfb\u662f\u5426\u4f1a\u6f14\u53d8\u4e3a\u7c7b\u4f3c\u5bc4\u751f\u7684\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4fe1\u606f\u8bba\u5de5\u5177\uff08\u71b5\u3001\u4e92\u4fe1\u606f\u548c\u4f20\u9012\u71b5\uff09\u5bf9\u4e09\u8005\u4e4b\u95f4\u7684\u4ea4\u4e92\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u4e09\u73a9\u5bb6\u968f\u673a\u535a\u5f08\u6a21\u578b\u5206\u6790\u8fd9\u79cd\u4ea4\u4e92\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u4e2d\u7684\u751f\u6210AI\u4e0e\u4eba\u7c7b\u80fd\u591f\u5f62\u6210\u4e00\u4e2a\u805a\u5408\u4e2a\u4f53\uff0c\u5e76\u63ed\u793a\u4e86AI\u7cfb\u7edf\u662f\u5426\u4f1a\u4ece\u4eba\u7c7b\u63d0\u4f9b\u7684\u4fe1\u606f\u4e2d\u53d7\u76ca\u751a\u81f3\u5bc4\u751f\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u751f\u6210AI\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u7684\u4ea4\u4e92\u5177\u6709\u5171\u751f\u6f5c\u529b\uff0c\u4f46\u4e5f\u53ef\u80fd\u6f14\u53d8\u4e3a\u5355\u5411\u7684\u4fe1\u606f\u5229\u7528\u5173\u7cfb\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u4f26\u7406\u610f\u4e49\u3002"}}
{"id": "2508.11177", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.11177", "abs": "https://arxiv.org/abs/2508.11177", "authors": ["I-Chao Shen", "Ariel Shamir", "Takeo Igarashi"], "title": "LayoutRectifier: An Optimization-based Post-processing for Graphic Design Layout Generation", "comment": "11 pages, Pacific Graphics 2025", "summary": "Recent deep learning methods can generate diverse graphic design layouts\nefficiently. However, these methods often create layouts with flaws, such as\nmisalignment, unwanted overlaps, and unsatisfied containment. To tackle this\nissue, we propose an optimization-based method called LayoutRectifier, which\ngracefully rectifies auto-generated graphic design layouts to reduce these\nflaws while minimizing deviation from the generated layout. The core of our\nmethod is a two-stage optimization. First, we utilize grid systems, which\nprofessional designers commonly use to organize elements, to mitigate\nmisalignments through discrete search. Second, we introduce a novel box\ncontainment function designed to adjust the positions and sizes of the layout\nelements, preventing unwanted overlapping and promoting desired containment. We\nevaluate our method on content-agnostic and content-aware layout generation\ntasks and achieve better-quality layouts that are more suitable for downstream\ngraphic design tasks. Our method complements learning-based layout generation\nmethods and does not require additional training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5LayoutRectifier\uff0c\u7528\u4e8e\u7ea0\u6b63\u81ea\u52a8\u751f\u6210\u7684\u56fe\u5f62\u8bbe\u8ba1\u5e03\u5c40\u4e2d\u7684\u9519\u8bef\uff08\u5982\u4e0d\u5bf9\u9f50\u3001\u91cd\u53e0\u548c\u4e0d\u6ee1\u610f\u7684\u5305\u542b\uff09\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\uff08\u79bb\u6563\u641c\u7d22\u548c\u5305\u542b\u51fd\u6570\u8c03\u6574\uff09\u63d0\u9ad8\u5e03\u5c40\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u7684\u6df1\u5ea6\u5b66\u4e60\u751f\u6210\u56fe\u5f62\u8bbe\u8ba1\u5e03\u5c40\u65b9\u6cd5\u5e38\u5b58\u5728\u4e0d\u5bf9\u9f50\u3001\u91cd\u53e0\u548c\u5305\u542b\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u5e03\u5c40\u7684\u5b9e\u7528\u6027\u548c\u7f8e\u89c2\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u4f18\u5316\u65b9\u6cd5\u6765\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\u3002", "method": "LayoutRectifier\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u79bb\u6563\u641c\u7d22\u5229\u7528\u7f51\u683c\u7cfb\u7edf\u89e3\u51b3\u4e0d\u5bf9\u9f50\u95ee\u9898\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u65b0\u7684\u5305\u542b\u51fd\u6570\u8c03\u6574\u5143\u7d20\u4f4d\u7f6e\u548c\u5927\u5c0f\uff0c\u9632\u6b62\u91cd\u53e0\u5e76\u63d0\u5347\u5305\u542b\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5185\u5bb9\u548c\u5185\u5bb9\u65e0\u5173\u7684\u5e03\u5c40\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u5e03\u5c40\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "conclusion": "LayoutRectifier\u6709\u6548\u8865\u5145\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u5e03\u5c40\u751f\u6210\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e03\u5c40\u7684\u5b9e\u7528\u6027\u548c\u7f8e\u89c2\u6027\u3002"}}
{"id": "2508.11203", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "51-04", "I.3.8; I.4.9"], "pdf": "https://arxiv.org/pdf/2508.11203", "abs": "https://arxiv.org/abs/2508.11203", "authors": ["Seungmi Lee", "Kwan Yun", "Junyong Noh"], "title": "StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation", "comment": "Pacific graphics 2025, CGF, 15 pages", "summary": "We introduce StyleMM, a novel framework that can construct a stylized 3D\nMorphable Model (3DMM) based on user-defined text descriptions specifying a\ntarget style. Building upon a pre-trained mesh deformation network and a\ntexture generator for original 3DMM-based realistic human faces, our approach\nfine-tunes these models using stylized facial images generated via text-guided\nimage-to-image (i2i) translation with a diffusion model, which serve as\nstylization targets for the rendered mesh. To prevent undesired changes in\nidentity, facial alignment, or expressions during i2i translation, we introduce\na stylization method that explicitly preserves the facial attributes of the\nsource image. By maintaining these critical attributes during image\nstylization, the proposed approach ensures consistent 3D style transfer across\nthe 3DMM parameter space through image-based training. Once trained, StyleMM\nenables feed-forward generation of stylized face meshes with explicit control\nover shape, expression, and texture parameters, producing meshes with\nconsistent vertex connectivity and animatability. Quantitative and qualitative\nevaluations demonstrate that our approach outperforms state-of-the-art methods\nin terms of identity-level facial diversity and stylization capability. The\ncode and videos are available at\n[kwanyun.github.io/stylemm_page](kwanyun.github.io/stylemm_page).", "AI": {"tldr": "StyleMM\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u6839\u636e\u7528\u6237\u5b9a\u4e49\u7684\u6587\u672c\u63cf\u8ff0\u6784\u5efa\u98ce\u683c\u5316\u76843D\u53ef\u53d8\u5f62\u6a21\u578b\uff083DMM\uff09\uff0c\u901a\u8fc7\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7ffb\u8bd1\u548c\u6269\u6563\u6a21\u578b\u751f\u6210\u98ce\u683c\u5316\u76ee\u6807\uff0c\u4fdd\u6301\u9762\u90e8\u5c5e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e00\u81f4\u76843D\u98ce\u683c\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u76843D\u53ef\u53d8\u5f62\u6a21\u578b\u5728\u98ce\u683c\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0cStyleMM\u65e8\u5728\u901a\u8fc7\u6587\u672c\u5f15\u5bfc\u7684\u65b9\u5f0f\u751f\u6210\u98ce\u683c\u5316\u76843D\u4eba\u8138\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u8eab\u4efd\u3001\u5bf9\u9f50\u548c\u8868\u60c5\u7b49\u5173\u952e\u5c5e\u6027\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684\u7f51\u683c\u53d8\u5f62\u7f51\u7edc\u548c\u7eb9\u7406\u751f\u6210\u5668\uff0c\u7ed3\u5408\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7ffb\u8bd1\u548c\u6269\u6563\u6a21\u578b\u751f\u6210\u98ce\u683c\u5316\u76ee\u6807\uff0c\u901a\u8fc7\u56fe\u50cf\u8bad\u7ec3\u5b9e\u73b0\u4e00\u81f4\u76843D\u98ce\u683c\u8fc1\u79fb\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u8868\u660e\uff0cStyleMM\u5728\u8eab\u4efd\u7ea7\u9762\u90e8\u591a\u6837\u6027\u548c\u98ce\u683c\u5316\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "StyleMM\u6210\u529f\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6587\u672c\u63cf\u8ff0\u76843D\u98ce\u683c\u8fc1\u79fb\uff0c\u751f\u6210\u7684\u9762\u90e8\u7f51\u683c\u5177\u6709\u4e00\u81f4\u7684\u9876\u70b9\u8fde\u63a5\u6027\u548c\u53ef\u52a8\u753b\u6027\uff0c\u63a8\u52a8\u4e863D\u53ef\u53d8\u5f62\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.11476", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.11476", "abs": "https://arxiv.org/abs/2508.11476", "authors": ["Qian Liang", "Zichong Chen", "Yang Zhou", "Hui Huang"], "title": "SPG: Style-Prompting Guidance for Style-Specific Content Creation", "comment": "Accepted to the Journal track of Pacific Graphics 2025", "summary": "Although recent text-to-image (T2I) diffusion models excel at aligning\ngenerated images with textual prompts, controlling the visual style of the\noutput remains a challenging task. In this work, we propose Style-Prompting\nGuidance (SPG), a novel sampling strategy for style-specific image generation.\nSPG constructs a style noise vector and leverages its directional deviation\nfrom unconditional noise to guide the diffusion process toward the target style\ndistribution. By integrating SPG with Classifier-Free Guidance (CFG), our\nmethod achieves both semantic fidelity and style consistency. SPG is simple,\nrobust, and compatible with controllable frameworks like ControlNet and\nIPAdapter, making it practical and widely applicable. Extensive experiments\ndemonstrate the effectiveness and generality of our approach compared to\nstate-of-the-art methods. Code is available at\nhttps://github.com/Rumbling281441/SPG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStyle-Prompting Guidance (SPG)\u7684\u65b0\u91c7\u6837\u7b56\u7565\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u7279\u5b9a\u98ce\u683c\u7684\u56fe\u50cf\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6269\u6563\u6a21\u578b\u5728\u5c06\u751f\u6210\u56fe\u50cf\u4e0e\u6587\u672c\u63d0\u793a\u5bf9\u9f50\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u63a7\u5236\u8f93\u51fa\u56fe\u50cf\u7684\u89c6\u89c9\u98ce\u683c\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "SPG\u6784\u5efa\u98ce\u683c\u566a\u58f0\u5411\u91cf\uff0c\u5e76\u5229\u7528\u5176\u4e0e\u65e0\u6761\u4ef6\u566a\u58f0\u7684\u65b9\u5411\u504f\u5dee\u6765\u5f15\u5bfc\u6269\u6563\u8fc7\u7a0b\u671d\u5411\u76ee\u6807\u98ce\u683c\u5206\u5e03\u3002\u8be5\u65b9\u6cd5\u8fd8\u4e0eClassifier-Free Guidance (CFG)\u96c6\u6210\uff0c\u4ee5\u5b9e\u73b0\u8bed\u4e49\u4fdd\u771f\u548c\u98ce\u683c\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSPG\u65b9\u6cd5\u5728\u8bed\u4e49\u548c\u98ce\u683c\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e76\u4e14\u4e0eControlNet\u548cIPAdapter\u7b49\u53ef\u63a7\u6846\u67b6\u517c\u5bb9\u3002", "conclusion": "SPG\u662f\u4e00\u79cd\u7b80\u5355\u3001\u9c81\u68d2\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u751f\u6210\u5177\u6709\u7279\u5b9a\u98ce\u683c\u7684\u56fe\u50cf\uff0c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u51c6\u786e\u6027\u3002"}}
