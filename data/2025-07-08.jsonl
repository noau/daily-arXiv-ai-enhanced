{"id": "2507.03256", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.03256", "abs": "https://arxiv.org/abs/2507.03256", "authors": ["Xinyang Li", "Gen Li", "Zhihui Lin", "Yichen Qian", "GongXin Yao", "Weinan Jia", "Weihua Chen", "Fan Wang"], "title": "MoDA: Multi-modal Diffusion Architecture for Talking Head Generation", "comment": "12 pages, 7 figures", "summary": "Talking head generation with arbitrary identities and speech audio remains a\ncrucial problem in the realm of digital humans and the virtual metaverse.\nRecently, diffusion models have become a popular generative technique in this\nfield with their strong generation and generalization capabilities. However,\nseveral challenges remain for diffusion-based methods: 1) inefficient inference\nand visual artifacts, which arise from the implicit latent space of Variational\nAuto-Encoders (VAE), complicating the diffusion process; 2) authentic facial\nexpressions and head movements, resulting from insufficient multi-modal\ninformation interaction. In this paper, MoDA handle these challenges by 1)\ndefines a joint parameter space to bridge motion generation and neural\nrendering, and leverages flow matching to simplify the diffusion learning\nprocess; 2) introduces a multi-modal diffusion architecture to model the\ninteraction among noisy motion, audio, and auxiliary conditions, ultimately\nenhancing overall facial expressiveness. Subsequently, a coarse-to-fine fusion\nstrategy is adopted to progressively integrate different modalities, ensuring\neffective integration across feature spaces. Experimental results demonstrate\nthat MoDA significantly improves video diversity, realism, and efficiency,\nmaking it suitable for real-world applications."}
{"id": "2507.03731", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.03731", "abs": "https://arxiv.org/abs/2507.03731", "authors": ["Dale Decatur", "Itai Lang", "Kfir Aberman", "Rana Hanocka"], "title": "3D PixBrush: Image-Guided Local Texture Synthesis", "comment": null, "summary": "We present 3D PixBrush, a method for performing image-driven edits of local\nregions on 3D meshes. 3D PixBrush predicts a localization mask and a\nsynthesized texture that faithfully portray the object in the reference image.\nOur predicted localizations are both globally coherent and locally precise.\nGlobally - our method contextualizes the object in the reference image and\nautomatically positions it onto the input mesh. Locally - our method produces\nmasks that conform to the geometry of the reference image. Notably, our method\ndoes not require any user input (in the form of scribbles or bounding boxes) to\nachieve accurate localizations. Instead, our method predicts a localization\nmask on the 3D mesh from scratch. To achieve this, we propose a modification to\nthe score distillation sampling technique which incorporates both the predicted\nlocalization and the reference image, referred to as localization-modulated\nimage guidance. We demonstrate the effectiveness of our proposed technique on a\nwide variety of meshes and images."}
{"id": "2507.03836", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.03836", "abs": "https://arxiv.org/abs/2507.03836", "authors": ["Jianxin Sun", "David Lenz", "Hongfeng Yu", "Tom Peterka"], "title": "F-Hash: Feature-Based Hash Design for Time-Varying Volume Visualization via Multi-Resolution Tesseract Encoding", "comment": null, "summary": "Interactive time-varying volume visualization is challenging due to its\ncomplex spatiotemporal features and sheer size of the dataset. Recent works\ntransform the original discrete time-varying volumetric data into continuous\nImplicit Neural Representations (INR) to address the issues of compression,\nrendering, and super-resolution in both spatial and temporal domains. However,\ntraining the INR takes a long time to converge, especially when handling\nlarge-scale time-varying volumetric datasets. In this work, we proposed F-Hash,\na novel feature-based multi-resolution Tesseract encoding architecture to\ngreatly enhance the convergence speed compared with existing input encoding\nmethods for modeling time-varying volumetric data. The proposed design\nincorporates multi-level collision-free hash functions that map dynamic 4D\nmulti-resolution embedding grids without bucket waste, achieving high encoding\ncapacity with compact encoding parameters. Our encoding method is agnostic to\ntime-varying feature detection methods, making it a unified encoding solution\nfor feature tracking and evolution visualization. Experiments show the F-Hash\nachieves state-of-the-art convergence speed in training various time-varying\nvolumetric datasets for diverse features. We also proposed an adaptive ray\nmarching algorithm to optimize the sample streaming for faster rendering of the\ntime-varying neural representation."}
{"id": "2507.04084", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.04084", "abs": "https://arxiv.org/abs/2507.04084", "authors": ["Xin Cao", "Haoyu Wang", "Yuzhu Mao", "Xinda Liu", "Linzhi Su", "Kang Li"], "title": "Attention-Guided Multi-Scale Local Reconstruction for Point Clouds via Masked Autoencoder Self-Supervised Learning", "comment": "22 pages", "summary": "Self-supervised learning has emerged as a prominent research direction in\npoint cloud processing. While existing models predominantly concentrate on\nreconstruction tasks at higher encoder layers, they often neglect the effective\nutilization of low-level local features, which are typically employed solely\nfor activation computations rather than directly contributing to reconstruction\ntasks. To overcome this limitation, we introduce PointAMaLR, a novel\nself-supervised learning framework that enhances feature representation and\nprocessing accuracy through attention-guided multi-scale local reconstruction.\nPointAMaLR implements hierarchical reconstruction across multiple local\nregions, with lower layers focusing on fine-scale feature restoration while\nupper layers address coarse-scale feature reconstruction, thereby enabling\ncomplex inter-patch interactions. Furthermore, to augment feature\nrepresentation capabilities, we incorporate a Local Attention (LA) module in\nthe embedding layer to enhance semantic feature understanding. Comprehensive\nexperiments on benchmark datasets ModelNet and ShapeNet demonstrate\nPointAMaLR's superior accuracy and quality in both classification and\nreconstruction tasks. Moreover, when evaluated on the real-world dataset\nScanObjectNN and the 3D large scene segmentation dataset S3DIS, our model\nachieves highly competitive performance metrics. These results not only\nvalidate PointAMaLR's effectiveness in multi-scale semantic understanding but\nalso underscore its practical applicability in real-world scenarios."}
{"id": "2507.03629", "categories": ["cs.PL", "cs.FL", "F.4.3; D.3.1; D.3.4"], "pdf": "https://arxiv.org/pdf/2507.03629", "abs": "https://arxiv.org/abs/2507.03629", "authors": ["Sérgio Queiroz de Medeiros", "Fabio Mascarenhas"], "title": "Towards Automatic Error Recovery in Parsing Expression", "comment": "arXiv admin note: substantial text overlap with arXiv:1905.02145", "summary": "Error recovery is an essential feature for a parser that should be plugged in\nIntegrated Development Environments (IDEs), which must build Abstract Syntax\nTrees (ASTs) even for syntactically invalid programs in order to offer features\nsuch as automated refactoring and code completion.\n  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes\nrecursive top-down parsers using a restricted form of backtracking. Labeled\nfailures are a conservative extension of PEGs that adds an error reporting\nmechanism for PEG parsers, and these labels can also be associated with\nrecovery expressions to also be an error recovery mechanism. These expressions\ncan use the full expressivity of PEGs to recover from syntactic errors.\n  Manually annotating a large grammar with labels and recovery expressions can\nbe difficult. In this work, we present an algorithm that automatically\nannotates a PEG with labels, and builds their corresponding recovery\nexpressions. We evaluate this algorithm by adding error recovery to the parser\nof the Titan programming language. The results shown that with a small amount\nof manual intervention our algorithm can be used to produce error recovering\nparsers for PEGs where most of the alternatives are disjoint."}
{"id": "2507.02931", "categories": ["cs.GT", "91B26"], "pdf": "https://arxiv.org/pdf/2507.02931", "abs": "https://arxiv.org/abs/2507.02931", "authors": ["Ningyuan Li", "Zhilin Zhang", "Tianyan Long", "Yuyao Liu", "Rongquan Bai", "Yurong Chen", "Xiaotie Deng", "Pengjie Wang", "Chuan Yu", "Jian Xu", "Bo Zheng"], "title": "Beyond Advertising: Mechanism Design for Platform-Wide Marketing Service \"QuanZhanTui\"", "comment": "Accepted by KDD 2025", "summary": "On e-commerce platforms, sellers typically bid for impressions from ad\ntraffic to promote their products. However, for most sellers, the majority of\ntheir sales come from organic traffic. Consequently, the relationship between\ntheir ad spending and total sales remains uncertain, resulting in operational\ninefficiency. To address this issue, e-commerce platforms have recently\nintroduced a novel platform-wide marketing service known as QuanZhanTui, which\nhas reportedly enhanced marketing efficiency for sellers and driven substantial\nrevenue growth for platforms. QuanZhanTui allows sellers to bid for impressions\nfrom the platform's entire traffic to boost their total sales without\ncompromising the platform's user experience. In this paper, we investigate the\nmechanism design problem that arises from QuanZhanTui. The problem is\nformulated as a multi-objective optimization to balance sellers' welfare and\nplatform's user experience. We first introduce the stock-constrained value\nmaximizer model, which reflects sellers' dual requirements on marketing\nefficiency and platform-wide ROI. Then, we propose the Liquid Payment Auction\n(LPA), an auction designed to optimize the balanced objectives while accounting\nfor sellers' requirements in the auto-bidding environment. It employs a simple\npayment rule based on sellers' liquid welfare, providing a clearer link between\ntheir investment and total sales. Under mild assumptions, we theoretically\nprove desirable properties of LPA, such as optimality and incentive\ncompatibility. Extensive experiments demonstrate LPA's superior performance\nover conventional auctions in QuanZhanTui."}
{"id": "2507.04147", "categories": ["cs.GR", "cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.04147", "abs": "https://arxiv.org/abs/2507.04147", "authors": ["Shuo Xin", "Haiyu Wang", "Sai Qian Zhang"], "title": "A3FR: Agile 3D Gaussian Splatting with Incremental Gaze Tracked Foveated Rendering in Virtual Reality", "comment": "ACM International Conference on Supercomputing 2025", "summary": "Virtual reality (VR) significantly transforms immersive digital interfaces,\ngreatly enhancing education, professional practices, and entertainment by\nincreasing user engagement and opening up new possibilities in various\nindustries. Among its numerous applications, image rendering is crucial.\nNevertheless, rendering methodologies like 3D Gaussian Splatting impose high\ncomputational demands, driven predominantly by user expectations for superior\nvisual quality. This results in notable processing delays for real-time image\nrendering, which greatly affects the user experience. Additionally, VR devices\nsuch as head-mounted displays (HMDs) are intricately linked to human visual\nbehavior, leveraging knowledge from perception and cognition to improve user\nexperience. These insights have spurred the development of foveated rendering,\na technique that dynamically adjusts rendering resolution based on the user's\ngaze direction. The resultant solution, known as gaze-tracked foveated\nrendering, significantly reduces the computational burden of the rendering\nprocess.\n  Although gaze-tracked foveated rendering can reduce rendering costs, the\ncomputational overhead of the gaze tracking process itself can sometimes\noutweigh the rendering savings, leading to increased processing latency. To\naddress this issue, we propose an efficient rendering framework\ncalled~\\textit{A3FR}, designed to minimize the latency of gaze-tracked foveated\nrendering via the parallelization of gaze tracking and foveated rendering\nprocesses. For the rendering algorithm, we utilize 3D Gaussian Splatting, a\nstate-of-the-art neural rendering technique. Evaluation results demonstrate\nthat A3FR can reduce end-to-end rendering latency by up to $2\\times$ while\nmaintaining visual quality."}
{"id": "2507.03867", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.03867", "abs": "https://arxiv.org/abs/2507.03867", "authors": ["Yu Xiang Zhu", "Amos Robinson", "Sophia Roshal", "Timothy Mou", "Julian Mackay", "Jonathan Aldrich", "Alex Potanin"], "title": "Semantically Separating Nominal Wyvern for Usability and Decidability", "comment": null, "summary": "The Dependent Object Types (DOT) calculus incorporates concepts from\nfunctional languages (e.g. modules) with traditional object-oriented features\n(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded\npolymorphism). However, this merger of paradigms comes at the cost of subtype\ndecidability. Recent work on bringing decidability to DOT has either sacrificed\nexpressiveness or ease of use. The unrestricted construction of recursive types\nand type bounds has made subtype decidability a much harder problem than in\ntraditional object-oriented programming.\n  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent\ntype system that takes an alternative approach: instead of having a uniform\nstructural syntax like DOT, Nominal Wyvern is designed around a \"semantic\nseparation\" between the nominal declaration of recursive types on the one hand,\nand the structural refinement of those types when they are used on the other.\nThis design naturally guides the user to avoid writing undecidably recursive\nstructural types.\n  From a technical standpoint, this separation also makes guaranteeing\ndecidability possible by allowing for an intuitive adaptation of material/shape\nseparation, a technique for achieving subtype decidability by separating types\nresponsible for subtyping constraints from types that represent concrete data.\nThe result is a type system with syntax and structure familiar to OOP users\nthat achieves decidability without compromising the expressiveness of F-bounded\npolymorphism and module systems as they are used in practice."}
{"id": "2507.03150", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.03150", "abs": "https://arxiv.org/abs/2507.03150", "authors": ["Serafina Kamp", "Reese Liebman", "Benjamin Fish"], "title": "Last-Iterate Convergence of No-Regret Learning for Equilibria in Bargaining Games", "comment": null, "summary": "Bargaining games, where agents attempt to agree on how to split utility, are\nan important class of games used to study economic behavior, which motivates a\nstudy of online learning algorithms in these games. In this work, we tackle\nwhen no-regret learning algorithms converge to Nash equilibria in bargaining\ngames. Recent results have shown that online algorithms related to Follow the\nRegularized Leader (FTRL) converge to Nash equilibria (NE) in the last iterate\nin a wide variety of games, including zero-sum games. However, bargaining games\ndo not have the properties used previously to established convergence\nguarantees, even in the simplest case of the ultimatum game, which features a\nsingle take-it-or-leave-it offer. Nonetheless, we establish that FTRL (without\nthe modifications necessary for zero-sum games) achieves last-iterate\nconvergence to an approximate NE in the ultimatum game along with a bound on\nconvergence time under mild assumptions. Further, we provide experimental\nresults to demonstrate that convergence to NE, including NE with asymmetric\npayoffs, occurs under a broad range of initial conditions, both in the\nultimatum game and in bargaining games with multiple rounds. This work\ndemonstrates how complex economic behavior (e.g. learning to use threats and\nthe existence of many possible equilibrium outcomes) can result from using a\nsimple learning algorithm, and that FTRL can converge to equilibria in a more\ndiverse set of games than previously known."}
{"id": "2507.05191", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05191", "abs": "https://arxiv.org/abs/2507.05191", "authors": ["Gene Wei-Chin Lin", "Egor Larionov", "Hsiao-yu Chen", "Doug Roble", "Tuur Stuyck"], "title": "Neuralocks: Real-Time Dynamic Neural Hair Simulation", "comment": null, "summary": "Real-time hair simulation is a vital component in creating believable virtual\navatars, as it provides a sense of immersion and authenticity. The dynamic\nbehavior of hair, such as bouncing or swaying in response to character\nmovements like jumping or walking, plays a significant role in enhancing the\noverall realism and engagement of virtual experiences. Current methods for\nsimulating hair have been constrained by two primary approaches: highly\noptimized physics-based systems and neural methods. However, state-of-the-art\nneural techniques have been limited to quasi-static solutions, failing to\ncapture the dynamic behavior of hair. This paper introduces a novel neural\nmethod that breaks through these limitations, achieving efficient and stable\ndynamic hair simulation while outperforming existing approaches. We propose a\nfully self-supervised method which can be trained without any manual\nintervention or artist generated training data allowing the method to be\nintegrated with hair reconstruction methods to enable automatic end-to-end\nmethods for avatar reconstruction. Our approach harnesses the power of compact,\nmemory-efficient neural networks to simulate hair at the strand level, allowing\nfor the simulation of diverse hairstyles without excessive computational\nresources or memory requirements. We validate the effectiveness of our method\nthrough a variety of hairstyle examples, showcasing its potential for\nreal-world applications."}
{"id": "2507.04298", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04298", "abs": "https://arxiv.org/abs/2507.04298", "authors": ["Youngju Song", "Minki Cho"], "title": "CCR 2.0: High-level Reasoning for Conditional Refinements", "comment": null, "summary": "In recent years, great progress has been made in the field of formal\nverification for low-level systems. Many of them are based on one of two\npopular approaches: refinement or separation logic. These two approaches are\nvery different in nature and offer complementary benefits in terms of\ncompositionality. Recently, to fuse these benefits in a unified mechanism, a\nnew approach called Conditional Contextual Refinement (CCR 1.0 for short) was\nproposed. In this paper, we advance the model of CCR 1.0 and provide novel and\nintuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0\n(i) comes with a better compositionality theorem, having the practical benefit\nof facilitating more proof reuse, and (ii) provides a proof technique that\nhides model-level (i.e., resources of the separation logic) details from the\nuser. Achieving this goal was challenging due to non-trivial counterexamples\nwhich necessitated us to devise novel notions. Our results are formalized in\nCoq."}
{"id": "2507.03252", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.03252", "abs": "https://arxiv.org/abs/2507.03252", "authors": ["Sébastien Lahaie", "Benjamin Lubin"], "title": "Iterative Vickrey Auctions via Linear Programming", "comment": "26 pages, 1 figure, 2 tables", "summary": "Building on the linear programming approach to competitive equilibrium\npricing, we develop a general method for constructing iterative auctions that\nachieve Vickrey-Clarke-Groves (VCG) outcomes. We show how to transform a linear\nprogram characterizing competitive equilibrium prices into one that\ncharacterizes universal competitive equilibrium (UCE) prices, which elicit\nprecisely the information needed to compute VCG payments. By applying a\nprimal-dual algorithm to these transformed programs, we derive iterative\nVickrey auctions that maintain a single price path, eliminating the overhead\nand incentive problems associated with multiple price paths used solely for\npayment calculations. We demonstrate the versatility of our method by\ndeveloping a novel iterative Vickrey auction for the multi-unit setting and an\niterative variant of the Product-Mix auction. The resulting auctions combine\nthe transparency of iterative price discovery with the efficiency and incentive\nproperties of the VCG mechanism."}
{"id": "2507.04316", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04316", "abs": "https://arxiv.org/abs/2507.04316", "authors": ["Jay Lee"], "title": "Retargeting an Abstract Interpreter for a New Language by Partial Evaluation", "comment": "Presented at the Student Research Competition (SRC) at PLDI 2025\n  (https://pldi25.sigplan.org/details/pldi-2025-src/1/)", "summary": "It is well-known that abstract interpreters can be systematically derived\nfrom their concrete counterparts using a \"recipe,\" but developing sound static\nanalyzers remains a time-consuming task. Reducing the effort required and\nmechanizing the process of developing analyzers continues to be a significant\nchallenge. Is it possible to automatically retarget an existing abstract\ninterpreter for a new language?\n  We propose a novel technique to automatically derive abstract interpreters\nfor various languages from an existing abstract interpreter. By leveraging\npartial evaluation, we specialize an abstract interpreter for a source\nlanguage. The specialization is performed using the semantics of target\nlanguages written in the source language. Our approach eliminates the need to\ndevelop analyzers for new targets from scratch. We show that our method can\neffectively retarget an abstract interpreter for one language into a correct\nanalyzer for another language."}
{"id": "2507.03359", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.03359", "abs": "https://arxiv.org/abs/2507.03359", "authors": ["Jugal Garg", "Yixin Tao", "László A. Végh"], "title": "Tight Efficiency Bounds for the Probabilistic Serial Mechanism under Cardinal Preferences", "comment": null, "summary": "The Probabilistic Serial (PS) mechanism -- also known as the simultaneous\neating algorithm -- is a canonical solution for the assignment problem under\nordinal preferences. It guarantees envy-freeness and ordinal efficiency in the\nresulting random assignment. However, under cardinal preferences, its\nefficiency may degrade significantly: it is known that PS may yield allocations\nthat are $\\Omega(\\ln{n})$-worse than Pareto optimal, but whether this bound is\ntight remained an open question.\n  Our first result resolves this question by showing that the PS mechanism\nguarantees $(\\ln(n)+2)$-approximate Pareto efficiency, even in the more general\nsubmodular setting introduced by Fujishige, Sano, and Zhan (ACM TEAC 2018).\nThis is established by showing that, although the PS mechanism may incur a loss\nof up to $O(\\sqrt{n})$ in utilitarian social welfare, it still achieves a\n$(\\ln{n}+2)$-approximation to the maximum Nash welfare. In addition, we present\na polynomial-time algorithm that computes an allocation which is envy-free and\n$e^{1/e}$-approximately Pareto-efficient, answering an open question posed by\nTr\\\"obst and Vazirani (EC 2024).\n  The PS mechanism also applies to the allocation of chores instead of goods.\nWe prove that it guarantees an $n$-approximately Pareto-efficient allocation in\nthis setting, and that this bound is asymptotically tight. This result provides\nthe first known approximation guarantee for computing a fair and efficient\nallocation in the assignment problem with chores under cardinal preferences."}
{"id": "2507.05234", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05234", "abs": "https://arxiv.org/abs/2507.05234", "authors": ["Jay Lee", "Joongwon Ahn", "Kwangkeun Yi"], "title": "React-tRace: A Semantics for Understanding React Hooks", "comment": "Conditionally accepted to OOPSLA 2025", "summary": "React has become the most widely used web front-end framework, enabling the\ncreation of user interfaces in a declarative and compositional manner. Hooks\nare a set of APIs that manage side effects in functional components in React.\nHowever, their semantics are often seen as opaque to developers, leading to UI\nbugs. In this paper, we formalize the semantics of the essence of React Hooks\nwe name React-tRace, providing a framework that clarifies their behavior. We\ndemonstrate that our model captures the behavior of React, by theoretically\nshowing that it embodies essential properties of Hooks and empirically\ncomparing our React-tRace-definitional interpreter against a test suite.\nFurthermore, we showcase a practical visualization tool based on the\nformalization to demonstrate how developers can better understand the semantics\nof Hooks."}
{"id": "2507.03502", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.03502", "abs": "https://arxiv.org/abs/2507.03502", "authors": ["Tingting Ni", "Anna Maddux", "Maryam Kamgarpour"], "title": "On characterization and existence of a constrained correlated equilibria in Markov games", "comment": null, "summary": "Markov games with coupling constraints provide a natural framework to study\nconstrained decision-making involving self-interested agents, where the\nfeasibility of an individual agent's strategy depends on the joint strategies\nof the others. Such games arise in numerous real-world applications involving\nsafety requirements and budget caps, for example, in environmental management,\nelectricity markets, and transportation systems. While correlated equilibria\nhave emerged as an important solution concept in unconstrained settings due to\ntheir computational tractability and amenability to learning, their constrained\ncounterparts remain less explored. In this paper, we study constrained\ncorrelated equilibria-feasible policies where any unilateral modifications are\neither unprofitable or infeasible. We first characterize the constrained\ncorrelated equilibrium showing that different sets of modifications result in\nan equivalent notion, a result which may enable efficient learning algorithms.\nWe then address existence conditions. In particular, we show that a strong\nSlater-type condition is necessary in games with playerwise coupling\nconstraints, but can be significantly weakened when all players share common\ncoupling constraints. Under this relaxed condition, we prove the existence of a\nconstrained correlated equilibrium."}
{"id": "2507.03946", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.03946", "abs": "https://arxiv.org/abs/2507.03946", "authors": ["Siddharth Barman", "Vishwa Prakash HV", "Aditi Sethia", "Mashbat Suzuki"], "title": "Fair and Efficient Allocation of Indivisible Mixed Manna", "comment": "31 pages", "summary": "We study fair division of indivisible mixed manna (items whose values may be\npositive, negative, or zero) among agents with additive valuations. Here, we\nestablish that fairness -- in terms of a relaxation of envy-freeness -- and\nPareto efficiency can always be achieved together. Specifically, our fairness\nguarantees are in terms of envy-freeness up to $k$ reallocations (EFR-$k$): An\nallocation $A$ of the indivisible items is said to be EFR-$k$ if there exists a\nsubset $R$ of at most $k$ items such that, for each agent $i$, we can reassign\nitems from within $R$ (in $A$) and obtain an allocation, $A^i$, which is\nenvy-free for $i$. We establish that, when allocating mixed manna among $n$\nagents with additive valuations, an EFR-$(n-1)$ and Pareto optimal (PO)\nallocation $A$ always exists. Further, the individual envy-free allocations\n$A^i$, induced by reassignments, are also PO. In addition, we prove that such\nfair and efficient allocations are efficiently computable when the number of\nagents, $n$, is fixed.\n  We also obtain positive results focusing on EFR by itself (and without the PO\ndesideratum). Specifically, we show that an EFR-$(n-1)$ allocation of mixed\nmanna can be computed in polynomial time. In addition, we prove that when all\nthe items are goods, an EFR-${\\lfloor n/2 \\rfloor}$ allocation exists and can\nbe computed efficiently. Here, the $(n-1)$ bound is tight for chores and\n$\\lfloor n/2 \\rfloor$ is tight for goods.\n  Our results advance the understanding of fair and efficient allocation of\nindivisible mixed manna and rely on a novel application of the\nKnaster-Kuratowski-Mazurkiewicz (KKM) Theorem in discrete fair division. We\nutilize weighted welfare maximization, with perturbed valuations, to achieve\nPareto efficiency, and overall, our techniques are notably different from\nexisting market-based approaches."}
{"id": "2507.04030", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.04030", "abs": "https://arxiv.org/abs/2507.04030", "authors": ["Xiaotie Deng", "Yanru Guan", "Ningyuan Li", "Zihe Wang", "Jie Zhang"], "title": "Ex-Ante Truthful Distribution-Reporting Mechanisms", "comment": "26 pages", "summary": "This paper studies mechanism design for revenue maximization in a\ndistribution-reporting setting, where the auctioneer does not know the buyers'\ntrue value distributions. Instead, each buyer reports and commits to a bid\ndistribution in the ex-ante stage, which the auctioneer uses as input to the\nmechanism. Buyers strategically decide the reported distributions to maximize\nex-ante utility, potentially deviating from their value distributions. As shown\nin previous work, classical prior-dependent mechanisms such as the Myerson\nauction fail to elicit truthful value distributions at the ex-ante stage,\ndespite satisfying Bayesian incentive compatibility at the interim stage. We\nstudy the design of ex-ante incentive compatible mechanisms, and aim to\nmaximize revenue in a prior-independent approximation framework. We introduce a\nfamily of threshold-augmented mechanisms, which ensures ex-ante incentive\ncompatibility while boosting revenue through ex-ante thresholds. Based on these\nmechanisms, we construct the Peer-Max Mechanism, which achieves an either-or\napproximation guarantee for general non-identical distributions. Specifically,\nfor any value distributions, its expected revenue either achieves a constant\nfraction of the optimal social welfare, or surpasses the second-price revenue\nby a constant fraction, where the constants depend on the number of buyers and\na tunable parameter. We also provide an upper bound on the revenue achievable\nby any ex-ante incentive compatible mechanism, matching our lower bound up to a\nconstant factor. Finally, we extend our approach to a setting where multiple\nunits of identical items are sold to buyers with multi-unit demands."}
{"id": "2507.04148", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.04148", "abs": "https://arxiv.org/abs/2507.04148", "authors": ["Saeed Alaei", "Shuchi Chawla", "Zhiyi Huang", "Ali Makhdoumi", "Azarakhsh Malekian"], "title": "Deterministic Refund Mechanisms", "comment": null, "summary": "We consider a mechanism design setting with a single item and a single buyer\nwho is uncertain about the value of the item. Both the buyer and the seller\nhave a common model for the buyer's value, but the buyer discovers her true\nvalue only upon receiving the item. Mechanisms in this setting can be\ninterpreted as randomized refund mechanisms, which allocate the item at some\nprice and then offer a (partial and/or randomized) refund to the buyer in\nexchange for the item if the buyer is unsatisfied with her purchase. Motivated\nby their practical importance, we study the design of optimal deterministic\nmechanisms in this setting. We characterize optimal mechanisms as virtual value\nmaximizers for both continuous and discrete type settings. We then use this\ncharacterization, along with bounds on the menu size complexity, to develop\nefficient algorithms for finding optimal and near-optimal deterministic\nmechanisms."}
{"id": "2507.04156", "categories": ["cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.04156", "abs": "https://arxiv.org/abs/2507.04156", "authors": ["Mohammadreza", "Ahmadnejadsaein", "Omar El Housni"], "title": "Adaptive Two-sided Assortment Optimization: Revenue Maximization", "comment": null, "summary": "We study adaptive two-sided assortment optimization for revenue maximization\nin choice-based matching platforms. The platform has two sides of agents, an\ninitiating side, and a responding side. The decision-maker sequentially selects\nagents from the initiating side, shows each an assortment of agents from the\nresponding side, and observes their choices. After processing all initiating\nagents, the responding agents are shown assortments and make their selections.\nA match occurs when two agents mutually select each other, generating\npair-dependent revenue. Choices follow Multinomial Logit (MNL) models. This\nsetting generalizes prior work focused on maximizing the number of matches\nunder submodular demand assumptions, which do not hold in our\nrevenue-maximization context. Our main contribution is the design of\npolynomial-time approximation algorithms with constant-factor guarantees. In\nparticular, for general pairwise revenues, we develop a randomized algorithm\nthat achieves a $(\\frac{1}{2} - \\epsilon)$-approximation in expectation for any\n$\\epsilon > 0$. The algorithm is static and provides guarantees under various\nagent arrival settings, including fixed order, simultaneous processing, and\nadaptive selection. When revenues are uniform across all pairs involving any\ngiven responding-side agent, the guarantee improves to $(1 - \\frac{1}{e} -\n\\epsilon)$. In structural settings where responding-side agents share a common\nrevenue-based ranking, we design a simpler adaptive deterministic algorithm\nachieving a $\\frac{1}{2}$-approximation. Our approach leverages novel linear\nprogramming relaxations, correlation gap arguments, and structural properties\nof the revenue functions."}
{"id": "2507.04485", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.04485", "abs": "https://arxiv.org/abs/2507.04485", "authors": ["Elijah Journey Fullerton", "Zeyuan Hu", "C. Gregory Plaxton"], "title": "Constant-Approximate and Constant-Strategyproof Two-Facility Location", "comment": null, "summary": "We study deterministic mechanisms for the two-facility location problem.\nGiven the reported locations of n agents on the real line, such a mechanism\nspecifies where to build the two facilities. The single-facility variant of\nthis problem admits a simple strategyproof mechanism that minimizes social\ncost. For two facilities, however, it is known that any strategyproof mechanism\nis $\\Omega(n)$-approximate. We seek to circumvent this strong lower bound by\nrelaxing the problem requirements. Following other work in the facility\nlocation literature, we consider a relaxed form of strategyproofness in which\nno agent can lie and improve their outcome by more than a constant factor.\nBecause the aforementioned $\\Omega(n)$ lower bound generalizes easily to\nconstant-strategyproof mechanisms, we introduce a second relaxation: Allowing\nthe facilities (but not the agents) to be located in the plane. Our first main\nresult is a natural mechanism for this relaxation that is constant-approximate\nand constant-strategyproof. A characteristic of this mechanism is that a small\nchange in the input profile can produce a large change in the solution.\nMotivated by this observation, and also by results in the facility reallocation\nliterature, our second main result is a constant-approximate,\nconstant-strategyproof, and Lipschitz continuous mechanism."}
{"id": "2507.04592", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.04592", "abs": "https://arxiv.org/abs/2507.04592", "authors": ["Aadityan Ganesh", "Qianfan Zhang"], "title": "Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments", "comment": null, "summary": "We consider a revenue-optimizing auctioneer in single-dimensional\nenvironments with matroid feasibility constraints. Akbarpour and Li (2020)\nargue that any revenue-optimal, truthful, and credible mechanism requires\nunbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et\nal., 2022; Chitra et al., 2024) circumvent their impossibility for the\nsingle-item setting through the use of cryptographic commitments and\nblockchains. We extend their results to matroid feasibility constraints.\n  At a high level, the two-round Deferred-Revelation Auction (DRA) discussed by\nFerreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to\nsubmit a deposit, which is slashed upon presenting verifiable evidence\nindicating a deviation from the behaviour prescribed by the mechanism. We prove\nthat the DRA satisfies truthfulness, credibility and revenue-optimality for all\nmatroid environments when bidders' values are drawn from $\\alpha$-strongly\nregular distributions for $\\alpha > 0$. Further, we argue that the DRA is not\ncredible for any feasibility constraint beyond matroids and for any smaller\ndeposits than suggested by previous literature even in single-item\nenvironments.\n  Finally, we modify the Ascending Deferred-Revelation Auction (ADRA) for\nsingle-item settings proposed by Essaidi et al., (2022) for arbitrary bidder\nvalue distributions. We implement a deferred-revelation variant of the\ndeferred-acceptance auction for matroids due to Bikhchandani et al., (2011),\nwhich requires the same bounded communication as the ADRA."}
{"id": "2507.04717", "categories": ["cs.GT", "91A46, 91A05"], "pdf": "https://arxiv.org/pdf/2507.04717", "abs": "https://arxiv.org/abs/2507.04717", "authors": ["Prem Kant", "Urban Larsson"], "title": "A number game reconciliation", "comment": null, "summary": "Number games play a central role in alternating normal play combinatorial\ngame theory due to their real-number-like properties (Conway 1976). Here we\nundertake a critical re-examination: we begin with integer and dyadic games and\nidentify subtle inconsistencies and oversights in the established literature\n(e.g. Siegel 2013), most notably, the lack of distinction between a game being\na number and a game being equal to a number. After addressing this, we move to\nthe general theory of number games. We analyze Conway's original definition and\na later refinement by Siegel, and highlight conceptual gaps that have largely\ngone unnoticed. Through a careful dissection of these issues, we propose a more\ncoherent and robust formulation. Specifically, we develop a refined\ncharacterization of numbers, via several subclasses, dyadics, canonical forms,\ntheir group theoretic closure and zugzwangs, that altogether better capture the\nessence of number games. This reconciliation not only clarifies existing\nambiguities but also uncovers several open problems."}
{"id": "2507.05171", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.05171", "abs": "https://arxiv.org/abs/2507.05171", "authors": ["Benjamin R. Toaz", "Shaunak D. Bopardikar"], "title": "Vector Cost Bimatrix Games with Applications to Autonomous Racing", "comment": "7 pages. Technical report associated with conference contributed\n  paper for MECC 2025", "summary": "We formulate a vector cost alternative to the scalarization method for\nweighting and combining multi-objective costs. The algorithm produces solutions\nto bimatrix games that are simultaneously pure, unique Nash equilibria and\nPareto optimal with guarantees for avoiding worst case outcomes. We achieve\nthis by enforcing exact potential game constraints to guide cost adjustments\ntowards equilibrium, while minimizing the deviation from the original cost\nstructure. The magnitude of this adjustment serves as a metric for\ndifferentiating between Pareto optimal solutions. We implement this approach in\na racing competition between agents with heterogeneous cost structures,\nresulting in fewer collision incidents with a minimal decrease in performance.\nCode is available at https://github.com/toazbenj/race_simulation."}
