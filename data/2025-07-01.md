<div id=toc></div>

# Table of Contents

- [cs.DM](#cs.DM) [Total: 3]
- [cs.DS](#cs.DS) [Total: 16]
- [cs.FL](#cs.FL) [Total: 2]
- [cs.GR](#cs.GR) [Total: 11]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.LO](#cs.LO) [Total: 8]
- [cs.MS](#cs.MS) [Total: 1]
- [cs.PL](#cs.PL) [Total: 3]
- [math.CT](#math.CT) [Total: 7]
- [math.GM](#math.GM) [Total: 1]
- [math.HO](#math.HO) [Total: 1]
- [math.LO](#math.LO) [Total: 3]
- [math.RT](#math.RT) [Total: 10]


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [1] [A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs](https://arxiv.org/abs/2506.23790)
*Jesse Beisegel,Katharina Klost,Kristin Knorr,Fabienne Ratajczak,Robert Scheffler*

Main category: cs.DM

TL;DR: 研究在有顶点偏序约束的图中寻找哈密顿路径或哈密顿圈的问题，结果显示路径问题在路径宽度为4的图中为$ackslashackslashmathsf{NP}$-complete，圈问题在路径宽度为5的图中为$ackslashackslashmathsf{NP}$-complete。同时，提供了路径宽度3/树宽2下的哈密顿路径和路径宽度4/树宽3下的哈密顿圈的多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 解决在有偏序约束的图中寻找哈密顿路径或哈密顿圈的问题，并探究其复杂性和可行算法。

Method: 通过理论分析，证明哈密顿路径和圈问题在不同路径宽度和树宽条件下的复杂性，并研究矩形网格图中的问题复杂度。

Result: 路径问题在路径宽度4时$ackslashackslashmathsf{NP}$-complete，圈问题在路径宽度5时$ackslashackslashmathsf{NP}$-complete；在多边形时间内可解决路径宽度3/树宽2的路径问题和路径宽度4/树宽3的圈问题。

Conclusion: 证明了特定图结构下的复杂性，并提供了多项式时间的解决方案，为受限条件下的问题提供了理论支持。

Abstract: We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle
with precedence constraints in the form of a partial order on the vertex set.
We show that the path problem is $\mathsf{NP}$-complete for graphs of pathwidth
4 while the cycle problem is $\mathsf{NP}$-complete on graphs of pathwidth 5.
We complement these results by giving polynomial-time algorithms for graphs of
pathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and
treewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the
path and cycle problems on rectangular grid graphs of bounded height. For
these, we show that the path and cycle problems are $\mathsf{NP}$-complete when
the height of the grid is greater or equal to 7 and 9, respectively. In the
variant where we look for minimum edge-weighted Hamiltonian paths and cycles,
the problems are $\mathsf{NP}$-hard for heights 5 and 6, respectively.

</details>


### [2] [Linear Layouts of Graphs with Priority Queues](https://arxiv.org/abs/2506.23943)
*Emilio Di Giacomo,Walter Didimo,Henry Förster,Torsten Ueckerdt,Johannes Zink*

Main category: cs.DM

TL;DR: 该论文研究了边加权图的优先级队列布局，展示了某些图需要线性数量的优先级队列，并提供了单队列布局的识别算法和路径宽度与树宽度的关系。同时，证明了在固定顶点线性排序下，确定最小优先级队列数是NP完全的。


<details>
  <summary>Details</summary>
Motivation: 研究动机是扩展堆栈和队列布局的概念到边加权图，通过引入优先级队列布局，探索其在存储边权重时的特性与应用。

Method: 论文引入了优先级队列布局的概念，并通过对边加权图的分析，展示了需要线性数量优先级队列的图实例，提供了单队列布局的识别算法，并研究了路径宽度和树宽度对所需优先级队列数的影响。

Result: 结果表明，某些边加权图需要线性数量的优先级队列；单队列布局的图可以被高效识别；优先级队列数与图的路径宽度相关，但在树宽度为二的图中可能无限大；固定顶点排序时，最小优先级队列数的确定是NP完全的。

Conclusion: 论文的结论是优先级队列布局为边加权图提供了新的工具，并且其在理论上的复杂度与图的拓扑结构密切相关，尤其是在固定排序下的计算复杂度问题。

Abstract: A linear layout of a graph consists of a linear ordering of its vertices and
a partition of its edges into pages such that the edges assigned to the same
page obey some constraint. The two most prominent and widely studied types of
linear layouts are stack and queue layouts, in which any two edges assigned to
the same page are forbidden to cross and nest, respectively. The names of these
two layouts derive from the fact that, when parsing the graph according to the
linear vertex ordering, the edges in a single page can be stored using a single
stack or queue, respectively. Recently, the concepts of stack and queue layouts
have been extended by using a double-ended queue or a restricted-input queue
for storing the edges of a page. We extend this line of study to edge-weighted
graphs by introducing priority queue layouts, that is, the edges on each page
are stored in a priority queue whose keys are the edge weights. First, we show
that there are edge-weighted graphs that require a linear number of priority
queues. Second, we characterize the graphs that admit a priority queue layout
with a single queue, regardless of the edge-weight function, and we provide an
efficient recognition algorithm. Third, we show that the number of priority
queues required independently of the edge-weight function is bounded by the
pathwidth of the graph, but can be arbitrarily large already for graphs of
treewidth two. Finally, we prove that determining the minimum number of
priority queues is NP-complete if the linear ordering of the vertices is fixed.

</details>


### [3] [Static Nuel Games with Terminal Payoff](https://arxiv.org/abs/2409.01681)
*S. Mastrakoulis,Ath. Kehagias*

Main category: cs.DM

TL;DR: 研究了一种Nuel游戏的变体，证明了对于任意N≥2，存在一个稳定的纳什均衡，并提供了计算该均衡的算法。


<details>
  <summary>Details</summary>
Motivation: 研究Nuel游戏（一种对决的推广形式）的变体，探索在多玩家回合制游戏中纳什均衡的存在性和计算方法。

Method: 通过数学证明和算法设计，分析了N玩家回合制游戏的均衡策略，并在固定射击顺序下研究了玩家行为。

Result: 证明了对于任意N≥2，Nuel游戏存在一个稳定的纳什均衡，并提出了计算该均衡的具体算法。

Conclusion: 研究表明，Nuel游戏的变体在多玩家场景下具有稳定的纳什均衡，为相关博弈论研究提供了理论支持。

Abstract: In this paper we study a variant of the Nuel game (a generalization of the
duel) which is played in turns by $N$ players. In each turn a single player
must fire at one of the other players and has a certain probability of hitting
and killing his target. The players shoot in a fixed sequence and when a player
is eliminated, the ``move'' passes to the next surviving player. The winner is
the last surviving player. We prove that, for every $N\geq2$, the Nuel has a
stationary Nash equilibrium and provide algorithms for its computation.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [4] [On Fine-Grained Distinct Element Estimation](https://arxiv.org/abs/2506.22608)
*Ilias Diakonikolas,Daniel M. Kane,Jasper C. H. Lee,Thanasis Pittas,David P. Woodruff,Samson Zhou*

Main category: cs.DS

TL;DR: 本文研究了分布式去重元素估计问题，提出了一种基于碰撞数量C的新参数化方法，并设计了一种更高效的通信协议，突破了之前的理论下限。


<details>
  <summary>Details</summary>
Motivation: 传统的分布式去重元素估计方法依赖于一些在现实中可能不成立的假设，导致通信代价较高。本文旨在通过新参数化方法改进这一问题。

Method: 引入碰撞数量C作为参数，设计了一种通信代价仅为O(αlog n + √β/ε² log n)的协议，并在不同假设下优化算法。

Result: 实验结果表明，新算法在C较小时显著优于传统方法，并且在各种情况下均匹配理论下限，证明了C作为复杂度衡量标准的紧致性。

Conclusion: 本文揭示了统计问题在实际中可以高效解决的原因，为分布式去重元素估计提供了新的理论和技术支持。

Abstract: We study the problem of distributed distinct element estimation, where
$\alpha$ servers each receive a subset of a universe $[n]$ and aim to compute a
$(1+\varepsilon)$-approximation to the number of distinct elements using
minimal communication. While prior work establishes a worst-case bound of
$\Theta\left(\alpha\log n+\frac{\alpha}{\varepsilon^2}\right)$ bits, these
results rely on assumptions that may not hold in practice. We introduce a new
parameterization based on the number $C = \frac{\beta}{\varepsilon^2}$ of
pairwise collisions, i.e., instances where the same element appears on multiple
servers, and design a protocol that uses only $\mathcal{O}\left(\alpha\log
n+\frac{\sqrt{\beta}}{\varepsilon^2} \log n\right)$ bits, breaking previous
lower bounds when $C$ is small. We further improve our algorithm under
assumptions on the number of distinct elements or collisions and provide
matching lower bounds in all regimes, establishing $C$ as a tight complexity
measure for the problem. Finally, we consider streaming algorithms for distinct
element estimation parameterized by the number of items with frequency larger
than $1$. Overall, our results offer insight into why statistical problems with
known hardness results can be efficiently solved in practice.

</details>


### [5] [On Finding $\ell$-th Smallest Perfect Matchings](https://arxiv.org/abs/2506.22619)
*Nicolas El Maalouly,Sebastian Haslebacher,Adrian Taubner,Lasse Wulf*

Main category: cs.DS

TL;DR: 本文研究了精确权重完美匹配问题（EWPM）及其变体，提出了一个简单确定性算法，并扩展了与EWPM等价的问题列表。


<details>
  <summary>Details</summary>
Motivation: 研究EWPM问题的动机在于其在单编码权重情况下的随机多项式时间解法已知40年，但至今未能确定性解决，因此本文尝试填补这一空白。

Method: 提出了一个时间复杂度为$n^{O(\ell)}$的确定性算法，其中$\ell$为完美匹配可能的不同权值数量，并研究了EWPM与其他问题的等价性。

Result: 证明了EWPM与保守权函数下的精确循环和问题（ECS）等价，同时研究了特殊情况BCPM与最短奇数循环问题（SOC）的等价性。

Conclusion: 本文通过提出确定性算法和扩展等价问题列表，对EWPM问题及其变体进行了深入探讨，为进一步研究提供了基础。

Abstract: Given an undirected weighted graph $G$ and an integer $k$, Exact-Weight
Perfect Matching (EWPM) is the problem of finding a perfect matching of weight
exactly $k$ in $G$. In this paper, we study EWPM and its variants. The EWPM
problem is famous, since in the case of unary encoded weights, Mulmuley,
Vazirani, and Vazirani showed almost 40 years ago that the problem can be
solved in randomized polynomial time. However, up to this date no
derandomization is known.
  Our first result is a simple deterministic algorithm for EWPM that runs in
time $n^{O(\ell)}$, where $\ell$ is the number of distinct weights that perfect
matchings in $G$ can take. In fact, we show how to find an $\ell$-th smallest
perfect matching in any weighted graph (even if the weights are encoded in
binary, in which case EWPM in general is known to be NP-complete) in time
$n^{O(\ell)}$ for any integer $\ell$. Similar next-to-optimal variants have
also been studied recently for the shortest path problem.
  For our second result, we extend the list of problems that are known to be
equivalent to EWPM. We show that EWPM is equivalent under a weight-preserving
reduction to the Exact Cycle Sum problem (ECS) in undirected graphs with a
conservative (i.e. no negative cycles) weight function. To the best of our
knowledge, we are the first to study this problem. As a consequence, the latter
problem is contained in RP if the weights are encoded in unary. Finally, we
identify a special case of EWPM, called BCPM, which was recently studied by El
Maalouly, Steiner and Wulf. We show that BCPM is equivalent under a
weight-preserving transformation to another problem recently studied by
Schlotter and Seb\H{o} as well as Geelen and Kapadia: the Shortest Odd Cycle
problem (SOC) in undirected graphs with conservative weights.

</details>


### [6] [Simple Approximations for General Spanner Problems](https://arxiv.org/abs/2506.23638)
*Fritz Bökler,Markus Chimani,Henning Jasper*

Main category: cs.DS

TL;DR: 论文提出了两种简单的近似算法（Adapted Greedy和Randomized Rounding）来解决一般形式的spanner问题，分别实现了m和O(n log n)的近似比，并保持了Greedy算法的规模和权重优势。


<details>
  <summary>Details</summary>
Motivation: 现有的spanner问题近似算法在一般形式下复杂且不实用，缺乏非平凡的近似算法。本文旨在提供简单且实用的解决方案。

Method: 提出了Adapted Greedy算法，实现了m的近似比；另外提出Randomized Rounding算法，通过图变换和LP舍入方案实现了O(n log n)的近似比。

Result: Adapted Greedy算法首次实现了非平凡的m近似比，Randomized Rounding算法在整数长度和多距离需求下匹配了现有最复杂算法的近似比例。

Conclusion: 论文通过两种简单算法解决了spanner问题的一般形式，为理论和实践提供了新的工具，尤其在权重和长度独立的情况下具有突破性意义。

Abstract: Consider a graph with n nodes and m edges, independent edge weights and
lengths, and arbitrary distance demands for node pairs. The spanner problem
asks for a minimum-weight subgraph that satisfies these demands via
sufficiently short paths w.r.t. the edge lengths. For multiplicative
alpha-spanners (where demands equal alpha times the original distances) and
assuming that each edge's weight equals its length, the simple Greedy heuristic
by Alth\"ofer et al. (1993) is known to yield strong solutions, both in theory
and practice. To obtain guarantees in more general settings, recent
approximations typically abandon this simplicity and practicality. Still, so
far, there is no known non-trivial approximation algorithm for the spanner
problem in its most general form. We provide two surprisingly simple
approximations algorithms. In general, our Adapted Greedy achieves the first
unconditional approximation ratio of m, which is non-trivial due to the
independence of weights and lengths. Crucially, it maintains all size and
weight guarantees Greedy is known for, i.e., in the aforementioned
multiplicative alpha-spanner scenario and even for additive +beta-spanners.
Further, it generalizes some of these size guarantees to derive new weight
guarantees. Our second approach, Randomized Rounding, establishes a graph
transformation that allows a simple rounding scheme over a standard
multicommodity flow LP. It yields an O(n log n)-approximation, assuming integer
lengths and polynomially bounded distance demands. The only other known
approximation guarantee in this general setting requires several complex
subalgorithms and analyses, yet we match it up to a factor of O(n^{1/5-eps})
using standard tools. Further, on bounded-degree graphs, we yield the first
O(log n) approximation ratio for constant-bounded distance demands (beyond
multiplicative 2-spanners in unit-length graphs).

</details>


### [7] [Counting distinct (non-)crossing substrings](https://arxiv.org/abs/2506.22728)
*Haruki Umezaki,Hiroki Shibata,Dominik Köppl,Yuto Nakashima,Shunsuke Inenaga,Hideo Bannai*

Main category: cs.DS

TL;DR: 本文提出了新的算法，用于计算字符串中所有位置的$ackslashackslashmathcal{C}(w,k)$和$ackslashackslashmathcal{N}(w,k)$，时间复杂$O(n)$，适用于一般有序字母表和线性可排序字母表。


<details>
  <summary>Details</summary>
Motivation: 解决现有算法在处理字符串中所有位置时的效率问题，现有方法需要$O(n^2)$时间，而新算法将其优化至$O(n)$时间。

Method: 提出了针对一般有序字母表计算$ackslashackslashmathcal{C}(w,k)$和在线性可排序字母表下计算$ackslashackslashmathcal{N}(w,k)$的新算法，总时间复杂度为$O(n)$。

Result: 新算法显著提高了计算效率，将时间复杂度从$O(n^2)$降至$O(n)$。

Conclusion: 本文提出的算法在计算字符串中所有位置的$ackslashackslashmathcal{C}(w,k)$和$ackslashackslashmathcal{N}(w,k)$时更高效，适用于更广泛的字母表类型。

Abstract: Let $w$ be a string of length $n$. The problem of counting factors crossing a
position - Problem 64 from the textbook ``125 Problems in Text Algorithms''
[Crochemore, Leqroc, and Rytter, 2021], asks to count the number
$\mathcal{C}(w,k)$ (resp. $\mathcal{N}(w,k)$) of distinct substrings in $w$
that have occurrences containing (resp. not containing) a position $k$ in $w$.
The solutions provided in their textbook compute $\mathcal{C}(w,k)$ and
$\mathcal{N}(w,k)$ in $O(n)$ time for a single position $k$ in $w$, and thus a
direct application would require $O(n^2)$ time for all positions $k = 1,
\ldots, n$ in $w$. Their solution is designed for constant-size alphabets. In
this paper, we present new algorithms which compute $\mathcal{C}(w,k)$ in
$O(n)$ total time for general ordered alphabets, and $\mathcal{N}(w,k)$ in
$O(n)$ total time for linearly sortable alphabets, for all positions $k = 1,
\ldots, n$ in $w$.

</details>


### [8] [Translating between the representations of an acyclic convex geometry of bounded degree](https://arxiv.org/abs/2506.24052)
*Oscar Defrain,Arthur Ohana,Simon Vilmin*

Main category: cs.DS

TL;DR: 本文研究了在给定蕴涵基的闭包系统中枚举不可约闭集的问题，特别是在无环凸几何的背景下，通过定义度数参数（即元素在蕴涵基中出现的最大次数），证明了该问题在度数有界时是可解的，并提出了基于算法枚举技术的高效算法。


<details>
  <summary>Details</summary>
Motivation: 研究不可约闭集的枚举问题在Horn逻辑和特征模型中的应用背景下的复杂性，尤其是在无环闭包系统中，该问题是广为人知的双重超图问题的推广，其复杂性状态尚未确定。

Method: 利用无环凸几何的结构性质，结合算法枚举技术（如解图遍历、饱和技术和顺序方法），设计了针对度数有界情况的高效算法。

Result: 证明了在度数有界时，不可约闭集的枚举问题可以在增量多项式时间内解决，而蕴涵基的构造可以在多项式时间内完成。同时指出标准的手电筒搜索框架无法将运行时间改进为多项式延迟。

Conclusion: 本文通过限定度数参数，实现了无环闭包系统中不可约闭集的高效枚举和蕴涵基构造，为相关领域提供了实用的算法工具和理论支持。

Abstract: We consider the problem of enumerating the irreducible closed sets of a
closure system given by an implicational base. In the context of Horn logic,
these correspond to Horn expressions and characteristic models, respectively.
To date, the complexity status of this problem is widely open, and it is
further known to generalize the notorious hypergraph dualization problem, even
in the context of acyclic convex geometries, i.e., closure systems admitting an
acyclic implicational base. This paper studies this later class with a focus on
the degree, which corresponds to the maximal number of implications in which an
element occurs. We show that the problem is tractable for bounded values of
this parameter, even when relaxed to the notions of premise- and
conclusion-degree. Our algorithms rely on structural properties of acyclic
convex geometries and involve various techniques from algorithmic enumeration
such as solution graph traversal, saturation techniques, and a sequential
approach leveraging from acyclicity. They are shown to perform in
incremental-polynomial time for the computation of irreducible closed sets, and
in polynomial time for the construction of an implicational base. Finally, we
argue that our running times cannot be improved to polynomial delay using the
standard framework of flashlight search.

</details>


### [9] [Tight Additive Sensitivity on LZ-style Compressors and String Attractors](https://arxiv.org/abs/2506.22778)
*Yuto Fujie,Hiroki Shibata,Yuto Nakashima,Shunsuke Inenaga*

Main category: cs.DS

TL;DR: 本文研究了字符串重复性度量的最坏情况加性敏感度，并针对最小字符串吸引子大小γ和最小双向方案大小b提出了O(√n)的上界。此外，还对Lempel-Ziv家族的最坏情况加性敏感度提出了匹配的上界与下界。


<details>
  <summary>Details</summary>
Motivation: 研究字符串重复性度量的最坏情况加性敏感度，是为了理解在单字符编辑操作下这些度量的变化范围，从而为字符串压缩和模式匹配等领域提供理论基础。

Method: 通过分析字符串的单字符编辑操作对重复性度量的影响，推导出最坏情况下的加性敏感度上界，并与已知的下界进行比较。

Result: 对于最小字符串吸引子大小γ和最小双向方案大小b，给出了O(√n)的上界，与已知的Ω(√n)下界匹配。对于Lempel-Ziv家族的度量，得到了LZSS和LZ-End的Θ(n^(2/3))上下界，以及LZ78的Θ(n)上下界。

Conclusion: 本文的结果为字符串重复性度量的加性敏感度提供了严格的理论界限，填补了现有研究的空白，并为相关应用提供了理论支持。

Abstract: The worst-case additive sensitivity of a string repetitiveness measure $c$ is
defined to be the largest difference between $c(w)$ and $c(w')$, where $w$ is a
string of length $n$ and $w'$ is a string that can be obtained by performing a
single-character edit operation on $w$. We present $O(\sqrt{n})$ upper bounds
for the worst-case additive sensitivity of the smallest string attractor size
$\gamma$ and the smallest bidirectional scheme size $b$, which match the known
lower bounds $\Omega(\sqrt{n})$ for $\gamma$ and $b$ [Akagi et al. 2023].
Further, we present matching upper and lower bounds for the worst-case additive
sensitivity of the Lempel-Ziv family - $\Theta(n^{\frac{2}{3}})$ for LZSS and
LZ-End, and $\Theta(n)$ for LZ78.

</details>


### [10] [Global Predecessor Indexing: Avoiding Binary Search in Weighted Job Scheduling](https://arxiv.org/abs/2506.22922)
*Amit Joshi*

Main category: cs.DS

TL;DR: 论文提出了一种改进的加权作业调度（WJS）问题解决方案，通过引入全局前驱索引（GPI）技术，消除了二分搜索瓶颈，最终实现了一个完整的线性时间解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的动态规划（DP）解决方案在加权作业调度问题中存在二分搜索瓶颈，导致时间复杂度为$O(n \log(n))$。为了提高效率并避免重复的二分搜索，需要一种新的预处理技术。

Method: 论文提出了一种名为全局前驱索引（GPI）的多阶段预处理技术。通过两指针线性时间扫描，GPI为所有作业计算其最近的非重叠作业（即前驱），从而可以在经典DP递推中直接使用。结合线性时间排序，该方法实现了$O(n)$的解决方案。

Result: 实验结果表明，即使在基于比较的排序下，GPI技术能够显著优于传统解决方案，避免重复的二分搜索。

Conclusion: 全局前驱索引（GPI）技术成功地解决了加权作业调度问题中的二分搜索瓶颈，提供了一个高效的线性时间解决方案。

Abstract: We present an improved solution to the Weighted Job Scheduling (WJS) problem.
While the classical dynamic programming (DP) solution runs in $O(n \log(n))$
time due to comparison-based sorting and per-job binary search, we eliminate
the binary search bottleneck. In its place, we introduce a novel multi-phase
preprocessing technique called Global Predecessor Indexing (GPI), which
computes the latest non-overlapping job (i.e., the predecessor) for all jobs
via a two-pointer linear-time pass. GPI enables direct use in the classical DP
recurrence. When combined with linear-time sorting, GPI yields a complete
$O(n)$ solution. Even with comparison-based sorting, GPI significantly
outperforms the classical solution in practice by avoiding repeated binary
searches. Keywords: Weighted Job Scheduling, Interval Scheduling, Dynamic
Programming, Linear Sorting, Two Pointers, Preprocessing

</details>


### [11] [Near-Optimal Vertex Fault-Tolerant Labels for Steiner Connectivity](https://arxiv.org/abs/2506.23215)
*Koustav Bhanja,Asaf Petruschka*

Main category: cs.DS

TL;DR: 该论文提出了一种针对图中终端集连通性的紧凑标签方案，能够在顶点故障发生后快速判断终端集是否保持连通。


<details>
  <summary>Details</summary>
Motivation: 现有的全局连通性标签方案虽然有效，但对于终端集的连通性问题尚未有最优解。本文旨在填补这一空白，提供一种适用于终端集的紧凑标签方案。

Method: 采用Duan和Pettie提出的分解定理生成结构化的Steiner树，并避免了Nagamochi-Ibaraki稀疏化的需要。

Result: 方案实现了标签长度为|U|^{1-1/f} \cdot \mathrm{poly}(f, \log n)，对于终端集的大小|U|来说是接近最优的。

Conclusion: 该标签方案为终端集的连通性问题提供了高效且紧凑的解决方案，显著提升了处理特定子集连通性问题的能力。

Abstract: We present a compact labeling scheme for determining whether a designated set
of terminals in a graph remains connected after any $f$ (or less) vertex
failures occur. An $f$-FT Steiner connectivity labeling scheme for an
$n$-vertex graph $G=(V,E)$ with terminal set $U \subseteq V$ provides labels to
the vertices of $G$, such that given only the labels of any subset $F \subseteq
V$ with $|F| \leq f$, one can determine if $U$ remains connected in $G-F$. The
main complexity measure is the maximum label length.
  The special case $U=V$ of global connectivity has been recently studied by
Jiang, Parter, and Petruschka, who provided labels of $n^{1-1/f} \cdot
\mathrm{poly}(f,\log n)$ bits. This is near-optimal (up to
$\mathrm{poly}(f,\log n)$ factors) by a lower bound of Long, Pettie and
Saranurak. Our scheme achieves labels of $|U|^{1-1/f} \cdot \mathrm{poly}(f,
\log n)$ for general $U \subseteq V$, which is near-optimal for any given size
$|U|$ of the terminal set. To handle terminal sets, our approach differs from
Jiang et al. We use a well-structured Steiner tree for $U$ produced by a
decomposition theorem of Duan and Pettie, and bypass the need for
Nagamochi-Ibaraki sparsification.

</details>


### [12] [Parameterized Critical Node Cut Revisited](https://arxiv.org/abs/2506.23363)
*Dušan Knop,Nikolaos Melissinos,Manolis Vasilakis*

Main category: cs.DS

TL;DR: 论文研究了Critical Node Cut问题的参数化复杂性，证明了其在多种结构参数下的W[1]-难解性，并提出了几种使其固定参数可解的结构参数，同时还开发了一种FPT近似方案。


<details>
  <summary>Details</summary>
Motivation: Critical Node Cut问题在网络安全、流行病学和社会网络分析中有广泛应用，其作为Vertex Cover问题的推广，研究其在参数化复杂度下的表现具有重要意义。

Method: 论文通过证明W[1]-难解性，并利用结构参数（如max-leaf number、vertex integrity和modular-width）来研究问题的固定参数可解性，同时开发了一种基于Lampis技术的FPT近似方案。

Result: 结果表明，Critical Node Cut在多种结构参数下是W[1]-难解的，但在max-leaf number、vertex integrity和modular-width等参数下是固定参数可解的。此外，FPT近似方案能够在特定时间内提供近似解。

Conclusion: 论文全面分析了Critical Node Cut问题的复杂性，拓展了其参数化复杂度的研究范围，为实际应用提供了理论支持。

Abstract: Given a graph $G$ and integers $k, x \geq 0$, the Critical Node Cut problem
asks whether it is possible to delete at most $k$ vertices from $G$ such that
the number of remaining pairs of connected vertices is at most $x$. This
problem generalizes Vertex Cover (when $x = 0$), and has applications in
network design, epidemiology, and social network analysis. We investigate the
parameterized complexity of Critical Node Cut under various structural
parameters. We first significantly strengthen existing hardness results by
proving W[1]-hardness even when parameterized by the combined parameter $k +
\mathrm{fes} + \Delta + \mathrm{pw}$, where $\mathrm{fes}$ is the feedback edge
set number, $\Delta$ the maximum degree, and $\mathrm{pw}$ the pathwidth of the
input graph. We then identify three structural parameters--max-leaf number,
vertex integrity, and modular-width--that render the problem fixed-parameter
tractable. Furthermore, leveraging a technique introduced by Lampis [ICALP
'14], we develop an FPT approximation scheme that, for any $\varepsilon > 0$,
computes a $(1+\varepsilon)$-approximate solution in time $(\mathrm{tw} /
\varepsilon)^{\mathcal{O}(\mathrm{tw})} n^{\mathcal{O}(1)}$, where
$\mathrm{tw}$ denotes the treewidth of the input graph. Finally, we show that
Critical Node Cut does not admit a polynomial kernel when parameterized by
vertex cover number, unless standard complexity assumptions fail. Overall, our
results significantly sharpen the known complexity landscape of Critical Node
Cut.

</details>


### [13] [Planar Multiway Cut with Terminals on Few Faces](https://arxiv.org/abs/2506.23399)
*Sukanya Pandey,Erik Jan van Leeuwen*

Main category: cs.DS

TL;DR: 本文提出了一种新方法，解决了平面图上的边多路割问题，证明了可以在n^O(√k)时间内解决，其中k是覆盖所有终端的面数。


<details>
  <summary>Details</summary>
Motivation: 平面图上的边多路割问题在已知的时间复杂度极限下（n^O(√t)和n^o(√t)），研究者希望找到一个更强的参数k（覆盖所有终端的面数），以提升算法的效率。

Method: 通过使用平面图的同伦和球面切割分解等概念，结合全局树宽动态规划和Dreyfus-Wagner风格的局部动态规划，来处理大量终端的情况。

Result: 证明了边多路割问题可以在n^O(√k)时间内解决，与之前Steiner树问题的结果一致。

Conclusion: 本文通过完全不同的方法，成功将边多路割问题的时间复杂度优化到n^O(√k)，拓展了相关研究的应用范围。

Abstract: We consider the \textsc{Edge Multiway Cut} problem on planar graphs. It is
known that this can be solved in $n^{O(\sqrt{t})}$ time [Klein, Marx, ICALP
2012] and not in $n^{o(\sqrt{t})}$ time under the Exponential Time Hypothesis
[Marx, ICALP 2012], where $t$ is the number of terminals. A stronger parameter
is the number $k$ of faces of the planar graph that jointly cover all
terminals. For the related {\sc Steiner Tree} problem, an $n^{O(\sqrt{k})}$
time algorithm was recently shown [Kisfaludi-Bak et al., SODA 2019]. By a
completely different approach, we prove in this paper that \textsc{Edge
Multiway Cut} can be solved in $n^{O(\sqrt{k})}$ time as well.
  Our approach employs several major concepts on planar graphs, including
homotopy and sphere-cut decomposition. We also mix a global treewidth dynamic
program with a Dreyfus-Wagner style dynamic program to locally deal with large
numbers of terminals.

</details>


### [14] [Efficient Resource Allocation under Adversary Attacks: A Decomposition-Based Approach](https://arxiv.org/abs/2506.23442)
*Mansoor Davoodi,Setareh Maghsudi*

Main category: cs.DS

TL;DR: 该论文提出了一种基于分解的方法，用于在网络中分配有限资源以应对未知的持续对抗攻击，通过优化节点级资源分配和节点间资源转移，最小化系统损坏和运营成本。


<details>
  <summary>Details</summary>
Motivation: 在网络中，节点可能因对抗攻击而部分退化，但未被完全禁用。如何在这些条件下高效分配防御资源，同时最小化系统损坏和资源转移成本，是一个重要问题。

Method: 论文将问题建模为双目标优化问题，提出了一种分解方法，结合机会约束规划和网络流优化，分为节点级资源分配和节点间资源转移两个子问题。

Result: 理论证明该方法在对抗攻击统计知识完全的情况下收敛到最优解，仿真表明该方法能高效学习攻击模式，并在多种参数设置下显著优于对比策略。

Conclusion: 该方法能有效应对未知对抗攻击，优化资源分配，显著降低系统损坏和运营成本。

Abstract: We address the problem of allocating limited resources in a network under
persistent yet statistically unknown adversarial attacks. Each node in the
network may be degraded, but not fully disabled, depending on its available
defensive resources. The objective is twofold: to minimize total system damage
and to reduce cumulative resource allocation and transfer costs over time. We
model this challenge as a bi-objective optimization problem and propose a
decomposition-based solution that integrates chance-constrained programming
with network flow optimization. The framework separates the problem into two
interrelated subproblems: determining optimal node-level allocations across
time slots, and computing efficient inter-node resource transfers. We
theoretically prove the convergence of our method to the optimal solution that
would be obtained with full statistical knowledge of the adversary. Extensive
simulations demonstrate that our method efficiently learns the adversarial
patterns and achieves substantial gains in minimizing both damage and
operational costs, comparing three benchmark strategies under various parameter
settings.

</details>


### [15] [Towards practical FPRAS for #NFA: Exploiting the Power of Dependence](https://arxiv.org/abs/2506.23561)
*Kuldeep S. Meel,Alexis de Colnet*

Main category: cs.DS

TL;DR: 本文提出了一种新的#NFA问题的实用FPRAS算法，其时间复杂度为$O(n^2m^3\log(nm)\varepsilon^{-2}\log(\delta^{-1}))$，相较于现有方法显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的#NFA问题的FPRAS算法虽然理论上有改进，但时间复杂度仍然过高，难以在实际中应用。本文旨在找到一种更实用的FPRAS算法。

Method: 提出了一种新的FPRAS算法，通过优化时间复杂度和减少计算量，使其在实际中更具可行性。算法的时间复杂度为$O(n^2m^3\log(nm)\varepsilon^{-2}\log(\delta^{-1}))$。

Result: 新算法的时间复杂度相较于之前最好的FPRAS算法（$\tilde{O}((n^{10}m^2 + n^6m^3)\varepsilon^{-4}\log^2(\delta^{-1}))$）有显著提升，且更接近实际应用的需求。

Conclusion: 本文的新算法在#NFA问题上实现了更高效和实用的FPRAS，为实际应用提供了可行的解决方案。

Abstract: #NFA refers to the problem of counting the words of length $n$ accepted by a
non-deterministic finite automaton. #NFA is #P-hard, and although
fully-polynomial-time randomized approximation schemes (FPRAS) exist, they are
all impractical. The first FPRAS for #NFA had a running time of
$\tilde{O}(n^{17}m^{17}\varepsilon^{-14}\log(\delta^{-1}))$, where $m$ is the
number of states in the automaton, $\delta \in (0,1]$ is the confidence
parameter, and $\varepsilon > 0$ is the tolerance parameter (typically smaller
than $1$). The current best FPRAS achieved a significant improvement in the
time complexity relative to the first FPRAS and obtained FPRAS with time
complexity $\tilde{O}((n^{10}m^2 +
n^6m^3)\varepsilon^{-4}\log^2(\delta^{-1}))$. The complexity of the improved
FPRAS is still too intimidating to attempt any practical implementation.
  In this paper, we pursue the quest for practical FPRAS for #NFA by presenting
a new algorithm with a time complexity of
$O(n^2m^3\log(nm)\varepsilon^{-2}\log(\delta^{-1}))$. Observe that evaluating
whether a word of length $n$ is accepted by an NFA has a time complexity of
$O(nm^2)$. Therefore, our proposed FPRAS achieves sub-quadratic complexity with
respect to membership checks.

</details>


### [16] [Segmented Operations using Matrix Multiplications](https://arxiv.org/abs/2506.23906)
*Aleksandros Sobczyk,Giuseppe Sorrentino,Anastasios Zouzias*

Main category: cs.DS

TL;DR: 本文提出了一种针对矩阵乘法加速器的计算模型MMV-RAM，通过扩展Vector-RAM模型并引入矩阵乘法单元，研究了分段扫描和求和等基础并行算法的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代加速器中专用计算单元主要用于矩阵乘法，但其他基础运算的利用率较低，且缺乏严格的数学模型来分析此类架构的算法性能。

Method: 扩展Vector-RAM模型，引入矩阵乘法单元（可并行计算$n\times s$和$s\times s$矩阵乘法），并基于电路复杂性下限分析模型设计。

Result: 提出的分段扫描算法在MMV-RAM中仅需$O(\log_s(n))$步，显著优于仅使用向量单元的算法。还展示了在向量乘法和矩阵乘法中的类似性能提升。

Conclusion: MMV-RAM为矩阵乘法加速器提供了高效的理论模型，其算法设计在实际实现中具有潜力，如分段运算的高效实现。

Abstract: Specialized computational units that perform small matrix multiplications as
primitive operations are typically present in modern accelerators. However,
these units are often underutilized for many fundamental operations besides
dense matrix multiplications. The analysis of algorithms for such architectures
is currently stagnated due to the lack of a rigorous theoretical model of
computation that captures their characteristics. In this work, we propose
MMV-RAM, a computational model tailored to matrix multiplication accelerators.
MMV-RAM judiciously extends the Vector-RAM model with an additional processing
unit that multiplies two matrices of sizes $n\times s$ and $s\times s$ in a
single parallel step, where $s$ is a model parameter. We provide a detailed
theoretical analysis of the model, and carefully balance the computational
power between the matrix and vector units, guided by the circuit complexity
lower bound that parity is not in AC[0].
  In MMV-RAM, we study algorithms for segmented scan and sum, two fundamental
parallel primitives. We propose a segmented scan algorithm that uses matrix
multiplications to perform speculative block-scan computations, which runs in
$O(\log_s(n))$ steps. In contrast, we show that any algorithm that uses only
the vector unit of MMV-RAM requires
$\Omega\left(\frac{\log_2(n)}{\log_2\log_2(n)}\right)$ steps. We further apply
these techniques to obtain similar theoretical speedups for element-wise vector
multiplication and matrix multiplication. Beyond the worst-case complexity
analysis, we propose algorithms for segmented operations that could lead to
highly efficient and pragmatic implementations. For example, we observe that
segmented sum is a combination of three elementary parallel primitives: scan,
compress, and vector differentiation. As a case study, we implement...

</details>


### [17] [Fantastic Flips and Where to Find Them: A General Framework for Parameterized Local Search on Partitioning Problem](https://arxiv.org/abs/2506.24001)
*Niels Grüttemeier,Nils Morawietz,Frank Sommer*

Main category: cs.DS

TL;DR: 本文提出了一种参数化局部搜索的抽象框架，用于解决分割问题，并通过参数优化提高了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 传统局部搜索算法通过单步操作改进解，而参数化方法旨在通过同时执行k步操作改进解，以平衡搜索半径k与运行时间的关系。

Method: 提出了一个适用于分割问题的抽象框架，允许通过移除和重新分配最多k个物品来改进解，并引入类型数τ作为参数，优化算法运行时间。

Result: 框架适用于如Cluster Editing、Vector Bin Packing等问题，算法运行时间为τ^k 2^O(k) |I|^O(1)。同时证明改进此算法的困难性。

Conclusion: 参数化局部搜索框架有效优化了问题求解效率，但在仅以搜索半径k为参数时，问题是W[1]-难的。

Abstract: Parameterized local search combines classic local search heuristics with the
paradigm of parameterized algorithmics. While most local search algorithms aim
to improve given solutions by performing one single operation on a given
solution, the parameterized approach aims to improve a solution by performing
$k$ simultaneous operations. Herein, $k$ is a parameter called search radius
for which the value can be chosen by a user. One major goal in the field of
parameterized local search is to outline the trade-off between the size of $k$
and the running time of the local search step. In this work, we introduce an
abstract framework that generalizes natural parameterized local search
approaches for a large class of partitioning problems: Given $n$ items that are
partitioned into $b$ bins and a target function that evaluates the quality of
the current partition, one asks whether it is possible to improve the solution
by removing up to $k$ items from their current bins and reassigning them to
other bins. Among others, our framework applies for the local search versions
of problems like Cluster Editing, Vector Bin Packing, and Nash Social Welfare.
Motivated by a real-world application of the problem Vector Bin Packing, we
introduce a parameter called number of types $\tau \le n$ and show that all
problems fitting in our framework can be solved in $\tau^k 2^{O(k)} |I|^{O(1)}$
time, where $|I|$ denotes the total input size. In case of Cluster Editing, the
parameter $\tau$ generalizes the well-known parameter neighborhood diversity of
the input graph. We complement this by showing that for all considered
problems, an algorithm significantly improving over our algorithm with running
time $\tau^k 2^{O(k)} |I|^{O(1)}$ would contradict the ETH. Additionally, we
show that even on very restricted instances, all considered problems are
W[1]-hard when parameterized by the search radius $k$ alone.

</details>


### [18] [Dominating Set Knapsack: Profit Optimization on Dominating Sets](https://arxiv.org/abs/2506.24032)
*Sipra Singh*

Main category: cs.DS

TL;DR: 论文提出了一种结合支配集和背包问题的图论问题——支配集背包问题，证明了其在二分图和星图中的复杂性，并为树结构提出了伪多项式时间算法，同时展示了其不太可能是固定参数可解的。


<details>
  <summary>Details</summary>
Motivation: 在大规模网络中，需要在有限预算内选择一些具有影响力的节点以获得最大利润，同时避免选择相邻节点。这引发了如何结合支配集和背包问题的研究需求。

Method: 将支配集问题与背包问题结合，每个顶点关联成本和利润。研究其在不同图类（如二分图、星图和树）中的复杂性，并提出了伪多项式时间算法和固定参数算法。

Result: 证明了支配集背包问题在二分图中是强NP完全的，在星图中是弱NP完全的；为树结构提供了伪多项式时间算法；并展示了其不太可能是固定参数可解的。

Conclusion: 支配集背包问题在多种图结构中具有高复杂性，但针对特定结构（如树）可以设计高效算法，而其固定参数可解性较弱。

Abstract: In a large-scale network, we want to choose some influential nodes to make a
profit by paying some cost within a limited budget so that we do not have to
spend more budget on some nodes adjacent to the chosen nodes; our problem is
the graph-theoretic representation of it. We define our problem Dominating Set
Knapsack by attaching Knapsack Problem with Dominating Set on graphs. Each
vertex is associated with a cost factor and a profit amount. We aim to choose
some vertices within a fixed budget that gives maximum profit so that we do not
need to choose their 1-hop neighbors. We show that the Dominating Set Knapsack
problem is strongly NP-complete even when restricted to Bipartite graphs but
weakly NP-complete for Star graphs. We present a pseudo-polynomial time
algorithm for Trees in time $O(n\cdot min\{s^2, (\alpha(V))^2\})$. We show that
Dominating Set Knapsack is very unlikely to be Fixed Parameter Tractable(FPT)
by proving that it is in W[2]-hard parameterized by the solution size. We
developed FPT algorithms with running time $O(4^{tw}\cdot n^{O(1)} \cdot
min\{s^2,{\alpha(V)}^2\})$ and $O(2^{vck-1}\cdot n^{O(1)} \cdot
min\{s^2,{\alpha(V)}^2\})$, where $tw$ represents the treewidth of the given
graph, $vck$ is the solution size of the Vertex Cover Knapsack, $s$ is the size
of the knapsack and $\alpha(V)=\sum_{v\in V}\alpha(v)$.

</details>


### [19] [A Refined Kernel for $d$-Hitting Set](https://arxiv.org/abs/2506.24114)
*Yuxi Liu,Mingyu Xiao*

Main category: cs.DS

TL;DR: 通过线性规划技术改进超图中的冠分解方法，将$d$-Hitting Set问题的最优核大小从$(2d - 1)k^{d - 1} + k$顶点减少到$(2d - 2)k^{d - 1} + k$顶点。


<details>
  <summary>Details</summary>
Motivation: $d$-Hitting Set问题是参数化复杂性中的一个基本问题，其核心是为超图找到一个大小为$k$的顶点子集$S$，使其与每条超边相交。现有的最佳核大小为$(2d - 1)k^{d - 1} + k$，研究旨在进一步优化这一结果。

Method: 采用线性规划技术构造超图中的冠分解，通过改进现有的分解方法，实现了对核大小的优化。

Result: 改进后的方法将核大小显著减少为$(2d - 2)k^{d - 1} + k$顶点，虽然改进幅度不大，但在理论上有重要意义。

Conclusion: 研究通过线性规划技术成功优化了$d$-Hitting Set问题的核大小，为参数化复杂性领域提供了更高效的解决方案。

Abstract: The $d$-Hitting Set problem is a fundamental problem in parameterized
complexity, which asks whether a given hypergraph contains a vertex subset $S$
of size at most $k$ that intersects every hyperedge (i.e., $S \cap e \neq
\emptyset$ for each hyperedge $e$). The best known kernel for this problem,
established by Abu-Khzam [1], has $(2d - 1)k^{d - 1} + k$ vertices. This result
has been very widely used in the literature as many problems can be modeled as
a special $d$-Hitting Set problem. In this work, we present a refinement to
this result by employing linear programming techniques to construct crown
decompositions in hypergraphs. This approach yields a slight but notable
improvement, reducing the size to $(2d - 2)k^{d - 1} + k$ vertices.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [20] [Programmable Co-Transcriptional Splicing: Realizing Regular Languages via Hairpin Deletion](https://arxiv.org/abs/2506.23384)
*Da-Jung Cho,Szilárd Zsolt Fazekas,Shinnosuke Seki,Max Wiedenhöft*

Main category: cs.FL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: RNA co-transcriptionality, where RNA is spliced or folded during
transcription from DNA templates, offers promising potential for molecular
programming. It enables programmable folding of nano-scale RNA structures and
has recently been shown to be Turing universal. While post-transcriptional
splicing is well studied, co-transcriptional splicing is gaining attention for
its efficiency, though its unpredictability still remains a challenge. In this
paper, we focus on engineering co-transcriptional splicing, not only as a
natural phenomenon but as a programmable mechanism for generating specific RNA
target sequences from DNA templates. The problem we address is whether we can
encode a set of RNA sequences for a given system onto a DNA template word,
ensuring that all the sequences are generated through co-transcriptional
splicing. Given that finding the optimal encoding has been shown to be
NP-complete under the various energy models considered, we propose a practical
alternative approach under the logarithmic energy model. More specifically, we
provide a construction that encodes an arbitrary nondeterministic finite
automaton (NFA) into a circular DNA template from which co-transcriptional
splicing produces all sequences accepted by the NFA. As all finite languages
can be efficiently encoded as NFA, this framework solves the problem of finding
small DNA templates for arbitrary target sets of RNA sequences. The quest to
obtain the smallest possible such templates naturally leads us to consider the
problem of minimizing NFA and certain practically motivated variants of it, but
as we show, those minimization problems are computationally intractable.

</details>


### [21] [Reachability in symmetric VASS](https://arxiv.org/abs/2506.23578)
*Łukasz Kamiński,Sławomir Lasota*

Main category: cs.FL

TL;DR: 研究了对称向量加法系统状态（VASS）中的可达性问题，其中转换在坐标置换群下保持不变。对称群情况下可达性问题可在PSPACE内解决，而普通VASS则具有Ackermannian复杂度。


<details>
  <summary>Details</summary>
Motivation: 探讨在对称性约束下的VASS中可达性问题的复杂性，并为数据VASS中的类似问题提供理论支持。

Method: 通过分析不同群（如对称群、交替群和循环群）下的VASS转换不变性，研究可达性问题的计算复杂性。

Result: 对称群下的VASS可达性问题可在PSPACE内解决，而普通VASS的复杂度更高（Ackermannian）。

Conclusion: 对称性约束可以显著降低VASS可达性问题的复杂度，为数据VASS中的类似问题提供了理论参考。

Abstract: We investigate the reachability problem in symmetric vector addition systems
with states (VASS), where transitions are invariant under a group of
permutations of coordinates. One extremal case, the trivial groups, yields
general VASS. In another extremal case, the symmetric groups, we show that the
reachability problem can be solved in PSPACE, regardless of the dimension of
input VASS (to be contrasted with Ackermannian complexity in general VASS). We
also consider other groups, in particular alternating and cyclic ones.
Furthermore, motivated by the open status of the reachability problem in data
VASS, we estimate the gain in complexity when the group arises as a combination
of the trivial and symmetric groups.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [22] [VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding](https://arxiv.org/abs/2506.22799)
*Minchao Jiang,Shunyu Jia,Jiaming Gu,Xiaoyuan Lu,Guangming Zhu,Anqi Dong,Liang Zhang*

Main category: cs.GR

TL;DR: VoteSplat是一个结合Hough投票与3DGS的新型3D场景理解框架，通过SAM进行实例分割和生成2D投票图，利用空间偏移向量嵌入高斯基元，实现高效的3D语义定位。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）方法主要关注几何和外观建模，缺乏更深层次的场景理解，并且训练成本高。因此，需要一种既能保持高效渲染又能实现深度场景理解的解决方案。

Method: 结合Hough投票与3DGS，利用SAM进行实例分割生成2D投票图，并通过空间偏移向量嵌入高斯基元来关联2D与3D投票，同时加入深度失真约束优化深度定位。

Result: 实验表明，VoteSplat在开放词汇3D实例定位、3D点云理解、点击式3D对象定位和分层分割等方面表现优异，同时降低了训练成本。

Conclusion: VoteSplat通过集成Hough投票与3DGS，不仅实现了高效的3D场景理解，还在多个任务中表现出色，为3D语义定位提供了新的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time
rendering for novel view synthesis of 3D scenes. However, existing methods
focus primarily on geometric and appearance modeling, lacking deeper scene
understanding while also incurring high training costs that complicate the
originally streamlined differentiable rendering pipeline. To this end, we
propose VoteSplat, a novel 3D scene understanding framework that integrates
Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized
for instance segmentation, extracting objects, and generating 2D vote maps. We
then embed spatial offset vectors into Gaussian primitives. These offsets
construct 3D spatial votes by associating them with 2D image votes, while depth
distortion constraints refine localization along the depth axis. For
open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D
point clouds via voting points, reducing training costs associated with
high-dimensional CLIP features while preserving semantic unambiguity. Extensive
experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D
instance localization, 3D point cloud understanding, click-based 3D object
localization, hierarchical segmentation, and ablation studies. Our code is
available at https://sy-ja.github.io/votesplat/

</details>


### [23] [DOBB-BVH: Efficient Ray Traversal by Transforming Wide BVHs into Oriented Bounding Box Trees using Discrete Rotations](https://arxiv.org/abs/2506.22849)
*Michael A. Kern,Alain Galvan,David Oldcorn,Daniel Skinner,Rohan Mehalwal,Leo Reyes Lozano,Matthäus G. Chajdas*

Main category: cs.GR

TL;DR: 本文提出了一种新型的OBB构建技术，通过一致化内部节点变换并使用离散量化旋转集，显著提升了光线追踪性能，同时限制构建时间对实时应用的影响。


<details>
  <summary>Details</summary>
Motivation: 在光线追踪中，OBB包围盒层次结构（BVH）比轴对齐包围盒（AABB）层次结构更适合细长和任意旋转的几何体，但构建高效OBB的计算和内存开销较大。

Method: 提出一种OBB构建方法，所有内部节点的子节点共享一致的OBB变换，并从离散量化旋转集中选择变换方式。进一步通过k-DOP扩展支持多子节点层次结构，构建过程作为后处理步骤集成到现有流水线中。

Result: 实验结果显示，构建时间增加12.6%，但光线追踪性能提升显著：主光线性能平均提升18.5%，次光线性能平均提升32.4%，最大提升65%的光线相交性能。

Conclusion: 该方法通过优化OBB变换的编码和计算复杂度，有效提升了光线追踪性能，适合实时应用需求。

Abstract: Oriented bounding box (OBB) bounding volume hierarchies offer a more precise
fit than axis-aligned bounding box hierarchies in scenarios with thin elongated
and arbitrarily rotated geometry, enhancing intersection test performance in
ray tracing. However, determining optimally oriented bounding boxes can be
computationally expensive and have high memory requirements. Recent research
has shown that pre-built hierarchies can be efficiently converted to OBB
hierarchies on the GPU in a bottom-up pass, yielding significant ray tracing
traversal improvements. In this paper, we introduce a novel OBB construction
technique where all internal node children share a consistent OBB transform,
chosen from a fixed set of discrete quantized rotations. This allows for
efficient encoding and reduces the computational complexity of OBB
transformations. We further extend our approach to hierarchies with multiple
children per node by leveraging Discrete Orientation Polytopes (k-DOPs),
demonstrating improvements in traversal performance while limiting the build
time impact for real-time applications. Our method is applied as a
post-processing step, integrating seamlessly into existing hierarchy
construction pipelines. Despite a 12.6% increase in build time, our
experimental results demonstrate an average improvement of 18.5% in primary,
32.4% in secondary rays, and maximum gain of 65% in ray intersection
performance, highlighting its potential for advancing real-time applications.

</details>


### [24] [Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions](https://arxiv.org/abs/2506.22973)
*AmirHossein Naghi Razlighi,Elaheh Badali Golezani,Shohreh Kasaei*

Main category: cs.GR

TL;DR: 提出了一种基于可学习置信分数的损失压缩方法，用于优化3D高斯泼溅技术中的存储和计算开销，同时保持视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅技术虽然可以实现高质量的实时渲染，但通常会产生数百万个泼溅，导致存储和计算开销过大。

Method: 提出了一种基于Beta分布的可学习置信分数模型，通过重建感知损失优化每个泼溅的置信度，从而能够修剪低置信度的泼溅。

Result: 实验表明，该方法在压缩和保真度之间实现了优于现有工作的平衡。此外，平均置信值可作为评估场景质量的新指标。

Conclusion: 该方法是一种与架构无关的解决方案，可应用于任何高斯泼溅变体，且其代码和数据已公开。

Abstract: 3D Gaussian Splatting enables high-quality real-time rendering but often
produces millions of splats, resulting in excessive storage and computational
overhead. We propose a novel lossy compression method based on learnable
confidence scores modeled as Beta distributions. Each splat's confidence is
optimized through reconstruction-aware losses, enabling pruning of
low-confidence splats while preserving visual fidelity. The proposed approach
is architecture-agnostic and can be applied to any Gaussian Splatting variant.
In addition, the average confidence values serve as a new metric to assess the
quality of the scene. Extensive experiments demonstrate favorable trade-offs
between compression and fidelity compared to prior work. Our code and data are
publicly available at
https://github.com/amirhossein-razlighi/Confident-Splatting

</details>


### [25] [The ultimate display: Where will all the pixels come from?](https://arxiv.org/abs/2506.23001)
*Benjamin Watson,David Luebke*

Main category: cs.GR

TL;DR: 论文探讨了通过减少像素计算和采用时间自适应采样来实现高分辨率壁式显示器的高速更新。


<details>
  <summary>Details</summary>
Motivation: 传统渲染器的帧模式可能无法满足打印机分辨率壁式显示器每秒数百次更新的需求，因此需要寻找新的方法。

Method: 提出了一种打破传统帧模式的时间自适应采样方法，以减少像素计算。

Result: 研究表明，这种方法可能是实现高分辨率壁式显示器高速更新的关键。

Conclusion: 时间自适应采样为高分辨率显示器的实时更新提供了一种可行的解决方案。

Abstract: Could the answer be to compute fewer pixels? Renderers that break traditional
framed patterns and opt for temporally adaptive sampling might be the key to
printer-resolution wall displays that update hundreds of times per second.

</details>


### [26] [Glyph-Based Multiscale Visualization of Turbulent Multi-Physics Statistics](https://arxiv.org/abs/2506.23092)
*Arisa Cowe,Tyson Neuroth,Qi Wu,Martin Rieth,Jacqueline Chen,Myoungkyu Lee,Kwan-Liu Ma*

Main category: cs.GR

TL;DR: 提出一种新颖的局部空间统计可视化方法，用于跨多场和湍流尺度分析流动场，帮助科学家更好地理解多场和多尺度之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 多物理问题涉及多尺度，理解跨尺度的相互作用对复杂问题的全面理解至关重要，但目前的多变量、多尺度数据可视化仍具有挑战性。

Method: 方法包括使用曲线波变换进行尺度分解、基于水平集的Centroidal Voronoi剖分进行空间域分区，以及设计符号以整合多尺度和多场信息。

Result: 通过案例研究（湍流燃烧数据和多标量可压缩流动数据）验证了方法的有效性，实现了对湍流中多场和长度尺度相互作用的直观展示。

Conclusion: 该方法成功集成到交互式可视化系统中，支持整体分析，为科学家研究多尺度和多场相互作用提供了新工具。

Abstract: Many scientific and engineering problems involving multi-physics span a wide
range of scales. Understanding the interactions across these scales is
essential for fully comprehending such complex problems. However, visualizing
multivariate, multiscale data within an integrated view where correlations
across space, scales, and fields are easily perceived remains challenging. To
address this, we introduce a novel local spatial statistical visualization of
flow fields across multiple fields and turbulence scales. Our method leverages
the curvelet transform for scale decomposition of fields of interest, a
level-set-restricted centroidal Voronoi tessellation to partition the spatial
domain into local regions for statistical aggregation, and a set of glyph
designs that combines information across scales and fields into a single, or
reduced set of perceivable visual representations. Each glyph represents data
aggregated within a Voronoi region and is positioned at the Voronoi site for
direct visualization in a 3D view centered around flow features of interest. We
implement and integrate our method into an interactive visualization system
where the glyph-based technique operates in tandem with linked 3D spatial views
and 2D statistical views, supporting a holistic analysis. We demonstrate with
case studies visualizing turbulent combustion data--multi-scalar compressible
flows--and turbulent incompressible channel flow data. This new capability
enables scientists to better understand the interactions between multiple
fields and length scales in turbulent flows.

</details>


### [27] [Data-Driven Compute Overlays for Interactive Geographic Simulation and Visualization](https://arxiv.org/abs/2506.23364)
*Patrick Komon,Gerald Kimmersdorfer,Adam Celarek,Manuela Waldner*

Main category: cs.GR

TL;DR: 该论文提出了一种基于WebGPU的交互式数据驱动计算覆盖层，用于原生和基于Web的3D地理地图应用，通过GPU多步计算工作流生成覆盖层，展示了在雪盖和雪崩模拟中的应用。


<details>
  <summary>Details</summary>
Motivation: 论文旨在解决传统Python实现计算速度慢的问题，提供一种能够快速处理大规模地理数据并实时交互的方法。

Method: 采用WebGPU技术构建数据驱动的覆盖层，通过多步GPU计算工作流从多个数据源生成覆盖层，支持实时调整模拟参数。

Result: 实现的雪崩模拟计算速度比传统Python实现快多个数量级，能在毫秒到秒级内完成大规模地形模拟。

Conclusion: 该方法显著提升了地理数据模拟的效率，为实时交互式地理应用提供了新的解决方案。

Abstract: We present interactive data-driven compute overlays for native and web-based
3D geographic map applications based on WebGPU. Our data-driven overlays are
generated in a multi-step compute workflow from multiple data sources on the
GPU. We demonstrate their potential by showing results from snow cover and
avalanche simulations, where simulation parameters can be adjusted
interactively and results are visualized instantly. Benchmarks show that our
approach can compute large-scale avalanche simulations in milliseconds to
seconds, depending on the size of the terrain and the simulation parameters,
which is multiple orders of magnitude faster than a state-of-the-art Python
implementation.

</details>


### [28] [Escher Tile Deformation via Closed-Form Solution](https://arxiv.org/abs/2506.23388)
*Crane He Chen,Vladimir G. Kim*

Main category: cs.GR

TL;DR: 该论文提出了一种实时变形Escher瓷砖的方法，通过周期性位移场的分析解，实现无缝变形，支持多种表示形式，并提供交互工具供艺术家精细控制。


<details>
  <summary>Details</summary>
Motivation: 为了在不引入间隙或重叠的情况下变形Escher瓷砖，并满足艺术家的精细控制需求，论文提出了一种实时变形方法。

Method: 通过周期性位移场的分析解，实现对17种壁纸群瓷砖的变形，包括图像和网格表示，同时考虑边界和内部的纹理形状变形。

Result: 方法在各种示例中展示了有效性，包括照片编辑和形状雕刻，适用于制造和动画等应用。

Conclusion: 论文提出的方法为Escher瓷砖的实时变形提供了高效且灵活的解决方案，支持艺术家的创造性输入。

Abstract: We present a real-time deformation method for Escher tiles -- interlocking
organic forms that seamlessly tessellate the plane following symmetry rules. We
formulate the problem as determining a periodic displacement field. The goal is
to deform Escher tiles without introducing gaps or overlaps. The resulting
displacement field is obtained in closed form by an analytical solution. Our
method processes tiles of 17 wallpaper groups across various representations
such as images and meshes. Rather than treating tiles as mere boundaries, we
consider them as textured shapes, ensuring that both the boundary and interior
deform simultaneously. To enable fine-grained artistic input, our interactive
tool features a user-controllable adaptive fall-off parameter, allowing precise
adjustment of locality and supporting deformations with meaningful semantic
control. We demonstrate the effectiveness of our method through various
examples, including photo editing and shape sculpting, showing its use in
applications such as fabrication and animation.

</details>


### [29] [Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles](https://arxiv.org/abs/2506.23406)
*Tim Gerrits*

Main category: cs.GR

TL;DR: 该论文提出了一种统一框架，用于分析张量场集合中的不确定模式表面，包括退化张量线和任意模式表面，从而更全面地理解张量场拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定张量场可视化方法通常依赖于标量属性或张量标志，无法捕捉全局行为，且缺乏对模式表面的不确定性分析。

Method: 论文提出了一种将不确定退化张量特征扩展到任意模式值的方法，支持表面和线几何的表示，形成一个统一的分析框架。

Result: 方法在工程和材料科学的多个实际模拟数据集上验证了其有效性。

Conclusion: 该研究为张量场集合中的不确定模式表面分析提供了通用框架，填补了现有方法的不足。

Abstract: The analysis of 3D symmetric second-order tensor fields often relies on
topological features such as degenerate tensor lines, neutral surfaces, and
their generalization to mode surfaces, which reveal important structural
insights into the data. However, uncertainty in such fields is typically
visualized using derived scalar attributes or tensor glyph representations,
which often fail to capture the global behavior. Recent advances have
introduced uncertain topological features for tensor field ensembles by
focusing on degenerate tensor locations. Yet, mode surfaces, including neutral
surfaces and arbitrary mode surfaces are essential to a comprehensive
understanding of tensor field topology. In this work, we present a
generalization of uncertain degenerate tensor features to uncertain mode
surfaces of arbitrary mode values, encompassing uncertain degenerate tensor
lines as a special case. Our approach supports both surface and line
geometries, forming a unified framework for analyzing uncertain mode-based
topological features in tensor field ensembles. We demonstrate the
effectiveness of our method on several real-world simulation datasets from
engineering and materials science.

</details>


### [30] [Synthetically Expressive: Evaluating gesture and voice for emotion and empathy in VR and 2D scenarios](https://arxiv.org/abs/2506.23777)
*Haoyang Du,Kiran Chhatre,Christopher Peters,Brian Keegan,Rachel McDonnell,Cathy Ennis*

Main category: cs.GR

TL;DR: 该研究探讨了虚拟现实中真实与合成语音和手势、沉浸感及情感背景对用户体验的影响，发现VR增强了自然手势语音配对的感知，但对合成信号的感知差距有所放大。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟人技术的快速发展，语音和手势生成的独立开发及虚拟现实的普及带来了这些信号如何整合以及在沉浸式环境中传达情感细节的问题。

Method: 研究者通过评估真实与合成的语音和手势、不同的沉浸感（VR与2D显示）和情感背景（积极、中性、消极）对用户感知的影响，探究了沉浸感如何影响手势与语音的匹配感知以及对用户体验的关键方面的影响。

Result: 研究结果表明，VR增强了自然手势与语音配对的感知，但对合成信号的感知没有类似提升，放大了它们之间的感知差距。

Conclusion: 这些发现强调需要重新评估手势的适当性，并改进AI驱动的合成技术以适配沉浸式环境。

Abstract: The creation of virtual humans increasingly leverages automated synthesis of
speech and gestures, enabling expressive, adaptable agents that effectively
engage users. However, the independent development of voice and gesture
generation technologies, alongside the growing popularity of virtual reality
(VR), presents significant questions about the integration of these signals and
their ability to convey emotional detail in immersive environments. In this
paper, we evaluate the influence of real and synthetic gestures and speech,
alongside varying levels of immersion (VR vs. 2D displays) and emotional
contexts (positive, neutral, negative) on user perceptions. We investigate how
immersion affects the perceived match between gestures and speech and the
impact on key aspects of user experience, including emotional and empathetic
responses and the sense of co-presence. Our findings indicate that while VR
enhances the perception of natural gesture-voice pairings, it does not
similarly improve synthetic ones - amplifying the perceptual gap between them.
These results highlight the need to reassess gesture appropriateness and refine
AI-driven synthesis for immersive environments. See video:
https://youtu.be/WMfjIB1X-dc

</details>


### [31] [GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering](https://arxiv.org/abs/2506.23957)
*Zinuo You,Stamatios Georgoulis,Anpei Chen,Siyu Tang,Dengxin Dai*

Main category: cs.GR

TL;DR: 提出了一种新的3D基础视频稳定方法GaVS，通过局部重建和渲染范式，解决了现有方法的几何失真、过度裁剪和泛化能力差等问题，并在定量和定性评估中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有视频稳定方法存在几何失真、过度裁剪和泛化能力差等问题，影响了用户体验。为了解决这些问题，论文提出了一种新的3D基础方法。

Method: 提出了GaVS方法，通过3D相机位姿预测高斯溅射基元，并进行多视图动态感知光度监督和跨帧正则化的微调，实现时间一致的局部重建和渲染。避免帧裁剪的场景外推模块也被引入。

Result: 在定量评估中，GaVS在传统任务指标和几何一致性方面优于或与现有2D和2.5D方法相当。定性评估显示其效果显著优于其他方法，并通过用户研究验证。

Conclusion: GaVS方法通过3D基础的方式有效解决了视频稳定中的常见问题，显著提升了用户体验，并在多个评估维度上优于现有技术。

Abstract: Video stabilization is pivotal for video processing, as it removes unwanted
shakiness while preserving the original user motion intent. Existing
approaches, depending on the domain they operate, suffer from several issues
(e.g. geometric distortions, excessive cropping, poor generalization) that
degrade the user experience. To address these issues, we introduce
\textbf{GaVS}, a novel 3D-grounded approach that reformulates video
stabilization as a temporally-consistent `local reconstruction and rendering'
paradigm. Given 3D camera poses, we augment a reconstruction model to predict
Gaussian Splatting primitives, and finetune it at test-time, with multi-view
dynamics-aware photometric supervision and cross-frame regularization, to
produce temporally-consistent local reconstructions. The model are then used to
render each stabilized frame. We utilize a scene extrapolation module to avoid
frame cropping. Our method is evaluated on a repurposed dataset, instilled with
3D-grounded information, covering samples with diverse camera motions and scene
dynamics. Quantitatively, our method is competitive with or superior to
state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics
and new geometry consistency. Qualitatively, our method produces noticeably
better results compared to alternatives, validated by the user study.

</details>


### [32] [Navigating with Annealing Guidance Scale in Diffusion Space](https://arxiv.org/abs/2506.24108)
*Shai Yehezkel,Omer Dahary,Andrey Voynov,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: 提出了一种动态调整引导比例的退火引导调度器，通过基于条件噪声信号学习调度策略，显著提升了文本到图像生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的去噪扩散模型在文本提示条件下生成高质量图像时，依赖于采样过程中的精细引导，而分类器自由引导（CFG）的引导比例选择对图像质量和提示一致性具有重要影响。然而，CFG的行为不稳定，需要一种更好的动态调整方法。

Method: 通过提出退火引导调度器，动态调整引导比例，基于条件噪声信号学习调度策略，无需额外激活或内存消耗，可直接替代常见的分类器自由引导。

Result: 实验结果表明，该方法显著提升了图像质量和文本提示的一致性，优化了提示一致性与图像质量之间的权衡。

Conclusion: 提出的退火引导调度器有效解决了CFG的不稳定性问题，为文本到图像生成提供了更优的解决方案。

Abstract: Denoising diffusion models excel at generating high-quality images
conditioned on text prompts, yet their effectiveness heavily relies on careful
guidance during the sampling process. Classifier-Free Guidance (CFG) provides a
widely used mechanism for steering generation by setting the guidance scale,
which balances image quality and prompt alignment. However, the choice of the
guidance scale has a critical impact on the convergence toward a visually
appealing and prompt-adherent image. In this work, we propose an annealing
guidance scheduler which dynamically adjusts the guidance scale over time based
on the conditional noisy signal. By learning a scheduling policy, our method
addresses the temperamental behavior of CFG. Empirical results demonstrate that
our guidance scheduler significantly enhances image quality and alignment with
the text prompt, advancing the performance of text-to-image generation.
Notably, our novel scheduler requires no additional activations or memory
consumption, and can seamlessly replace the common classifier-free guidance,
offering an improved trade-off between prompt alignment and quality.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [33] [Capacity Planning in Stable Matching with Truthful or Strategic Preference Uncertainty](https://arxiv.org/abs/2506.22560)
*Maria Bazotte,Margarida Carvalho,Thibaut Vidal*

Main category: cs.GT

TL;DR: 论文研究了两阶段随机匹配问题，考虑了不确定偏好下的学校选择问题，开发了基于样本平均近似（SAA）的优化方法，并在学生匹配偏好和录取结果上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的学校选择和住院医生匹配等场景中，偏好通常在容量决策之后才揭示，且存在不确定性。此外，即使在策略证明机制下，代理人也可能基于录取概率的策略性偏好误报。

Method: 提出了一个两阶段随机匹配问题框架，第一阶段根据不确定性扩展学校容量，第二阶段基于学生报告偏好和学校优先级计算最优稳定匹配。使用样本平均近似（SAA）处理不确定性，并开发了基于拉格朗日和局部搜索的启发式算法。

Result: 基于SAA的方法在学生匹配偏好和录取结果上表现优于传统平均场景方法，表明随机偏好对容量决策有显著影响，学生行为对容量设计也有重要影响。

Conclusion: 研究强调了在容量规划中考虑策略性偏好误报的重要性，并展示了处理不确定性和优化匹配结果的有效方法。

Abstract: Recent studies on many-to-one matching markets have explored agents with
flexible capacity and truthful preference reporting, focusing on mechanisms
that jointly design capacities and select a matching. However, in real-world
applications such as school choice and residency matching, preferences are
revealed after capacity decisions are made, with matching occurring afterward;
uncertainty about agents' preferences must be considered during capacity
planning. Moreover, even under strategy-proof mechanisms, agents may
strategically misreport preferences based on beliefs about admission chances.
We introduce a two-stage stochastic matching problem with uncertain
preferences, using school choice as a case study. In the first stage, the
clearinghouse expands schools' capacities before observing students' reported
preferences. Students either report their true preferences, producing exogenous
uncertainty, or act strategically, submitting reported preferences based on
their true preferences and admission chances (which depend on capacities),
introducing endogenous uncertainty. In the second stage, the clearinghouse
computes the student-optimal stable matching based on schools' priorities and
students' reported preferences. In strategic cases, endogenous reported
preferences are utility-maximizing transformations of capacity decisions and
exogenous true preferences; we handle uncertainty using sample average
approximation(SAA). We develop behavior-based mathematical formulations and,
due to problem complexity, propose Lagrangian- and local-search-based
behavior-specific heuristics for near-optimal solutions. Our SAA-based
approaches outperform the average scenario approach on students' matching
preferences and admission outcomes, emphasizing the impact of stochastic
preferences on capacity decisions. Student behavior notably influences capacity
design, stressing the need to consider misreports.

</details>


### [34] [Learning Truthful Mechanisms without Discretization](https://arxiv.org/abs/2506.22911)
*Yunxuan Ma,Siqiang Wang,Zhijian Duan,Yukun Cheng,Xiaotie Deng*

Main category: cs.GT

TL;DR: 本文提出了一种名为TEDI的无离散化算法，用于学习真实且效用最大化的机制，克服了现有方法因离散化导致效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法通常依赖结果空间的离散化来保证真实性，但随着问题规模的增加会导致效率低下，本文旨在解决这一局限性。

Method: 通过形式化定价规则的概念，提出了一种新颖的菜单机制，并使用Partial GroupMax Network参数化定价规则，开发了包括协方差技巧和连续采样在内的训练技术。

Result: TEDI在研究的拍卖设置中表现出色，性能与或优于现有最先进方法，并保证了真实性、完全表达性和维度不敏感性。

Conclusion: 本文首次提出了无需结果离散化即可学习真实机制的方法，提升了算法效率，为自动化机制设计和可微分经济学提供了新的见解。

Abstract: This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive
approach), a discretization-free algorithm to learn truthful and
utility-maximizing mechanisms. Existing learning-based approaches often rely on
discretization of outcome spaces to ensure truthfulness, which leads to
inefficiency with increasing problem size. To address this limitation, we
formalize the concept of pricing rules, defined as functions that map outcomes
to prices. Based on this concept, we propose a novel menu mechanism, which can
be equivalent to a truthful direct mechanism under specific conditions. The
core idea of TEDI lies in its parameterization of pricing rules using Partial
GroupMax Network, a new network architecture designed to universally
approximate partial convex functions. To learn optimal pricing rules, we
develop novel training techniques, including covariance trick and continuous
sampling, to derive unbiased gradient estimators compatible with first-order
optimization. Theoretical analysis establishes that TEDI guarantees
truthfulness, full expressiveness, and dimension-insensitivity. Experimental
evaluation in the studied auction setting demonstrates that TEDI achieves
strong performance, competitive with or exceeding state-of-the-art methods.
  This work presents the first approaches to learn truthful mechanisms without
outcome discretization, thereby enhancing algorithmic efficiency. The proposed
concepts, network architecture, and learning techniques might offer potential
value and provide new insights for automated mechanism design and
differentiable economics.

</details>


### [35] [Markov Chains of Evolutionary Games with a Small Number of Players](https://arxiv.org/abs/2506.23134)
*Athanasios Kehagias*

Main category: cs.GT

TL;DR: 论文构建并研究了有限玩家进化博弈的转移概率矩阵，专注于特定游戏和修订协议的分析。


<details>
  <summary>Details</summary>
Motivation: 研究有限玩家进化博弈的转移概率矩阵，以更好地理解小规模群体中的策略动态。

Method: 采用了Sandholm研究的简化版群体博弈框架，并通过具体游戏（如迭代囚徒困境、迭代猎鹿游戏和石头剪刀布）以及多种修订协议（如最佳响应、成对比较等）来构建转移概率矩阵。

Result: 研究为每种修订协议和游戏构建了显式的马尔可夫链转移概率矩阵，并分析了其特性。

Conclusion: 通过具体案例和修订协议的分析，论文为有限玩家进化博弈的转移概率矩阵提供了新的见解和工具。

Abstract: We construct and study the transition probability matrix of evolutionary
games in which the number of players is finite (and relatively small) of such
games. We use a simplified version of the population games studied by Sandholm.
After laying out a general framework we concentrate on specific examples,
involving the Iterated Prisoner's Dilemma, the Iterated Stag Hunt, and the
Rock-Paper-Scissors game. Also we consider several revision protocols: Best
Response, Pairwise Comparison, Pairwise Proportional Comparison etc. For each
of these we explicitly construct the MC transition probability matrix and study
its properties.

</details>


### [36] [Interdependent Bilateral Trade: Information vs Approximation](https://arxiv.org/abs/2506.23896)
*Shahar Dobzinski,Alon Eden,Kira Goldner,Ariel Shaulker,Thodoris Tsilivis*

Main category: cs.GT

TL;DR: 该论文研究了双边贸易中福利最大化问题，尤其在相互依赖价值的情况下，提出了基于信息结构分类的机制设计方法，并探讨了近似机制的可行性和近似比。


<details>
  <summary>Details</summary>
Motivation: 以往的研究仅针对私有价值情况提出了激励兼容的近似机制，但在相互依赖价值的情况下，机制设计更为复杂，因为玩家的价值取决于他人的私有信息。本文旨在填补这一研究空白。

Method: 论文通过量化玩家的私有信号对其自身价值的影响来分类信息结构，并基于这些结构分析近似机制的可行性和局限性。

Result: 研究揭示了在某些信息结构下近似机制可以实现，而在其他情况下则不可行，同时还探讨了一类自然信息结构下的可能近似比。

Conclusion: 本文为双边贸易中相互依赖价值情况下的福利最大化提供了新的理论框架，扩展了现有机制设计的适用范围。

Abstract: Welfare maximization in bilateral trade has been extensively studied in
recent years. Previous literature obtained incentive-compatible approximation
mechanisms only for the private values case. In this paper, we study welfare
maximization in bilateral trade with interdependent values. Designing
mechanisms for interdependent settings is much more challenging because the
values of the players depend on the private information of the others,
requiring complex belief updates and strategic inference. We propose to
classify information structures by quantifying the influence that a player's
private signal has on their own valuation. We then paint a picture of where
approximations are possible and impossible based on these information
structures. Finally, we also study the possible approximation ratios for a
natural family of information structures.

</details>


### [37] [Quickest Detection of Adversarial Attacks Against Correlated Equilibria](https://arxiv.org/abs/2506.24040)
*Kiarash Kazari,Aris Kanellopoulos,György Dán*

Main category: cs.GT

TL;DR: 论文研究在对抗环境中战略游戏的关联均衡，提出一种快速检测攻击的方案以最小化效用损失，并通过数值实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在战略游戏中，对抗者可能通过影响公共信号来操纵玩家策略，导致玩家效用损失。如何快速检测并应对此类攻击成为研究的动机。

Method: 采用零和博弈框架建模玩家与对抗者互动，利用快速变化检测理论推导双方的最优策略，并提出广义CUSUM方案作为最优检测方法。

Result: 数值实验表明，所提出的检测方案在Sioux-Falls交通路由游戏中能有效限制对抗者的效用损失。

Conclusion: 论文提出并验证了一种在对抗环境中保护玩家效用的检测方案，为战略游戏的安全研究提供了新思路。

Abstract: We consider correlated equilibria in strategic games in an adversarial
environment, where an adversary can compromise the public signal used by the
players for choosing their strategies, while players aim at detecting a
potential attack as soon as possible to avoid loss of utility. We model the
interaction between the adversary and the players as a zero-sum game and we
derive the maxmin strategies for both the defender and the attacker using the
framework of quickest change detection. We define a class of adversarial
strategies that achieve the optimal trade-off between attack impact and attack
detectability and show that a generalized CUSUM scheme is asymptotically
optimal for the detection of the attacks. Our numerical results on the
Sioux-Falls benchmark traffic routing game show that the proposed detection
scheme can effectively limit the utility loss by a potential adversary.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [38] [On the Reachability Problem for Two-Dimensional Branching VASS](https://arxiv.org/abs/2506.22561)
*Clotilde Bizière,Thibault Hilaire,Jérôme Leroux,Grégoire Sutre*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vectors addition systems with states (VASS), or equivalently Petri nets, are
arguably one of the most studied formalisms for the modeling and analysis of
concurrent systems. A central decision problem for VASS is reachability:
whether there exists a run from an initial configuration to a final one. This
problem has been known to be decidable for over forty years, and its complexity
has recently been precisely characterized. Our work concerns the reachability
problem for BVASS, a branching generalization of VASS. In dimension one, the
exact complexity of this problem is known. In this paper, we prove that the
reachability problem for 2-dimensional BVASS is decidable. In fact, we even
show that the reachability set admits a computable semilinear presentation. The
decidability status of the reachability problem for BVASS remains open in
higher dimensions.

</details>


### [39] [One-Parametric Presburger Arithmetic has Quantifier Elimination](https://arxiv.org/abs/2506.23730)
*Alessio Mansutti,Mikhail R. Starchak*

Main category: cs.LO

TL;DR: 本文提出了一种针对单参数Presburger算术的量词消去方法，解决了[Bogart et al., 2017]提出的开放性问题，并验证了[Goodrick, 2018]的猜想。


<details>
  <summary>Details</summary>
Motivation: 单参数Presburger算术作为Presburger算术的扩展，引入了一个自由变量t的函数，其量词消去问题一直是未解决的开放性问题。

Method: 该方法通过迭代消除存在量词块实现量词消去，结合了两种子方法：一种是改进的Presburger算术量词消去方法，另一种是类似Bogart等人提出的基t除法方法。

Result: 结果表明，单参数Presburger算术的满足性问题属于NP类，且其最小解具有多项式大小。

Conclusion: 本文解决了单参数Presburger算术的量词消去问题，为相关领域提供了有效的理论基础和算法支持。

Abstract: We give a quantifier elimination procedure for one-parametric Presburger
arithmetic, the extension of Presburger arithmetic with the function $x \mapsto
t \cdot x$, where $t$ is a fixed free variable ranging over the integers. This
resolves an open problem proposed in [Bogart et al., Discrete Analysis, 2017].
As conjectured in [Goodrick, Arch. Math. Logic, 2018], quantifier elimination
is obtained for the extended structure featuring all integer division functions
$x \mapsto \lfloor{\frac{x}{f(t)}}\rfloor$, one for each integer polynomial
$f$.
  Our algorithm works by iteratively eliminating blocks of existential
quantifiers. The elimination of a block builds on two sub-procedures, both
running in non-deterministic polynomial time. The first one is an adaptation of
a recently developed and efficient quantifier elimination procedure for
Presburger arithmetic, modified to handle formulae with coefficients over the
ring $\mathbb{Z}[t]$ of univariate polynomials. The second is reminiscent of
the so-called "base $t$ division method" used by Bogart et al. As a result, we
deduce that the satisfiability problem for the existential fragment of
one-parametric Presburger arithmetic (which encompasses a broad class of
non-linear integer programs) is in NP, and that the smallest solution to a
satisfiable formula in this fragment is of polynomial bit size.

</details>


### [40] [From MBQI to Enumerative Instantiation and Back](https://arxiv.org/abs/2506.22584)
*Marek Dančo,Petra Hozzová,Mikoláš Janota*

Main category: cs.LO

TL;DR: 该研究探讨了基于模型的量词实例化（MBQI）和枚举实例化（EI）在可满足性模理论（SMT）中的关系，并提出了一种结合两者的算法。


<details>
  <summary>Details</summary>
Motivation: MBQI和EI在SMT中各有优劣，MBQI能在语义层面找到反例但可能导致弱实例化，而EI在语法层面枚举术语但可能无法找到反例。研究旨在探索两者的关系并提出结合方案。

Method: 研究了MBQI和EI的关系，并提出了一种结合两者的算法，随后进行了初步实验验证。

Result: 初步实验验证了提出的结合算法的有效性，展示了MBQI和EI互补的潜力。

Conclusion: 结合MBQI和EI的算法在SMT中表现出潜力，为未来进一步优化和扩展奠定了基础。

Abstract: This work investigates the relation between model-based quantifier
instantiation (MBQI) and enumerative instantiation (EI) in Satisfiability
Modulo Theories (SMT). MBQI operates at the semantic level and guarantees to
find a counterexample to a given a non-model. However, it may lead to weak
instantiations. In contrast, EI strives for completeness by systematically
enumerating terms at the syntactic level. However, such terms may not be
counter-examples. Here we investigate the relation between the two techniques
and report on our initial experiments of the proposed algorithm that combines
the two.

</details>


### [41] [Compositional Control-Driven Boolean Circuits](https://arxiv.org/abs/2506.22687)
*Damian Arellanes*

Main category: cs.LO

TL;DR: 本文提出了一种基于余极限的操作符，用于构建组合电路，填补了长期以来布尔电路组合性研究的理论空白。


<details>
  <summary>Details</summary>
Motivation: 布尔电路的组合性长期以来被忽视或非正式研究，本文旨在通过引入组合性操作符，支持模块化和形式化推理。

Method: 提出基于余极限的操作符，定义了一系列用于构建顺序、并行、分支和迭代电路的运算符。

Result: 展示了新模型（控制驱动的布尔电路族）至少与传统布尔电路模型具有相同的计算能力，能够非均匀地计算任意长度的布尔函数。

Conclusion: 通过组合性操作符，本文填补了布尔电路组合性研究的理论空白，并展示了新模型的计算能力与传统模型相当。

Abstract: Boolean circuits abstract away from physical details to focus on the logical
structure and computational behaviour of digital components. Despite they have
been studied for many decades, compositionality has been widely ignored or
examined in an informal manner, which is a property for combining circuits
without delving into their internal structure, while supporting modularity and
formal reasoning. In this paper, we address this longstanding theoretical gap
by proposing colimit-based operators for compositional circuit construction. We
define separate operators for forming sequential, parallel, branchial and
iterative circuits. As composites encapsulate explicit control flow, a new
model of computation emerges which we refer to as (families of) control-driven
Boolean circuits. We show how this model is at least as powerful as its
classical counterpart. In other words, it is able to non-uniformly compute any
Boolean function on inputs of arbitrary length.

</details>


### [42] [Questions as cognitive filters](https://arxiv.org/abs/2506.22735)
*Willem Conradie,Krishna Manoorkar,Alessandra Palmigiano,Apostolos Tzimoulis,Nachoem Wijnberg*

Main category: cs.LO

TL;DR: 本文开发了一个逻辑代数框架，用于通过多智能体环境中的审议来建模决策过程，核心概念是表示智能体认知立场的询问议程。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为多智能体环境中的决策过程提供一个形式化的逻辑代数框架，以帮助理解智能体在审议过程中如何选择相关特征并达成决策。

Method: 方法包括将智能体的询问议程建模为等价关系，识别智能体认为不相关的方面，并通过子格和双排序逻辑代数结构（相关询问议程的格和智能体联盟的布尔代数）来建模审议过程中的互动。

Result: 研究结果表明，该框架能够形式化不同“获胜规则”下的询问议程子格，并讨论了在此框架内可定义和不可定义的互动条件。

Conclusion: 本文提出的逻辑代数框架为多智能体决策的审议过程提供了形式化工具，同时也揭示了框架的限制和未来研究方向。

Abstract: In this paper, we develop a logico-algebraic framework for modeling
decision-making through deliberation in multi-agent settings. The central
concept in this framework is that of interrogative agendas, which represent the
cognitive stances of agents regarding which features should be considered
relevant in the final decision. We formalize an agent's interrogative agenda as
an equivalence relation that identifies outcomes differing only in aspects the
agent deems irrelevant. Moreover, we characterize the sublattices of the
resulting lattice that correspond to relevant interrogative agendas for
deliberation scenarios governed by different ``winning rules." We then
introduce a two-sorted logico-algebraic structure-comprising the lattice of
relevant interrogative agendas and the Boolean algebras of agent coalitions-to
model the interaction between agents and agendas during deliberation. Finally,
we discuss which interaction conditions can and cannot be defined within this
framework.

</details>


### [43] [Model-theoretic Forcing in Transition Algebra](https://arxiv.org/abs/2506.22828)
*Go Hashimoto,Daniel Găină*

Main category: cs.LO

TL;DR: 研究了过渡代数中的Löwenheim-Skolem和Omitting Types定理，通过强制技术方法证明了向下Löwenheim-Skolem和Omitting Types定理，并扩展了证明系统以处理构造型和有限过渡代数。


<details>
  <summary>Details</summary>
Motivation: 研究过渡代数中Löwenheim-Skolem和Omitting Types定理的动机是为了理解这一逻辑系统中模型的表达性和局限性，并探索如何在非紧凑的系统中建立这些经典定理。

Method: 通过扩展经典的强制技术方法，采用签名有向图的形式，以解决过渡代数中模型的多样性和非紧凑性问题。同时，扩展了证明系统以涵盖构造型和有限过渡代数。

Result: 证明了在过渡代数中，向上Löwenheim-Skolem定理、任何形式的紧致性及联合Robinson一致性性质由于过渡传递闭包的表达性而失效。然而，通过强制技术，成功建立了向下Löwenheim-Skolem和Omitting Types定理。

Conclusion: 在过渡代数中，尽管存在非紧凑性和模型多样性问题，但通过强制技术和扩展的证明系统，仍然可以实现部分经典定理的证明，适用于构造型和有限过渡代数的片段。

Abstract: We study L\"owenheim-Skolem and Omitting Types theorems in Transition
Algebra, a logical system obtained by enhancing many sorted first-order logic
with features from dynamic logic. The sentences we consider include
compositions, unions, and transitive closures of transition relations, which
are treated similarly to actions in dynamic logics to define necessity and
possibility operators. We show that Upward L\"owenheim-Skolem theorem, any form
of compactness, and joint Robinson consistency property fail due to the
expressivity of transitive closures of transitions. In this non-compact
many-sorted logical system, we develop a forcing technique method by
generalizing the classical method of forcing used by Keisler to prove Omitting
Types theorem. Instead of working within a single signature, we work with a
directed diagram of signatures, which allows us to establish Downward
L\"owenheim-Skolem and Omitting Types theorems despite the fact that models
interpret sorts as sets, possibly empty. Building on a complete system of proof
rules for Transition Algebra, we extend it with additional proof rules to
reason about constructor-based and/or finite transition algebras. We then
establish the completeness of this extended system for a fragment of Transition
Algebra obtained by restricting models to constructor-based and/or finite
transition algebras.

</details>


### [44] [Querying Attack-Fault-Defense Trees: Property Specification in Smart Grid and Aerospace Case Studies](https://arxiv.org/abs/2506.23789)
*Reza Soltani,Stefano M. Nicoletti,Milan Lopuhaä-Zwakenberg,Mariëlle Stoelinga*

Main category: cs.LO

TL;DR: 本文介绍了AFDL，一种基于逻辑的框架，用于在攻击-故障-防御树中进行安全、安全和防御交互的推理，并通过LangAFDL查询语言支持复杂分析目标的表达。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个统一的框架，以同时捕捉安全、安全和防御领域的交互，并支持复杂的分析目标表达。

Method: 提出AFDL逻辑框架和LangAFDL查询语言，支持布尔和量化查询以及最小割集分析。

Result: AFDL和LangAFDL在两个实际案例（Gridshield和Ground Segment as a Service）中展示了其表达能力和实用性。

Conclusion: 该框架为关键任务系统的自动化安全-安全分析奠定了基础，并为未来工具开发和设计工作流的集成铺平了道路。

Abstract: This paper introduces AFDL, a logic-based framework for reasoning about
safety, security, and defense interactions in Attack-Fault-Defense Trees, which
is a model that captures all safety, security, and defense domains in a single
framework. We showcase both AFDL and propose a structured domain specific query
language, LangAFDL, which enables domain experts to express complex analysis
goals through intuitive templates. LangAFDL supports both Boolean and
quantified queries as well as minimal cut set analysis, capturing the interplay
between safety, security, and defensive measures. We illustrate the
expressiveness and utility of the approach through representative queries over
two different real-world case studies: Gridshield and Ground Segment as a
Service. The formalization lays the automated safety-security groundwork for
analyses in mission-critical systems and paves the way for future tool
development and integration into design workflows.

</details>


### [45] [Protocol insecurity with finitely many sessions and XOR](https://arxiv.org/abs/2506.24072)
*R Ramanujam,Vaishnavi Sundararajan,S P Suresh*

Main category: cs.LO

TL;DR: 本文提出了一个关于XOR不安全问题的新证明，利用类型化术语和良好类型化的证明，扩展了[CKRT05]证明的适用范围。


<details>
  <summary>Details</summary>
Motivation: Chevalier等人（2005年）解决了XOR的不安全问题，但其证明对协议类有所限制。本文旨在通过引入更自然的协议概念，移除这一限制。

Method: 采用类型化术语和良好类型化证明的方法，重新定义协议范围，使得诚实代理的发送操作可以从同一会话中之前的接收操作中推导出来。

Result: 成功扩展了[CKRT05]的证明适用范围，提供了更通用的不安全问题证明框架。

Conclusion: 通过引入新的协议概念，本文不仅解决了XOR的不安全问题，还提升了证明的普适性和自然性。

Abstract: We present a different proof of the insecurity problem for XOR, solved in by
Chevalier, Kuesters, Rusinowitch and Turuani (2005). Our proof uses the notion
of typed terms and well-typed proofs, and removes a restriction on the class of
protocols to which the [CKRT05] proof applies, by introducing a slightly
different (but very natural) notion of protocols, where honest agent sends are
derivable from previous receives in the same session.

</details>


<div id='cs.MS'></div>

# cs.MS [[Back]](#toc)

### [46] [The Distributed and Unified Numerics Environment (DUNE), Version 2.10](https://arxiv.org/abs/2506.23558)
*Markus Blatt,Samuel Burbulla,Ansgar Burchardt,Andreas Dedner,Christian Engwer,Carsten Gräser,Christoph Grüninger,Robert Klöfkorn,Timo Koch,Santiago Ospina De Los Ríos,Simon Praetorius,Oliver Sander*

Main category: cs.MS

TL;DR: DUNE 2.10版本在核心模块和扩展模块中引入了多项改进，重点增强了现代C++的集成和可用性，包括对C++20特性的支持、曲线几何的改进以及数据结构的现代化。


<details>
  <summary>Details</summary>
Motivation: 此次升级旨在通过现代C++特性的支持和模块化改进，提升DUNE框架的灵活性、安全性和表达能力，满足用户对高性能数值计算的需求。

Method: DUNE 2.10通过引入C++20的概念（concepts）、改进曲线几何支持、现代化数据结构和重构构建系统，实现了功能和性能的提升。

Result: 新版本提供了更安全的泛型编程范式、更灵活的几何接口、性能优化的稀疏矩阵，以及现代化的构建流程，进一步扩展了数值计算的能力。

Conclusion: DUNE 2.10通过全面的改进和扩展，显著提升了框架的现代性和实用性，为高性能数值计算提供了更强大的支持。

Abstract: Version 2.10 of the Distributed and Unified Numerics Environment DUNE
introduces a range of enhancements across its core and extension modules, with
a continued emphasis on modern C++ integration and improved usability. This
release extends support for C++20 features, particularly concepts, through
comprehensive refinements in dune-common and dune-grid, enabling safer and more
expressive generic programming paradigms. A notable advancement is the improved
support for curved geometries, including new geometry implementations and a
more flexible interface. Data structures have been modernized through native
support for std::mdspan and std::mdarray, performance improvements in sparse
matrices, and tools for visualization of matrix patterns. The build system has
been restructured towards a modern CMake workflow, emphasizing target-based
configuration and improved automation. Furthermore, new local finite elements
have been introduced to broaden numerical capabilities. The release also brings
updates across DUNE extensions, as well as improvements to infrastructure and
module-level components.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [47] [Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language](https://arxiv.org/abs/2506.23058)
*Nikolaj Hey Hinnerskov,Robert Schenck,Cosmin E. Oancea*

Main category: cs.PL

TL;DR: 论文提出了一种新颖的方法，用于自动验证具有非线性索引的纯数据并行程序的属性。该方法通过将程序表示为索引函数变换，并利用代数不等式证明这些属性，从而为编译器优化提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着数据并行程序的复杂度增加，传统的验证方法难以处理非线性索引和复杂的程序属性。本文旨在提出一种实用的验证框架，以自动推断和验证程序属性，同时支持编译器的优化。

Method: 论文将数组表示为索引函数，并将程序视为索引函数的变换。通过将属性提炼为代数不等式，并使用基于Fourier-Motzkin的求解器进行验证，框架能够处理非线性和复杂的程序属性。

Result: 在Futhark语言中实现了该系统，并在七个应用中验证了其实用性，平均验证时间为1秒。两个案例研究展示了消除GPU程序中的动态验证如何带来显著的性能提升。

Conclusion: 该方法不仅支持程序正确性验证，还能为整个编译器管道提供优化机会，展示了其在高性能计算中的实际应用潜力。

Abstract: This paper presents a novel approach to automatically verify properties of
pure data-parallel programs with non-linear indexing -- expressed as pre- and
post-conditions on functions. Programs consist of nests of second-order array
combinators (e.g., map, scan, and scatter) and loops. The key idea is to
represent arrays as index functions: programs are index function
transformations over which properties are propagated and inferred. Our
framework proves properties on index functions by distilling them into
algebraic (in)equalities and discharging them to a Fourier-Motzkin-based
solver. The framework is practical and accessible: properties are not
restricted to a decidable logic, but instead are carefully selected to express
practically useful guarantees that can be automatically reasoned about and
inferred. These guarantees extend beyond program correctness and can be
exploited by the entire compiler pipeline for optimization. We implement our
system in the pure data-parallel language Futhark and demonstrate its
practicality on seven applications, reporting an average verification time of 1
second. Two case studies show how eliminating dynamic verification in GPU
programs results in significant speedups.

</details>


### [48] [A Denotational Semantics for Quantum Loops](https://arxiv.org/abs/2506.23320)
*Nicola Assolini,Alessandra Di Pierro*

Main category: cs.PL

TL;DR: 本文提出了一种用于高级量子编程结构的形式语义，重点关注量子控制分支和迭代的概念含义。


<details>
  <summary>Details</summary>
Motivation: 量子计算机编程是一个在不同抽象层次上可以解决的问题，本文旨在为高级量子编程结构提供一个形式语义框架。

Method: 引入了一个形式语义域，用于定义量子控制流（包括循环）的数学含义，以反映程序实现的量子系统的相干演化。

Result: 提出了一个能够准确描述量子控制流语义的形式框架。

Conclusion: 通过形式语义的方法，可以更好地理解和定义量子编程中的控制流行为。

Abstract: Programming a quantum computer, i.e., implementing quantum algorithms on a
quantum processor-based copmputer architecture, is a task that can be addressed
(just as for classical computers) at different levels of abstraction. This
paper proposes a denotational semantics for high-level quantum programming
constructs, focusing on the conceptual meaning of quantum-controlled branching
and iteration. We introduce a denotational domain where a mathematical meaning
of a quantum control flow with loops can be defined, which reflects the
coherent evolution of the quantum system implementing the program.

</details>


### [49] [Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR](https://arxiv.org/abs/2506.23407)
*Marcus Edwards*

Main category: cs.PL

TL;DR: 实现了一个从Q#到QASM 3.0的编译工具链，包括完整的词法分析器和解析器，以及支持Q#部分功能的编译器。


<details>
  <summary>Details</summary>
Motivation: 为了将Q#的功能移植到Web环境中，开发了一种基于TypeScript的编译工具链，不同于官方的Microsoft实现。

Method: 实现了词法分析器、解析器和编译器，支持Q#的部分功能，并与现有的Q#编译工具进行了对比。

Result: 工具链能够处理多种输入Q#程序，并在功能上与官方实现进行了比较验证。

Conclusion: 基于TypeScript的编译工具链成功实现了Q#到QASM 3.0的转换，适用于Web环境。

Abstract: We implement a compile toolchain from Q# to QASM 3.0 including a
full-featured lexer and parser implementation, as well as a compiler that
supports a subset of Q# features. The lexer, parser and compiler are shown to
work with various input Q# programs and the implementation is compared against
existing Q# compile tools. Unlike the Microsoft implementation of the official
Q# compile toolchain, our implementation is written in TypeScript in order to
port functionality to web environments.

</details>


<div id='math.CT'></div>

# math.CT [[Back]](#toc)

### [50] [A model structure on the category of A$_\infty$-categories with strict morphisms](https://arxiv.org/abs/2506.22847)
*Mattia Ornaghi*

Main category: math.CT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We prove that the category of (strictly unital) A$_\infty$-categories, linear
over a commutative ring $R$, with strict A$_\infty$-morphisms has a cofibrantly
generated model structure. In this model structure every object is fibrant and
the cofibrant objects have cofibrant morphisms. As a consequence we prove that
the semi-free A$_\infty$-categories (resp. resolutions) are cofibrant objects
(resp. resolution) in this model structure.

</details>


### [51] [Hopf categories associated to comonoidal functors](https://arxiv.org/abs/2506.22872)
*Andrea Rivezzi*

Main category: math.CT

TL;DR: 该论文提出了一种与共协函子相关的Hopf范畴的显式构造，扩展了Ševera的Hopf幺半群构造，并以Lie双代数的扭曲类为例进行了讨论，并进一步应用于变形范畴的设定。


<details>
  <summary>Details</summary>
Motivation: Motivation of the paper is to generalize Ševera's construction of Hopf monoids associated with M-adapted functors by introducing Hopf categories linked to comonoidal functors. This aims to provide a broader framework for understanding structures in Lie bialgebras and deformed categories.

Method: The method involves the explicit construction of Hopf categories associated with comonoidal functors. The paper further illustrates this by examining the example of a Hopf category based on twists of a Lie bialgebra.

Result: The results include a successful generalization of Ševera's construction to Hopf categories and a concrete example involving the twists of a Lie bialgebra. The framework is also applied to deformed categories, showcasing its versatility.

Conclusion: The paper concludes that the construction of Hopf categories provides a useful extension of existing theories, with potential applications in areas like Lie bialgebras and deformed categories, demonstrating the broader utility of the approach.

Abstract: We provide an explicit construction of Hopf categories associated to
comonoidal functors, generalizing \v{S}evera's construction of Hopf monoids
through M-adapted functors. We discuss the example of the Hopf category whose
underlying class is the set of twists of a Lie bialgebra. Finally, we apply the
result to the setting of deformed categories.

</details>


### [52] [Graphs With Polarities](https://arxiv.org/abs/2506.23375)
*John C. Baez,Adittya Chaudhuri*

Main category: math.CT

TL;DR: 该论文研究了带标签边的有向图，将其推广到边标签为幺半群的图，并研究了三类图之间的态射及其应用，进一步利用广义同调理论分析了反馈环的生成。


<details>
  <summary>Details</summary>
Motivation: 在从商业到系统生物的多个领域中，带符号边的有向图被用来简单建模系统，但现有的模型局限于正负标签。该论文旨在推广这一模型，以更一般的幺半群元素作为边标签，研究更复杂的系统行为及其数学结构。

Method: 论文提出将边标签推广到幺半群元素，并研究了三类图态射，分别用于图的细化、简化和模式发现。此外，通过构造对称幺半双范畴的“开放”图，并利用广义同调理论分析反馈环的生成，尤其是使用Mayer-Vietoris精确序列的变体。

Result: 论文展示了如何通过幺半群标签的广义同调理论分析反馈环的生成，并描述了在组合开放图时新反馈环的出现。

Conclusion: 通过将边标签推广到幺半群元素并研究相应的图态射和同调理论，论文为复杂系统的建模和分析提供了更广泛的数学工具，尤其是在反馈环的研究方面。

Abstract: In fields ranging from business to systems biology, directed graphs with
edges labeled by signs are used to model systems in a simple way: the nodes
represent entities of some sort, and an edge indicates that one entity directly
affects another either positively or negatively. Multiplying the signs along a
directed path of edges lets us determine indirect positive or negative effects,
and if the path is a loop we call this a positive or negative feedback loop.
Here we generalize this to graphs with edges labeled by a monoid, whose
elements represent `polarities' possibly more general than simply "positive" or
"negative". We study three notions of morphism between graphs with labeled
edges, each with its own distinctive application: to refine a simple graph into
a complicated one, to transform a complicated graph into a simple one, and to
find recurring patterns called "motifs". We construct three corresponding
symmetric monoidal double categories of "open" graphs. We study feedback loops
using a generalization of the homology of a graph to homology with coefficients
in a commutative monoid. In particular, we describe the emergence of new
feedback loops when we compose open graphs using a variant of the
Mayer-Vietoris exact sequence for homology with coefficients in a commutative
monoid.

</details>


### [53] [When are exact categories co-exact?](https://arxiv.org/abs/2506.23413)
*James Richard Andrew Gray*

Main category: math.CT

TL;DR: 证明了共完备预拓扑的对立范畴在理想情况下是精确的且具有算术性质。


<details>
  <summary>Details</summary>
Motivation: 研究共完备预拓扑对立范畴的性质，并探索其与其他范畴（如加性和广泛范畴）的共同条件。

Method: 通过展示加性和广泛范畴的共同条件，在精确上下文中推导出以下性质：单态射的推沿任意态射存在且为拉回；单态射在推沿下稳定；共自反关系是共有效等价关系；以及共模性成立。

Result: 证明了共完备预拓扑的对立范畴满足理想条件下的精确性和算术性质。

Conclusion: 共完备预拓扑对立范畴在理想情况下具备精确性和算术性质，这些性质通过加性和广泛范畴的共同条件得到验证。

Abstract: We show that opposite category of a cocomplete pretopos is ideally exact and
arithmetical. We do this by showing that there are conditions common to
additive and lextensive categories which, in the exact context, imply that:
pushouts of monomorphisms along arbitrary morphisms exist and are pullbacks;
monomorphisms are stable under pushout; co-reflexive-relations are
co-effective-equivalence-relations; and coprotomodularity holds.

</details>


### [54] [Large condensation in enriched $\infty$-categories](https://arxiv.org/abs/2506.23632)
*Devon Stockall*

Main category: math.CT

TL;DR: 使用富集$\infty$-范畴的语言，我们形式化并推广了融合$n$-范畴的定义，以及$E_i$-代数的迭代凝聚的类比。该理论能够处理任意维度和余维度的对称性，且具有富集、连续、派生、非半单和非可分离的特性。


<details>
  <summary>Details</summary>
Motivation: 动机在于扩展范畴凝聚的理论，使其不仅适用于融合$n$-范畴，还能够应用于所有具有特定余极限的富集幺半$\infty$-范畴。

Method: 方法包括使用富集$\infty$-范畴的语言，形式化融合$n$-范畴和$E_i$-代数的迭代凝聚，并通过Day卷积和Eilenberg-Moore函子的幺半性结果来支持理论。

Result: 结果表明，该理论能够处理更广泛的对称性，包括富集、连续、派生、非半单和非可分离的情况。同时还提供了关于Day卷积和Eilenberg-Moore函子的新结果。

Conclusion: 结论是该工作扩展了范畴凝聚的范围，并为处理复杂对称性提供了新的工具。Day卷积和Eilenberg-Moore函子的结果也具有独立的应用价值。

Abstract: Using the language of enriched $\infty$-categories, we formalize and
generalize the definition of fusion n-category, and an analogue of iterative
condensation of $E_i$-algebras. The former was introduced by Johnson-Freyd, and
the latter by Kong, Zhang, Zhao, and Zheng. This extends categorical
condensation beyond fusion n-categories to all enriched monoidal
$\infty$-categories with certain colimits. The resulting theory is capable of
treating symmetries of arbitrary dimension and codimension that are enriched,
continuous, derived, non-semisimple and non-separable. Additionally, we
consider a truncated variant of the notion of condensation introduced by
Gaiotto and Johnson-Freyd, and show that iterative condensation of monoidal
monads and $E_i$-algebras provide examples. In doing so, we prove results on
functoriality of Day convolution for enriched $\infty$-categories, and
monoidality of two versions of the Eilenberg-Moore functor, which may be of
independent interest.

</details>


### [55] [Doubly weak double categories](https://arxiv.org/abs/2506.23651)
*Aaron David Fairbanks,Michael Shulman*

Main category: math.CT

TL;DR: 提出了一种定义双范畴的新方法，其中1细胞的组合在双方向上是弱的，称为双重弱双范畴。


<details>
  <summary>Details</summary>
Motivation: 研究双范畴的弱组合性质，探索其在数学结构中的适用性。

Method: 采用双重计算结构和隐式双范畴来定义双重弱双范畴，并通过简洁的可表示性标准实现。

Result: 证明了双重弱双范畴可以通过双重计算结构、隐式双范畴或Verity的双重双范畴加上“整洁性”条件来定义。

Conclusion: 双重弱双范畴为双范畴的弱组合提供了一种新的定义方法，扩展了现有理论框架。

Abstract: We propose a definition of double categories whose composition of 1-cells is
weak in both directions. Namely, a doubly weak double category is a double
computad -- a structure with 2-cells of all possible double-categorical shapes
-- equipped with all possible composition operations, coherently. We also
characterize them using "implicit" double categories, which are double
computads having all possible compositions of 2-cells, but no compositions of
1-cells; doubly weak double categories are then obtained by a simple
representability criterion. Finally, they can also be defined by adding a
"tidiness" condition to the double bicategories of Verity, or to the cubical
bicategories of Garner.

</details>


### [56] [Extending conceptual completeness via virtual ultracategories](https://arxiv.org/abs/2506.23935)
*Gabriel Saadia*

Main category: math.CT

TL;DR: 引入了虚拟超类（virtual ultracategory）的概念，从拓扑、范畴和逻辑角度进行了分类和推广，并扩展了Makkai--Lurie的概念完备性结果。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟超类的动机在于从不同角度（拓扑、范畴、逻辑）推广和分类现有的概念，并探索其在拓扑空间中的实际应用。

Method: 通过引入虚拟超类的定义，将其与关系$\beta$-代数、超类和多元类进行了类比和推广，并验证了其在拓扑空间中的适用性。

Result: 证明了一个拓扑空间的点集合可以形成虚拟超类，并且有足够点的拓扑空间可以通过其虚拟超类点集合重建。

Conclusion: 虚拟超类是一个具有广泛应用潜力的新概念，能够统一和扩展多种数学和逻辑结构。

Abstract: We introduce the notion of virtual ultracategory. From a topological point of
view, this notion can be seen as a categorification of relational
$\beta$-algebras. From a categorical point of view, virtual ultracategories
generalize ultracategories in the same way that multicategories generalize
monoidal categories. From a logical point of view, whereas the points of a
coherent topos form an ultracategory, the points of an arbitrary topos form a
virtual ultracategory. We then extend Makkai--Lurie's conceptual completeness:
a topos with enough points can be reconstructed from its virtual ultracategory
of points.

</details>


<div id='math.GM'></div>

# math.GM [[Back]](#toc)

### [57] [Iteration Steps of 3x+1 Problem](https://arxiv.org/abs/2506.23070)
*Youchun Luo*

Main category: math.GM

TL;DR: 该论文提出了一个关于3x+1问题的弱残差猜想，并证明了如果该猜想及3x+1猜想成立，可以推导出D(N)、O(N)和E(N)之间的非平凡关系。


<details>
  <summary>Details</summary>
Motivation: 研究3x+1问题中迭代步数的关系，通过提出弱残差猜想并验证其与3x+1猜想的关联，揭示步数之间的数学关系。

Method: 提出弱残差猜想(即2^E(N)/(3^O(N)·N)≤2)，并证明在3x+1猜想和弱残差猜想成立的条件下，可以推导出D(N)、O(N)和E(N)之间的具体关系式。

Result: 证明了在特定条件下，D(N)、O(N)和E(N)之间存在非平凡关系，并给出了6个相关方程。

Conclusion: 论文通过理论推导揭示了3x+1问题中迭代步数的潜在关系，为进一步研究提供了新的视角。

Abstract: On the 3x+1 problem, given a positive integer $N$, let $D\left( N \right) $,
$O\left( N \right) $, $E\left( N \right) $ be the total iteration steps, the
odd iteration steps and the even iteration steps when $N$ iterates to 1(except
1) respectively. Trivially, we have $D\left( N \right) =O\left( N \right)
+E\left( N \right) $. In this paper, we propose a so-called weak residue
conjecture(i.e., $\frac{2^{E\left( N \right)}}{3^{O\left( N \right)}\cdot N}\le
2$). We prove that if 3x+1 conjecture is true and the weak residue conjecture
is true, there exist non-trivial relationships among $D\left( N \right) $,
$O\left( N \right) $, $E\left( N \right) $, i.e., $O\left( N \right) =\left[
\log _62\cdot D\left( N \right) -\log _6N \right] $(it implies that we can
calculate $O\left( N \right) $, $E\left( N \right) $ directly by $D\left( N
\right) $ only, of course given $N$), and 5 more similar equations are derived
simultaneously.

</details>


<div id='math.HO'></div>

# math.HO [[Back]](#toc)

### [58] [The VIBE Framework: A Student-Centered Approach to Teaching Knot Theory in Secondary Mathematics](https://arxiv.org/abs/2506.22886)
*Ioannis Diamantis*

Main category: math.HO

TL;DR: 论文提出了VIBE框架，通过视觉、探究式、协作和情境化学习，将结理论引入中学教育，以促进学生的认知发展和数学兴趣。


<details>
  <summary>Details</summary>
Motivation: 结理论作为拓扑学的一个直观分支，具有跨学科相关性，但标准课程中却鲜少涉及。作者希望通过VIBE框架将其引入中学教育，以支持学生的认知和空间推理能力发展。

Method: 采用VIBE框架，围绕视觉、探究式、协作和情境化四个教学支柱，设计了一系列低门槛、高挑战性的活动，并结合定性热图、聚类可视化和课堂案例进行展示。

Result: 通过教学活动和可视化工具，论文展示了结理论如何成为探究和跨学科连接的媒介，并验证了VIBE框架的可行性和适应性。

Conclusion: VIBE框架为中学教育提供了一种结构化和灵活的方法，能够整合深层且有意义的数学学习体验，促进学生的全面发展。

Abstract: Knot theory, a visual and intuitive branch of topology, offers a unique
opportunity to introduce advanced mathematical thinking in secondary education.
Despite its accessibility and cross-disciplinary relevance, it remains largely
absent from standard curricula. This paper proposes the {\it VIBE framework}, a
student-centered approach, structured around four pedagogical pillars: Visual,
Inquiry-based, Braided (collaborative), and Embedded (contextualized) learning.
Rooted in constructivist theory, VIBE supports cognitive development, spatial
reasoning, and mathematical engagement across diverse learners. We present a
sequence of low-threshold, high-ceiling activities designed to develop core
topological concepts while fostering creativity and exploration. Through
qualitative heatmaps, clustering visualizations, and classroom snapshots, we
demonstrate how knot theory can be transformed into a powerful medium for
inquiry and interdisciplinary connection. We believe that the VIBE framework
provides a structured yet adaptable approach that supports the integration of
deep, meaningful mathematical experiences into secondary education.

</details>


<div id='math.LO'></div>

# math.LO [[Back]](#toc)

### [59] [Externally definable fsg groups in NIP theories](https://arxiv.org/abs/2506.23265)
*Artem Chernikov*

Main category: math.LO

TL;DR: 论文证明每个在NIP结构中外部可定义的fsg群均可定义同构于该结构中可解释的群，并利用诚实定义和群块结果重构超可定义群。


<details>
  <summary>Details</summary>
Motivation: 研究NIP结构中外部可定义的fsg群的性质及其与可解释群的关系，解决Eleftheriou关于实闭值域中fsg群的猜想。

Method: 利用诚实定义和翻译不变的可定义Keisler测度下的群块结果重构超可定义群。

Result: 证明了每个外部可定义的fsg群均可定义同构于结构中可解释的群，并解决了Eleftheriou的猜想，描述了外部可定义的可定义顺从子群。

Conclusion: 论文在NIP结构中建立了fsg群与可解释群的关系，解决了相关猜想，扩展了对可定义群的理解。

Abstract: We show that every fsg group externally definable in an NIP structure is
definably isomorphic to a group interpretable in it. Our proof relies on honest
definitions and a group chunk result reconstructing a hyper-definable group
from its multiplication given generically with respect to a translation
invariant definable Keisler measure on it. We obtain related results on
externally (type-)definable sets and groups, including a proof of a conjecture
of Eleftheriou on fsg groups in real closed valued fields, and a description of
externally definable, definably amenable subgroups of definable groups.

</details>


### [60] [A Galois correspondence for automorphism groups of structures with the Lascar Property](https://arxiv.org/abs/2506.23586)
*Gianluca Paolini,Federico Pisciotta*

Main category: math.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generalizing the $\omega$-categorical context, we introduce a notion, which
we call the Lascar Property, that allows for a fine analysis of the topological
isomorphisms between automorphism groups of countable structures satisfying
this property. In particular, under the assumption of the Lascar Property, we
exhibit a definable Galois correspondence between pointwise stabilizers of
finitely generated Galois algebraically closed subsets of $M$ and finitely
generated Galois algebraically closed subsets of $M$. We use this to
characterize the group of automorphisms of $\mathrm{Aut}(M)$, for $M$ the
countable saturated model of $\mathrm{ACF}_0$, $\mathrm{DCF}_0$, or the theory
of infinite $\mathrm{K}$-vector spaces, generalizing results of Evans $\&$
Lascar, and Konnerth, while at the same time subsuming the analysis from [11]
for $\omega$-categorical structures with weak elimination of imaginaries.

</details>


### [61] [Nonstandard Universes](https://arxiv.org/abs/2506.23654)
*Peter Ouwehand*

Main category: math.LO

TL;DR: 本文为初学者编写的关于非标准分析中集合论宇宙存在性与基本性质的笔记。


<details>
  <summary>Details</summary>
Motivation: 为初学者提供关于非标准分析中集合论宇宙的基本概念和性质的综合介绍。

Method: 假设读者具备一阶逻辑的基础知识，并通过附录A复习相关内容，从标准资料中整理和总结。

Result: 展示了集合论宇宙的存在性及其在非标准分析中的基本性质。

Conclusion: 本文为非标准分析的初学者提供了系统的集合论宇宙介绍，尽管内容并非原创，但对学习该领域具有重要参考价值。

Abstract: These notes are concerned with the existence and the basic properties of the
set-theoretic universes for nonstandard analysis, compiled by a beginner in the
subject. It assumes a basic background in first-order logic, though the
necessary material is revised in Appendix A. Needless to say, none of the
material presented here is original, but has been adapted from standard
sources.

</details>


<div id='math.RT'></div>

# math.RT [[Back]](#toc)

### [62] [Howe duality over finite fields II: explicit stable computation](https://arxiv.org/abs/2506.22983)
*Sophie Kriz*

Main category: math.RT

TL;DR: 论文通过分解有限辛群的一个振荡器表示，在稳定范围内明确描述了对一个辛子群和一个正交子群的限制，这些子群在G. Lusztig的分类中是中心化子。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于深入理解有限域上I型Howe对偶性，特别是在稳定范围内分解振荡器表示，以补充这一领域的理论框架。

Method: 论文采用G. Lusztig的有限Lie型群不可约表示分类方法，在稳定范围内分解振荡器表示到辛子群和正交子群的乘积上。

Result: 研究明确描述了振荡器表示在稳定范围内的分解形式，揭示了辛子群和正交子群作为中心化子的结构和关系。

Conclusion: 结论证明了在稳定范围内，有限辛群的振荡器表示的分解完全可由G. Lusztig的分类理论解释，进一步丰富了有限域上Howe对偶性的研究。

Abstract: In this second paper of a series dedicated to type I Howe duality for finite
fields, we explicitly decompose the restriction of an oscillator representation
of a finite symplectic group to the product of a symplectic and an orthogonal
subgroup which are each other's centralizers in terms of G. Lusztig's
classification of irreducible representations of finite groups of Lie type in
the two so-called stable ranges.

</details>


### [63] [Howe duality over finite fields III: full computation and the Gurevich-Howe conjectures](https://arxiv.org/abs/2506.22986)
*Sophie Kriz*

Main category: math.RT

TL;DR: 该论文是有限域上Howe对偶性的第三篇，完整描述了振荡表示在有限域上对偶对的限制，并构造了有限辛群和正交群的所有不可约表示，同时证明了Gurevich-Howe猜想。


<details>
  <summary>Details</summary>
Motivation: 研究有限域上Howe对偶性，目标是完整描述振荡表示对偶对的限制，并构造不可约表示，验证相关猜想。

Method: 通过描述振荡表示在有限域上对偶对的限制，采用归纳法构造所有不可约表示，并证明Gurevich-Howe猜想。

Result: 成功描述了振荡表示的限制，构造了所有不可约表示，并证明了Gurevich-Howe猜想。

Conclusion: 论文提供了有限辛群和正交群的不可约表示构造方法，并验证了相关猜想，为相关领域的研究提供了理论基础。

Abstract: In this third paper in a series on type I Howe duality for finite fields, we
give a complete description of the restriction of the oscillator representation
over a finite field to products of dual pairs of symplectic and orthogonal
groups in all cases that occur. In particular, this gives an inductive
construction of all irreducible complex representations of finite symplectic
and orthogonal groups. We also give a proof of the Gurevich-Howe rank and
exhaustion conjectures for type I pairs.

</details>


### [64] [Representation theory of hereditary artin algebras of finite representation type](https://arxiv.org/abs/2506.22987)
*Shiping Liu,Gordana Todorov*

Main category: math.RT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Let $H$ be a hereditary artin algebra of finite representation type. We first
determine all hammocks in the Auslander-Reiten quiver $\GaH$ of $\mmod H$, the
category of finitely generated left $H$-modules. This enables us to obtain an
effective method to construct $\GaH$ by simply viewing the ext-quiver of $H$.
As easy applications, we compute the numbers of non-isomorphic indecomposable
objects in $\mmod H$ and the associated cluster category $\mathscr{C}_H$, as
well as the nilpotencies of the radicals of $\mmod H\hspace{-.4pt},$
$\hspace{-.5pt} D^{\hspace{.5pt}b\hspace{-.6pt}}(\hspace{-.5pt}\mmod
H\hspace{-.5pt})$ and $\mathscr{C}_H$.

</details>


### [65] [On sporadic symmetry breaking operators for principal series representations of the de Sitter and Lorentz groups](https://arxiv.org/abs/2506.23064)
*Víctor Pérez-Valdés*

Main category: math.RT

TL;DR: 本文构造并分类了满足特定条件的所有微分对称破缺算子，证明了它们的局部性定理，并指出这些算子是稀疏的。


<details>
  <summary>Details</summary>
Motivation: 研究微分对称破缺算子在特定条件下的构造和分类问题，以及其局部性性质和稀疏性。

Method: 通过分析微分算子在主级数表示之间的作用，并在参数满足特定条件时构造和分类这些算子。

Result: 证明了所有满足条件的对称破缺算子都是微分算子，且这些算子是稀疏的，无法通过分布核的残差公式获得。

Conclusion: 本研究为微分对称破缺算子的分类和性质提供了一种新的理解，并揭示了其独特的稀疏性特征。

Abstract: In this paper, we construct and classify all differential symmetry breaking
operators $\mathbb{D}_{\lambda, \nu}^{N,m}: C^\infty(S^3,
\mathcal{V}_\lambda^{2N+1})\rightarrow C^\infty(S^2, \mathcal{L}_{m, \nu})$
between principal series representations with respect to the restriction
$SO_0(4,1) \downarrow SO_0(3,1)$ when the parameters satisfy the condition $|m|
> N$. In this case we also prove a localness theorem, namely, all symmetry
breaking operators between the principal series representations above are
necessarily differential operators. In addition, we show that all these
symmetry breaking operators are sporadic in the sense of T. Kobayashi, that is,
they cannot be obtained by residue formulas of distributional kernels.

</details>


### [66] [Gorenstein categories and separable equivalences](https://arxiv.org/abs/2506.23243)
*Guoqiang Zhao,Juxiang Sun*

Main category: math.RT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Let $\mathscr{C}$ be an additive subcategory of left $\Lambda$-modules, we
establish relations of the orthogonal classes of $\mathscr{C}$ and (co)res
$\widetilde{\mathscr{C}}$ under separable equivalences. As applications, we
obtain that the (one-sided) Gorenstein category and Wakamatsu tilting module
are preserved under separable equivalences. Furthermore, we discuss when
$G_{C}$-projective (injective) modules and Auslander (Bass) class with respect
to $C$ are invariant under separable equivalences.

</details>


### [67] [Rational structures on quivers and a generalization of Gelfand's equivalence](https://arxiv.org/abs/2506.23251)
*Fabian Januszewski*

Main category: math.RT

TL;DR: 本文引入了一种新的有理结构概念，用于研究可分离域扩展中的箭图表示，并通过建立范畴对偶关系推广了Gelfand等价性。其核心贡献是定义了有理箭图和étale K-species之间的等价性，并开发了一种称为unipotent stabilization的技术工具。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为箭图表示提供一个统一的有理结构框架，尤其是在可分离域扩展中，以推广Gelfand的经典等价性。

Method: 通过引入有理箭图和étale K-species的概念，并建立它们之间的范畴对偶关系。此外，开发了unipotent stabilization技术工具，用于构造从有理Harish-Chandra模到有理箭图表示的函子。

Result: 证明了从有理Harish-Chandra模到有理箭图表示的函子是一个等价关系。此外，该有理框架还使得Gelfand箭图的定义关系在特定域上变得多余。

Conclusion: 本文成功地将Gelfand等价性推广到有理设置中，并通过有理框架简化了某些箭图的表示问题。这在K-species的无关系语言中提供了一个新的视角。

Abstract: We introduce the notion of rational structure on a quiver and associated
representations to establish a coherent framework for studying quiver
representations in separable field extensions. This notion is linked to a
refinement of the notion of $K$-species, which we term \'etale $K$-species: We
establish a categorical anti-equivalence between the category of $K$-rational
quivers and that of \'etale $K$-species, which extends to an equivalence of
their respective representation categories. For $K$-rational quivers there is a
canonical notion of base change, which suggests a corresponding notion of base
change for (\'etale) $K$-species which we elaborate. As a primary application,
we generalize Gelfand's celebrated equivalence between certain blocks of
Harish-Chandra modules for $\mathrm{SL}_2(\mathbb{R})$ and representations of
the Gelfand quiver to a rational setting. To this end, we define a
$\mathbb{Q}$-rational structure on the Gelfand quiver and its representations.
A key technical tool, which we call unipotent stabilization, is developed to
construct the functor from certain rational Harish-Chandra modules to nilpotent
rational quiver representations. We prove that this functor is an equivalence.
A similar result is established for the cyclic quiver. A notable consequence of
this rational framework is that the defining relation of the Gelfand quiver
becomes superfluous when working over fields not containing $\sqrt{-1}$. This
allows us to recast our results in the language of $\mathbb{Q}$-species without
relations.

</details>


### [68] [Truncated symbols of differential symmetry breaking operators](https://arxiv.org/abs/2506.23599)
*Toshihisa Kubo,Víctor Pérez-Valdés*

Main category: math.RT

TL;DR: 论文介绍了截断符号$\mathrm{symb}_0(\mathbb{D})$，将其推广到非阿贝尔情形，并应用F方法的逆映射$\mathrm{symb}_0^{-1}$。在$SL(3,\mathbb{R})/B$上分类和构造了微分交织算子$\mathcal{D}$与Verma模同态$\varphi$，发现Cayley行列式$\mathrm{Cay}_m(x;y)$出现在算子系数中。最后分类了微分算子和同态的因子化恒等式，证明中二元Krawtchouk多项式$K_m(x;y$起关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究微分对称破缺算子的符号及其逆映射，推广到非阿贝尔情形，并寻找其在微分交织算子和Verma模同态构造中的应用。

Method: 引入截断符号$\mathrm{symb}_0(\mathbb{D})$，利用F方法的逆映射$\mathrm{symb}_0^{-1}$，在$SL(3,\mathbb{R})/B$上分类和构造微分交织算子$\mathcal{D}$与Verma模同态$\varphi$。

Result: 成功构造了五族算子，发现Cayley行列式$\mathrm{Cay}_m(x;y)$出现在算子系数中，并分类了微分算子和同态的因子化恒等式，证明中二元Krawtchouk多项式$K_m(x;y$起关键作用。

Conclusion: 论文通过截断符号的推广和F方法的应用，成功分类和构造了微分交织算子与Verma模同态，揭示了Cayley行列式在算子系数中的意外出现，并通过二元Krawtchouk多项式完成了证明。

Abstract: In this paper, we introduce the truncated symbol
$\mathrm{symb}_0(\mathbb{D})$ of a differential symmetry breaking operator
$\mathbb{D}$ between parabolically induced representations, which generalizes
the symbol $\mathrm{symb}(\mathbb{D})$ for abelian nilpotent radicals to the
non-abelian case. The inverse $\mathrm{symb}_0^{-1}$ of the truncated symbol
map $\mathrm{symb}_0$ enables one to perform a recipe of the F-method for any
nilpotent radical.
  As an application, we classify and construct differential intertwining
operators $\mathcal{D}$ on the full flag variety $SL(3,\mathbb{R})/B$ and
homomorphisms $\varphi$ between Verma modules. It turned out that,
surprisingly, Cayley continuants $\mathrm{Cay}_m(x;y)$ appeared in the
coefficients of one of the five families of operators that we constructed. At
the end, the factorization identities of the differential operators
$\mathcal{D}$ and homomorphisms $\varphi$ are also classified. Binary
Krawtchouk polynomials $K_m(x;y)$ play a key role in the proof.

</details>


### [69] [Quiver subrepresentations and the Derksen-Weyman saturation property](https://arxiv.org/abs/2506.23633)
*Velleda Baldoni,Michèle Vergne,Michael Walter*

Main category: math.RT

TL;DR: 利用Schofield对箭图表示的子表示维数向量的描述，直接证明了Derksen-Weyman的饱和性质。


<details>
  <summary>Details</summary>
Motivation: 为验证Derksen-Weyman饱和性质提供理论基础。

Method: 基于Schofield对箭图表示的子表示维数向量的描述，采用直接证明方法。

Result: 成功直接证明了Derksen-Weyman饱和性质。

Conclusion: 研究为理解箭图表示的饱和性质提供了新的理论支持。

Abstract: Using Schofield's characterization of the dimension vectors of general
subrepresentations of a representation of a quiver, we give a direct proof of
the Derksen-Weyman saturation property.

</details>


### [70] [Monomial arrow removal and the finitistic dimension conjecture](https://arxiv.org/abs/2506.23747)
*Karin Erdmann,Odysseas Giatagantzidis,Chrysostomos Psaroudakis,Øyvind Solberg*

Main category: math.RT

TL;DR: 本文介绍了用于有界箭图代数的单项式箭头移除操作，展示了一种新的简化技术用于确定有限维度的有限性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发一种新的简化技术，以确定有界箭图代数的有限维度。

Method: 方法包括在阿贝尔范畴分裂扩张理论中开发通用方法，并通过非交换Gr\"{o}bner基的应用验证特定条件。

Result: 结果表明，通过严格单项式箭头移除的分裂扩张满足该方法条件，并通过具体示例进行了说明。

Conclusion: 结论是该操作是一种有效的简化技术，可用于确定有限维度的有限性。

Abstract: In this paper, we introduce the monomial arrow removal operation for bound
quiver algebras, and show that it is a novel reduction technique for
determining the finiteness of the finitistic dimension. Our approach first
develops a general method within the theory of abelian category cleft
extensions. We then demonstrate that the specific conditions of this method are
satisfied by the cleft extensions arising from strict monomial arrow removals.
This crucial connection is established through the application of
non-commutative Gr\"{o}bner bases in the sense of Green. The theory is
illustrated with various concrete examples.

</details>


### [71] [Little $q$-Jacobi polynomials and symmetry breaking operators for $U_q(sl_2)$](https://arxiv.org/abs/2506.23848)
*Quentin Labriet,Loïc Poulain d'Andecy*

Main category: math.RT

TL;DR: 本文提出了量子群$U_q(sl_2)$在Verma模张量积上作用的显式公式，通过$q$-Jacobi多项式表达了全息算子，并对偶地构造了$q$-变形的Rankin--Cohen算子。


<details>
  <summary>Details</summary>
Motivation: 研究量子群$U_q(sl_2)$在Verma模上的交织算子及其显式表达，特别是通过$q$-多项式和非交换变量的方法，填补了理论中的空白。

Method: 利用多项式空间实现Verma模，并通过$q$-Jacobi多项式和$q$-Hahn多项式构建交织算子的显式公式。

Result: 成功构造了全息算子和对称破缺算子的显式表达，并揭示了与$q$-Hahn多项式的关系。

Conclusion: 论文通过非交换变量的方法和$q$-多项式理论，为量子群交织算子的研究提供了新的工具和视角。

Abstract: This paper presents explicit formulas for intertwining operators of the
quantum group $U_q(sl_2)$ acting on tensor products of Verma modules. We
express a first set of intertwining operators (the holographic operators) in
terms of the little $q$-Jacobi polynomials, and we obtain for the dual set (the
symmetry breaking operators) a $q$-deformation of the Rankin--Cohen operators.
The Verma modules are realised on polynomial spaces and, interestingly, we find
along the way the need to work with non-commuting variables. Explicit
connections are given with the Clebsch--Gordan coefficients of $U_q(sl_2)$
expressed with the $q$-Hahn polynomials.

</details>
