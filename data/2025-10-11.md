<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 9]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation](https://arxiv.org/abs/2510.07340)
*Yongzhi Li,Saining Zhang,Yibing Chen,Boying Li,Yanxin Zhang,Xiaoyu Du*

Main category: cs.GR

TL;DR: SpotDiff是一种新型学习型方法，通过提取特定主题特征并消除干扰因素，实现高效的个性化图像生成，同时保持高保真度和可控编辑。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的方法计算成本高，而基于学习的方法虽高效但易受干扰因素影响，导致特征纠缠。SpotDiff旨在解决这一问题。

Method: SpotDiff利用预训练的CLIP图像编码器和专用专家网络，通过特征空间的正交约束隔离主题身份，并结合SpotDiff10k数据集进行训练。

Result: 实验表明，SpotDiff在仅10k训练样本的情况下，实现了比现有方法更具鲁棒性的主题保留和可控编辑。

Conclusion: SpotDiff在高效性和保真度之间取得了平衡，是一种有前景的个性化图像生成方法。

Abstract: Personalized image generation aims to faithfully preserve a reference
subject's identity while adapting to diverse text prompts. Existing
optimization-based methods ensure high fidelity but are computationally
expensive, while learning-based approaches offer efficiency at the cost of
entangled representations influenced by nuisance factors. We introduce
SpotDiff, a novel learning-based method that extracts subject-specific features
by spotting and disentangling interference. Leveraging a pre-trained CLIP image
encoder and specialized expert networks for pose and background, SpotDiff
isolates subject identity through orthogonality constraints in the feature
space. To enable principled training, we introduce SpotDiff10k, a curated
dataset with consistent pose and background variations. Experiments demonstrate
that SpotDiff achieves more robust subject preservation and controllable
editing than prior methods, while attaining competitive performance with only
10k training samples.

</details>


### [2] [Local MAP Sampling for Diffusion Models](https://arxiv.org/abs/2510.07343)
*Shaorong Zhang,Rob Brekelmans,Greg Ver Steeg*

Main category: cs.GR

TL;DR: LMAPS是一种新的推理框架，通过局部MAP子问题解决优化问题，提供了概率解释，并在图像恢复和科学任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 逆问题的目标是最准确的恢复，而非覆盖后验，而现有优化方法缺乏明确的概率基础。LMAPS旨在提供一个统一的概率解释框架。

Method: LMAPS提出局部MAP子问题迭代解决的方法，结合概率解释的协方差近似、稳定性和可解释性的目标重构以及对非可微分算子的梯度近似。

Result: LMAPS在多种任务中表现优异，如运动去模糊、JPEG恢复和量化中提升≥2 dB，逆散射基准中提升>1.5 dB。

Conclusion: LMAPS为优化方法提供了统一的概率解释，并在实际应用中表现卓越，成为解决逆问题的有力工具。

Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to
inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the
goal of inverse problem solving is not to cover the posterior but to recover
the most accurate reconstruction, where optimization-based diffusion solvers
often excel despite lacking a clear probabilistic foundation. We introduce
Local MAP Sampling (LMAPS), a new inference framework that iteratively solving
local MAP subproblems along the diffusion trajectory. This perspective
clarifies their connection to global MAP estimation and DPS, offering a unified
probabilistic interpretation for optimization-based methods. Building on this
foundation, we develop practical algorithms with a probabilistically
interpretable covariance approximation, a reformulated objective for stability
and interpretability, and a gradient approximation for non-differentiable
operators. Across a broad set of image restoration and scientific tasks, LMAPS
achieves state-of-the-art performance, including $\geq 2$ dB gains on motion
deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on
inverse scattering benchmarks.

</details>


### [3] [Differentiable Variable Fonts](https://arxiv.org/abs/2510.07638)
*Kinjal Parikh,Danny M. Kaufman,David I. W. Levin,Alec Jacobson*

Main category: cs.GR

TL;DR: 通过可微分变量字体技术，实现了自动化字体设计和动画工作流，提升了创意表达的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 传统字体设计和动画需要艺术家手动调整，变量字体虽提供了参数化扩展，但仍未被充分利用。本文旨在通过可微分方法简化这一过程。

Method: 提出了一种紧凑的数学公式，将变量字体参数与底层矢量图形非线性映射连接起来，构建了可微分框架，支持梯度优化。

Result: 展示了四种应用：直接形状操纵、重叠感知建模、基于物理的文本动画和自动化字体设计优化。

Conclusion: 可微分变量字体技术为现代设计优化提供了新工具，开启了直观、高效的字体设计和动画工作流。

Abstract: Editing and animating text appearance for graphic designs, commercials, etc.
remain highly skilled tasks requiring detailed, hands on efforts from artists.
Automating these manual workflows requires balancing the competing goals of
maintaining legibility and aesthetics of text, while enabling creative
expression. Variable fonts, recent parametric extensions to traditional fonts,
offer the promise of new ways to ease and automate typographic design and
animation. Variable fonts provide custom constructed parameters along which
fonts can be smoothly varied. These parameterizations could then potentially
serve as high value continuous design spaces, opening the door to automated
design optimization tools. However, currently variable fonts are underutilized
in creative applications, because artists so far still need to manually tune
font parameters. Our work opens the door to intuitive and automated font design
and animation workflows with differentiable variable fonts. To do so we distill
the current variable font specification to a compact mathematical formulation
that differentiably connects the highly non linear, non invertible mapping of
variable font parameters to the underlying vector graphics representing the
text. This enables us to construct a differentiable framework, with respect to
variable font parameters, allowing us to perform gradient based optimization of
energies defined on vector graphics control points, and on target rasterized
images. We demonstrate the utility of this framework with four applications:
direct shape manipulation, overlap aware modeling, physics based text
animation, and automated font design optimization. Our work now enables
leveraging the carefully designed affordances of variable fonts with
differentiability to use modern design optimization technologies, opening new
possibilities for easy and intuitive typographic design workflows.

</details>


### [4] [NRRS: Neural Russian Roulette and Splitting](https://arxiv.org/abs/2510.07868)
*Haojie Jin,Jierui Ren,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 本文提出了一种专为波前路径追踪设计的俄罗斯轮盘赌与分割（RRS）新框架，解决了传统RRS方法与波前架构内存预分配和调度需求不兼容的问题。通过引入归一化RRS公式和有界路径计数，提高了执行的稳定性和内存效率。此外，还首次使用神经网络学习RRS因子，提出了NRRS和AID-NRRS两种模型，并通过Mix-Depth机制平衡计算成本与推断精度，显著提升了渲染质量和性能。


<details>
  <summary>Details</summary>
Motivation: 传统的俄罗斯轮盘赌与分割（RRS）方法因路径计数不可预测，无法兼容波前路径追踪这一高度并行的渲染架构的内存预分配和调度需求。本文旨在解决这一问题，并提出更高效的RRS实现方案。

Method: 1. 提出归一化RRS公式，限定路径计数以实现稳定和内存高效的执行；2. 创新性地使用神经网络学习RRS因子，设计NRRS和AID-NRRS两种模型；3. 引入Mix-Depth机制，根据路径深度自适应调节神经网络评估，平衡计算成本和推断精度。

Result: 实验表明，该方法在各种复杂场景中，无论是渲染质量还是性能，均优于传统启发式方法和近期的RRS技术。

Conclusion: 本文提出的RRS新框架及其神经网络实现，通过归一化设计和自适应机制，显著提高了波前路径追踪的效率和质量，为并行渲染架构中的RRS应用提供了新思路。

Abstract: We propose a novel framework for Russian Roulette and Splitting (RRS)
tailored to wavefront path tracing, a highly parallel rendering architecture
that processes path states in batched, stage-wise execution for efficient GPU
utilization. Traditional RRS methods, with unpredictable path counts, are
fundamentally incompatible with wavefront's preallocated memory and scheduling
requirements. To resolve this, we introduce a normalized RRS formulation with a
bounded path count, enabling stable and memory-efficient execution.
  Furthermore, we pioneer the use of neural networks to learn RRS factors,
presenting two models: NRRS and AID-NRRS. At a high level, both feature a
carefully designed RRSNet that explicitly incorporates RRS normalization, with
only subtle differences in their implementation. To balance computational cost
and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism
that adaptively regulates neural evaluation, further improving efficiency.
  Extensive experiments demonstrate that our method outperforms traditional
heuristics and recent RRS techniques in both rendering quality and performance
across a variety of complex scenes.

</details>


### [5] [Variable-Rate Texture Compression: Real-Time Rendering with JPEG](https://arxiv.org/abs/2510.08166)
*Elias Kristmann,Markus Schütz,Michael Wimmer*

Main category: cs.GR

TL;DR: 该论文研究了在现代GPU上使用JPEG格式进行可变速率纹理压缩的可行性，并与固定速率压缩方法BC1和ASTC进行了比较。结果表明，JPEG在质量和压缩率上优于BC1，与ASTC相当，且渲染时间仅增加不到0.3毫秒。


<details>
  <summary>Details</summary>
Motivation: 尽管可变速率压缩图像格式（如JPEG）被广泛用于高效编码图像，但由于实时渲染的特殊需求（如对单个纹理元素的随机访问），这类格式尚未应用于实时渲染。论文旨在探索JPEG在现代GPU上的应用潜力。

Method: 论文采用延迟渲染管线，识别每帧所需的纹理块子集，解码这些块并为帧缓冲区像素着色。使用JPEG格式进行比较，并与固定速率压缩方法BC1和ASTC进行对比。

Result: 尽管JPEG方法需要额外的约0.17位每像素，但其在质量和压缩率上显著优于BC1，并与ASTC相当或优于ASTC。在RTX 4090上，JPEG渲染管线仅增加不到0.3毫秒的渲染时间。

Conclusion: 研究表明，即使在VR等高性能需求场景中，现代GPU上采用复杂的可变速率压缩方案是可行的。JPEG格式在质量和效率上的表现使其成为实时渲染的可行选择。

Abstract: Although variable-rate compressed image formats such as JPEG are widely used
to efficiently encode images, they have not found their way into real-time
rendering due to special requirements such as random access to individual
texels. In this paper, we investigate the feasibility of variable-rate texture
compression on modern GPUs using the JPEG format, and how it compares to the
GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred
rendering pipeline, we are able to identify the subset of blocks that are
needed for a given frame, decode these, and colorize the framebuffer's pixels.
Despite the additional $\sim$0.17 bit per pixel that we require for our
approach, JPEG maintains significantly better quality and compression rates
compared to BC1, and depending on the type of image, outperforms or competes
with ASTC. The JPEG rendering pipeline increases rendering duration by less
than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate
compression schemes are feasible on modern GPUs, even in VR. Source code and
data sets are available at: https://github.com/elias1518693/jpeg_textures

</details>


### [6] [SViM3D: Stable Video Material Diffusion for Single Image 3D Generation](https://arxiv.org/abs/2510.08271)
*Andreas Engelhardt,Mark Boss,Vikram Voletti,Chun-Han Yao,Hendrik P. A. Lensch,Varun Jampani*

Main category: cs.GR

TL;DR: SViM3D是一个通过单张图像预测多视角一致的基于物理的渲染（PBR）材料的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型虽能从单张图像高效重建3D物体，但反射属性仍由简单材料模型表示或需额外步骤估算，限制了重新照明和外观编辑的控制。

Method: 扩展了潜在视频扩散模型，基于显式相机控制联合输出空间变化的PBR参数和表面法线，并引入多种机制提升质量。

Result: 在多个以物体为中心的数据集上，展示了最先进的重新照明和新视角合成性能。

Conclusion: 该方法适用于多样化输入，能生成可用于AR/VR、电影、游戏等视觉媒体的可重新照明3D资产。

Abstract: We present Stable Video Materials 3D (SViM3D), a framework to predict
multi-view consistent physically based rendering (PBR) materials, given a
single image. Recently, video diffusion models have been successfully used to
reconstruct 3D objects from a single image efficiently. However, reflectance is
still represented by simple material models or needs to be estimated in
additional steps to enable relighting and controlled appearance edits. We
extend a latent video diffusion model to output spatially varying PBR
parameters and surface normals jointly with each generated view based on
explicit camera control. This unique setup allows for relighting and generating
a 3D asset using our model as neural prior. We introduce various mechanisms to
this pipeline that improve quality in this ill-posed setting. We show
state-of-the-art relighting and novel view synthesis performance on multiple
object-centric datasets. Our method generalizes to diverse inputs, enabling the
generation of relightable 3D assets useful in AR/VR, movies, games and other
visual media.

</details>


### [7] [Spectral Prefiltering of Neural Fields](https://arxiv.org/abs/2510.08394)
*Mustafa B. Yaldiz,Ishit Mehta,Nithin Raghavan,Andreas Meuleman,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出了一种简单而强大的方法来优化神经网络场，支持单次前向传递中的预滤波，提高了效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络场通常在单一固定分辨率下运行，限制了其应用灵活性。本文旨在解决这一问题，通过创新的方法实现多分辨率滤波。

Method: 方法包括：(1)在输入域进行卷积滤波，通过傅里叶特征嵌入的频率响应分析缩放；(2)支持高斯滤波之外的参数化滤波；(3)使用单样本蒙特卡罗估计训练神经网络场。

Result: 实验结果表明，该方法在训练和推理阶段均快速有效，且在神经网络场滤波方面优于现有方法，提供了定量和定性的改进。

Conclusion: 本文提出的方法不仅提高了神经网络场的灵活性，还为多分辨率滤波提供了一种高效的解决方案。

Abstract: Neural fields excel at representing continuous visual signals but typically
operate at a single, fixed resolution. We present a simple yet powerful method
to optimize neural fields that can be prefiltered in a single forward pass. Key
innovations and features include: (1) We perform convolutional filtering in the
input domain by analytically scaling Fourier feature embeddings with the
filter's frequency response. (2) This closed-form modulation generalizes beyond
Gaussian filtering and supports other parametric filters (Box and Lanczos) that
are unseen at training time. (3) We train the neural field using single-sample
Monte Carlo estimates of the filtered signal. Our method is fast during both
training and inference, and imposes no additional constraints on the network
architecture. We show quantitative and qualitative improvements over existing
methods for neural-field filtering.

</details>


### [8] [Splat the Net: Radiance Fields with Splattable Neural Primitives](https://arxiv.org/abs/2510.08491)
*Xilong Zhou,Bao-Huy Nguyen,Loïc Magne,Vladislav Golyanik,Thomas Leimkühler,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出了一种新的体积表示方法，结合了神经模型的表现力和基于图元的快速渲染效率，称为可撒布神经图元。


<details>
  <summary>Details</summary>
Motivation: 当前的3D场景外观建模方法中，神经辐射场表现力强但渲染成本高，而基于图元的方法（如3D高斯泼溅）虽然实时性强但表现力不足。本文提出了一种新的表示方法，旨在兼顾两者优势。

Method: 通过引入可撒布神经图元，每个图元编码一个有界的神经密度场，并由浅层神经网络参数化。该方法支持精确的解析解计算视线积分，无需昂贵的光线行进。

Result: 在新视角合成基准测试中，该方法在质量和速度上与3D高斯泼溅相当，但使用的图元数量减少了10倍，参数减少了6倍。

Conclusion: 提出的表示方法直接实现了高效和高表现力的平衡，无需依赖复杂的控制或适配框架。

Abstract: Radiance fields have emerged as a predominant representation for modeling 3D
scene appearance. Neural formulations such as Neural Radiance Fields provide
high expressivity but require costly ray marching for rendering, whereas
primitive-based methods such as 3D Gaussian Splatting offer real-time
efficiency through splatting, yet at the expense of representational power.
Inspired by advances in both these directions, we introduce splattable neural
primitives, a new volumetric representation that reconciles the expressivity of
neural models with the efficiency of primitive-based splatting. Each primitive
encodes a bounded neural density field parameterized by a shallow neural
network. Our formulation admits an exact analytical solution for line
integrals, enabling efficient computation of perspectively accurate splatting
kernels. As a result, our representation supports integration along view rays
without the need for costly ray marching. The primitives flexibly adapt to
scene geometry and, being larger than prior analytic primitives, reduce the
number required per scene. On novel-view synthesis benchmarks, our approach
matches the quality and speed of 3D Gaussian Splatting while using $10\times$
fewer primitives and $6\times$ fewer parameters. These advantages arise
directly from the representation itself, without reliance on complex control or
adaptation frameworks. The project page is
https://vcai.mpi-inf.mpg.de/projects/SplatNet/.

</details>


### [9] [X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](https://arxiv.org/abs/2510.08530)
*Zhitong Huang,Mohan Zhang,Renhan Wang,Rui Tang,Hao Zhu,Jing Liao*

Main category: cs.GR

TL;DR: X2Video是首個基於RGB擴散模型生成逼真視頻的系統，支持多模態控制（參考圖像和文本提示）和內在通道（如反照率、法線等）引導。


<details>
  <summary>Details</summary>
Motivation: 現有視頻生成技術難以精確控制顏色、材料、幾何和光照等內在屬性，且缺乏多模態直觀控制。X2Video旨在解決這些問題。

Method: X2Video擴展了XRGB模型，引入混合自注意力確保時間一致性，並開發遮蔽交叉注意力處理全局和局部文本提示。還採用遞歸採樣生成長視頻。

Result: X2Video能生成長時間一致的逼真視頻，並支持通過參數調整編輯顏色、材料、幾何和光照，效果在定性和定量評估中表現優異。

Conclusion: X2Video通過多模態控制和內在通道引導，實現了高效且精確的視頻生成和編輯，為視頻生成領域提供了新的解決方案。

Abstract: We present X2Video, the first diffusion model for rendering photorealistic
videos guided by intrinsic channels including albedo, normal, roughness,
metallicity, and irradiance, while supporting intuitive multi-modal controls
with reference images and text prompts for both global and local regions. The
intrinsic guidance allows accurate manipulation of color, material, geometry,
and lighting, while reference images and text prompts provide intuitive
adjustments in the absence of intrinsic information. To enable these
functionalities, we extend the intrinsic-guided image generation model XRGB to
video generation by employing a novel and efficient Hybrid Self-Attention,
which ensures temporal consistency across video frames and also enhances
fidelity to reference images. We further develop a Masked Cross-Attention to
disentangle global and local text prompts, applying them effectively onto
respective local and global regions. For generating long videos, our novel
Recursive Sampling method incorporates progressive frame sampling, combining
keyframe prediction and frame interpolation to maintain long-range temporal
consistency while preventing error accumulation. To support the training of
X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154
rooms from 295 interior scenes, complete with reliable ground-truth intrinsic
channel sequences and smooth camera trajectories. Both qualitative and
quantitative evaluations demonstrate that X2Video can produce long, temporally
consistent, and photorealistic videos guided by intrinsic conditions.
Additionally, X2Video effectively accommodates multi-modal controls with
reference images, global and local text prompts, and simultaneously supports
editing on color, material, geometry, and lighting through parametric tuning.
Project page: https://luckyhzt.github.io/x2video

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Type, Ability, and Effect Systems: Perspectives on Purity, Semantics, and Expressiveness](https://arxiv.org/abs/2510.07582)
*Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 本文提出了一种基于语义的纯度定义，并引入表达性度量标准，比较了不同类型系统在表达性上的优劣，最终提出了一种结合类型、能力和效应系统优势的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如单子、类型与效应系统、能力系统）在强制分离纯计算与不纯效应之间存在精度与可用性的矛盾，本文旨在提升评估这些系统的标准。

Method: 提出了基于上下文等价性的语义纯度定义，并通过完整性度量比较了最小效应和能力系统的表达性。

Result: 研究表明，最小效应和能力系统在表达性上不可比较，且结合类型、能力和效应系统可以整合各自的优势。

Conclusion: 本文的综合方法为效应类型系统提供了一种新的研究方向，并开发了逻辑关系以支持纯度证明。

Abstract: Programming benefits from a clear separation between pure, mathematical
computation and impure, effectful interaction with the world. Existing
approaches to enforce this separation include monads, type-and-effect systems,
and capability systems. All share a tension between precision and usability,
and each one has non-obvious strengths and weaknesses.
  This paper aims to raise the bar in assessing such systems. First, we propose
a semantic definition of purity, inspired by contextual equivalence, as a
baseline independent of any specific typing discipline. Second, we propose that
expressiveness should be measured by the degree of completeness, i.e., how many
semantically pure terms can be typed as pure. Using this measure, we focus on
minimal meaningful effect and capability systems and show that they are
incomparable, i.e., neither subsumes the other in terms of expressiveness.
  Based on this result, we propose a synthesis and show that type, ability, and
effect systems combine their respective strengths while avoiding their
weaknesses. As part of our formal model, we provide a logical relation to
facilitate proofs of purity and other properties for a variety of effect typing
disciplines.

</details>


### [11] [The Functional Machine Calculus III: Control](https://arxiv.org/abs/2510.07851)
*Willem Heijltjes*

Main category: cs.PL

TL;DR: 本文提出了一种新的方法——功能机器演算，用于统一命令式和函数式编程范式，扩展了lambda演算以嵌入计算效果和控制流操作。


<details>
  <summary>Details</summary>
Motivation: 旨在统一命令式和函数式编程范式，并提供一种能够嵌入计算效果和控制流操作的模型。

Method: 通过扩展lambda演算，引入多操作数栈和继续栈来建模效果和控制流，使用简化的Krivine机器定义操作语义。

Result: 该演算支持融合归约关系和简单类型系统，确保机器终止和强规范化归约，并将这些特性传递给嵌入的命令式语言。

Conclusion: 功能机器演算提供了一个统一的函数-命令式计算模型，支持简单类型、直观的操作语义和融合的归约语义。

Abstract: The Functional Machine Calculus (Heijltjes 2022) is a new approach to
unifying the imperative and functional programming paradigms. It extends the
lambda-calculus, preserving the key features of confluent reduction and typed
termination, to embed computational effects, evaluation strategies, and control
flow operations. The first instalment modelled sequential higher-order
computation with global store, input/output, probabilities, and
non-determinism, and embedded both the call-by-name and call-by-value
lambda-calculus, as well as Moggi's computational metalanguage and Levy's
call-by-push-value. The present paper extends the calculus from sequential to
branching and looping control flow. This allows the faithful embedding of a
minimal but complete imperative language, including conditionals, exception
handling, and iteration, as well as constants and algebraic data types.
  The calculus is defined through a simple operational semantics, extending the
(simplified) Krivine machine for the lambda-calculus with multiple operand
stacks to model effects and a continuation stack to model sequential,
branching, and looping computation. It features a confluent reduction relation
and a system of simple types that guarantees termination of the machine and
strong normalization of reduction (in the absence of iteration). These
properties carry over to the embedded imperative language, providing a unified
functional-imperative model of computation that supports simple types, a direct
and intuitive operational semantics, and a confluent reduction semantics.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [12] [BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats](https://arxiv.org/abs/2510.07430)
*Yang Jiao,Guanpu Chen,Yiguang Hong*

Main category: cs.GT

TL;DR: 本文提出了一种名为BG-FlipIn的贝叶斯游戏框架，用于研究具有不同偏好的内部人员的APT问题，并分析了防御者的决策指导。


<details>
  <summary>Details</summary>
Motivation: 研究高级持续性威胁（APT）中内部人员不同偏好的不确定性，并提供一个框架来应对这一问题。

Method: 提出了BG-FlipIn框架，一种贝叶斯游戏模型，用于分析FlipIt-内部人员模型，并计算了闭式贝叶斯纳什均衡表达式。

Result: 发现了与防御者移动率和成本以及内部人员偏好相关的APT现象，并在不同参数条件下提供了防御者的决策指导。

Conclusion: BG-FlipIn框架使防御者能够一致地做出决策，而无需频繁检测内部人员具体偏好或调整策略。

Abstract: In this paper, we study advanced persistent threats (APT) with an insider who
has different preferences. To address the uncertainty of the insider's
preference, we propose the BG-FlipIn: a Bayesian game framework for
FlipIt-insider models with an investigation on malicious, inadvertent, or
corrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium
expression and further obtain three edge cases with deterministic insiders
corresponding to their Nash Equilibrium expressions. On this basis, we further
discover several phenomena in APT related to the defender's move rate and cost,
as well as the insider's preferences. We then provide decision-making guidance
for the defender, given different parametric conditions. Two applications
validate that our BG-FlipIn framework enables the defender to make decisions
consistently, avoiding detecting the insider's concrete preference or adjusting
its strategy frequently.

</details>


### [13] [Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices](https://arxiv.org/abs/2510.07572)
*Jesse D Wei,Guo Wei*

Main category: cs.GT

TL;DR: 本研究设计了确定性算法，用于在不均匀伯努利试验中近似计算Shapley值，具有线性或二次时间复杂性，并提供了严格的误差分析。


<details>
  <summary>Details</summary>
Motivation: 传统计算Shapley值的方法存在指数计算复杂性或蒙特卡洛采样性能不稳定的问题，因此需要设计更高效的确定性算法。

Method: 研究采用了不均匀伯努利试验的确定性算法，并结合严格的误差分析，同时补充了Shapley原始证明的方法，使用了定积分和组合分析。

Result: 设计的算法能够在线性或二次时间内近似计算Shapley值，并在附录中展示了二项式定理和Beta函数在证明中的作用。

Conclusion: 本研究填补了Shapley值计算的效率和时间复杂性问题的空白，并提供了一种严格的证明方法。

Abstract: Suppose that $n$ computer devices are to be connected to a network via
inhomogeneous Bernoulli trials. The Shapley value of a device quantifies how
much the network's value increases due to the participation of that device.
Characteristic functions of such games are naturally taken as the belief
function (containment function) and Choquet capacity (hitting probability) of a
random set (random network of devices).
  Traditionally, the Shapley value is either calculated as the expected
marginal contribution over all possible coalitions (subnetworks), which results
in exponential computational complexity, or approximated by the Monte Carlo
sampling technique, where the performance is highly dependent on the stochastic
sampling process.
  The purpose of this study is to design deterministic algorithms for games
formulated via inhomogeneous Bernoulli trials that approximate the Shapley
value in linear or quadratic time, with rigorous error analysis (Sections 3 and
4). Additionally, we provide a review of relevant literature on existing
calculation methods in Remark 3.1 and Appendix I.
  A further goal is to supplement Shapley's original proof by deriving the
Shapley value formula using a rigorous approach based on definite integrals and
combinatorial analysis. This method explicitly highlights the roles of the
Binomial Theorem and the Beta function in the proof, addressing a gap in
Shapley's work (Appendix II).

</details>


### [14] [Extending Games beyond the Finite Horizon](https://arxiv.org/abs/2510.08453)
*Kiri Sakahara,Takashi Sato*

Main category: cs.GT

TL;DR: 本文认为有限视界悖论源于标准数系在建模无限认知时的局限性，提出基于替代集合论的新框架，通过不同拓扑解决悖论。


<details>
  <summary>Details</summary>
Motivation: 有限视界悖论显示标准数系无法模拟人类对无限的认知，需新方法解决此类悖论。

Method: 提出基于替代集合论的框架，利用不同拓扑表示认知视角，定义不可区分等价关系。

Result: 框架为新直觉子博弈完美均衡提供依据，并解决长期存在的悖论，如Selten连锁店悖论。

Conclusion: 通过基于人类认知的数学基础，扩展了博弈论在长期场景中的解释力。

Abstract: This paper argues that the finite horizon paradox, where game theory
contradicts intuition, stems from the limitations of standard number systems in
modelling the cognitive perception of infinity. To address this issue, we
propose a new framework based on Alternative Set Theory (AST). This framework
represents different cognitive perspectives on a long history of events using
distinct topologies. These topologies define an indiscernibility equivalence
that formally treats huge, indistinguishable quantities as equivalent. This
offers criterion-dependent resolutions to long-standing paradoxes, such as
Selten's chain store paradox and Rosenthal's centipede game. Our framework
reveals new intuitive subgame perfect equilibria, the characteristics of which
depend on the chosen temporal perspective and payoff evaluation. Ultimately, by
grounding its mathematical foundation in different modes of human cognition,
our work expands the explanatory power of game theory for long-horizon
scenarios.

</details>
