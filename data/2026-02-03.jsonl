{"id": "2602.00898", "categories": ["cs.GR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.00898", "abs": "https://arxiv.org/abs/2602.00898", "authors": ["Behrooz Zarebavami", "Ahmed H. Mahmoud", "Ana Dodik", "Changcheng Yuan", "Serban D. Porumbescu", "John D. Owens", "Maryam Mehri Dehnavi", "Justin Solomon"], "title": "Fast Sparse Matrix Permutation for Mesh-Based Direct Solvers", "comment": null, "summary": "We present a fast sparse matrix permutation algorithm tailored to linear systems arising from triangle meshes. Our approach produces nested-dissection-style permutations while significantly reducing permutation runtime overhead. Rather than enforcing strict balance and separator optimality, the algorithm deliberately relaxes these design decisions to favor fast partitioning and efficient elimination-tree construction. Our method decomposes permutation into patch-level local orderings and a compact quotient-graph ordering of separators, preserving the essential structure required by sparse Cholesky factorization while avoiding its most expensive components. We integrate our algorithm into vendor-maintained sparse Cholesky solvers on both CPUs and GPUs. Across a range of graphics applications, including single factorizations, repeated factorizations, our method reduces permutation time and improves the sparse Cholesky solve performance by up to 6.27x."}
{"id": "2602.01589", "categories": ["cs.GR", "cs.CV", "cs.LG", "math.AG"], "pdf": "https://arxiv.org/pdf/2602.01589", "abs": "https://arxiv.org/abs/2602.01589", "authors": ["Zhehao Xu", "Lok Ming Lui"], "title": "Genus-0 Surface Parameterization using Spherical Beltrami Differentials", "comment": null, "summary": "Spherical surface parameterization is a fundamental tool in geometry processing and imaging science. For a genus-0 closed surface, many efficient algorithms can map the surface to the sphere; consequently, a broad class of task-driven genus-0 mapping problems can be reduced to constructing a high-quality spherical self-map. However, existing approaches often face a trade-off between satisfying task objectives (e.g., landmark or feature alignment), maintaining bijectivity, and controlling geometric distortion. We introduce the Spherical Beltrami Differential (SBD), a two-chart representation of quasiconformal self-maps of the sphere, and establish its correspondence with spherical homeomorphisms up to conformal automorphisms. Building on the Spectral Beltrami Network (SBN), we propose a neural optimization framework BOOST that optimizes two Beltrami fields on hemispherical stereographic charts and enforces global consistency through explicit seam-aware constraints. Experiments on large-deformation landmark matching and intensity-based spherical registration demonstrate the effectiveness of our proposed framework. We further apply the method to brain cortical surface registration, aligning sulcal landmarks and jointly matching cortical sulci depth maps, showing improved task fidelity with controlled distortion and robust bijective behavior."}
{"id": "2602.01748", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2602.01748", "abs": "https://arxiv.org/abs/2602.01748", "authors": ["Seokhwan Yang", "Boram Yoon", "Seoyoung Kang", "Hail Song", "Woontack Woo"], "title": "OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR", "comment": "Accepted as an IEEE TVCG paper at IEEE VR 2026 (journal track)", "summary": "We propose OFERA, a novel framework for real-time expression control of photorealistic Gaussian head avatars for VR headset users. Existing approaches attempt to recover occluded facial expressions using additional sensors or internal cameras, but sensor-based methods increase device weight and discomfort, while camera-based methods raise privacy concerns and suffer from limited access to raw data. To overcome these limitations, we leverage the blendshape signals provided by commercial VR headsets as expression inputs. Our framework consists of three key components: (1) Blendshape Distribution Alignment (BDA), which applies linear regression to align the headset-provided blendshape distribution to a canonical input space; (2) an Expression Parameter Mapper (EPM) that maps the aligned blendshape signals into an expression parameter space for controlling Gaussian head avatars; and (3) a Mapper-integrated Avatar (MiA) that incorporates EPM into the avatar learning process to ensure distributional consistency. Furthermore, OFERA establishes an end-to-end pipeline that senses and maps expressions, updates Gaussian avatars, and renders them in real-time within VR environments. We show that EPM outperforms existing mapping methods on quantitative metrics, and we demonstrate through a user study that the full OFERA framework enhances expression fidelity while preserving avatar realism. By enabling real-time and photorealistic avatar expression control, OFERA significantly improves telepresence in VR communication. A project page is available at https://ysshwan147.github.io/projects/ofera/."}
{"id": "2602.01720", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.01720", "abs": "https://arxiv.org/abs/2602.01720", "authors": ["Peisen Yao", "Zinan Gu", "Qingkai Shi"], "title": "Phoenix: A Modular and Versatile Framework for C/C++ Pointer Analysis", "comment": null, "summary": "We present Phoenix, a modular pointer analysis framework for C/C++ that unifies multiple state-of-the-art alias analysis algorithms behind a single, stable interface. Phoenix addresses the fragmentation of today's C/C++ pointer analysis ecosystem by cleanly separating IR construction, constraint generation, solver backends, and client-facing queries, making analyses easy to compare, swap, and compose while exposing explicit precision-performance trade-offs. We evaluate Phoenix against SVF under two representative configurations: a flow- and context-insensitive setting and a more precise flow- and context-sensitive setting, on 28 GNU coreutils programs. Phoenix delivers robust speedups in the baseline configuration (up to 2.88x) and remains competitive, and often faster, even in the stronger precision regime (up to 2.91x), without a systematic runtime penalty. In production, Phoenix serves as the analysis substrate for static analysis and fuzzing tools that have uncovered hundreds of new bugs and enabled deployments reporting more than 1000 bugs found in an industrial toolchain."}
{"id": "2602.00771", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00771", "abs": "https://arxiv.org/abs/2602.00771", "authors": ["Matteo Bollini", "Francesco Bacchiocchi", "Samuel Coutts", "Matteo Castiglioni", "Alberto Marchesi"], "title": "Learning in Bayesian Stackelberg Games With Unknown Follower's Types", "comment": null, "summary": "We study online learning in Bayesian Stackelberg games, where a leader repeatedly interacts with a follower whose unknown private type is independently drawn at each round from an unknown probability distribution. The goal is to design algorithms that minimize the leader's regret with respect to always playing an optimal commitment computed with knowledge of the game. We consider, for the first time to the best of our knowledge, the most realistic case in which the leader does not know anything about the follower's types, i.e., the possible follower payoffs. This raises considerable additional challenges compared to the commonly studied case in which the payoffs of follower types are known. First, we prove a strong negative result: no-regret is unattainable under action feedback, i.e., when the leader only observes the follower's best response at the end of each round. Thus, we focus on the easier type feedback model, where the follower's type is also revealed. In such a setting, we propose a no-regret algorithm that achieves a regret of $\\widetilde{O}(\\sqrt{T})$, when ignoring the dependence on other parameters."}
{"id": "2602.00859", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.00859", "abs": "https://arxiv.org/abs/2602.00859", "authors": ["Anurag Satpathy", "Arindam Khanda", "Chittaranjan Swain", "Sajal K. Das"], "title": "ReACT-TTC: Capacity-Aware Top Trading Cycles for Post-Choice Reassignment in Shared CPS", "comment": "Accepted in the 17th ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS), Saint Mao, France, May 11-14, 2026", "summary": "Cyber-physical systems (CPS) increasingly manage shared physical resources in the presence of human decision-making, where system-assigned actions must be executed by users or agents in the physical world. A fundamental challenge in such settings is user non-compliance: individuals may deviate from assigned resources due to personal preferences or local information, degrading system efficiency and requiring light-weight reassignment schemes. This paper proposes a post-deviation reassignment framework for shared-resource CPS that operates on top of any initial allocation algorithm and is invoked only when users diverge from prescribed assignments. We advance the Top-Trading-Cycle (TTC) mechanism to enable voluntary, preference-driven exchanges after deviation events, and extend it to handle many-to-one resource capacities and unassigned resource conditions that are not supported by the classical TTC. We formalize these structural cases, introduce capacity-aware cycle-detection rules, and prove termination along with the preservation of Pareto efficiency, individual rationality, and strategy-proofness. A Prospect-Theoretic (PT) preference model is further incorporated to capture realistic user satisfaction behavior. We demonstrate the applicability of this framework on an electric-vehicle (EV) charging case study using real-world data, where it increases user satisfaction and effective assignment quality under non-compliant behavior."}
{"id": "2602.01048", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.01048", "abs": "https://arxiv.org/abs/2602.01048", "authors": ["Yuhang Guo", "Houyu Zhou"], "title": "Minimizing Inequity in Facility Location Games", "comment": "Accepted in AAAI 2026", "summary": "This paper studies the problem of minimizing group-level inequity in facility location games on the real line, where agents belong to different groups and may act strategically. We explore a fairness-oriented objective that minimizes the maximum group effect introduced by Marsh and Schilling (1994). Each group's effect is defined as its total or maximum distance to the nearest facility, weighted by group-specific factors. We show that this formulation generalizes several prominent optimization objectives, including the classical utilitarian (social cost) and egalitarian (maximum cost) objectives, as well as two group-fair objectives, maximum total and average group cost. In order to minimize the maximum group effect, we first propose two novel mechanisms for the single-facility case, the BALANCED mechanism and the MAJOR-PHANTOM mechanism. Both are strategyproof and achieve tight approximation guarantees under distinct formulations of the maximum group effect objective. Our mechanisms not only close the existing gap in approximation bounds for group-fairness objectives identified by Zhou, Li, and Chan (2022), but also unify many classical truthful mechanisms within a broader fairness-aware framework. For the two-facility case, we revisit and extend the classical endpoint mechanism to our generalized setting and demonstrate that it provides tight bounds for two distinct maximum group effect objectives."}
{"id": "2602.01066", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2602.01066", "abs": "https://arxiv.org/abs/2602.01066", "authors": ["Shipra Agrawal", "Yiding Feng", "Wei Tang"], "title": "Simple and Robust Quality Disclosure: The Power of Quantile Partition", "comment": null, "summary": "Quality information on online platforms is often conveyed through simple, percentile-based badges and tiers that remain stable across different market environments. Motivated by this empirical evidence, we study robust quality disclosure in a market where a platform commits to a public disclosure policy mapping the seller's product quality into a signal, and the seller subsequently sets a downstream monopoly price. Buyers have heterogeneous private types and valuations that are linear in quality. We evaluate a disclosure policy via a minimax competitive ratio: its worst-case revenue relative to the Bayesian-optimal disclosure-and-pricing benchmark, uniformly over all prior quality distributions, type distributions, and admissible valuations.\n  Our main results provide a sharp theoretical justification for quantile-partition disclosure. For K-quantile partition policies, we fully characterize the robust optimum: the optimal worst-case ratio is pinned down by a one-dimensional fixed-point equation and the optimal thresholds follow a backward recursion. We also give an explicit formula for the robust ratio of any quantile partition as a simple \"max-over-bins\" expression, which explains why the robust-optimal partition allocates finer resolution to upper quantiles and yields tight guarantees such as 1 + 1/K for uniform percentile buckets. In contrast, we show a robustness limit for finite-signal monotone (quality-threshold) partitions, which cannot beat a factor-2 approximation. Technically, our analysis reduces the robust quality disclosure to a robust disclosure design program by establishing a tight functional characterization of all feasible indirect revenue functions."}
{"id": "2602.01568", "categories": ["cs.GT", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.01568", "abs": "https://arxiv.org/abs/2602.01568", "authors": ["Hamzah Khan", "Dong Ho Lee", "Jingqi Li", "Tianyu Qiu", "Christian Ellis", "Jesse Milzman", "Wesley Suttle", "David Fridovich-Keil"], "title": "Efficiently Solving Mixed-Hierarchy Games with Quasi-Policy Approximations", "comment": null, "summary": "Multi-robot coordination often exhibits hierarchical structure, with some robots' decisions depending on the planned behaviors of others. While game theory provides a principled framework for such interactions, existing solvers struggle to handle mixed information structures that combine simultaneous (Nash) and hierarchical (Stackelberg) decision-making. We study N-robot forest-structured mixed-hierarchy games, in which each robot acts as a Stackelberg leader over its subtree while robots in different branches interact via Nash equilibria. We derive the Karush-Kuhn-Tucker (KKT) first-order optimality conditions for this class of games and show that they involve increasingly high-order derivatives of robots' best-response policies as the hierarchy depth grows, rendering a direct solution intractable. To overcome this challenge, we introduce a quasi-policy approximation that removes higher-order policy derivatives and develop an inexact Newton method for efficiently solving the resulting approximated KKT systems. We prove local exponential convergence of the proposed algorithm for games with non-quadratic objectives and nonlinear constraints. The approach is implemented in a highly optimized Julia library (MixedHierarchyGames.jl) and evaluated in simulated experiments, demonstrating real-time convergence for complex mixed-hierarchy information structures."}
{"id": "2602.02254", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.02254", "abs": "https://arxiv.org/abs/2602.02254", "authors": ["Samuel McCauley", "Benjamin Moseley", "Helia Niaparast", "Shikha Singh"], "title": "Stable Matching with Predictions: Robustness and Efficiency under Pruned Preferences", "comment": null, "summary": "In this paper, we study the fundamental problem of finding a stable matching in two-sided matching markets. In the classic variant, it is assumed that both sides of the market submit a ranked list of all agents on the other side. However, in large matching markets such as the National Resident Matching Program (NRMP), it is infeasible for hospitals to interview or mutually rank each resident. In this paper, we study the stable matching problem with truncated preference lists. In particular, we assume that, based on historical datasets, each hospital has a predicted rank of its likely match and only ranks residents within a bounded interval around that prediction.\n  We use the algorithms-with-predictions framework and show that the classic deferred-acceptance (DA) algorithm used to compute stable matchings is robust to such truncation. We present two algorithms and theoretically and empirically evaluate their performance. Our results show that even with reasonably accurate predictions, it is possible to significantly cut down on both instance size (the length of preference lists) as well as the number of proposals made. These results explain the practical success of the DA algorithm and connect market design to the emerging theory of algorithms with predictions."}
{"id": "2602.02487", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.02487", "abs": "https://arxiv.org/abs/2602.02487", "authors": ["Timothy Highley", "Tannah Duncan", "Ilia Volkov"], "title": "Carry-Over Lottery Allocation: Practical Incentive-Compatible Drafts", "comment": "28 pages, 4 figures", "summary": "The NBA Draft lottery is designed to promote competitive balance by awarding better draft positions to weaker teams, but it creates incentives to deliberately lose, a practice known as tanking. We propose a draft mechanism that is simultaneously practical, incentive-compatible, and advantages weaker teams. The \\textbf{Carry-Over Lottery Allocation (COLA) Draft Mechanism} represents a paradigm shift in evaluating team quality, replacing a single season's standings with playoff outcomes over multiple years. COLA uses a draft lottery where every non-playoff team receives the same number of lottery tickets, removing incentives to lose additional games after elimination. Lottery tickets that do not win a top draft pick carry over to future lotteries, while playoff success or winning a top pick diminishes a team's accumulated tickets. Over time, COLA rewards teams with poor long-term performance and less prior draft assistance. By retaining the lottery format, COLA preserves transparency and fan engagement.\n  Real-world implementation challenges are addressed to demonstrate feasibility, including transitioning from the current system, handling traded draft picks, and accommodating draft classes of varying strength. The most significant challenge occurs in years with exceptionally strong draft classes, where teams may prefer missing the playoffs in order to gain lottery access, violating a foundational assumption: that teams prefer playoff success to lottery participation. We provide a solution to this problem, employing a truth-elicitation mechanism to identify such years and expand lottery eligibility to include as many playoff teams as necessary to preserve anti-tanking incentives."}
