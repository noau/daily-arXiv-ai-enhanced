{"id": "2507.02464", "categories": ["cs.GT", "cs.DC", "cs.FL", "cs.IR", "econ.GN", "q-fin.EC", "68M14, 91A05, 68Q85", "C.2.4; D.2.4; F.1.1"], "pdf": "https://arxiv.org/pdf/2507.02464", "abs": "https://arxiv.org/abs/2507.02464", "authors": ["Craig S Wright"], "title": "Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems", "comment": "51 pages 4 tables, includes formal proofs, automata construction, and\n  case study on Bitcoin Script", "summary": "The CAP theorem asserts a trilemma between consistency, availability, and\npartition tolerance. This paper introduces a rigorous automata-theoretic and\neconomically grounded framework that reframes the CAP trade-off as a constraint\noptimization problem. We model distributed systems as partition-aware state\nmachines and embed economic incentive layers to stabilize consensus behavior\nacross adversarially partitioned networks. By incorporating game-theoretic\nmechanisms into the global transition semantics, we define provable bounds on\nconvergence, liveness, and correctness. Our results demonstrate that\navailability and consistency can be simultaneously preserved within bounded\nepsilon margins, effectively extending the classical CAP limits through formal\neconomic control.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5f15\u5165\u81ea\u52a8\u673a\u7406\u8bba\u548c\u7ecf\u6d4e\u5b66\u6846\u67b6\uff0c\u5c06CAP\u5b9a\u7406\u7684\u6743\u8861\u95ee\u9898\u8f6c\u5316\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u6709\u9650\u8303\u56f4\u5185\u53ef\u540c\u65f6\u4fdd\u6301\u53ef\u7528\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "CAP\u5b9a\u7406\u6307\u51fa\u4e86\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4e00\u81f4\u6027\u3001\u53ef\u7528\u6027\u548c\u5206\u533a\u5bb9\u9519\u6027\u4e4b\u95f4\u7684\u4e09\u96be\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7ecf\u6d4e\u5b66\u548c\u81ea\u52a8\u673a\u7406\u8bba\u91cd\u65b0\u5b9a\u4e49\u8fd9\u4e00\u6743\u8861\u3002", "method": "\u5c06\u5206\u5e03\u5f0f\u7cfb\u7edf\u5efa\u6a21\u4e3a\u5206\u533a\u611f\u77e5\u72b6\u6001\u673a\uff0c\u5e76\u5d4c\u5165\u7ecf\u6d4e\u6fc0\u52b1\u5c42\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u673a\u5236\u5b9a\u4e49\u5168\u5c40\u8f6c\u6362\u8bed\u4e49\uff0c\u8bc1\u660e\u6536\u655b\u6027\u3001\u6d3b\u6027\u548c\u6b63\u786e\u6027\u7684\u754c\u9650\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u03b5\u8303\u56f4\u5185\uff0c\u53ef\u7528\u6027\u548c\u4e00\u81f4\u6027\u53ef\u4ee5\u540c\u65f6\u4fdd\u6301\uff0c\u4ece\u800c\u901a\u8fc7\u5f62\u5f0f\u5316\u7684\u7ecf\u6d4e\u63a7\u5236\u6269\u5c55\u4e86\u7ecf\u5178CAP\u5b9a\u7406\u7684\u754c\u9650\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u7ecf\u6d4e\u6fc0\u52b1\u548c\u81ea\u52a8\u673a\u7406\u8bba\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86CAP\u5b9a\u7406\u7684\u9002\u7528\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.02675", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.02675", "abs": "https://arxiv.org/abs/2507.02675", "authors": ["Zhaoqilin Yang", "Xin Wang", "Ruichen Zhang", "Chanchan Li", "Youliang Tian"], "title": "TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games", "comment": null, "summary": "We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO),\na new deep reinforcement learning framework. It extends Proximal Policy\nOptimization (PPO) by integrating team welfare objectives specifically for\nspatial public goods games. Unlike conventional approaches where cooperation\nemerges indirectly from individual rewards, TUC-PPO instead optimizes a\nbi-level objective integrating policy gradients and team utility constraints.\nConsequently, all policy updates explicitly incorporate collective payoff\nthresholds. The framework preserves PPO's policy gradient core while\nincorporating constrained optimization through adaptive Lagrangian multipliers.\nTherefore, decentralized agents dynamically balance selfish and cooperative\nincentives. The comparative analysis demonstrates superior performance of this\nconstrained deep reinforcement learning approach compared to unmodified PPO and\nevolutionary game theory baselines. It achieves faster convergence to\ncooperative equilibria and greater stability against invasion by defectors. The\nframework formally integrates team objectives into policy updates. This work\nadvances multi-agent deep reinforcement learning for social dilemmas while\nproviding new computational tools for evolutionary game theory research.", "AI": {"tldr": "TUC-PPO\u662f\u4e00\u4e2a\u65b0\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u56e2\u961f\u798f\u5229\u76ee\u6807\u6269\u5c55\u4e86PPO\uff0c\u65e8\u5728\u89e3\u51b3\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u6e38\u620f\u4e2d\u7684\u5408\u4f5c\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u8fc7\u95f4\u63a5\u7684\u4e2a\u4f53\u5956\u52b1\u4fc3\u53d1\u5408\u4f5c\uff0c\u800cTUC-PPO\u76f4\u63a5\u4f18\u5316\u4e86\u6574\u5408\u7b56\u7565\u68af\u5ea6\u548c\u56e2\u961f\u6548\u7528\u7ea6\u675f\u7684\u53cc\u5c42\u76ee\u6807\uff0c\u4ee5\u66f4\u663e\u5f0f\u5730\u7eb3\u5165\u96c6\u4f53\u6536\u76ca\u9608\u503c\u3002", "method": "TUC-PPO\u4fdd\u7559\u4e86PPO\u7684\u7b56\u7565\u68af\u5ea6\u6838\u5fc3\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u5f15\u5165\u7ea6\u675f\u4f18\u5316\uff0c\u4f7f\u5206\u6563\u7684\u4ee3\u7406\u52a8\u6001\u5e73\u8861\u81ea\u79c1\u548c\u5408\u4f5c\u7684\u6fc0\u52b1\u3002", "result": "\u76f8\u6bd4\u672a\u4fee\u6539\u7684PPO\u548c\u8fdb\u5316\u535a\u5f08\u8bba\u57fa\u7ebf\uff0cTUC-PPO\u5728\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u66f4\u5feb\u8fbe\u5230\u5408\u4f5c\u5747\u8861\u5e76\u62b5\u5fa1\u53db\u9003\u8005\u7684\u5165\u4fb5\u3002", "conclusion": "TUC-PPO\u5c06\u56e2\u961f\u76ee\u6807\u6b63\u5f0f\u6574\u5408\u5230\u7b56\u7565\u66f4\u65b0\u4e2d\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8fdb\u5316\u535a\u5f08\u8bba\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba1\u7b97\u5de5\u5177\u3002"}}
{"id": "2507.02801", "categories": ["cs.GT", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.02801", "abs": "https://arxiv.org/abs/2507.02801", "authors": ["Hu Fu", "Tao Lin"], "title": "Learning to Coordinate Bidders in Non-Truthful Auctions", "comment": null, "summary": "In non-truthful auctions such as first-price and all-pay auctions, the\nindependent strategic behaviors of bidders, with the corresponding equilibrium\nnotion -- Bayes Nash equilibria -- are notoriously difficult to characterize\nand can cause undesirable outcomes. An alternative approach to designing better\nauction systems is to coordinate the bidders: let a mediator make\nincentive-compatible recommendations of correlated bidding strategies to the\nbidders, namely, implementing a Bayes correlated equilibrium (BCE). The\nimplementation of BCE, however, requires knowledge of the distribution of\nbidders' private valuations, which is often unavailable. We initiate the study\nof the sample complexity of learning Bayes correlated equilibria in\nnon-truthful auctions. We prove that the BCEs in a large class of non-truthful\nauctions, including first-price and all-pay auctions, can be learned with a\npolynomial number $\\tilde O(\\frac{n}{\\varepsilon^2})$ of samples from the\nbidders' value distributions. Our technique is a reduction to the problem of\nestimating bidders' expected utility from samples, combined with an analysis of\nthe pseudo-dimension of the class of all monotone bidding strategies of\nbidders.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u975e\u771f\u5b9e\u6027\u62cd\u5356\u4e2d\u5b66\u4e60\u8d1d\u53f6\u65af\u76f8\u5173\u5747\u8861\uff08BCE\uff09\u7684\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u4e00\u5927\u7c7b\u62cd\u5356\u4e2d\uff08\u5305\u62ec\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u548c\u5168\u652f\u4ed8\u62cd\u5356\uff09\uff0c\u53ef\u4ee5\u7528\u591a\u9879\u5f0f\u6570\u91cf\u7684\u6837\u672c\u5b66\u4e60BCE\u3002", "motivation": "\u5728\u975e\u771f\u5b9e\u6027\u62cd\u5356\u4e2d\uff0c\u72ec\u7acb\u7b56\u7565\u884c\u4e3a\uff08\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff09\u96be\u4ee5\u8868\u5f81\u4e14\u53ef\u80fd\u5bfc\u81f4\u4e0d\u826f\u7ed3\u679c\u3002\u901a\u8fc7\u5f15\u5165\u534f\u8c03\u673a\u5236\uff08BCE\uff09\u53ef\u4ee5\u6539\u5584\u62cd\u5356\u7cfb\u7edf\uff0c\u4f46BCE\u7684\u5b9e\u73b0\u9700\u8981\u6295\u6807\u4eba\u79c1\u6709\u4f30\u503c\u7684\u5206\u5e03\u77e5\u8bc6\uff0c\u800c\u8fd9\u901a\u5e38\u662f\u672a\u77e5\u7684\u3002", "method": "\u901a\u8fc7\u51cf\u5c11\u6837\u672c\u4f30\u8ba1\u6295\u6807\u4eba\u671f\u671b\u6548\u7528\u7684\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u5bf9\u6295\u6807\u4eba\u6240\u6709\u5355\u8c03\u6295\u6807\u7b56\u7565\u7c7b\u522b\u7684\u4f2a\u7ef4\u5206\u6790\uff0c\u7814\u7a76\u5b66\u4e60BCE\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u8bc1\u660e\u5728\u4e00\u5927\u7c7b\u975e\u771f\u5b9e\u6027\u62cd\u5356\u4e2d\uff0c\u53ef\u4ee5\u7528\u591a\u9879\u5f0f\u6570\u91cf$\tilde O(\\frac{n}{\\varepsilon^2})$\u7684\u6837\u672c\u5b66\u4e60BCE\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u6837\u672c\u590d\u6742\u5ea6\u5206\u6790\uff0c\u53ef\u4ee5\u5728\u975e\u771f\u5b9e\u6027\u62cd\u5356\u4e2d\u6709\u6548\u5b66\u4e60\u548c\u5b9e\u73b0\u8d1d\u53f6\u65af\u76f8\u5173\u5747\u8861\uff08BCE\uff09\u3002"}}
{"id": "2507.02257", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.02257", "abs": "https://arxiv.org/abs/2507.02257", "authors": ["Stephen Pasch", "Joel K. Salzman", "Changxi Zheng"], "title": "Gbake: Baking 3D Gaussian Splats into Reflection Probes", "comment": "SIGGRAPH 2025 Posters", "summary": "The growing popularity of 3D Gaussian Splatting has created the need to\nintegrate traditional computer graphics techniques and assets in splatted\nenvironments. Since 3D Gaussian primitives encode lighting and geometry jointly\nas appearance, meshes are relit improperly when inserted directly in a mixture\nof 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a\nspecialized tool for baking reflection probes from Gaussian-splatted scenes\nthat enables realistic reflection mapping of traditional 3D meshes in the Unity\ngame engine.", "AI": {"tldr": "GBake\u662f\u4e00\u6b3e\u4e13\u7528\u5de5\u5177\uff0c\u7528\u4e8e\u4ece\u9ad8\u65af\u6563\u5c04\u573a\u666f\u4e2d\u70d8\u7119\u53cd\u5c04\u63a2\u5934\uff0c\u4f7fUnity\u6e38\u620f\u5f15\u64ce\u4e2d\u7684\u4f20\u7edf3D\u7f51\u683c\u80fd\u591f\u5b9e\u73b0\u903c\u771f\u7684\u53cd\u5c04\u6620\u5c04\u3002", "motivation": "\u968f\u77403D\u9ad8\u65af\u6563\u5c04\u7684\u666e\u53ca\uff0c\u9700\u8981\u5c06\u4f20\u7edf\u8ba1\u7b97\u673a\u56fe\u5f62\u6280\u672f\uff08\u5982\u7f51\u683c\uff09\u96c6\u6210\u5230\u9ad8\u65af\u6563\u5c04\u73af\u5883\u4e2d\u3002\u7531\u4e8e3D\u9ad8\u65af\u57fa\u5143\u5c06\u5149\u7167\u548c\u51e0\u4f55\u4fe1\u606f\u7f16\u7801\u4e3a\u5916\u89c2\uff0c\u76f4\u63a5\u63d2\u5165\u7f51\u683c\u4f1a\u5bfc\u81f4\u4e0d\u6b63\u786e\u7684\u5149\u7167\u6548\u679c\u3002", "method": "\u5f15\u5165\u4e86GBake\u5de5\u5177\uff0c\u4e13\u95e8\u7528\u4e8e\u4ece\u9ad8\u65af\u6563\u5c04\u573a\u666f\u4e2d\u70d8\u7119\u53cd\u5c04\u63a2\u5934\uff0c\u4ee5\u5728Unity\u6e38\u620f\u5f15\u64ce\u4e2d\u5b9e\u73b0\u4f20\u7edf3D\u7f51\u683c\u7684\u903c\u771f\u53cd\u5c04\u6620\u5c04\u3002", "result": "GBake\u80fd\u591f\u89e3\u51b3\u9ad8\u65af\u6563\u5c04\u73af\u5883\u4e2d\u7f51\u683c\u5149\u7167\u4e0d\u6b63\u786e\u7684\u95ee\u9898\uff0c\u4f7f\u5176\u80fd\u591f\u81ea\u7136\u5730\u878d\u5165\u573a\u666f\u3002", "conclusion": "GBake\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u4f20\u7edf3D\u7f51\u683c\u4e0e\u9ad8\u65af\u6563\u5c04\u573a\u666f\u65e0\u7f1d\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u89c6\u89c9\u6548\u679c\u7684\u771f\u5b9e\u611f\u3002"}}
{"id": "2507.02226", "categories": ["cs.PL", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02226", "abs": "https://arxiv.org/abs/2507.02226", "authors": ["Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "comment": "Accepted to the International Conference on Computer-Aided Design\n  (ICCAD 2025)", "summary": "As one of their many applications, large language models (LLMs) have recently\nshown promise in automating register transfer level (RTL) code generation.\nHowever, conventional LLM decoding strategies, originally designed for natural\nlanguage, often fail to meet the structural and semantic demands of RTL,\nleading to hallucinated, repetitive, or invalid code outputs. In this paper, we\nfirst investigate the root causes of these decoding failures through an\nempirical analysis of token-level entropy during RTL generation. Our findings\nreveal that LLMs exhibit low confidence in regions of structural ambiguity or\nsemantic complexity, showing that standard decoding strategies fail to\ndifferentiate between regions requiring determinism (syntax-critical regions)\nand those that benefit from creative exploratory variability (design-critical\nregions). Then, to overcome this, we introduce DecoRTL, a novel run-time\ndecoding strategy, that is both syntax-aware and contrastive for RTL code\ngeneration. DecoRTL integrates two complementary components: (i)\nself-consistency sampling, which generates multiple candidates and re-ranks\nthem based on token-level agreement to promote correctness while maintaining\ndiversity; and (ii) syntax-aware temperature adaptation, which classifies\ntokens by their syntactical and functional roles and adjusts the sampling\ntemperature accordingly, enforcing low temperature for syntax-critical tokens\nand higher temperature for exploratory ones. Our approach operates entirely at\ninference time without requiring any additional model fine-tuning. Through\nevaluations on multiple open-source LLMs using the VerilogEval benchmark, we\ndemonstrate significant improvements in syntactic validity, functional\ncorrectness, and output diversity, while the execution overhead (performance\noverhead) is imperceptible.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DecoRTL\uff0c\u4e00\u79cd\u9488\u5bf9RTL\u4ee3\u7801\u751f\u6210\u7684\u65b0\u578b\u8fd0\u884c\u65f6\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u4e00\u81f4\u6027\u91c7\u6837\u548c\u8bed\u6cd5\u611f\u77e5\u6e29\u5ea6\u8c03\u6574\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u6cd5\u6709\u6548\u6027\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u8f93\u51fa\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u7684LLM\u89e3\u7801\u7b56\u7565\u5728\u751f\u6210RTL\u4ee3\u7801\u65f6\u5e38\u5e38\u65e0\u6cd5\u6ee1\u8db3\u7ed3\u6784\u548c\u8bed\u4e49\u9700\u6c42\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u5e7b\u89c9\u3001\u91cd\u590d\u6216\u65e0\u6548\u7684\u95ee\u9898\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u95ee\u9898\u7684\u6839\u6e90\u5e76\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86DecoRTL\uff0c\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u81ea\u4e00\u81f4\u6027\u91c7\u6837\uff08\u751f\u6210\u591a\u4e2a\u5019\u9009\u5e76\u57fa\u4e8e\u6807\u8bb0\u7ea7\u4e00\u81f4\u6027\u91cd\u65b0\u6392\u5e8f\uff09\u548c\u8bed\u6cd5\u611f\u77e5\u6e29\u5ea6\u8c03\u6574\uff08\u6839\u636e\u6807\u8bb0\u7684\u8bed\u6cd5\u548c\u529f\u80fd\u89d2\u8272\u8c03\u6574\u91c7\u6837\u6e29\u5ea6\uff09\u3002", "result": "\u5728VerilogEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDecoRTL\u5728\u591a\u4e2a\u5f00\u6e90LLM\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u6cd5\u6709\u6548\u6027\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u8f93\u51fa\u591a\u6837\u6027\uff0c\u4e14\u8fd0\u884c\u65f6\u5f00\u9500\u51e0\u4e4e\u4e0d\u53ef\u611f\u77e5\u3002", "conclusion": "DecoRTL\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u7b56\u7565\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86RTL\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2507.02674", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.02674", "abs": "https://arxiv.org/abs/2507.02674", "authors": ["Tom Kneiphof", "Reinhard Klein"], "title": "Real-time Image-based Lighting of Glints", "comment": null, "summary": "Image-based lighting is a widely used technique to reproduce shading under\nreal-world lighting conditions, especially in real-time rendering applications.\nA particularly challenging scenario involves materials exhibiting a sparkling\nor glittering appearance, caused by discrete microfacets scattered across their\nsurface. In this paper, we propose an efficient approximation for image-based\nlighting of glints, enabling fully dynamic material properties and environment\nmaps. Our novel approach is grounded in real-time glint rendering under area\nlight illumination and employs standard environment map filtering techniques.\nCrucially, our environment map filtering process is sufficiently fast to be\nexecuted on a per-frame basis. Our method assumes that the environment map is\npartitioned into few homogeneous regions of constant radiance. By filtering the\ncorresponding indicator functions with the normal distribution function, we\nobtain the probabilities for individual microfacets to reflect light from each\nregion. During shading, these probabilities are utilized to hierarchically\nsample a multinomial distribution, facilitated by our novel dual-gated Gaussian\napproximation of binomial distributions. We validate that our real-time\napproximation is close to ground-truth renderings for a range of material\nproperties and lighting conditions, and demonstrate robust and stable\nperformance, with little overhead over rendering glints from a single\ndirectional light. Compared to rendering smooth materials without glints, our\napproach requires twice as much memory to store the prefiltered environment\nmap.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u56fe\u50cf\u5149\u7167\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u6e32\u67d3\u5177\u6709\u95ea\u4eae\u6216\u95ea\u70c1\u5916\u89c2\u7684\u6750\u6599\uff0c\u652f\u6301\u52a8\u6001\u6750\u6599\u5c5e\u6027\u548c\u73af\u5883\u8d34\u56fe\u3002", "motivation": "\u57fa\u4e8e\u56fe\u50cf\u7684\u5149\u7167\u6280\u672f\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u91cd\u5efa\u771f\u5b9e\u4e16\u754c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u9634\u5f71\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u79bb\u6563\u5fae\u8868\u9762\u7ed3\u6784\u7684\u95ea\u4eae\u6750\u6599\u65f6\u5b58\u5728\u6311\u6218\u3002", "method": "\u91c7\u7528\u5b9e\u65f6\u533a\u57df\u5149\u7167\u4e0b\u7684\u95ea\u4eae\u6e32\u67d3\u6280\u672f\u548c\u6807\u51c6\u73af\u5883\u8d34\u56fe\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u91c7\u6837\u591a\u6a21\u6001\u5206\u5e03\u548c\u53cc\u95e8\u9ad8\u65af\u8fd1\u4f3c\u6765\u9ad8\u6548\u5904\u7406\u73af\u5883\u8d34\u56fe\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6750\u6599\u5c5e\u6027\u548c\u5149\u7167\u6761\u4ef6\u4e0b\u63a5\u8fd1\u771f\u5b9e\u6e32\u67d3\u6548\u679c\uff0c\u6027\u80fd\u7a33\u5b9a\u4e14\u989d\u5916\u5f00\u9500\u4f4e\uff0c\u4ec5\u9700\u4e24\u500d\u4e8e\u5e73\u6ed1\u6750\u6599\u6e32\u67d3\u7684\u5185\u5b58\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b9e\u65f6\u6e32\u67d3\u95ea\u4eae\u6750\u6599\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u63a5\u8fd1\u771f\u5b9e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\u548c\u6750\u6599\u5c5e\u6027\u7684\u573a\u666f\u3002"}}
