<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
*Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman*

Main category: cs.GR

TL;DR: 我们提出了一种零样本框架，用于文本到视频模型中动态概念的个性化，无需实例微调即可生成高质量且一致的视频。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成方法在动态概念个性化时需要针对每个实例进行微调，这限制了其可扩展性。

Method: 通过结构化2x2视频网格和轻量级Grid-LoRA适配器，我们的方法在单次前向传递中完成未见过的动态概念的编辑和合成。

Result: 实验结果表明，该方法在广泛的未训练概念和编辑场景中均能产生高质量且一致的结果。

Conclusion: 我们的框架在无需测试时优化的情况下，能够推广到未见过的动态概念，显著提升了文本到视频生成的效率和可扩展性。

Abstract: Recent advances in text-to-video generation have enabled high-quality
synthesis from text and image prompts. While the personalization of dynamic
concepts, which capture subject-specific appearance and motion from a single
video, is now feasible, most existing methods require per-instance fine-tuning,
limiting scalability. We introduce a fully zero-shot framework for dynamic
concept personalization in text-to-video models. Our method leverages
structured 2x2 video grids that spatially organize input and output pairs,
enabling the training of lightweight Grid-LoRA adapters for editing and
composition within these grids. At inference, a dedicated Grid Fill module
completes partially observed layouts, producing temporally coherent and
identity preserving outputs. Once trained, the entire system operates in a
single forward pass, generalizing to previously unseen dynamic concepts without
any test-time optimization. Extensive experiments demonstrate high-quality and
consistent results across a wide range of subjects beyond trained concepts and
editing scenarios.

</details>


### [2] [DanceGraph: A Complementary Architecture for Synchronous Dancing Online](https://arxiv.org/abs/2507.18052)
*David Sinclair,Ademyemi Ademola,Babis Koniaris,Kenny Mitchell*

Main category: cs.GR

TL;DR: DanceGraph是一种用于克服网络化身体姿态共享延迟的同步在线舞蹈架构，通过实时带宽高效设计减少滞后，并通过在线舞蹈校正实现舞蹈动作的参数化风格化。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线舞蹈中因网络延迟导致的身体姿态同步问题，以及如何在音乐节奏下实现舞蹈动作的实时同步与风格化。

Method: 提出了DanceGraph架构，包括实时带宽高效设计以减少延迟，并引入在线舞蹈校正技术实现舞蹈动作的参数化风格化。

Result: 成功减少了舞蹈动作同步所需的滞后时间，并展示了在线舞蹈校正技术在节奏舞蹈中的应用效果。

Conclusion: DanceGraph为在线舞蹈提供了一种高效的同步和风格化解决方案，显著提升了用户体验。

Abstract: DanceGraph is an architecture for synchronized online dancing overcoming the
latency of networked body pose sharing. We break down this challenge by
developing a real-time bandwidth-efficient architecture to minimize lag and
reduce the timeframe of required motion prediction for synchronization with the
music's rhythm. In addition, we show an interactive method for the
parameterized stylization of dance motions for rhythmic dance using online
dance correctives.

</details>


### [3] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
*SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park*

Main category: cs.GR

TL;DR: GeoAvatar是一个用于自适应几何高斯喷洒的框架，通过APS分割高斯点为刚性和灵活集，并提出嘴巴结构和部分变形策略，提升了3D头部头像的动画质量。


<details>
  <summary>Details</summary>
Motivation: 尽管3D头部头像生成取得了进展，但在保留身份特征（重建）与支持新姿态和表情（动画）之间仍存在平衡问题，现有方法难以适应面部区域间的几何偏差。

Method: GeoAvatar采用APS对高斯点进行无监督分割，提出基于嘴巴解剖结构的部分变形策略，并引入正则化损失来实现高斯点与3DMM面部的精确绑定。

Result: 实验表明，GeoAvatar在重建和新动画场景中优于现有方法，DynamicFace数据集的发布进一步支持了研究。

Conclusion: GeoAvatar通过自适应几何高斯喷洒和嘴巴结构优化，显著提升了3D头部头像的动画质量和保真度。

Abstract: Despite recent progress in 3D head avatar generation, balancing identity
preservation, i.e., reconstruction, with novel poses and expressions, i.e.,
animation, remains a challenge. Existing methods struggle to adapt Gaussians to
varying geometrical deviations across facial regions, resulting in suboptimal
quality. To address this, we propose GeoAvatar, a framework for adaptive
geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation
Stage (APS), an unsupervised method that segments Gaussians into rigid and
flexible sets for adaptive offset regularization. Then, based on mouth anatomy
and dynamics, we introduce a novel mouth structure and the part-wise
deformation strategy to enhance the animation fidelity of the mouth. Finally,
we propose a regularization loss for precise rigging between Gaussians and 3DMM
faces. Moreover, we release DynamicFace, a video dataset with highly expressive
facial motions. Extensive experiments show the superiority of GeoAvatar
compared to state-of-the-art methods in reconstruction and novel animation
scenarios.

</details>


### [4] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
*Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng*

Main category: cs.GR

TL;DR: 论文提出了一种名为PS-GS的方法，通过结合多视角光度立体（MVPS）与逆渲染，高效地估计物体的几何、材质和光照，从而提升3D重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的逆渲染方法依赖于固定的环境光照，导致3D重建结果不够准确，而结合MVPS的逆渲染方法仍然面临效率挑战。本文旨在填补这一空白。

Method: PS-GS通过构建初始2D高斯溅射模型作为几何基础，随后基于完整渲染方程进行延迟逆渲染，并通过多层感知器计算光照。优化过程中通过光度立体法估计的法线图和提出的2D高斯光线追踪方法规范光照，结合多视角和多光源图像缓解逆渲染的病态问题。

Result: 实验表明，PS-GS在合成和真实数据集上的重建精度和计算效率均优于现有方法，且重建结果可用于新视角合成、重光照以及材质和形状编辑。

Conclusion: 本文提出的PS-GS方法通过多视角和多光源图像的结合以及高效优化策略，显著提升了逆渲染在3D重建中的表现，为后续应用提供了强大支持。

Abstract: Integrating inverse rendering with multi-view photometric stereo (MVPS)
yields more accurate 3D reconstructions than the inverse rendering approaches
that rely on fixed environment illumination. However, efficient inverse
rendering with MVPS remains challenging. To fill this gap, we introduce the
Gaussian Splatting for Multi-view Photometric Stereo (PS-GS), which efficiently
and jointly estimates the geometry, materials, and lighting of the object that
is illuminated by diverse directional lights (multi-light). Our method first
reconstructs a standard 2D Gaussian splatting model as the initial geometry.
Based on the initialization model, it then proceeds with the deferred inverse
rendering by the full rendering equation containing a lighting-computing
multi-layer perceptron. During the whole optimization, we regularize the
rendered normal maps by the uncalibrated photometric stereo estimated normals.
We also propose the 2D Gaussian ray-tracing for single directional light to
refine the incident lighting. The regularizations and the use of multi-view and
multi-light images mitigate the ill-posed problem of inverse rendering. After
optimization, the reconstructed object can be used for novel-view synthesis,
relighting, and material and shape editing. Experiments on both synthetic and
real datasets demonstrate that our method outperforms prior works in terms of
reconstruction accuracy and computational efficiency.

</details>


### [5] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
*Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage*

Main category: cs.GR

TL;DR: 该论文提出了一种通过混合知识蒸馏和伪标签技术，训练轻量级、实时的语音驱动3D面部动画模型的方法，解决了现有模型过大且需要离线推理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有高质量语音驱动3D面部动画模型依赖于大型预训练语音编码器，导致模型过大且仅适用于离线推理。为实现在设备上实时运行的目标，需要开发轻量级模型。

Method: 通过混合知识蒸馏和伪标签技术，利用大型音频数据集和教师模型，训练仅包含卷积和全连接层的小型学生模型，摒弃注意力机制或循环更新的需求。

Result: 实验表明，该方法将内存占用压缩至3.4 MB，所需未来音频上下文缩短至81毫秒，同时保持高质量动画效果。

Conclusion: 该方法为实现设备上的实时推理提供了可能，是迈向逼真、模型驱动数字角色的重要一步。

Abstract: The training of high-quality, robust machine learning models for
speech-driven 3D facial animation requires a large, diverse dataset of
high-quality audio-animation pairs. To overcome the lack of such a dataset,
recent work has introduced large pre-trained speech encoders that are robust to
variations in the input audio and, therefore, enable the facial animation model
to generalize across speakers, audio quality, and languages. However, the
resulting facial animation models are prohibitively large and lend themselves
only to offline inference on a dedicated machine. In this work, we explore
on-device, real-time facial animation models in the context of game
development. We overcome the lack of large datasets by using hybrid knowledge
distillation with pseudo-labeling. Given a large audio dataset, we employ a
high-performing teacher model to train very small student models. In contrast
to the pre-trained speech encoders, our student models only consist of
convolutional and fully-connected layers, removing the need for attention
context or recurrent updates. In our experiments, we demonstrate that we can
reduce the memory footprint to up to 3.4 MB and required future audio context
to up to 81 ms while maintaining high-quality animations. This paves the way
for on-device inference, an important step towards realistic, model-driven
digital characters.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 该论文提出了一种统一的范畴化方法（Howe's method），用于证明高阶语言中行为等价性的程序同余性，适用于包括概率特性在内的多种行为一致性，并通过抽象高阶规范（AHOS）和纤维化模型实现了广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 近年来，具有定量特性（如概率）的高阶语言兴起，需要扩展共归纳方法以处理更精细的行为一致性（如行为距离）。为了保证这些方法的正确性，需要证明行为一致性是程序同余的，然而传统的Howe's方法需针对特定语言和行为一致性定制，复杂度高。

Method: 论文提出了一种统一的范畴方法，通过两个正交的抽象维度实现：(1) 使用抽象高阶规范（AHOS）对高阶语言建模；(2) 通过纤维化模型描述行为一致性（如关系或度量）。该方法在广泛的条件下证明了行为一致性的同余性。

Result: 在AHOS模型下，论文提出了一个基本的同余定理：在自然条件下，行为一致性的最大双一致性形成同余。通过应用该方法，成功证明了概率高阶语言的互模拟性和行为伪度量的同余性。

Conclusion: 通过统一的范畴化方法，论文简化了Howe's方法的复杂性，使其能够广泛应用于不同语言和行为一致性的同余性证明，为高阶语言的形式化验证提供了更通用的工具。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [$k$-Approval Veto: A Spectrum of Voting Rules Balancing Metric Distortion and Minority Protection](https://arxiv.org/abs/2507.17981)
*Fatih Erdem Kizilkaya,David Kempe*

Main category: cs.GT

TL;DR: 研究单胜者排名选举中的多数原则与少数原则的权衡，提出k-Approval Veto投票规则，既能满足不同少数保护水平，又需承受社会福祉下降的代价。


<details>
  <summary>Details</summary>
Motivation: 探讨民主系统中多数原则（最大化社会福利）与少数原则（保护少数群体免受极端结果影响）之间的权衡关系。

Method: 使用度量扭曲框架（包括功利性、α百分位数和平均主义目标）衡量社会福利，引入ℓ-互惠少数标准衡量少数保护，分析k-Approval Veto投票规则在不同参数下的表现。

Result: k-Approval Veto规则能提供至少k水平的少数保护，但社会福利会下降。功利目标下，度量扭曲与k线性增长；α百分位数目标下，最优扭曲为5（α≥k/(k+1)）或无限（α<k/(k+1)）；平均主义目标下，最优扭曲为3。

Conclusion: k-Approval Veto规则为多数与少数原则的权衡提供了灵活的选择，但其社会福利代价随少数保护水平增加而上升。

Abstract: In the context of single-winner ranked-choice elections between $m$
candidates, we explore the tradeoff between two competing goals in every
democratic system: the majority principle (maximizing the social welfare) and
the minority principle (safeguarding minority groups from overly bad
outcomes).To measure the social welfare, we use the well-established framework
of metric distortion subject to various objectives: utilitarian (i.e., total
cost), $\alpha$-percentile (e.g., median cost for $\alpha = 1/2$), and
egalitarian (i.e., max cost). To measure the protection of minorities, we
introduce the $\ell$-mutual minority criterion, which requires that if a
sufficiently large (parametrized by $\ell$) coalition $T$ of voters ranks all
candidates in $S$ lower than all other candidates, then none of the candidates
in $S$ should win. The highest $\ell$ for which the criterion is satisfied
provides a well-defined measure of mutual minority protection (ranging from 1
to $m$).
  Our main contribution is the analysis of a recently proposed class of voting
rules called $k$-Approval Veto, offering a comprehensive range of trade-offs
between the two principles. This class spans between Plurality Veto (for $k=1$)
- a simple voting rule achieving optimal metric distortion - and Vote By Veto
(for $k=m$) which picks a candidate from the proportional veto core. We show
that $k$-Approval Veto has minority protection at least $k$, and thus, it
accommodates any desired level of minority protection. However, this comes at
the price of lower social welfare. For the utilitarian objective, the metric
distortion increases linearly in $k$. For the $\alpha$-percentile objective,
the metric distortion is the optimal value of 5 for $\alpha \ge k/(k+1)$ and
unbounded for $\alpha < k/(k+1)$. For the egalitarian objective, the metric
distortion is the optimal value of 3 for all values of $k$.

</details>


### [8] [On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities](https://arxiv.org/abs/2507.18251)
*Jiarong Jin,Biaoshuai Tao*

Main category: cs.GT

TL;DR: 该研究分析了将不可分割物品分配给具有个性化双值效用的代理人的公平分割问题，给出了Pareto最优分配的完整描述，并探讨了其计算复杂性和EFX分配的存在性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决不可分割物品在个性化双值效用下的公平分配问题，填补现有研究中关于Pareto最优分配和EFX分配的理论空白。

Method: 通过分析代理人的价值比率（$r_i = a_i / b_i$），研究提供了Pareto最优分配的完整描述，并针对整数$r_i$情形设计多项式时间算法，同时证明了一般情况下判定问题的coNP-完全性。

Result: 结果表明，当$r_i$为整数时，Pareto最优分配的判定问题可在多项式时间内解决；而在一般情况下为coNP-完全。同时，证明了EFX分配在个性化双值效用下存在且可多项式时间计算。

Conclusion: 结论指出，研究扩展了双值效用下的EFX分配结果，并提出了EFX与Pareto最优分配是否始终存在并可多项式时间计算的开放性问题。

Abstract: We study the fair division problem of allocating $m$ indivisible goods to $n$
agents with additive personalized bi-valued utilities. Specifically, each agent
$i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating
that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For
convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.
  We give a characterization to all the Pareto-optimal allocations. Our
characterization implies a polynomial-time algorithm to decide if a given
allocation is Pareto-optimal in the case each $r_i$ is an integer. For the
general case (where $r_i$ may be fractional), we show that this decision
problem is coNP-complete. Our result complements the existing results: this
decision problem is coNP-complete for tri-valued utilities (where each agent's
value for each good belongs to $\{a,b,c\}$ for some prescribed $a>b>c\geq0$),
and this decision problem belongs to P for bi-valued utilities (where $r_i$ in
our model is the same for each agent).
  We further show that an EFX allocation always exists and can be computed in
polynomial time under the personalized bi-valued utilities setting, which
extends the previous result on bi-valued utilities. We propose the open problem
of whether an EFX and Pareto-optimal allocation always exists (and can be
computed in polynomial time).

</details>
