<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 8]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 9]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [DecoMind: A Generative AI System for Personalized Interior Design Layouts](https://arxiv.org/abs/2508.16696)
*Reema Alshehri,Rawan Alotaibi,Leen Almasri,Rawan Altaweel*

Main category: cs.GR

TL;DR: 本文介绍了一种基于用户输入的室内设计布局生成系统，利用CLIP提取相关家具，结合Stable Diffusion与ControlNet生成设计，并通过分类器评估设计一致性。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种自动化解决方案，根据用户的房间类型、风格和家具偏好生成符合需求的室内设计布局。

Method: 使用CLIP从数据集中提取相关家具，结合Stable Diffusion与ControlNet生成设计布局，并通过分类器评估设计的符合度。

Result: 系统能够生成符合用户输入需求的室内设计布局，并通过自动化评估确保设计的一致性。

Conclusion: 本研究提出了一种高效且自动化的室内设计生成方法，能够满足用户的多样化需求。

Abstract: This paper introduces a system for generating interior design layouts based
on user inputs, such as room type, style, and furniture preferences. CLIP
extracts relevant furniture from a dataset, and a layout that contains
furniture and a prompt are fed to Stable Diffusion with ControlNet to generate
a design that incorporates the selected furniture. The design is then evaluated
by classifiers to ensure alignment with the user's inputs, offering an
automated solution for realistic interior design.

</details>


### [2] [MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation](https://arxiv.org/abs/2508.16911)
*Prerit Gupta,Jason Alexander Fotso-Puepi,Zhengyuan Li,Jay Mehta,Aniket Bera*

Main category: cs.GR

TL;DR: MDD是一个多元化的多模态基准数据集，用于文本控制和音乐条件下的3D双人舞动作生成，包含620分钟的动捕数据、音乐同步和10K+细粒度自然语言描述。


<details>
  <summary>Details</summary>
Motivation: 为促进文本控制和音乐条件下的双人舞动作生成研究，填补现有数据集的空白。

Method: 构建了包含高质量动捕数据、音乐同步和详细文本描述的MDD数据集，并设计了两个新任务：文本到双人舞和文本到舞蹈伴奏。

Result: 提供了包含丰富动作词汇和详细注释的数据集，并在两个新任务上进行了基线评估，为未来研究提供了支持。

Conclusion: MDD数据集首次将人体动作、音乐和文本无缝整合，为双人舞生成研究提供了重要的资源和方向。

Abstract: We introduce Multimodal DuetDance (MDD), a diverse multimodal benchmark
dataset designed for text-controlled and music-conditioned 3D duet dance motion
generation. Our dataset comprises 620 minutes of high-quality motion capture
data performed by professional dancers, synchronized with music, and detailed
with over 10K fine-grained natural language descriptions. The annotations
capture a rich movement vocabulary, detailing spatial relationships, body
movements, and rhythm, making MDD the first dataset to seamlessly integrate
human motions, music, and text for duet dance generation. We introduce two
novel tasks supported by our dataset: (1) Text-to-Duet, where given music and a
textual prompt, both the leader and follower dance motion are generated (2)
Text-to-Dance Accompaniment, where given music, textual prompt, and the
leader's motion, the follower's motion is generated in a cohesive, text-aligned
manner. We include baseline evaluations on both tasks to support future
research.

</details>


### [3] [A Survey of Deep Learning-based Point Cloud Denoising](https://arxiv.org/abs/2508.17011)
*Jinxi Wang,Ben Fei,Dasith de Silva Edirimuni,Zheng Liu,Ying He,Xuequan Lu*

Main category: cs.GR

TL;DR: 本文总结了截至2025年8月基于深度学习的点云去噪方法，从监督水平和建模视角分类，并分析架构趋势、建立统一基准，同时探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 点云数据在真实环境中常受噪声污染，影响几何精度和下游任务性能。传统优化方法难以处理复杂噪声，而深度学习方法显示出优势，因此有必要对其进行全面综述。

Method: 从监督水平（有监督与无监督）和建模视角对文献进行分类，提出功能性分类法，并在统一基准下评估方法的去噪质量、表面保真度、点分布和计算效率。

Result: 深度学习在点云去噪领域取得显著进展，尤其是在复杂和大规模点云上表现优异。通过统一评估，揭示了不同方法的优缺点。

Conclusion: 点云去噪领域仍有挑战，未来研究需进一步提升方法性能，尤其是在噪声多样性和计算效率方面。

Abstract: Accurate 3D geometry acquisition is essential for a wide range of
applications, such as computer graphics, autonomous driving, robotics, and
augmented reality. However, raw point clouds acquired in real-world
environments are often corrupted with noise due to various factors such as
sensor, lighting, material, environment etc, which reduces geometric fidelity
and degrades downstream performance. Point cloud denoising is a fundamental
problem, aiming to recover clean point sets while preserving underlying
structures. Classical optimization-based methods, guided by hand-crafted
filters or geometric priors, have been extensively studied but struggle to
handle diverse and complex noise patterns. Recent deep learning approaches
leverage neural network architectures to learn distinctive representations and
demonstrate strong outcomes, particularly on complex and large-scale point
clouds. Provided these significant advances, this survey provides a
comprehensive and up-to-date review of deep learning-based point cloud
denoising methods up to August 2025. We organize the literature from two
perspectives: (1) supervision level (supervised vs. unsupervised), and (2)
modeling perspective, proposing a functional taxonomy that unifies diverse
approaches by their denoising principles. We further analyze architectural
trends both structurally and chronologically, establish a unified benchmark
with consistent training settings, and evaluate methods in terms of denoising
quality, surface fidelity, point distribution, and computational efficiency.
Finally, we discuss open challenges and outline directions for future research
in this rapidly evolving field.

</details>


### [4] [DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions](https://arxiv.org/abs/2508.17342)
*Hengyuan Zhang,Zhe Li,Xingqun Qi,Mengze Li,Muyi Sun,Man Zhang,Sirui Han*

Main category: cs.GR

TL;DR: 论文提出了一种名为DanceEditor的框架，用于从音乐信号中生成可迭代编辑的连贯且多样化的舞蹈动作，并构建了大规模可编辑舞蹈数据集DanceRemix。


<details>
  <summary>Details</summary>
Motivation: 现有的舞蹈合成方法虽然支持直接生成舞蹈动作，但未能满足实际编舞场景中用户对舞蹈动作编辑的需求，同时缺乏高质量的可编辑舞蹈数据集。

Method: 论文提出了一个预测-编辑范式框架DanceEditor，通过直接建模舞蹈动作和音乐信号的关联，并在后续编辑阶段引入文本描述作为条件信息，利用跨模态编辑模块（CEM）生成可编辑的舞蹈序列。

Result: 实验表明，DanceEditor在新构建的DanceRemix数据集上优于现有方法，能够生成既符合音乐节奏又满足文本语义的舞蹈动作。

Conclusion: DanceEditor框架通过在预测阶段生成高质量舞蹈动作和在编辑阶段引入多模态条件，实现了可迭代编辑的舞蹈合成，为实际编舞场景提供了实用工具。

Abstract: Generating coherent and diverse human dances from music signals has gained
tremendous progress in animating virtual avatars. While existing methods
support direct dance synthesis, they fail to recognize that enabling users to
edit dance movements is far more practical in real-world choreography
scenarios. Moreover, the lack of high-quality dance datasets incorporating
iterative editing also limits addressing this challenge. To achieve this goal,
we first construct DanceRemix, a large-scale multi-turn editable dance dataset
comprising the prompt featuring over 25.3M dance frames and 84.5K pairs. In
addition, we propose a novel framework for iterative and editable dance
generation coherently aligned with given music signals, namely DanceEditor.
Considering the dance motion should be both musical rhythmic and enable
iterative editing by user descriptions, our framework is built upon a
prediction-then-editing paradigm unifying multi-modal conditions. At the
initial prediction stage, our framework improves the authority of generated
results by directly modeling dance movements from tailored, aligned music.
Moreover, at the subsequent iterative editing stages, we incorporate text
descriptions as conditioning information to draw the editable results through a
specifically designed Cross-modality Editing Module (CEM). Specifically, CEM
adaptively integrates the initial prediction with music and text prompts as
temporal motion cues to guide the synthesized sequences. Thereby, the results
display music harmonics while preserving fine-grained semantic alignment with
text descriptions. Extensive experiments demonstrate that our method
outperforms the state-of-the-art models on our newly collected DanceRemix
dataset. Code is available at https://lzvsdy.github.io/DanceEditor/.

</details>


### [5] [Random-phase Gaussian Wave Splatting for Computer-generated Holography](https://arxiv.org/abs/2508.17480)
*Brian Chao,Jacqueline Yang,Suyeon Choi,Manu Gopakumar,Ryota Koiso,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 论文提出了一种名为GWS-RP的随机相位高斯波溅射方法，通过改进带宽利用，提升全息近眼显示的图像质量和3D效果。


<details>
  <summary>Details</summary>
Motivation: 现有的高斯波溅射（GWS）方法假设高斯原语具有平滑相位分布，限制了其对视图依赖效应和散焦模糊的建模能力，且未充分利用空间光调制器的带宽。因此，需要一种改进方法以解决这些问题。

Method: 论文提出了一种随机相位高斯波溅射（GWS-RP）方法，包括新的波前合成流程和针对随机相位高斯原语的Alpha混合方案，并首次推导了将随机相位应用于高斯原语的算法。

Result: 通过仿真和实验验证，GWS-RP在提升带宽利用率的同时，实现了更大的视窗、准确的散焦模糊和视差效果，并支持时间复用渲染以减少散斑噪声，最终实现了高质量的3D全息图像。

Conclusion: GWS-RP为新一代全息近眼显示提供了更高质量的图像和更真实的3D效果，是计算机生成全息术的重要进展。

Abstract: Holographic near-eye displays offer ultra-compact form factors for virtual
and augmented reality systems, but rely on advanced computer-generated
holography (CGH) algorithms to convert 3D scenes into interference patterns
that can be displayed on spatial light modulators (SLMs). Gaussian Wave
Splatting (GWS) has recently emerged as a powerful CGH paradigm that allows for
the conversion of Gaussians, a state-of-the-art neural 3D representation, into
holograms. However, GWS assumes smooth-phase distributions over the Gaussian
primitives, limiting their ability to model view-dependent effects and
reconstruct accurate defocus blur, and severely under-utilizing the
space-bandwidth product of the SLM. In this work, we propose random-phase GWS
(GWS-RP) to improve bandwidth utilization, which has the effect of increasing
eyebox size, reconstructing accurate defocus blur and parallax, and supporting
time-multiplexed rendering to suppress speckle artifacts.
  At the core of GWS-RP are (1) a fundamentally new wavefront compositing
procedure and (2) an alpha-blending scheme specifically designed for
random-phase Gaussian primitives, ensuring physically correct color
reconstruction and robust occlusion handling. Additionally, we present the
first formally derived algorithm for applying random phase to Gaussian
primitives, grounded in rigorous statistical optics analysis and validated
through practical near-eye display applications. Through extensive simulations
and experimental validations, we demonstrate that these advancements,
collectively with time-multiplexing, uniquely enables full-bandwith light field
CGH that supports accurate accurate parallax and defocus, yielding
state-of-the-art image quality and perceptually faithful 3D holograms for
next-generation near-eye displays.

</details>


### [6] [Enhancing Reference-based Sketch Colorization via Separating Reference Representations](https://arxiv.org/abs/2508.17620)
*Dingkun Yan,Xinrui Wang,Zhuoru Li,Suguru Saito,Yusuke Iwasawa,Yutaka Matsuo,Jiaxian Guo*

Main category: cs.GR

TL;DR: 该论文提出了一种基于参考的草图着色新框架，通过分解着色过程为模块化阶段，优化了视觉质量和参考相似度，同时减少了空间伪影。


<details>
  <summary>Details</summary>
Motivation: 现有的参考着色方法通常假设训练数据和推理数据的分布一致，但现实中的草图和参考图像往往存在显著不对齐，导致颜色化结果出现伪影和质量下降。论文旨在解决这一问题。

Method: 论文提出了一个新颖的框架，通过分解着色过程为模块化阶段，并引入背景编码器和风格编码器，分别在不同阶段训练，以优化低层级特征的转移和参考相似度。

Result: 实验通过定性和定量评估以及用户研究，证明了所提方法在视觉质量和参考相似度方面优于现有方法。

Conclusion: 该论文提出的框架显著改进了草图着色效果，并提供了灵活的推理模式，适用于多种应用场景。

Abstract: Reference-based sketch colorization methods have garnered significant
attention for the potential application in animation and digital illustration
production. However, most existing methods are trained with image triplets of
sketch, reference, and ground truth that are semantically and spatially
similar, while real-world references and sketches often exhibit substantial
misalignment. This mismatch in data distribution between training and inference
leads to overfitting, consequently resulting in artifacts and signif- icant
quality degradation in colorization results. To address this issue, we conduct
an in-depth analysis of the reference representations, defined as the
intermedium to transfer information from reference to sketch. Building on this
analysis, we introduce a novel framework that leverages distinct reference
representations to optimize different aspects of the colorization process. Our
approach decomposes colorization into modular stages, al- lowing
region-specific reference injection to enhance visual quality and reference
similarity while mitigating spatial artifacts. Specifically, we first train a
backbone network guided by high-level semantic embeddings. We then introduce a
background encoder and a style encoder, trained in separate stages, to enhance
low-level feature transfer and improve reference similar- ity. This design also
enables flexible inference modes suited for a variety of use cases. Extensive
qualitative and quantitative evaluations, together with a user study,
demonstrate the superior performance of our proposed method compared to
existing approaches. Code and pre-trained weight will be made publicly
available upon paper acceptance.

</details>


### [7] [Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph](https://arxiv.org/abs/2508.17645)
*Xiaoyang Huang,Bingbing Ni,Wenjun Zhang*

Main category: cs.GR

TL;DR: 该论文提出了一种将AI生成的3D内容与设计师工作流程对接的方法，通过可微分操作序列实现高效几何建模，提升人机协作效率。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的3D内容（如网格或神经表示）与设计师使用的参数化建模工具之间存在脱节，限制了AI在3D设计行业的实用价值。论文旨在解决这一鸿沟，使AI生成的内容更贴合设计师的实际工作流程。

Method: 论文将基本建模操作（如挤出、布尔运算）转化为可微分单元，并通过基于梯度的学习优化连续和离散参数。构建了一个带有门控机制的分层图，通过最小化Chamfer距离实现端到端优化。多阶段序列长度约束和领域规则惩罚实现了无监督学习。

Result: 生成的3D设计操作序列在几何保真度、网格平滑性、步骤合理性以及编辑灵活性方面表现优异，完全兼容设计行业标准。

Conclusion: 该方法成功地将AI生成的3D内容与设计师的工作流程结合，显著提升了人机协作效率，并展示了在3D设计行业的广泛应用潜力。

Abstract: The emergence of 3D artificial intelligence-generated content (3D-AIGC) has
enabled rapid synthesis of intricate geometries. However, a fundamental
disconnect persists between AI-generated content and human-centric design
paradigms, rooted in representational incompatibilities: conventional AI
frameworks predominantly manipulate meshes or neural representations
(\emph{e.g.}, NeRF, Gaussian Splatting), while designers operate within
parametric modeling tools. This disconnection diminishes the practical value of
AI for 3D industry, undermining the efficiency of human-AI collaboration. To
resolve this disparity, we focus on generating design operation sequences,
which are structured modeling histories that comprehensively capture the
step-by-step construction process of 3D assets and align with designers'
typical workflows in modern 3D software. We first reformulate fundamental
modeling operations (\emph{e.g.}, \emph{Extrude}, \emph{Boolean}) into
differentiable units, enabling joint optimization of continuous (\emph{e.g.},
\emph{Extrude} height) and discrete (\emph{e.g.}, \emph{Boolean} type)
parameters via gradient-based learning. Based on these differentiable
operations, a hierarchical graph with gating mechanism is constructed and
optimized end-to-end by minimizing Chamfer Distance to target geometries.
Multi-stage sequence length constraint and domain rule penalties enable
unsupervised learning of compact design sequences without ground-truth sequence
supervision. Extensive validation demonstrates that the generated operation
sequences achieve high geometric fidelity, smooth mesh wiring, rational step
composition and flexible editing capacity, with full compatibility within
design industry.

</details>


### [8] [MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting](https://arxiv.org/abs/2508.17811)
*Hanzhi Chang,Ruijie Zhu,Wenjie Chang,Mulin Yu,Yanzhe Liang,Jiahao Lu,Zhuoyuan Li,Tianzhu Zhang*

Main category: cs.GR

TL;DR: MeshSplat是一种基于高斯溅射的通用稀疏视图表面重建框架，通过2DGS连接新视图合成与学习几何先验，从而在稀疏输入视图下实现精确的几何恢复。


<details>
  <summary>Details</summary>
Motivation: 现有表面重建方法在输入视图极为稀疏时难以恢复准确的场景几何，因此需要一种能够在稀疏视图下仍能保持高精度的重建方法。

Method: 提出了一种结合前馈网络预测逐视图像素对齐的2DGS的方法，并引入了加权Chamfer距离损失和法线预测网络以优化2DGS的位置与方向预测。

Result: 实验验证了方法的有效性，证明其在通用稀疏视图网格重建任务中达到了最先进的性能。

Conclusion: MeshSplat通过2DGS和几何先验的转换，成功解决了稀疏视图下表面重建的挑战，展示了其在稀疏输入情况下的优越性。

Abstract: Surface reconstruction has been widely studied in computer vision and
graphics. However, existing surface reconstruction works struggle to recover
accurate scene geometry when the input views are extremely sparse. To address
this issue, we propose MeshSplat, a generalizable sparse-view surface
reconstruction framework via Gaussian Splatting. Our key idea is to leverage
2DGS as a bridge, which connects novel view synthesis to learned geometric
priors and then transfers these priors to achieve surface reconstruction.
Specifically, we incorporate a feed-forward network to predict per-view
pixel-aligned 2DGS, which enables the network to synthesize novel view images
and thus eliminates the need for direct 3D ground-truth supervision. To improve
the accuracy of 2DGS position and orientation prediction, we propose a Weighted
Chamfer Distance Loss to regularize the depth maps, especially in overlapping
areas of input views, and also a normal prediction network to align the
orientation of 2DGS with normal vectors predicted by a monocular normal
estimator. Extensive experiments validate the effectiveness of our proposed
improvement, demonstrating that our method achieves state-of-the-art
performance in generalizable sparse-view mesh reconstruction tasks. Project
Page: https://hanzhichang.github.io/meshsplat_web

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [9] [SafeTree: Expressive Tree Policies for Microservices](https://arxiv.org/abs/2508.16746)
*Karuna Grewal,P. Brighten Godfrey,Justin Hsu*

Main category: cs.PL

TL;DR: 提出了一种基于微服务树结构的策略语言和执行机制，通过非侵入式运行时监控在服务网格中实现精细化的通信控制，实验证明其在毫秒级延迟下有效执行安全性策略。


<details>
  <summary>Details</summary>
Motivation: 现有微服务部署工具仅支持简单的单跳策略，忽视了微服务调用中的树形结构，导致策略可能过于宽松。需要一种更精细化的策略语言和执行机制来控制通信。

Method: 设计了一种表达性强的策略语言描述服务树结构，并开发了基于显式下推自动机的动态执行机制。在服务网格上构建运行时监控，利用Istio的可编程网络流量过滤功能实现分布式监控。

Result: 实验结果表明，该方法能够在毫秒级延迟开销下强制执行丰富的安全策略，且无需修改服务实现或访问微服务代码。

Conclusion: 提出的非侵入式监控方法为开发和安全管理团队提供了对微服务通信模式的精细化控制，有效弥补了现有工具的不足。

Abstract: A microservice-based application is composed of multiple self-contained
components called microservices, and controlling inter-service communication is
important for enforcing safety properties. Presently, inter-service
communication is configured using microservice deployment tools. However, such
tools only support a limited class of single-hop policies, which can be overly
permissive because they ignore the rich service tree structure of microservice
calls. Policies that can express the service tree structure can offer
development and security teams more fine-grained control over communication
patterns.
  To this end, we design an expressive policy language to specify service tree
structures, and we develop a visibly pushdown automata-based dynamic
enforcement mechanism to enforce service tree policies. Our technique is
non-invasive: it does not require any changes to service implementations, and
does not require access to microservice code. To realize our method, we build a
runtime monitor on top of a service mesh, an emerging network infrastructure
layer that can control inter-service communication during deployment. In
particular, we employ the programmable network traffic filtering capabilities
of Istio, a popular service mesh implementation, to implement an online and
distributed monitor. Our experiments show that our monitor can enforce rich
safety properties while adding minimal latency overhead on the order of
milliseconds.

</details>


### [10] [Syntactic Completions with Material Obligations](https://arxiv.org/abs/2508.16848)
*David Moon,Andrew Blinn,Thomas J. Porter,Cyrus Omar*

Main category: cs.PL

TL;DR: 论文介绍了一种名为$\texttt{tylr}$的解析器和编辑器生成工具，通过插入“义务”来补全代码中的语法错误，并支持视觉化展示，提供了一种介于文本编辑器和结构编辑器之间的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的语法错误恢复技术（如恐慌模式和多选项修复）要么过于粗糙，要么导致补全选项过多。$\texttt{tylr}$旨在解决这些问题，提供更精确和灵活的语法错误补全方法。

Method: $\texttt{tylr}$基于改进的基于瓦片的解析理论，通过语法行走生成义务，并使用基于语法拉链的“成型”系统扩展语法表达性，同时提供了视觉化展示功能。

Result: 通过示例和形式化分析，论文展示了$\texttt{tylr}$的有效性。人类用户研究表明，这种可视化的语法义务编辑器具有实用性和潜力。

Conclusion: $\texttt{tylr}$为语法错误补全和代码编辑提供了一种新颖且有前景的方法，同时为未来研究开辟了新的方向。

Abstract: Code editors provide essential services that help developers understand,
navigate, and modify programs. However, these services often fail in the
presence of syntax errors. Existing syntax error recovery techniques, like
panic mode and multi-option repairs, are either too coarse, e.g. in deleting
large swathes of code, or lead to a proliferation of possible completions. This
paper introduces $\texttt{tylr}$, a parser and editor generator that completes
arbitrarily malformed code by inserting obligations, which generalize holes to
cover missing operands, operators, mixfix keywords, and sort transitions.
$\texttt{tylr}$ is backed by a novel theory of tile-based parsing, which
extends operator-precedence parsing in two ways. First, traditional token
precedence comparisons are replaced by a notion of grammar walks, which form
the basis for generating obligations. Second, a distinct "molding" system based
on grammar zippers expand grammar expressivity by allowing the system to
disambiguate between possible parses and completions based on an obligation
minimization criterion. In addition to serving as a novel approach to error
correction, $\texttt{tylr}$'s design enables the development of an editor that
visually materializes obligations to the human user, serving as a novel hybrid
between a text editor and a structure editor. We introduce $\texttt{tylr}$ by
example, then formalize its key ideas. Finally, we conduct a human subjects
study to evaluate the extent to which an editor like $\texttt{tylr}$ that
materializes syntactic obligations might be usable and useful, finding both
points of positivity and interesting new avenues for future work.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [Risk-Averse and Optimistic Advertiser Incentive Compatibility in Auto-bidding](https://arxiv.org/abs/2508.16823)
*Christopher Liaw,Wennan Zhu*

Main category: cs.GT

TL;DR: 论文提出了两种改进的自动竞价激励兼容性概念——风险厌恶型（RAIC）和乐观型（OAIC），并通过分析第二价格拍卖（SPA）的激励特性，展示了其在自动竞价环境中的适用性。


<details>
  <summary>Details</summary>
Motivation: 自动竞价的兴起为广告商的激励兼容性带来了挑战，尤其是在广告商将竞价委托给具有高层约束的代理时。现有的自动竞价激励兼容性（AIC）定义过于严格，且忽略了广告商对约束的多重偏好。

Method: 论文引入了两种改进的激励兼容性概念：风险厌恶型自动竞价激励兼容性（RAIC）和乐观型自动竞价激励兼容性（OAIC）。这些概念通过比较真实报告和误报的最优或最差均衡结果来定义激励兼容性。

Result: 论文证明了第二价格拍卖（SPA）满足RAIC和OAIC条件，并且在假设两个广告商采用统一竞价时，SPA仍然满足这些条件。

Conclusion: 这些发现为自动竞价环境中SPA的激励特性提供了新的见解，尤其是在考虑广告商对均衡选择的不同态度时。

Abstract: The rise of auto-bidding has created challenges for ensuring advertiser
incentive compatibility, particularly when advertisers delegate bidding to
agents with high-level constraints. One challenge in defining incentive
compatibility is the multiplicity of equilibria. After advertisers submit
reports, it is unclear what the result will be and one only has knowledge of a
range of possible results. Nevertheless, Alimohammadi et al. proposed a notion
of Auto-bidding Incentive Compatibility (AIC) which serves to highlight that
auctions may not incentivize truthful reporting of constraints. However, their
definition of AIC is very stringent as it requires that the worst-case outcome
of an advertiser's truthful report is at least as good as the best-case outcome
of any of the advertiser's possible deviations. Indeed, they show both
First-Price Auction and Second-Price Auction are not AIC. Moreover, the AIC
definition precludes having ordinal preferences on the possible constraints
that the advertiser can report.
  In this paper, we introduce two refined and relaxed concepts: Risk-Averse
Auto-bidding Incentive Compatibility (RAIC) and Optimistic Auto-bidding
Incentive Compatibility (OAIC). RAIC (OAIC) stipulates that truthful reporting
is preferred if its least (most) favorable equilibrium outcome is no worse than
the least (most) favorable equilibrium outcome from any misreport. This
distinction allows for a clearer modeling of ordinal preferences for
advertisers with differing attitudes towards equilibrium uncertainty. We
demonstrate that SPA satisfies both RAIC and OAIC. Furthermore, we show that
SPA also meets these conditions for two advertisers when they are assumed to
employ uniform bidding. These findings provide new insights into the incentive
properties of SPA in auto-bidding environments, particularly when considering
advertisers' perspectives on equilibrium selection.

</details>


### [12] [Personalized Pricing Through Strategic User Profiling in Social Networks](https://arxiv.org/abs/2508.17111)
*Qinqi Lin,Lingjie Duan,Jianwei Huang*

Main category: cs.GT

TL;DR: 该研究首次分析了用户如何在社交媒体活动中最佳管理以应对潜在的个性化定价，以及卖家如何策略性地调整定价方案以促进用户画像。通过动态贝叶斯博弈模型，研究揭示了随着画像技术准确性的提高，卖家倾向于提高均衡统一价格以激励用户增加社交活动，但导致大多数用户在知情同意政策下变得更糟。


<details>
  <summary>Details</summary>
Motivation: 随着隐私增强技术的兴起，用户开始避免数据跟踪，卖家转向社交网络进行用户画像。研究旨在分析用户如何管理与卖家之间的互动，以应对个性化定价，以及卖家如何策略调整定价方案。

Method: 研究采用动态贝叶斯博弈模型，分析卖家和用户在不对称信息下的互动。通过交替应用前后向归纳法，成功刻画了唯一的完美贝叶斯均衡（PBE）。

Result: 研究发现，随着画像技术准确性的提高，卖家提高均衡统一价格以激励用户社交活动，但导致大多数用户在知情同意政策下变得更糟。

Conclusion: 研究指出，增强用户隐私意识的监管改革可能会意外减少用户的收益，揭示了当前隐私保护政策可能带来的负面影响。

Abstract: Traditional user profiling techniques rely on browsing history or purchase
records to identify users' willingness to pay. This enables sellers to offer
personalized prices to profiled users while charging only a uniform price to
non-profiled users. However, the emergence of privacy-enhancing technologies
has caused users to actively avoid on-site data tracking. Today, major online
sellers have turned to public platforms such as online social networks to
better track users' profiles from their product-related discussions. This paper
presents the first analytical study on how users should best manage their
social activities against potential personalized pricing, and how a seller
should strategically adjust her pricing scheme to facilitate user profiling in
social networks. We formulate a dynamic Bayesian game played between the seller
and users under asymmetric information. The key challenge of analyzing this
game comes from the double couplings between the seller and the users as well
as among the users. Furthermore, the equilibrium analysis needs to ensure
consistency between users' revealed information and the seller's belief under
random user profiling. We address these challenges by alternately applying
backward and forward induction, and successfully characterize the unique
perfect Bayesian equilibrium (PBE) in closed form. Our analysis reveals that as
the accuracy of profiling technology improves, the seller tends to raise the
equilibrium uniform price to motivate users' increased social activities and
facilitate user profiling. However, this results in most users being worse off
after the informed consent policy is imposed to ensure users' awareness of data
access and profiling practices by potential sellers. This finding suggests that
recent regulatory evolution towards enhancing users' privacy awareness may have
unintended consequences of reducing users' payoffs.

</details>


### [13] [Designing Rules to Pick a Rule: Aggregation by Consistency](https://arxiv.org/abs/2508.17177)
*Ratip Emin Berker,Ben Armstrong,Vincent Conitzer,Nihar B. Shah*

Main category: cs.GT

TL;DR: 本文提出了一种新颖的规则选择规则（RPR）框架，通过最大化结果的重复一致性来选择最优排名聚合方法，并在理论和实践中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在排名聚合问题中，现有方法各有优缺点且无法同时满足所有理想属性，因此需要一种原则性的方法来选择最适合具体场景的聚合规则。

Method: 引入了一种数据驱动的规则选择规则（RPR），通过最大化重复数据收集过程中的一致性来选取最佳聚合方法，无需假设生成模型。

Result: 提出的RPR满足多项一致性公理，并在实验中成功选择了数据最大似然估计器，验证了其在实际应用中的有效性。

Conclusion: 本文为排名聚合问题中的规则选择提供了理论支持，将公理化和统计方法相结合，为实际应用中的规则改进奠定了基础。

Abstract: Given a set of items and a set of evaluators who all individually rank them,
how do we aggregate these evaluations into a single societal ranking? Work in
social choice and statistics has produced many aggregation methods for this
problem, each with its desirable properties, but also with its limitations.
Further, existing impossibility results rule out designing a single method that
achieves every property of interest. Faced with this trade-off between
incompatible desiderata, how do we decide which aggregation rule to use, i.e.,
what is a good rule picking rule?
  In this paper, we formally address this question by introducing a novel
framework for rule picking rules (RPRs). We then design a data-driven RPR that
identifies the best aggregation method for each specific setting, without
assuming any generative model. The principle behind our RPR is to pick the rule
which maximizes the consistency of the output ranking if the data collection
process were repeated. We introduce several consistency-related axioms for RPRs
and show that our method satisfies them, including those failed by a wide class
of natural RPRs. While we prove that the algorithmic problem of maximizing
consistency is computationally hard, we provide a sampling-based implementation
of our RPR that is efficient in practice. We run this implementation on known
statistical models and find that, when possible, our method selects the maximum
likelihood estimator of the data. Finally, we show that our RPR can be used in
many real-world settings to gain insights about how the rule currently being
used can be modified or replaced to substantially improve the consistency of
the process.
  Taken together, our work bridges an important gap between the axiomatic and
statistical approaches to rank aggregation, laying a robust theoretical and
computational foundation for principled rule picking.

</details>


### [14] [Decision-Making on Timing and Route Selection: A Game-Theoretic Approach](https://arxiv.org/abs/2508.17206)
*Chenlan Wang,Mingyan Liu*

Main category: cs.GT

TL;DR: 本文提出了一个Stackelberg博弈模型，研究个体在时间和路线选择上的决策，适用于鸟类迁徙、交通规划等多种场景。


<details>
  <summary>Details</summary>
Motivation: 研究个体在时间和路线选择上的决策行为，并探讨这些行为如何自然形成群体，特别是在鸟类迁徙、交通规划等场景中的应用。

Method: 采用Stackelberg博弈模型，结合个体的旅行成本差异，分析时间和路线选择的决策过程。

Result: 模型揭示了比以往仅关注时间的模型更丰富的子博弈完美均衡（SPEs），并引入了中性状态，扩展了“合作”与“竞争”之外的选项。

Conclusion: 模型不仅适用于鸟类迁徙，还为交通规划和灾害疏散等提供了新视角，强调了时间和路线选择的复杂性。

Abstract: We present a Stackelberg game model to investigate how individuals make their
decisions on timing and route selection. Group formation can naturally result
from these decisions, but only when individuals arrive at the same time and
choose the same route. Although motivated by bird migration, our model applies
to scenarios such as traffic planning, disaster evacuation, and other animal
movements. Early arrivals secure better territories, while traveling together
enhances navigation accuracy, foraging efficiency, and energy efficiency.
Longer or more difficult migration routes reduce predation risks but increase
travel costs, such as higher elevations and scarce food resources. Our analysis
reveals a richer set of subgame perfect equilibria (SPEs) and heightened
competition, compared to earlier models focused only on timing. By
incorporating individual differences in travel costs, our model introduces a
"neutrality" state in addition to "cooperation" and "competition."

</details>


### [15] [A Dynamic Approach to Collaborative Document Writing](https://arxiv.org/abs/2508.17489)
*Avital Finanser,Nimrod Talmon*

Main category: cs.GT

TL;DR: 论文提出了一个协作文本聚合模型，社区代理通过投票机制共同编写文档，并通过模拟实验验证其快速收敛至高社会价值文档的可能性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何通过动态投票机制实现社区代理协作撰写文档，同时关注过程的稳定性和社会价值的最大化。

Method: 方法包括形式化协作文本聚合场景，设计投票机制将代理提议的段落整合为动态文档，并通过结合NLP和LLM的代理模拟实验验证模型。

Result: 实验结果显示，通过所提出的投票机制，协作文本能够快速收敛至高质量且具有高社会价值的文档。

Conclusion: 研究表明，动态投票机制可以有效促进协作文本的稳定性和社会价值，为社区代理协作提供了可行的解决方案。

Abstract: We introduce a model for collaborative text aggregation in which an agent
community coauthors a document, modeled as an unordered collection of
paragraphs, using a dynamic mechanism: agents propose paragraphs and vote on
those suggested by others. We formalize the setting and explore its
realizations, concentrating on voting mechanisms that aggregate votes into a
single, dynamic document. We focus on two desiderata: the eventual stability of
the process and its expected social welfare. Following an impossibility result,
we describe several aggregation methods and report on agent-based simulations
that utilize natural language processing (NLP) and large-language models (LLMs)
to model agents and their contexts. Using these simulations, we demonstrate
promising results regarding the possibility of rapid convergence to a high
social welfare collaborative text.

</details>


### [16] [Price of Uncertainty for Consensus Games](https://arxiv.org/abs/2508.17557)
*Yunzhe Bai,Alec Sun*

Main category: cs.GT

TL;DR: 本文研究了博弈模型中不确定性对社交成本的影响，证明了共识游戏中不确定性价格的紧界为Θ(ε²n²)。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，博弈模型中的玩家通常面临信息的不确定性，而现有模型常假设信息准确。本文旨在填补这一理论空缺，探索不确定性对博弈结果的影响。

Method: 通过引入对抗性扰动，对玩家的观察成本施加相对幅度1+ε的不确定性，并分析这种不确定性对社交成本的影响。

Result: 证明了在共识游戏中，不确定性价格的紧界为Θ(ε²n²)，改进了此前Ω(ε³n²)的下界和O(εn²)的上界。

Conclusion: 本研究为博弈论中的不确定性分析提供了更精确的理论工具，并展示了对抗性扰动对社交成本的深刻影响。

Abstract: Many game-theoretic models assume that players have access to accurate
information, but uncertainty in observed data is frequently present in
real-world settings. In this paper, we consider a model of uncertainty where
adversarial perturbations of relative magnitude $1+\varepsilon$ are introduced
to players' observed costs. The effect of uncertainty on social cost is denoted
as the price of uncertainty. We prove a tight bound on the price of uncertainty
for consensus games of $\Theta(\varepsilon^2 n^2)$ for all $\varepsilon =
\Omega\mathopen{}\left(n^{-1/4}\right)$. This improves a previous lower bound
of $\Omega(\varepsilon^3 n^2)$ as well as a previous upper bound of
$O(\varepsilon n^2)$.

</details>


### [17] [Consistent Opponent Modeling of Static Opponents in Imperfect-Information Games](https://arxiv.org/abs/2508.17671)
*Sam Ganzfried*

Main category: cs.GT

TL;DR: 本文提出了一种新算法，通过解决基于序列形式博弈表示的凸最小化问题，有效建模对手策略，解决了现有对手建模方法在静态对手环境中无法保证收敛的缺陷。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，现有对手建模方法无法利用历史数据有效建模对手策略，尤其是在不完全信息博弈中效果有限。本文旨在解决这一问题。

Method: 本文开发了一种新算法，利用序列形式博弈表示，通过投影梯度下降解决凸最小化问题，实现对对手策略的高效建模。

Result: 该算法能保证在游戏迭代次数趋近于无穷时，模型能收敛到对手的真实策略，且在历史和实时数据可用时表现出高效性。

Conclusion: 本文提出的算法在多智能体环境中表现优越，解决了现有对手建模方法的局限性，尤其是在不完全信息博弈中的应用潜力巨大。

Abstract: The goal of agents in multi-agent environments is to maximize total reward
against the opposing agents that are encountered. Following a game-theoretic
solution concept, such as Nash equilibrium, may obtain a strong performance in
some settings; however, such approaches fail to capitalize on historical and
observed data from repeated interactions against our opponents. Opponent
modeling algorithms integrate machine learning techniques to exploit suboptimal
opponents utilizing available data; however, the effectiveness of such
approaches in imperfect-information games to date is quite limited. We show
that existing opponent modeling approaches fail to satisfy a simple desirable
property even against static opponents drawn from a known prior distribution;
namely, they do not guarantee that the model approaches the opponent's true
strategy even in the limit as the number of game iterations approaches
infinity. We develop a new algorithm that is able to achieve this property and
runs efficiently by solving a convex minimization problem based on the
sequence-form game representation using projected gradient descent. The
algorithm is guaranteed to efficiently converge to the opponent's true strategy
given observations from gameplay and possibly additional historical data if it
is available.

</details>


### [18] [WOMAC: A Mechanism For Prediction Competitions](https://arxiv.org/abs/2508.17907)
*Siddarth Srinivasan,Tao Lin,Connacher Murphy,Anish Thilagar,Yiling Chen,Ezra Karger*

Main category: cs.GT

TL;DR: 论文提出了一种名为WOMAC的新型确定性机制，用于解决标准比赛设计中因结果/标签噪声导致的问题，并通过理论和实证证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 标准比赛设计在判断性预测和机器学习中广泛使用，但由于结果/标签的噪声，既不激励兼容，统计效率也不高。这导致较弱的竞争者可能凭运气获胜，并激励参赛者通过虚假报告提高获胜概率。

Method: 引入了WOMAC（Wisdom of the Most Accurate Crowd）机制，通过将专家的评分基于最优的后验同行预测聚合，而非直接评分于噪声结果，从而减少噪声影响。

Result: 理论分析和实证研究表明，WOMAC在典型设置中比标准设计更高效，并能够更可靠地预测专家的样本外表现。

Conclusion: WOMAC是一种适用于结果/标签噪声较大的竞争的新型机制，具有更高的可靠性和统计效率。

Abstract: Competitions are widely used to identify top performers in judgmental
forecasting and machine learning, and the standard competition design ranks
competitors based on their cumulative scores against a set of realized outcomes
or held-out labels. However, this standard design is neither
incentive-compatible nor very statistically efficient. The main culprit is
noise in outcomes/labels that experts are scored against; it allows weaker
competitors to often win by chance, and the winner-take-all nature incentivizes
misreporting that improves win probability even if it decreases expected score.
Attempts to achieve incentive-compatibility rely on randomized mechanisms that
add even more noise in winner selection, but come at the cost of determinism
and practical adoption. To tackle these issues, we introduce a novel
deterministic mechanism: WOMAC (Wisdom of the Most Accurate Crowd). Instead of
scoring experts against noisy outcomes, as is standard, WOMAC scores experts
against the best ex-post aggregate of peer experts' predictions given the noisy
outcomes. WOMAC is also more efficient than the standard competition design in
typical settings. While the increased complexity of WOMAC makes it challenging
to analyze incentives directly, we provide a clear theoretical foundation to
justify the mechanism. We also provide an efficient vectorized implementation
and demonstrate empirically on real-world forecasting datasets that WOMAC is a
more reliable predictor of experts' out-of-sample performance relative to the
standard mechanism. WOMAC is useful in any competition where there is
substantial noise in the outcomes/labels.

</details>


### [19] [Adaptive Learning for Moving Target defence: Enhancing Cybersecurity Strategies](https://arxiv.org/abs/2508.17945)
*Mandar Datar,Yann Dujardin*

Main category: cs.GT

TL;DR: 本文通过将移动目标防御建模为一个部分可观察的随机博弈，提出了一种基于阈值的策略梯度强化学习算法，帮助攻击者和防御者收敛到纳什均衡，从而提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: 为了提升系统安全性，需要一种动态防御策略来平衡性能成本和安全性，同时对抗不断演变的攻击威胁。

Method: 将移动目标防御建模为部分可观察的随机博弈，并提出一种基于阈值结构的策略梯度强化学习算法。

Result: 最优策略表现出阈值结构，算法帮助攻击者和防御者收敛到纳什均衡，并通过数值模拟验证了其有效性。

Conclusion: 所提出的方法能够有效增强防御者的适应性，提高系统整体安全性。

Abstract: In this work, we model Moving Target Defence (MTD) as a partially observable
stochastic game between an attacker and a defender. The attacker tries to
compromise the system through probing actions, while the defender minimizes the
risk by reimaging the system, balancing between performance cost and security
level. We demonstrate that the optimal strategies for both players follow a
threshold structure. Based on this insight, we propose a structure-aware policy
gradient reinforcement learning algorithm that helps both players converge to
the Nash equilibrium. This approach enhances the defender's ability to adapt
and effectively counter evolving threats, improving the overall security of the
system. Finally, we validate the proposed method through numerical simulations.

</details>
