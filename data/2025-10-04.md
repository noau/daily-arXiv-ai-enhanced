<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics](https://arxiv.org/abs/2510.01619)
*Changmin Lee,Jihyun Lee,Tae-Kyun Kim*

Main category: cs.GR

TL;DR: MPMAvatar是一个基于多视角视频创建3D人体化身的框架，通过改进的材料点方法模拟器实现了高真实感的动态建模和渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模拟松散衣物的物理动力学时存在准确性不足或对新动画输入鲁棒性差的问题，MPMAvatar旨在解决这些问题。

Method: 使用基于材料点方法的模拟器，结合各向异性本构模型和新型碰撞处理算法，实现对复杂变形衣物的精确建模，并与3D高斯溅射渲染技术结合。

Result: 实验中，MPMAvatar在动态建模准确性、渲染质量和鲁棒性方面显著优于现有技术，并能零样本泛化到未见过的交互场景。

Conclusion: MPMAvatar成功解决了现有技术在动态建模和渲染中的局限性，展示了更高的准确性和鲁棒性，为未来虚拟化身技术提供了新的可能性。

Abstract: While there has been significant progress in the field of 3D avatar creation
from visual observations, modeling physically plausible dynamics of humans with
loose garments remains a challenging problem. Although a few existing works
address this problem by leveraging physical simulation, they suffer from
limited accuracy or robustness to novel animation inputs. In this work, we
present MPMAvatar, a framework for creating 3D human avatars from multi-view
videos that supports highly realistic, robust animation, as well as
photorealistic rendering from free viewpoints. For accurate and robust dynamics
modeling, our key idea is to use a Material Point Method-based simulator, which
we carefully tailor to model garments with complex deformations and contact
with the underlying body by incorporating an anisotropic constitutive model and
a novel collision handling algorithm. We combine this dynamics modeling scheme
with our canonical avatar that can be rendered using 3D Gaussian Splatting with
quasi-shadowing, enabling high-fidelity rendering for physically realistic
animations. In our experiments, we demonstrate that MPMAvatar significantly
outperforms the existing state-of-the-art physics-based avatar in terms of (1)
dynamics modeling accuracy, (2) rendering accuracy, and (3) robustness and
efficiency. Additionally, we present a novel application in which our avatar
generalizes to unseen interactions in a zero-shot manner-which was not
achievable with previous learning-based methods due to their limited simulation
generalizability. Our project page is at:
https://KAISTChangmin.github.io/MPMAvatar/

</details>


### [2] [Multimodal Feedback for Task Guidance in Augmented Reality](https://arxiv.org/abs/2510.01690)
*Hu Guo,Lily Patel,Rohan Gupt*

Main category: cs.GR

TL;DR: 本研究探討結合光學透視增強現實（OST-AR）與手腕振動觸覺反饋的多模態系統，以提高深度感知和任務精度。


<details>
  <summary>Details</summary>
Motivation: 現有的OST-AR系統依賴視覺疊加，可能導致注意力過載和深度感知不足。為解決這些限制，研究者探索結合振動觸覺反饋的多模態方法。

Method: 設計了一個帶有六個振動馬達的手腕帶，提供定向和狀態提示，並與OST-AR和手持工具集成。通過形式化研究和兩個實驗（N=21和N=27），評估其效果。

Result: 實驗表明，參與者在認知負荷下能準確識別觸覺模式，且多模態反饋在空間精確度和可用性上優於僅視覺或僅觸覺條件。

Conclusion: 結合OST-AR與手腕振動觸覺反饋的多模態系統顯著改善了任務指導的精度和用戶體驗。

Abstract: Optical see-through augmented reality (OST-AR) overlays digital targets and
annotations on the physical world, offering promising guidance for hands-on
tasks such as medical needle insertion or assembly. Recent work on OST-AR depth
perception shows that target opacity and tool visualization significantly
affect accuracy and usability; opaque targets and rendering the real instrument
reduce depth errors, whereas transparent targets and absent tools impair
performance. However, reliance on visual overlays may overload attention and
leaves little room for depth cues when occlusion or lighting hampers
perception. To address these limitations, we explore multimodal feedback that
combines OST-AR with wrist-based vibrotactile haptics. The past two years have
seen rapid advances in haptic technology. Researchers have investigated
skin-stretch and vibrotactile cues for conveying spatial information to blind
users, wearable ring actuators that support precise pinching in AR, cross-modal
audio-haptic cursors that enable eyes-free object selection, and wrist-worn
feedback for teleoperated surgery that improves force awareness at the cost of
longer task times. Studies comparing pull versus push vibrotactile metaphors
found that pull cues yield faster gesture completion and lower cognitive load.
These findings motivate revisiting OST-AR guidance with a fresh perspective on
wrist-based haptics. We design a custom wristband with six vibromotors
delivering directional and state cues, integrate it with a handheld tool and
OST-AR, and assess its impact on cue recognition and depth guidance. Through a
formative study and two experiments (N=21 and N=27), we show that participants
accurately identify haptic patterns under cognitive load and that multimodal
feedback improves spatial precision and usability compared with visual-only or
haptic-only conditions.

</details>


### [3] [MIRAGE: Patient-Specific Mixed Reality Coaching for MRI via Depth-Only Markerless Registration and Immersive VR](https://arxiv.org/abs/2510.01743)
*Daniel Brooks,Emily Carter,Hu Guo,Rajesh Nair*

Main category: cs.GR

TL;DR: MIRAGE利用混合现实技术减少MRI检查中的焦虑和幽闭恐惧症，提升患者体验。


<details>
  <summary>Details</summary>
Motivation: MRI检查中的封闭空间和噪音易引发患者焦虑和幽闭恐惧，导致运动伪影和不完整扫描，亟需非药物解决方案。

Method: 通过混合现实技术（MR）结合虚拟现实（VR）和无标记增强现实（AR）注册，为患者提供沉浸式指导环境。

Result: 深度注册技术实现厘米级精度，沉浸式指导环境显著降低患者焦虑并提高可用性评分。

Conclusion: MIRAGE系统在临床部署中表现出潜力，能有效改善MRI检查的患者体验和工作流程。

Abstract: Magnetic resonance imaging (MRI) is an indispensable diagnostic tool, yet the
confined bore and acoustic noise can evoke considerable anxiety and
claustrophobic reactions. High anxiety leads to motion artifacts, incomplete
scans and reliance on pharmacological sedation. MIRAGE (Mixed Reality Anxiety
Guidance Environment) harnesses the latest mixed reality (MR) hardware to
prepare patients for MRI through immersive virtual reality (VR) and markerless
augmented reality (AR) registration. In this paper, we extend our previous work
by providing a comprehensive review of related research, detailing the system
architecture, and exploring metrics for patient and clinician experience. We
also present considerations for clinical deployment of MR systems within
hospital workflows. Our results indicate that depth-based registration achieves
sub-centimeter accuracy with minimal setup, while the immersive coaching
environment reduces patient anxiety and yields favourable usability scores.

</details>


### [4] [ROI-GS: Interest-based Local Quality 3D Gaussian Splatting](https://arxiv.org/abs/2510.01978)
*Quoc-Anh Bui,Gilles Rougeron,Géraldine Morin,Simone Gasparini*

Main category: cs.GR

TL;DR: ROI-GS是一种对象感知框架，通过对象引导的相机选择和有针对性训练，优先在兴趣对象上实现高分辨率细节，同时减少模型大小并保持实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在场景中均匀分配资源，限制了兴趣区域的精细细节并增加了模型大小，因此需要一种更高效的重建方法。

Method: ROI-GS利用对象引导的相机选择、针对性的对象训练，并将高保真的兴趣对象重建无缝集成到全局场景中。

Result: 实验显示ROI-GS显著提升了局部质量（PSNR最高提升2.96 dB），模型大小减少了约17%，并且在单兴趣对象场景中训练更快。

Conclusion: ROI-GS在提升兴趣对象细节的同时，优化了模型大小和训练效率，优于现有方法。

Abstract: We tackle the challenge of efficiently reconstructing 3D scenes with high
detail on objects of interest. Existing 3D Gaussian Splatting (3DGS) methods
allocate resources uniformly across the scene, limiting fine detail to Regions
Of Interest (ROIs) and leading to inflated model size. We propose ROI-GS, an
object-aware framework that enhances local details through object-guided camera
selection, targeted Object training, and seamless integration of high-fidelity
object of interest reconstructions into the global scene. Our method
prioritizes higher resolution details on chosen objects while maintaining
real-time performance. Experiments show that ROI-GS significantly improves
local quality (up to 2.96 dB PSNR), while reducing overall model size by
$\approx 17\%$ of baseline and achieving faster training for a scene with a
single object of interest, outperforming existing methods.

</details>


### [5] [Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects](https://arxiv.org/abs/2510.02069)
*Georgios Kouros,Minye Wu,Tinne Tuytelaars*

Main category: cs.GR

TL;DR: 提出了一种基于微面BRDF和2D高斯泼溅的可重光照框架，实现了高质量的光滑物体几何和材质重建。


<details>
  <summary>Details</summary>
Motivation: 光滑物体的精确重建和重光照是一个长期挑战，现有神经渲染方法依赖于简化的BRDF模型或耦合漫反射和镜面反射的参数化，限制了材质的忠实恢复和重光照的保真度。

Method: 结合微面BRDF与镜面光泽参数化的2D高斯泼溅框架，采用延迟着色，并利用基于扩散的表面法线和漫反射颜色先验指导早期优化。

Result: 实验表明，该方法在复杂光滑场景中实现了高质量的几何和材质重建，相比现有高斯泼溅方法，新光照条件下的重光照效果更真实一致。

Conclusion: 该框架通过更物理一致的材质分解和优化策略，显著提升了光滑物体的重建和重光照质量。

Abstract: Accurate reconstruction and relighting of glossy objects remain a
longstanding challenge, as object shape, material properties, and illumination
are inherently difficult to disentangle. Existing neural rendering approaches
often rely on simplified BRDF models or parameterizations that couple diffuse
and specular components, which restricts faithful material recovery and limits
relighting fidelity. We propose a relightable framework that integrates a
microfacet BRDF with the specular-glossiness parameterization into 2D Gaussian
Splatting with deferred shading. This formulation enables more physically
consistent material decomposition, while diffusion-based priors for surface
normals and diffuse color guide early-stage optimization and mitigate
ambiguity. A coarse-to-fine optimization of the environment map accelerates
convergence and preserves high-dynamic-range specular reflections. Extensive
experiments on complex, glossy scenes demonstrate that our method achieves
high-quality geometry and material reconstruction, delivering substantially
more realistic and consistent relighting under novel illumination compared to
existing Gaussian splatting methods.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Learning to Play Multi-Follower Bayesian Stackelberg Games](https://arxiv.org/abs/2510.01387)
*Gerson Personnat,Tao Lin,Safwan Hossain,David C. Parkes*

Main category: cs.GT

TL;DR: 该研究针对多跟随者贝叶斯Stackelberg游戏中的在线学习问题，设计了在不同反馈设置下领导者的学习算法，以最小化后悔。


<details>
  <summary>Details</summary>
Motivation: 研究在线学习版本的贝叶斯Stackelberg游戏，领导者需要在不知道跟随者类型分布的情况下与多跟随者互动，目标是设计算法以最小化后悔。

Method: 提出了两种反馈设置下的学习算法：类型反馈（观察到跟随者类型）和动作反馈（仅观察到动作），并分析了算法的后悔界。

Result: 在类型反馈下，算法达到次线性后悔界；在动作反馈下，设计了不同复杂度的算法，并提供接近类型反馈上界的下界。

Conclusion: 研究表明，设计的算法在多跟随者环境下能够有效降低后悔，且后悔界不会随跟随者数量多项式增长。

Abstract: In a multi-follower Bayesian Stackelberg game, a leader plays a mixed
strategy over $L$ actions to which $n\ge 1$ followers, each having one of $K$
possible private types, best respond. The leader's optimal strategy depends on
the distribution of the followers' private types. We study an online learning
version of this problem: a leader interacts for $T$ rounds with $n$ followers
with types sampled from an unknown distribution every round. The leader's goal
is to minimize regret, defined as the difference between the cumulative utility
of the optimal strategy and that of the actually chosen strategies. We design
learning algorithms for the leader under different feedback settings. Under
type feedback, where the leader observes the followers' types after each round,
we design algorithms that achieve $\mathcal O\big(\sqrt{\min\{L\log(nKA T), nK
\} \cdot T} \big)$ regret for independent type distributions and $\mathcal
O\big(\sqrt{\min\{L\log(nKA T), K^n \} \cdot T} \big)$ regret for general type
distributions. Interestingly, those bounds do not grow with $n$ at a polynomial
rate. Under action feedback, where the leader only observes the followers'
actions, we design algorithms with $\mathcal O( \min\{\sqrt{ n^L K^L A^{2L} L T
\log T}, K^n\sqrt{ T } \log T \} )$ regret. We also provide a lower bound of
$\Omega(\sqrt{\min\{L, nK\}T})$, almost matching the type-feedback upper
bounds.

</details>


### [7] [Designing Inferable Signaling Schemes for Bayesian Persuasion](https://arxiv.org/abs/2510.01434)
*Caleb Probine,Mustafa O. Karabag,Ufuk Topcu*

Main category: cs.GT

TL;DR: 该论文研究了贝叶斯说服中接收者通过反复互动推断信号方案的情境，对比了已知承诺情境下的性能损失，并提出了两种设计可推断信号方案的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯说服模型假设接收者知道发送者的承诺，而本文研究接收者通过反复互动推断信号方案的情境，探索其性能损失和设计方法。

Method: 论文首先理论分析了性能损失的界限，然后提出了两种设计可推断信号方案的方法：一种是基于发送者推断效用的随机梯度下降（SGD），另一种是基于有界理性接收者模型的优化。

Result: 研究发现，发送者在推断情境下需要比斯塔克伯格博弈更多的样本才能接近已知承诺的性能；SGD在低频互动中表现最佳，而有界理性模型提供了设计灵活方案的另一种方法。

Conclusion: 本文展示了在推断情境下设计信号方案的可行性，并通过SGD应用于安全警报示例，证明了其在减少信号数量和优化接收者行动方面的有效性。

Abstract: In Bayesian persuasion, an informed sender, who observes a state, commits to
a randomized signaling scheme that guides a self-interested receiver's actions.
Classical models assume the receiver knows the commitment. We, instead, study
the setting where the receiver infers the scheme from repeated interactions. We
bound the sender's performance loss relative to the known-commitment case by a
term that grows with the signal space size and shrinks as the receiver's
optimal actions become more distinct. We then lower bound the samples required
for the sender to approximately achieve their known-commitment performance in
the inference setting. We show that the sender requires more samples in
persuasion compared to the leader in a Stackelberg game, which includes
commitment but lacks signaling. Motivated by these bounds, we propose two
methods for designing inferable signaling schemes, one being stochastic
gradient descent (SGD) on the sender's inference-setting utility, and the other
being optimization with a boundedly-rational receiver model. SGD performs best
in low-interaction regimes, but modeling the receiver as boundedly-rational and
tuning the rationality constant still provides a flexible method for designing
inferable schemes. Finally, we apply SGD to a safety alert example and show it
to find schemes that have fewer signals and make citizens' optimal actions more
distinct compared to the known-commitment case.

</details>


### [8] [Incentive Analysis of Collusion in Fair Division](https://arxiv.org/abs/2510.01689)
*Haoqiang Huang,Biaoshuai Tao,Mingwei Yang,Shengwei Zhou*

Main category: cs.GT

TL;DR: 论文研究了战略性代理在公平分割问题中的合谋操纵行为，提出了SGIR和GIR来衡量操纵收益，并分析了MNW、PS和RR机制的合谋脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究表明基本机制（如MNW、PS和RR）在单个代理操纵下的激励比为2，但合谋操纵的问题尚未被探索。

Method: 通过定义SGIR和GIR来量化合谋操纵的收益，并分析了MNW、PS和RR机制在这些度量下的表现。

Result: 研究发现，MNW的GIR始终为2，而PS和RR的SGIR和GIR随联盟规模增长，RR的SGIR在联盟规模≥2时无界。

Conclusion: 研究揭示了MNW、PS和RR机制在合谋操纵脆弱性上的根本差异，为未来机制设计提供了重要参考。

Abstract: We study fair division problems with strategic agents capable of gaining
advantages by manipulating their reported preferences. Although several
impossibility results have revealed the incompatibility of truthfulness with
standard fairness criteria, subsequent works have circumvented this limitation
through the incentive ratio framework. Previous studies demonstrate that
fundamental mechanisms like Maximum Nash Welfare (MNW) and Probabilistic Serial
(PS) for divisible goods, and Round-Robin (RR) for indivisible goods achieve an
incentive ratio of $2$, implying that no individual agent can gain more than
double his truthful utility through manipulation. However, collusive
manipulation by agent groups remains unexplored.
  In this work, we define strong group incentive ratio (SGIR) and group
incentive ratio (GIR) to measure the gain of collusive manipulation, where SGIR
and GIR are respectively the maximum and minimum of the incentive ratios of
corrupted agents. Then, we tightly characterize the SGIRs and GIRs of MNW, PS,
and RR. In particular, the GIR of MNW is $2$ regardless of the coalition size.
Moreover, for coalition size $c \geq 1$, the SGIRs of MNW and PS, and the GIRs
of PS and RR are $c + 1$. Finally, the SGIR of RR is unbounded for coalition
size $c \geq 2$. Our results reveal fundamental differences of these three
mechanisms in their vulnerability to collusion.

</details>


### [9] [A Linear Programming Approach to Estimate the Core in Cooperative Games](https://arxiv.org/abs/2510.01766)
*J Camacho,JC Gonçalves-Dosantos,J Sánchez-Soriano*

Main category: cs.GT

TL;DR: 该论文提出了一种通过线性规划近似可转移效用(TU)合作博弈核心的新算法，通过随机线性问题(LPs)采样极端点，解决了确定完整核心的计算难题。


<details>
  <summary>Details</summary>
Motivation: 由于确定完整核心的计算复杂性，该研究旨在提供一种可处理的近似方法。

Method: 采用随机线性问题(LPs)采样极端点，并通过线性规划近似核心。

Result: 实验结果表明，该方法具有可扩展性，并在核心重构方面实现了高精度。

Conclusion: 该算法为解决TU合作博弈核心的计算难题提供了有效且高效的工具。

Abstract: This paper proposes a novel algorithm to approximate the core of transferable
utility (TU) cooperative games via linear programming. Given the computational
hardness of determining the full core, our approach provides a tractable
approximation by sampling extreme points through randomized linear problems
(LPs). We analyze its convergence and computational complexity, and validate
its effectiveness through extensive simulations on various game models. Our
results show that the method is scalable and achieves high accuracy in terms of
core reconstruction.

</details>


### [10] [Multi-group Bayesian Games](https://arxiv.org/abs/2510.02078)
*Hongxing Yuan,Xuan Zhang,Chunyu Wei,Yushun Fan*

Main category: cs.GT

TL;DR: 本文提出了一种多群体贝叶斯博弈模型(MBGs),用于描述贝叶斯博弈中的群体行为,并通过提出的转换方法找到(强)多群体贝叶斯纳什均衡(MBNE)。


<details>
  <summary>Details</summary>
Motivation: 研究群体行为在贝叶斯博弈中的表现,特别是群体内玩家合作与非合作情境下的最优策略。

Method: 提出MBGs模型并通过转换将其转化为多群体事前代理博弈(MEAG),给出了MEAG成为(强)潜力博弈的充要条件,并开发了寻找MBNE的算法。

Result: 通过转换方法的良好性质,可以找到MBG的所有(强)MBNE,并通过示例验证了结果的正确性。

Conclusion: 本文的方法有效地解决了MBGs中群体行为的最优策略问题,为研究贝叶斯博弈中的群体互动提供了新工具。

Abstract: This paper presents a model of multi-group Bayesian games (MBGs) to describe
the group behavior in Bayesian games, and gives methods to find (strongly)
multi-group Bayesian Nash equilibria (MBNE) of this model with a proposed
transformation. MBNE represent the optimal strategy \textit{profiles} under the
situation where players within a group play a cooperative game, while strongly
MBNE characterize the optimal strategy \textit{profiles} under the situation
where players within a group play a noncooperative game. Firstly, we propose a
model of MBGs and give a transformation to convert any MBG into a multi-group
ex-ante agent game (MEAG) which is a normal-form game. Secondly, we give a
sufficient and necessary condition for a MBG's MEAG to be (strongly) potential.
If it is (strongly) potential, all its (strongly) Nash equilibria can be found,
and then all (strongly) MBNE of the MBG can be obtained by leveraging the
transformation's good properties. Finally, we provide algorithms for finding
(strongly) MBNE of a MBG whose MEAG is (strongly) potential and use an
illustrative example to verify the correctness of our results.

</details>
