<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Cyclotron: Compilation of Recurrences to Distributed and Systolic Architectures](https://arxiv.org/abs/2511.09987)
*Shiv Sundram,Akhilesh Balasingam,Nathan Zhang,Kunle Olukotun,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: Cyclotron是一个框架和编译器，通过递归方程表达流数据流算法，并将其编译为分布式处理器拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 为了解决流数据流算法在分布式处理器拓扑上的高效实现问题，Cyclotron提供了一种递归方程的表达方式，并优化了内存访问。

Method: Cyclotron采用递归方程表达算法，通过中间语言将其转换为针对每个处理器的发送、接收和计算操作，并优化内存访问。

Result: Cyclotron能够编译到可重构模拟器和分布式CPU集群，展示了其在矩阵乘法和求解器等任务中的高效性能。

Conclusion: Cyclotron通过递归方程和调度语言，实现了高效的分布式算法实现，并在多种硬件平台上展示了其便携性和性能优势。

Abstract: We present Cyclotron, a framework and compiler for using recurrence equations to express streaming dataflow algorithms, which then get portably compiled to distributed topologies of interlinked processors. Our framework provides an input language of recurrences over logical tensors, which then gets lowered into an intermediate language of recurrences over logical iteration spaces, and finally into programs of send, receive, and computation operations specific to each individual processor. In Cyclotron's IR, programs are optimized such that external memory interactions are confined to the boundaries of the iteration space. Within inner iteration spaces, all data accesses become local: data accesses target values residing in local fast memory or on neighboring processing units, avoiding costly memory movement. We provide a scheduling language allowing users to define how data gets streamed and broadcasted between processors, enabling pipelined execution of computation kernels over distributed topologies of processing elements. We demonstrate the portability of our approach by compiling our IR to a reconfigurable simulator of systolic arrays and chiplet style distributed hardware, as well as to distributed-memory CPU clusters. In the simulated reconfigurable setting, we use our compiler for hardware design space exploration in which link costs and latencies can be specified. In the distributed CPU setting, we show how to use recurrences and our scheduling language to express various matrix multiplication routines (Cannon, SUMMA, PUMMA, weight stationary) and solvers (Triangular solve and Cholesky). For matrix multiplication and the triangular solve, we generate distributed implementations competitive with ScaLAPACK.

</details>


### [2] [Omnidirectional type inference for ML: principality any way](https://arxiv.org/abs/2511.10343)
*Alistair O'Brien,Didier Rémy,Gabriel Scherer*

Main category: cs.PL

TL;DR: 该论文提出了“全向类型推断”方法，通过动态信息流解决ML类型系统中因扩展特性（如GADTs、高阶多态和静态重载）导致的非主体性问题，相比静态顺序推断更具灵活性和表现力。


<details>
  <summary>Details</summary>
Motivation: ML类型系统因其主体性（每个类型良好的表达式有唯一最一般类型）而成功，但扩展特性引入的脆弱构造威胁了主体性，现有静态顺序推断方法会拒绝本应类型良好的程序。

Method: 提出全向类型推断，动态解决类型约束，引入“暂停匹配约束”和“增量实例化”技术，支持部分求解类型方案的实例化与更新。

Result: 该方法在OCaml的两个特性（静态重载记录标签和半显式一等多态）上验证了其表达力和主体性恢复能力。

Conclusion: 全向类型推断为脆弱特性下的主体性恢复提供通用框架，表现优于OCaml现有类型检查器。

Abstract: The Damas-Hindley-Milner (ML) type system owes its success to principality, the property that every well-typed expression has a unique most general type. This makes inference predictable and efficient. Unfortunately, many extensions of ML (GADTs, higher-rank polymorphism, and static overloading) endanger princpality by introducing _fragile_ constructs that resist principal inference. Existing approaches recover principality through directional inference algorithms, which propagate _known_ type information in a fixed (or static) order (e.g. as in bidirectional typing) to disambiguate such constructs. However, the rigidity of a static inference order often causes otherwise well-typed programs to be rejected.
  We propose _omnidirectional_ type inference, where type information flows in a dynamic order. Typing constraints may be solved in any order, suspending when progress requires known type information and resuming once it becomes available, using _suspended match constraints_. This approach is straightforward for simply typed systems, but extending it to ML is challenging due to let-generalization. Existing ML inference algorithms type let-bindings (let x = e1 in e2) in a fixed order: type e1, generalize its type, and then type e2. To overcome this, we introduce _incremental instantiation_, allowing partially solved type schemes containing suspended constraints to be instantiated, with a mechanism to incrementally update instances as the scheme is refined.
  Omnidirectionality provides a general framework for restoring principality in the presence of fragile features. We demonstrate its versatility on two fundamentally different features of OCaml: static overloading of record labels and datatype constructors and semi-explicit first-class polymorphism. In both cases, we obtain a principal type inference algorithm that is more expressive than OCaml's current typechecker.

</details>


### [3] [Lazy Linearity for a Core Functional Language](https://arxiv.org/abs/2511.10361)
*Rodrigo Mesquita,Bernardo Toninho*

Main category: cs.PL

TL;DR: 本文提出了Linear Core系统，用于处理惰性语言中线型资源的使用问题，确保语义上的线性性而非仅语法上的线性性。


<details>
  <summary>Details</summary>
Motivation: 传统的线型语言中，资源的使用与其语法表现紧密相关，但在惰性求值环境下，语义上的线性性更为重要。Haskell的优化编译器会重写源代码，破坏语法上的线性性但保留语义，这种现象促使了Linear Core的研究。

Method: 提出了Linear Core系统，适用于惰性语言如GHC的Core中间语言，并证明其能够静态接受线性的惰性语义，保证资源的线性使用。同时验证了优化转换在Linear Core中保持线性性而在Core中失败的情况。

Result: Linear Core被证明是可靠的，能够保证资源的线性使用，并且在实现中验证了其对线性资源密集型库（如linear-base）的有效性。

Conclusion: Linear Core成功地解决了惰性语言中线型资源的语义线性性问题，并通过实现验证了其实际应用价值。

Abstract: Traditionally, in linearly typed languages, consuming a linear resource is synonymous with its syntactic occurrence in the program. However, under the lens of non-strict evaluation, linearity can be further understood semantically, where a syntactic occurrence of a resource does not necessarily entail using that resource when the program is executed. While this distinction has been largely unexplored, it turns out to be inescapable in Haskell's optimising compiler, which heavily rewrites the source program in ways that break syntactic linearity but preserve the program's semantics. We introduce Linear Core, a novel system which accepts the lazy semantics of linearity statically and is suitable for lazy languages such as the Core intermediate language of the Glasgow Haskell Compiler. We prove that Linear Core is sound, guaranteeing linear resource usage, and that multiple optimising transformations preserve linearity in Linear Core while failing to do so in Core. We have implemented Linear Core as a compiler plugin to validate the system against linearity-heavy libraries, including linear-base.

</details>


### [4] [Modeling Layout Abstractions Using Integer Set Relations](https://arxiv.org/abs/2511.10374)
*Somashekaracharya G Bhaskaracharya,Aravind Acharya,Bastian Hagedorn,Vinod Grover*

Main category: cs.PL

TL;DR: 本文提出了一种利用整数集库（ISL）为CuTe和Triton线性布局系统建立统一数学表示的新方法，支持形式化分析和跨系统优化。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习编译器依赖布局抽象来管理逻辑张量结构与物理内存安排的复杂映射，但CuTe和Triton布局系统各自独立，缺乏统一的形式化分析基础。

Method: 通过整数集关系建模CuTe布局（基于步长的多维坐标到线性索引变换）和Triton线性布局（基于有限域F_2的二进制向量空间变换），并实现布局操作算法。

Result: 实验证明该系统能够处理从简单变换到复杂多维张量安排的完整布局复杂度，验证了数学建模方法的有效性。

Conclusion: 该方法为CuTe和Triton布局系统提供了统一的形式化基础，支持形式化验证和跨系统优化，为未来的布局优化策略奠定了基础。

Abstract: Modern deep learning compilers rely on layout abstractions to manage the complex mapping between logical tensor structures and physical memory arrangements. CuTe layouts and Triton linear layouts are widely adopted industry standards. However, these layout systems operate independently with distinct mathematical underpinnings, preventing unified formal analysis and cross-system reasoning. We bridge this gap by introducing a novel approach that leverages the Integer Set Library (ISL) to create a unified mathematical representation for both layout systems through integer set relations, thereby enabling rigorous formal analysis, correctness verification, and the foundation for future cross-system optimization strategies. Our approach models CuTe layouts through integer set relations that encode the transformation from multi-dimensional coordinates to linear indices using stride-based calculations, including sophisticated swizzle operations that perform bit-level manipulations for enhanced memory access patterns. For Triton linear layouts, we construct integer set relations that model the binary vector space transformations where arithmetic operations follow finite field F_2 rules. We implement a complete suite of layout manipulation algorithms for composition, inversion, complement using built-in operations in ISL to ensure mathematical correctness and preserve layout semantics. Experimental evaluation shows that the system handles the full spectrum of layout complexity, from elementary identity transformations to sophisticated multi-dimensional tensor arrangements with complex stride configurations and swizzle patterns, validating the mathematical modeling approach across different layout paradigms.

</details>


### [5] [zkStruDul: Programming zkSNARKs with Structural Duality](https://arxiv.org/abs/2511.10565)
*Rahul Krishnan,Ashley Samuelson,Emily Yao,Ethan Cecchetti*

Main category: cs.PL

TL;DR: zkStruDul是一种语言，它将输入转换和谓词定义统一为单一抽象，避免了现有NIZK工具中逻辑重复和安全缺陷的问题。


<details>
  <summary>Details</summary>
Motivation: 现有NIZK工具在优化谓词定义时需要单独实现输入转换和谓词定义，导致逻辑重复和安全风险。

Method: zkStruDul通过统一的抽象层将输入转换和谓词定义结合，并由编译器生成两个过程，消除重复代码和不匹配问题。

Result: zkStruDul提供了高层抽象，支持递归证明等功能，并通过源语义和行为一致性验证确保安全性。

Conclusion: zkStruDul解决了NIZK工具中的逻辑重复和安全问题，为实际应用提供了更高效和安全的解决方案。

Abstract: Non-Interactive Zero Knowledge (NIZK) proofs, such as zkSNARKS, let one prove knowledge of private data without revealing it or interacting with a verifier. While existing tooling focuses on specifying the predicate to be proven, real-world applications optimize predicate definitions to minimize proof generation overhead, but must correspondingly transform predicate inputs. Implementing these two steps separately duplicates logic that must precisely match to avoid catastrophic security flaws. We address this shortcoming with zkStruDul, a language that unifies input transformations and predicate definitions into a single combined abstraction from which a compiler can project both procedures, eliminating duplicate code and problematic mismatches. zkStruDul provides a high-level abstraction to layer on top of existing NIZK technology and supports important features like recursive proofs. We provide a source-level semantics and prove its behavior is identical to the projected semantics, allowing straightforward standard reasoning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Truth, Justice, and Secrecy: Cake Cutting Under Privacy Constraints](https://arxiv.org/abs/2511.09882)
*Yaron Salman,Tamir Tassa,Omer Lev,Roie Zivan*

Main category: cs.GT

TL;DR: 本研究扩展了Chen等人（2010）的策略证明蛋糕分配算法，引入了隐私保护维度，提出了首个兼具策略证明、无嫉妒性和隐私保护的蛋糕分配协议。


<details>
  <summary>Details</summary>
Motivation: 尽管现有蛋糕分配算法关注公平性，但隐私问题未被充分重视。代理可能因担心泄露商业机密而不愿真实表达偏好，这促使研究者设计一种既能保护隐私又保持公平性和策略证明性的新协议。

Method: 通过将中心化计算替换为新型密码学技术，实现了隐私保护。这一方法在不损害公平性或策略证明性的前提下，确保代理的真实偏好不被暴露。

Result: 提出的协议是首个同时满足隐私保护、无嫉妒性和策略证明性的蛋糕分配协议，有效鼓励代理真实表达偏好。

Conclusion: 本研究为蛋糕分配问题引入了隐私保护的新维度，为未来研究提供了兼具公平性、策略证明性和隐私保护的解决方案。

Abstract: Cake-cutting algorithms, which aim to fairly allocate a continuous resource based on individual agent preferences, have seen significant progress over the past two decades. Much of the research has concentrated on fairness, with comparatively less attention given to other important aspects. Chen et al. (2010) introduced an algorithm that, in addition to ensuring fairness, was strategyproof -- meaning agents had no incentive to misreport their valuations. However, even in the absence of strategic incentives to misreport, agents may still hesitate to reveal their true preferences due to privacy concerns (e.g., when allocating advertising time between firms, revealing preferences could inadvertently expose planned marketing strategies or product launch timelines). In this work, we extend the strategyproof algorithm of Chen et al. by introducing a privacy-preserving dimension. To the best of our knowledge, we present the first private cake-cutting protocol, and, in addition, this protocol is also envy-free and strategyproof. Our approach replaces the algorithm's centralized computation with a novel adaptation of cryptographic techniques, enabling privacy without compromising fairness or strategyproofness. Thus, our protocol encourages agents to report their true preferences not only because they are not incentivized to lie, but also because they are protected from having their preferences exposed.

</details>


### [7] [Robust Resource Allocation via Competitive Subsidies](https://arxiv.org/abs/2511.09934)
*David X. Lin,Giannis Fikioris,Siddhartha Banerjee,Éva Tardos*

Main category: cs.GT

TL;DR: 本文提出了一种新的在线资源分配机制，通过简单的拍卖形式实现了0.625的鲁棒性，几乎接近非策略性鲁棒性界限0.63。


<details>
  <summary>Details</summary>
Motivation: 现有机制在重复首次价格拍卖中的鲁棒性上限为0.6，无法突破。本文旨在突破这一限制，并接近非策略性情况下的最优值0.63。

Method: 提出了一种简单拍卖机制：每轮投标者决定是否竞标物品，并在竞标者中随机分配。关键创新是引入竞争补贴概念，根据竞标者数量动态调整获胜者的支付金额。

Result: 新机制实现了0.625的鲁棒性，并通过修改进一步提升了均衡策略下的鲁棒性至0.61。此外，证明了该机制在广泛拍卖机制类中具有最优界限。

Conclusion: 通过竞争补贴的动态支付策略，本文突破了首次价格拍卖的0.6鲁棒性限制，实现了接近理论最优值的性能。

Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.

</details>


### [8] [Facility Location for Congesting Commuters and Generalizing the Cost-Distance Problem](https://arxiv.org/abs/2511.10228)
*Thanasis Lianeas,Marios Mertzanidis,Aikaterini Nikolidaki*

Main category: cs.GT

TL;DR: 本文提出了一种新的设施选址问题，即拥堵（自私）通勤者的设施选址问题，考虑了代理人与设施之间的连接成本随拥堵而变化，并从不可分割设施选址问题出发进行研究。


<details>
  <summary>Details</summary>
Motivation: 现有的不可分割设施选址问题未考虑代理人连接成本随拥堵变化的情况，因此需要研究这种新型问题，以便更真实地反映实际交通场景。

Method: 论文分两种情况研究：当成本函数非递减时，利用近似版的Caratheodory定理推导问题的近似解；当成本函数非递增时，通过推广成本-距离问题并提供算法来实现相同的近似保证。

Result: 研究结果表明，对于非递减成本函数的情况，可以通过近似方法得到解；对于非递增成本函数的情况，算法在更一般的情况下保持了相同的近似保证。

Conclusion: 本文通过引入拥堵依赖的连接成本，扩展了设施选址问题的研究范围，并为不同情况提供了有效的近似解法。

Abstract: In Facility Location problems there are agents that should be connected to facilities and locations where facilities may be opened so that agents can connect to them. We depart from Uncapacitated Facility Location and by assuming that the connection costs of agents to facilities are congestion dependent, we define a novel problem, namely, Facility Location for Congesting (Selfish) Commuters. The connection costs of agents to facilities come as a result of how the agents commute to reach the facilities in an underlying network with cost functions on the edges. Inapproximability results follow from the related literature and thus approximate solutions is all we can hope for. For when the cost functions are nondecreasing we employ in a novel way an approximate version of Caratheodory's Theorem [5] to show how approximate solutions for different versions of the problem can be derived. For when the cost functions are nonincreasing we show how this problem generalizes the Cost-Distance problem [38] and provide an algorithm that for this more general case achieves the same approximation guarantees.

</details>
