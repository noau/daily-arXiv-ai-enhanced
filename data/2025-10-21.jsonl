{"id": "2510.15912", "categories": ["cs.PL", "cs.AR", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.15912", "abs": "https://arxiv.org/abs/2510.15912", "authors": ["Jack Cashman"], "title": "Latency Based Tiling", "comment": null, "summary": "Latency Based Tiling provides a systems based approach to deriving\napproximate tiling solution that maximizes locality while maintaining a fast\ncompile time. The method uses triangular loops to characterize miss ratio\nscaling of a machine avoiding prefetcher distortion. Miss ratio scaling\ncaptures the relationship between data access latency and working set size with\nsharp increases in latency indicating the data footprint exceeds capacity from\na cache level. Through these noticeable increases in latency we can determine\nan approximate location for L1, L2, and L3 memory sizes. These sizes are\nexpected to be under approximations of a systems true memory sizes which is in\nline with our expectations given the shared nature of cache in a multi process\nsystem as described in defensive loop tiling. Unlike auto tuning, which can be\neffective but prohibitively slow, Latency Based Tiling achieves negligible\ncompile time overhead. The implementation in Rust enables a hardware agnostic\napproach which combined with a cache timing based techniques, yields a\nportable, memory safe system running wherever Rust is supported. The tiling\nstrategy is applied to a subset of the polyhedral model, where loop nestings\nare tiled based on both the derived memory hierarchy and the observed data\nfootprint per iteration."}
{"id": "2510.16133", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.16133", "abs": "https://arxiv.org/abs/2510.16133", "authors": ["Daniel Sainati", "Joseph W. Cutler", "Benjamin C. Pierce", "Stephanie Weirich"], "title": "Typing Strictness (Extended Version)", "comment": "30 pages, 22 figures, extended version of a paper to be published at\n  POPL 2026", "summary": "Strictness analysis is critical to efficient implementation of languages with\nnon-strict evaluation, mitigating much of the performance overhead of laziness.\nHowever, reasoning about strictness at the source level can be challenging and\nunintuitive. We propose a new definition of strictness that refines the\ntraditional one by describing variable usage more precisely. We lay\ntype-theoretic foundations for this definition in both call-by-name and\ncall-by-push-value settings, drawing inspiration from the literature on type\nsystems tracking effects and coeffects. We prove via a logical relation that\nthe strictness attributes computed by our type systems accurately describe the\nuse of variables at runtime, and we offer a strictness-annotation-preserving\ntranslation from the call-by-name system to the call-by-push-value one. All our\nresults are mechanized in Rocq."}
{"id": "2510.16594", "categories": ["cs.PL", "F.3.2; F.1.1"], "pdf": "https://arxiv.org/pdf/2510.16594", "abs": "https://arxiv.org/abs/2510.16594", "authors": ["Moida Praneeth Jain", "Venkatesh Choppella"], "title": "SimpliPy: A Source-Tracking Notional Machine for Simplified Python", "comment": "15 pages, 1 figure, 1 table. Accepted at the 4th Workshop on Research\n  Highlights in Programming Languages (RHPL 2025), co-located with FSTTCS 2025.\n  Code available at: https://github.com/PraneethJain/simplipy", "summary": "Misconceptions about program execution hinder many novice programmers. We\nintroduce SimpliPy, a notional machine designed around a carefully chosen\nPython subset to clarify core control flow and scoping concepts. Its foundation\nis a precise operational semantics that explicitly tracks source code line\nnumbers for each execution step, making the link between code and behavior\nunambiguous. Complementing the dynamic semantics, SimpliPy uses static analysis\nto generate Control Flow Graphs (CFGs) and identify lexical scopes, helping\nstudents build a structural understanding before tracing. We also present an\ninteractive web-based debugger built on these principles. This tool embodies\nthe formal techniques, visualizing the operational state (environments, stack)\nand using the static CFG to animate control flow directly on the graph during\nstep-by-step execution. SimpliPy thus integrates formal semantics, program\nanalysis, and visualization to offer both a pedagogical approach and a\npractical demonstration of applying formal methods to program understanding."}
{"id": "2510.16883", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.16883", "abs": "https://arxiv.org/abs/2510.16883", "authors": ["Giulia Giusti", "Michele Pagani"], "title": "JAX Autodiff from a Linear Logic Perspective (Extended Version)", "comment": null, "summary": "Autodiff refers to the core of the automatic differentiation systems\ndeveloped in projects like JAX and Dex. Autodiff has recently been formalised\nin a linear typed calculus by Radul et al in arXiv:2204.10923. Although this\nformalisation suffices to express the main program transformations of Autodiff,\nthe calculus is very specific to this task, and it is not clear whether the\ntype system yields a substructural logic that has interest on its own.\n  We propose an encoding of Autodiff into a linear $\\lambda$-calculus that\nenjoys a Curry-Howard correspondence with Girard's linear logic. We prove that\nthe encoding is sound both qualitatively (the encoded terms are extensionally\nequivalent to the original ones) and quantitatively (the encoding preserves the\noriginal work cost as described in arXiv:2204.10923). As a byproduct, we show\nthat unzipping, one of the transformations used to implement backpropagation in\nAutodiff, is, in fact, optional."}
{"id": "2510.16385", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.16385", "abs": "https://arxiv.org/abs/2510.16385", "authors": ["Naoyuki Kamiyama"], "title": "The Strongly Stable Roommates Problem and Linear Programming", "comment": null, "summary": "The stable roommates problem is a non-bipartite version of the stable\nmatching problem in a bipartite graph. In this paper, we consider the stable\nroommates problem with ties. In particular, we focus on strong stability, which\nis one of the main stability concepts in the stable roommates problem with\nties. We propose a new polynomial-time algorithm for the problem of checking\nthe existence of a strongly stable matching in the stable roommates problem\nwith ties. More concretely, we extend the linear programming approach of\nAbeledo and Blum to the stable roommates problem with strict preferences to our\nproblem."}
{"id": "2510.15873", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15873", "abs": "https://arxiv.org/abs/2510.15873", "authors": ["Hengyuan Chang", "Xiaoxuan Xie", "Syuhei Sato", "Haoran Xie"], "title": "Two-Stage Sketch-Based Smoke Illustration Generation using Stream Function", "comment": "3 pages, 4 figures. SIGGRAPH 2025 Poster", "summary": "In this paper, we propose a two-stage sketch-based smoke illustration\ngeneration framework using stream function and latent diffusion models (LDM).\nThe user sketch is used to guide the generation of the stream function, which\nserves as the control condition for the velocity field generator. The generated\nvelocity field can be used to guide the smoke simulation to align with the\nintended flow. We adopt streamlines to encode global flow dynamics as sketch\nguidance during training. The stream function constitutes the intermediate\nrepresentation that captures continuous variation and rotational flow details\nabsent from sketches."}
{"id": "2510.17429", "categories": ["cs.PL", "D.3.1"], "pdf": "https://arxiv.org/pdf/2510.17429", "abs": "https://arxiv.org/abs/2510.17429", "authors": ["Jin Sano", "Naoki Yamamoto", "Kazunori Ueda"], "title": "Introducing Linear Implication Types to $Î»_{GT}$ for Computing With Incomplete Graphs", "comment": "26 pages, 14 figures, This paper is submitted to PRO2025-3", "summary": "Designing programming languages that enable intuitive and safe manipulation\nof data structures is a critical research challenge. Conventional destructive\nmemory operations using pointers are complex and prone to errors. Existing type\nsystems, such as affine types and shape types, address this problem towards\nsafe manipulation of heaps and pointers, but design of high-level declarative\nlanguages that allow us to manipulate complex pointer data structures at a\nhigher level of abstraction is largely an open problem. The $\\lambda_{GT}$\nlanguage, a purely functional programming language that treats hypergraphs\n(hereafter referred to as graphs) as primary data structures, addresses some of\nthese challenges. By abstracting data with shared references and cycles as\ngraphs, it enables declarative operations through pattern matching and\nleverages its type system to guarantee safety of these operations.\nNevertheless, the previously proposed type system of $\\lambda_{GT}$ leaves two\nsignificant open challenges. First, the type system does not support\n\\emph{incomplete graphs}, that is, graphs in which some elements are missing\nfrom the graphs of user-defined types. Second, the type system relies on\ndynamic type checking during pattern matching. This study addresses these two\nchallenges by incorporating linear implication into the $\\lambda_{GT}$ type\nsystem, while introducing new constraints to ensure its soundness."}
{"id": "2510.16869", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.16869", "abs": "https://arxiv.org/abs/2510.16869", "authors": ["Yuan Deng", "Yilin Li", "Wei Tang", "Hanrui Zhang"], "title": "No-Regret Online Autobidding Algorithms in First-price Auctions", "comment": "12 pages (main); appendix included. Conference version to appear in\n  the proceeding of the 39th Conference on Neural Information Processing\n  Systems (NeurIPS'25)", "summary": "Automated bidding to optimize online advertising with various constraints,\ne.g. ROI constraints and budget constraints, is widely adopted by advertisers.\nA key challenge lies in designing algorithms for non-truthful mechanisms with\nROI constraints. While prior work has addressed truthful auctions or\nnon-truthful auctions with weaker benchmarks, this paper provides a significant\nimprovement: We develop online bidding algorithms for repeated first-price\nauctions with ROI constraints, benchmarking against the optimal randomized\nstrategy in hindsight. In the full feedback setting, where the maximum\ncompeting bid is observed, our algorithm achieves a near-optimal\n$\\widetilde{O}(\\sqrt{T})$ regret bound, and in the bandit feedback setting\n(where the bidder only observes whether the bidder wins each auction), our\nalgorithm attains $\\widetilde{O}(T^{3/4})$ regret bound."}
{"id": "2510.15874", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15874", "abs": "https://arxiv.org/abs/2510.15874", "authors": ["Hao Jin", "Haoran Xie"], "title": "Sketch-based Fluid Video Generation Using Motion-Guided Diffusion Models in Still Landscape Images", "comment": "2 pages, 5 figures. SIGGRAPH 2025 Poster", "summary": "Integrating motion into static images not only enhances visual expressiveness\nbut also creates a sense of immersion and temporal depth, establishing it as a\nlongstanding and impactful theme in artistic expression. Fluid elements such as\nwaterfall, river, and oceans are common features in landscape, but their\ncomplex dynamic characteristics pose significant challenges in modeling and\ncontrolling their motion within visual computing. Physics-based methods are\noften used in fluid animation to track particle movement. However, they are\neasily affected by boundary conditions. Recently, latent diffusion models have\nbeen applied to video generation tasks, demonstrating impressive capabilities\nin producing high-quality and temporally coherent results. However, it is\nchallenging for the existing methods to animate fluid smooth and temporally\nconsistent motion. To solve these issues, this paper introduces a framework for\ngenerating landscape videos by animating fluid in still images under the\nguidance of motion sketches. We propose a finetuned conditional latent\ndiffusion model for generating motion field from user-provided sketches, which\nare subsequently integrated into a latent video diffusion model via a motion\nadapter to precisely control the fluid movement."}
{"id": "2510.17505", "categories": ["cs.PL", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.17505", "abs": "https://arxiv.org/abs/2510.17505", "authors": ["Jaeyeon Won", "Willow Ahrens", "Joel S. Emer", "Saman Amarasinghe"], "title": "Insum: Sparse GPU Kernels Simplified and Optimized with Indirect Einsums", "comment": null, "summary": "Programming high-performance sparse GPU kernels is notoriously difficult,\nrequiring both substantial effort and deep expertise. Sparse compilers aim to\nsimplify this process, but existing systems fall short in two key ways. First,\nthey are primarily designed for CPUs and rarely produce high-performance GPU\ncode. Second, when computations involve both sparse and dense regions, these\ncompilers often fail to optimize the dense portions effectively. In this paper,\nwe propose a new approach for expressing sparse computations. We start from\nformat-agnostic Einsums over sparse tensors and rewrite them into\nformat-conscious indirect Einsums, which explicitly encode format information\nby mapping sparse data and metadata onto dense tensor operations through\nindirect indexing. To execute indirect Einsums, we introduce the Insum\ncompiler, which generates efficient GPU code for these Einsums by lowering to\nthe PyTorch compiler, extended to better support Tensor Core-enabled indirect\nEinsums. We also present two fixed-length sparse formats, GroupCOO and\nBlockGroupCOO, designed to fit naturally with indirect Einsums. Our approach\nachieves 1.14x to 3.81x speedups across a range of sparse GPU applications\nwhile reducing lines of code by 202x to 4491x compared to hand-written\nimplementations."}
{"id": "2510.17067", "categories": ["cs.GT", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17067", "abs": "https://arxiv.org/abs/2510.17067", "authors": ["Ioannis Anagnostides", "Emanuel Tewolde", "Brian Hu Zhang", "Ioannis Panageas", "Vincent Conitzer", "Tuomas Sandholm"], "title": "Convergence of Regret Matching in Potential Games and Constrained Optimization", "comment": null, "summary": "Regret matching (RM} -- and its modern variants -- is a foundational online\nalgorithm that has been at the heart of many AI breakthrough results in solving\nbenchmark zero-sum games, such as poker. Yet, surprisingly little is known so\nfar in theory about its convergence beyond two-player zero-sum games. For\nexample, whether regret matching converges to Nash equilibria in potential\ngames has been an open problem for two decades. Even beyond games, one could\ntry to use RM variants for general constrained optimization problems. Recent\nempirical evidence suggests that they -- particularly regret matching$^+$\n(RM$^+$) -- attain strong performance on benchmark constrained optimization\nproblems, outperforming traditional gradient descent-type algorithms.\n  We show that alternating RM$^+$ converges to an $\\epsilon$-KKT point after\n$O_\\epsilon(1/\\epsilon^4)$ iterations, establishing for the first time that it\nis a sound and fast first-order optimizer. Our argument relates the KKT gap to\nthe accumulated regret, two quantities that are entirely disparate in general\nbut interact in an intriguing way in our setting, so much so that when regrets\nare bounded, our complexity bound improves all the way to\n$O_\\epsilon(1/\\epsilon^2)$. From a technical standpoint, while RM$^+$ does not\nhave the usual one-step improvement property in general, we show that it does\nin a certain region that the algorithm will quickly reach and remain in\nthereafter. In sharp contrast, our second main result establishes a lower\nbound: RM, with or without alternation, can take an exponential number of\niterations to reach a crude approximate solution even in two-player potential\ngames. This represents the first worst-case separation between RM and RM$^+$.\nOur lower bound shows that convergence to coarse correlated equilibria in\npotential games is exponentially faster than convergence to Nash equilibria."}
{"id": "2510.15876", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15876", "abs": "https://arxiv.org/abs/2510.15876", "authors": ["Abhinav Dayal", "Cliff Woolley", "Benjamin Watson", "David Luebke"], "title": "Adaptive Frameless Rendering", "comment": null, "summary": "We propose an adaptive form of frameless rendering with the potential to\ndramatically increase rendering speed over conventional interactive rendering\napproaches. Without the rigid sampling patterns of framed renderers, sampling\nand reconstruction can adapt with very fine granularity to spatio-temporal\ncolor change. A sampler uses closed-loop feedback to guide sampling toward\nedges or motion in the image. Temporally deep buffers store all the samples\ncreated over a short time interval for use in reconstruction and as sampler\nfeedback. GPU-based reconstruction responds both to sampling density and\nspace-time color gradients. Where the displayed scene is static, spatial color\nchange dominates and older samples are given significant weight in\nreconstruction, resulting in sharper and eventually antialiased images. Where\nthe scene is dynamic, more recent samples are emphasized, resulting in less\nsharp but more up-to-date images. We also use sample reprojection to improve\nreconstruction and guide sampling toward occlusion edges, undersampled regions,\nand specular highlights. In simulation our frameless renderer requires an order\nof magnitude fewer samples than traditional rendering of similar visual quality\n(as measured by RMS error), while introducing overhead amounting to 15% of\ncomputation time."}
{"id": "2510.17285", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.17285", "abs": "https://arxiv.org/abs/2510.17285", "authors": ["Leo Landolt", "Anna Maddux", "Andreas Schlaginhaufen", "Saurabh Vaishampayan", "Maryam Kamgarpour"], "title": "Eliciting Truthful Feedback for Preference-Based Learning via the VCG Mechanism", "comment": null, "summary": "We study resource allocation problems in which a central planner allocates\nresources among strategic agents with private cost functions in order to\nminimize a social cost, defined as an aggregate of the agents' costs. This\nsetting poses two main challenges: (i) the agents' cost functions may be\nunknown to them or difficult to specify explicitly, and (ii) agents may\nmisreport their costs strategically. To address these challenges, we propose an\nalgorithm that combines preference-based learning with Vickrey-Clarke-Groves\n(VCG) payments to incentivize truthful reporting. Our algorithm selects\ninformative preference queries via D-optimal design, estimates cost parameters\nthrough maximum likelihood, and computes VCG allocations and payments based on\nthese estimates. In a one-shot setting, we prove that the mechanism is\napproximately truthful, individually rational, and efficient up to an error of\n$\\tilde{\\mathcal O}(K^{-1/2})$ for $K$ preference queries per agent. In an\nonline setting, these guarantees hold asymptotically with sublinear regret at a\nrate of $\\tilde{\\mathcal O}(T^{2/3})$ after $T$ rounds. Finally, we validate\nour approach through a numerical case study on demand response in local\nelectricity markets."}
{"id": "2510.15877", "categories": ["cs.GR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15877", "abs": "https://arxiv.org/abs/2510.15877", "authors": ["Thomas Lechner", "Ben Watson", "Uri Wilenski", "Seth Tisue", "Martin Felsen", "Andy Moddrell", "Pin Ren", "Craig Brozefsky"], "title": "Procedural modeling of urban land use", "comment": null, "summary": "Cities are important elements of content in digital productions, but their\ncomplexity and size make them very challenging to model. Few tools exist that\ncan help artists with this work, even as rapid improvements in graphics\nhardware create demand for richer content without matching increases in\nproduction cost. We propose a method for procedurally generating realistic\npatterns of land use in cities, automating placement of buildings and roads for\nartists."}
{"id": "2510.15886", "categories": ["cs.GR", "cs.CG", "cs.HC", "68U05 (Primary) 05C85 (Secondary)", "I.3.5; G.2.2; I.2.1"], "pdf": "https://arxiv.org/pdf/2510.15886", "abs": "https://arxiv.org/abs/2510.15886", "authors": ["Diogo de Andrade", "Nuno Fachada"], "title": "Structural Tree Extraction from 3D Surfaces", "comment": null, "summary": "This paper introduces a method to extract a hierarchical tree representation\nfrom 3D unorganized polygonal data. The proposed approach first extracts a\ngraph representation of the surface, which serves as the foundation for\nstructural analysis. A Steiner tree is then generated to establish an optimized\nconnection between key terminal points, defined according to\napplication-specific criteria. The structure can be further refined by\nleveraging line-of-sight constraints, reducing redundancy while preserving\nessential connectivity. Unlike traditional skeletonization techniques, which\noften assume volumetric interpretations, this method operates directly on the\nsurface, ensuring that the resulting representation remains relevant for\nnavigation-aware geometric analysis. The method is validated through two use\ncases: extracting structural representations from tile-based elements for\nprocedural content generation, and identifying key points and structural\nmetrics for automated level analysis. Results demonstrate its ability to\nproduce simplified, coherent representations, supporting applications in\nprocedural generation, spatial reasoning, and map analysis."}
{"id": "2510.16147", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.16147", "abs": "https://arxiv.org/abs/2510.16147", "authors": ["Maxim Gumin", "Do Heon Han", "Seung Jean Yoo", "Aditya Ganeshan", "R. Kenny Jones", "Kailiang Fu", "Rio Aguina-Kang", "Stewart Morris", "Daniel Ritchie"], "title": "Procedural Scene Programs for Open-Universe Scene Generation: LLM-Free Error Correction via Program Search", "comment": "To appear in SIGGRAPH Asia 2025", "summary": "Synthesizing 3D scenes from open-vocabulary text descriptions is a\nchallenging, important, and recently-popular application. One of its critical\nsubproblems is layout generation: given a set of objects, lay them out to\nproduce a scene matching the input description. Nearly all recent work adopts a\ndeclarative paradigm for this problem: using an LLM to generate a specification\nof constraints between objects, then solving those constraints to produce the\nfinal layout. In contrast, we explore an alternative imperative paradigm, in\nwhich an LLM iteratively places objects, with each object's position and\norientation computed as a function of previously-placed objects. The imperative\napproach allows for a simpler scene specification language while also handling\na wider variety and larger complexity of scenes. We further improve the\nrobustness of our imperative scheme by developing an error correction mechanism\nthat iteratively improves the scene's validity while staying as close as\npossible to the original layout generated by the LLM. In forced-choice\nperceptual studies, participants preferred layouts generated by our imperative\napproach 82% and 94% of the time when compared against two declarative layout\ngeneration methods. We also present a simple, automated evaluation metric for\n3D scene layout generation that aligns well with human preferences."}
{"id": "2510.16486", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.16486", "abs": "https://arxiv.org/abs/2510.16486", "authors": ["Mathieu Pont", "Christoph Garth"], "title": "Region-Aware Wasserstein Distances of Persistence Diagrams and Merge Trees", "comment": null, "summary": "This paper presents a generalization of the Wasserstein distance for both\npersistence diagrams and merge trees [20], [66] that takes advantage of the\nregions of their topological features in the input domain. Specifically, we\nredefine the comparison of topological features as a distance between the\nvalues of their extrema-aligned regions. It results in a more discriminative\nmetric than the classical Wasserstein distance and generalizes it through an\ninput parameter adjusting the impact of the region properties in the distance.\nWe present two strategies to control both computation time and memory storage\nof our method by respectively enabling the use of subsets of the regions in the\ncomputation, and by compressing the regions' properties to obtain low-memory\nrepresentations. Extensive experiments on openly available ensemble data\ndemonstrate the efficiency of our method, with running times on the orders of\nminutes on average. We show the utility of our contributions with two\napplications. First, we use the assignments between topological features\nprovided by our method to track their evolution in time-varying ensembles and\npropose the temporal persistence curves to facilitate the understanding of how\nthese features appear, disappear and change over time. Second, our method\nallows to compute a distance matrix of an ensemble that can be used for\ndimensionality reduction purposes and visually represent in 2D all its members,\nwe show that such distance matrices also allow to detect key phases in the\nensemble. Finally, we provide a C++ implementation that can be used to\nreproduce our results."}
{"id": "2510.16684", "categories": ["cs.GR", "cs.CV", "I.3"], "pdf": "https://arxiv.org/pdf/2510.16684", "abs": "https://arxiv.org/abs/2510.16684", "authors": ["Devin Zhao", "Rephael Wenger"], "title": "Filtering of Small Components for Isosurface Generation", "comment": "8 pages, 6 figures, 5 tables", "summary": "Let $f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}$ be a scalar field. An isosurface\nis a piecewise linear approximation of a level set $f^{-1}(\\sigma)$ for some\n$\\sigma \\in \\mathbb{R}$ built from some regular grid sampling of $f$.\nIsosurfaces constructed from scanned data such as CT scans or MRIs often\ncontain extremely small components that distract from the visualization and do\nnot form part of any geometric model produced from the data. Simple\nprefiltering of the data can remove such small components while having no\neffect on the large components that form the body of the visualization. We\npresent experimental results on such filtering."}
{"id": "2510.16966", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.16966", "abs": "https://arxiv.org/abs/2510.16966", "authors": ["Paascal Grosset", "James Ahrens"], "title": "A Scalable In Transit Solution for Comprehensive Exploration of Simulation Data", "comment": null, "summary": "As simulations produce more data than available disk space on supercomputers,\nmany simulations are employing in situ analysis and visualization to reduce the\namount of data that needs to be stored. While in situ visualization offers\npotential for substantial data reduction, its efficacy is hindered by the need\nfor a priori knowledge. First, we need to know what visualization parameters to\nuse to highlight features of interest. Second, we do not know ahead of time how\nmuch resources will be needed to run the in situ workflows, e.g. how many\ncompute nodes will be needed for in situ work. In this work, we present SeerX,\na lightweight, scalable in-transit in situ service that supports dynamic\nresource allocation and lossy compression of 3D simulation data. SeerX enables\nmultiple simulations to offload analysis to a shared, elastic service\ninfrastructure without MPI synchronization."}
{"id": "2510.17101", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17101", "abs": "https://arxiv.org/abs/2510.17101", "authors": ["Lu Yin", "Ziying Shi", "Yinghao Wu", "Xinyu Yi", "Feng Xu", "Shihui Guo"], "title": "Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors", "comment": "Accepted by SIGGRAPH Asia 2025 (TOG)", "summary": "Human motion capture with sparse inertial sensors has gained significant\nattention recently. However, existing methods almost exclusively rely on a\ntemplate adult body shape to model the training data, which poses challenges\nwhen generalizing to individuals with largely different body shapes (such as a\nchild). This is primarily due to the variation in IMU-measured acceleration\ncaused by changes in body shape. To fill this gap, we propose Shape-aware\nInertial Poser (SAIP), the first solution considering body shape differences in\nsparse inertial-based motion capture. Specifically, we decompose the sensor\nmeasurements related to shape and pose in order to effectively model their\njoint correlations. Firstly, we train a regression model to transfer the\nIMU-measured accelerations of a real body to match the template adult body\nmodel, compensating for the shape-related sensor measurements. Then, we can\neasily follow the state-of-the-art methods to estimate the full body motions of\nthe template-shaped body. Finally, we utilize a second regression model to map\nthe joint velocities back to the real body, combined with a shape-aware\nphysical optimization strategy to calculate global motions on the subject.\nFurthermore, our method relies on body shape awareness, introducing the first\ninertial shape estimation scheme. This is accomplished by modeling the\nshape-conditioned IMU-pose correlation using an MLP-based network. To validate\nthe effectiveness of SAIP, we also present the first IMU motion capture dataset\ncontaining individuals of different body sizes. This dataset features 10\nchildren and 10 adults, with heights ranging from 110 cm to 190 cm, and a total\nof 400 minutes of paired IMU-Motion samples. Extensive experimental results\ndemonstrate that SAIP can effectively handle motion capture tasks for diverse\nbody shapes. The code and dataset are available at\nhttps://github.com/yinlu5942/SAIP."}
