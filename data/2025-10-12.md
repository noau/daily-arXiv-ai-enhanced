<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 9]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation](https://arxiv.org/abs/2510.07340)
*Yongzhi Li,Saining Zhang,Yibing Chen,Boying Li,Yanxin Zhang,Xiaoyu Du*

Main category: cs.GR

TL;DR: SpotDiff是一种基于学习的新方法，通过提取特定主题的特征并消除干扰，实现了高效且高保真的个性化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的优化方法虽然保真度高但计算成本高，而基于学习的方法效率高却受干扰因素影响；因此需要一种既能高效又能保持高保真的新方法。

Method: SpotDiff使用预训练的CLIP图像编码器和专门的姿势和背景专家网络，通过特征空间中的正交约束隔离主体身份。

Result: 实验表明，SpotDiff在仅使用10k训练样本的情况下，比现有方法具有更鲁棒的主题保持性和可控编辑能力。

Conclusion: SpotDiff通过消解干扰和高效训练，实现了在个性化图像生成中的高保真和高效率。

Abstract: Personalized image generation aims to faithfully preserve a reference
subject's identity while adapting to diverse text prompts. Existing
optimization-based methods ensure high fidelity but are computationally
expensive, while learning-based approaches offer efficiency at the cost of
entangled representations influenced by nuisance factors. We introduce
SpotDiff, a novel learning-based method that extracts subject-specific features
by spotting and disentangling interference. Leveraging a pre-trained CLIP image
encoder and specialized expert networks for pose and background, SpotDiff
isolates subject identity through orthogonality constraints in the feature
space. To enable principled training, we introduce SpotDiff10k, a curated
dataset with consistent pose and background variations. Experiments demonstrate
that SpotDiff achieves more robust subject preservation and controllable
editing than prior methods, while attaining competitive performance with only
10k training samples.

</details>


### [2] [Local MAP Sampling for Diffusion Models](https://arxiv.org/abs/2510.07343)
*Shaorong Zhang,Rob Brekelmans,Greg Ver Steeg*

Main category: cs.GR

TL;DR: LMAPS是一种新的推理框架，通过迭代求解扩散轨迹上的局部MAP子问题，为基于优化的扩散求解器提供了统一的概率解释，并在多种图像恢复和科学任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决逆问题时优化方法缺乏概率基础的问题，提出了LMAPS框架，以统一概率解释优化方法。

Method: 引入LMAPS框架，通过迭代求解局部MAP子问题，开发了具有概率解释的协方差近似、稳定性目标重构和梯度近似算法。

Result: 在图像去模糊、JPEG恢复、量化等任务中，LMAPS实现了≥2 dB的性能提升，在反向散射基准测试中提升了>1.5 dB。

Conclusion: LMAPS为优化方法提供了清晰的概率解释，并在多种任务中表现出卓越性能。

Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to
inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the
goal of inverse problem solving is not to cover the posterior but to recover
the most accurate reconstruction, where optimization-based diffusion solvers
often excel despite lacking a clear probabilistic foundation. We introduce
Local MAP Sampling (LMAPS), a new inference framework that iteratively solving
local MAP subproblems along the diffusion trajectory. This perspective
clarifies their connection to global MAP estimation and DPS, offering a unified
probabilistic interpretation for optimization-based methods. Building on this
foundation, we develop practical algorithms with a probabilistically
interpretable covariance approximation, a reformulated objective for stability
and interpretability, and a gradient approximation for non-differentiable
operators. Across a broad set of image restoration and scientific tasks, LMAPS
achieves state-of-the-art performance, including $\geq 2$ dB gains on motion
deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on
inverse scattering benchmarks.

</details>


### [3] [Differentiable Variable Fonts](https://arxiv.org/abs/2510.07638)
*Kinjal Parikh,Danny M. Kaufman,David I. W. Levin,Alec Jacobson*

Main category: cs.GR

TL;DR: 本文提出了一种基于可微分可变字体的直观自动化字体设计与动画工作流，解决了当前可变字体在创意应用中未充分利用的问题。


<details>
  <summary>Details</summary>
Motivation: 当前，可变字体在设计领域未被充分利用，艺术家仍需手动调整字体参数。本文旨在通过数学建模和可微分框架，实现自动化字体设计与动画，提升创作效率。

Method: 本文将可变字体规范提炼为紧凑的数学公式，建立了可变字体参数与底层矢量图形的可微分连接，从而构建了一个支持梯度优化的框架。

Result: 通过四个应用场景（直接形状操作、重叠感知建模、基于物理的文本动画和自动化字体设计优化），验证了该框架的有效性和实用性。

Conclusion: 本文的工作为利用可变字体的精心设计特性，结合现代设计优化技术，提供了新的可能性，使得字体设计与动画更加简单直观。

Abstract: Editing and animating text appearance for graphic designs, commercials, etc.
remain highly skilled tasks requiring detailed, hands on efforts from artists.
Automating these manual workflows requires balancing the competing goals of
maintaining legibility and aesthetics of text, while enabling creative
expression. Variable fonts, recent parametric extensions to traditional fonts,
offer the promise of new ways to ease and automate typographic design and
animation. Variable fonts provide custom constructed parameters along which
fonts can be smoothly varied. These parameterizations could then potentially
serve as high value continuous design spaces, opening the door to automated
design optimization tools. However, currently variable fonts are underutilized
in creative applications, because artists so far still need to manually tune
font parameters. Our work opens the door to intuitive and automated font design
and animation workflows with differentiable variable fonts. To do so we distill
the current variable font specification to a compact mathematical formulation
that differentiably connects the highly non linear, non invertible mapping of
variable font parameters to the underlying vector graphics representing the
text. This enables us to construct a differentiable framework, with respect to
variable font parameters, allowing us to perform gradient based optimization of
energies defined on vector graphics control points, and on target rasterized
images. We demonstrate the utility of this framework with four applications:
direct shape manipulation, overlap aware modeling, physics based text
animation, and automated font design optimization. Our work now enables
leveraging the carefully designed affordances of variable fonts with
differentiability to use modern design optimization technologies, opening new
possibilities for easy and intuitive typographic design workflows.

</details>


### [4] [NRRS: Neural Russian Roulette and Splitting](https://arxiv.org/abs/2510.07868)
*Haojie Jin,Jierui Ren,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出了一种针对波前路径追踪的俄罗斯轮盘赌与分裂（RRS）新框架，解决了传统RRS方法与波前架构的不兼容性问题，并通过神经网络优化RRS因子，显著提升了渲染质量和性能。


<details>
  <summary>Details</summary>
Motivation: 传统RRS方法因路径数量不可预测而与波前路径追踪的预分配内存和调度需求不兼容。为此，提出了归一化RRS框架和神经网络学习RRS因子的方法，以实现高效稳定的执行。

Method: 引入了归一化RRS公式，限定路径数量以确保内存高效利用；设计了NRRS和AID-NRRS两个模型，利用RRSNet学习RRS因子，并通过Mix-Depth机制动态调节计算成本与推理精度。

Result: 实验表明，该方法在多种复杂场景下，渲染质量和性能均优于传统启发式方法和近期RRS技术。

Conclusion: 通过归一化RRS框架和神经网络优化，有效解决了波前路径追踪中的RRS兼容性问题，显著提升了渲染效率和质量。

Abstract: We propose a novel framework for Russian Roulette and Splitting (RRS)
tailored to wavefront path tracing, a highly parallel rendering architecture
that processes path states in batched, stage-wise execution for efficient GPU
utilization. Traditional RRS methods, with unpredictable path counts, are
fundamentally incompatible with wavefront's preallocated memory and scheduling
requirements. To resolve this, we introduce a normalized RRS formulation with a
bounded path count, enabling stable and memory-efficient execution.
  Furthermore, we pioneer the use of neural networks to learn RRS factors,
presenting two models: NRRS and AID-NRRS. At a high level, both feature a
carefully designed RRSNet that explicitly incorporates RRS normalization, with
only subtle differences in their implementation. To balance computational cost
and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism
that adaptively regulates neural evaluation, further improving efficiency.
  Extensive experiments demonstrate that our method outperforms traditional
heuristics and recent RRS techniques in both rendering quality and performance
across a variety of complex scenes.

</details>


### [5] [Variable-Rate Texture Compression: Real-Time Rendering with JPEG](https://arxiv.org/abs/2510.08166)
*Elias Kristmann,Markus Schütz,Michael Wimmer*

Main category: cs.GR

TL;DR: 探索在现代GPU上使用JPEG格式的可变速率纹理压缩的可行性，并与固定速率压缩方法BC1和ASTC进行比较。


<details>
  <summary>Details</summary>
Motivation: 尽管JPEG等可变速率压缩图像格式广泛用于高效编码图像，但由于随机访问单个纹理等特殊需求，尚未应用于实时渲染。

Method: 采用延迟渲染管线识别所需块，解码并着色帧缓冲像素，实现JPEG压缩。

Result: JPEG在质量和压缩率上优于BC1，部分场景与ASTC相当，渲染时长仅增加0.3毫秒。

Conclusion: 研究表明，现代GPU支持复杂的可变速率压缩方案，即使在VR中也可行。

Abstract: Although variable-rate compressed image formats such as JPEG are widely used
to efficiently encode images, they have not found their way into real-time
rendering due to special requirements such as random access to individual
texels. In this paper, we investigate the feasibility of variable-rate texture
compression on modern GPUs using the JPEG format, and how it compares to the
GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred
rendering pipeline, we are able to identify the subset of blocks that are
needed for a given frame, decode these, and colorize the framebuffer's pixels.
Despite the additional $\sim$0.17 bit per pixel that we require for our
approach, JPEG maintains significantly better quality and compression rates
compared to BC1, and depending on the type of image, outperforms or competes
with ASTC. The JPEG rendering pipeline increases rendering duration by less
than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate
compression schemes are feasible on modern GPUs, even in VR. Source code and
data sets are available at: https://github.com/elias1518693/jpeg_textures

</details>


### [6] [SViM3D: Stable Video Material Diffusion for Single Image 3D Generation](https://arxiv.org/abs/2510.08271)
*Andreas Engelhardt,Mark Boss,Vikram Voletti,Chun-Han Yao,Hendrik P. A. Lensch,Varun Jampani*

Main category: cs.GR

TL;DR: SViM3D框架通过单张图像预测多视角一致的PBR材质，结合潜在视频扩散模型实现高质量的3D资产生成和重光照。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型在单图像3D重建中效率高，但反射率仍需简化模型或多步估计，限制了重光照和外观编辑的灵活性。SViM3D旨在解决这一问题。

Method: 扩展潜在视频扩散模型，联合输出PBR参数和表面法线，引入显式相机控制与多种机制以提升质量。

Result: 在多对象中心数据集上展示了最先进的重光照和新视角合成性能，适用于AR/VR、电影和游戏等视觉媒体。

Conclusion: SViM3D能泛化至多样化输入，为AR/VR等领域提供了实用的可重光照3D资产生成方法。

Abstract: We present Stable Video Materials 3D (SViM3D), a framework to predict
multi-view consistent physically based rendering (PBR) materials, given a
single image. Recently, video diffusion models have been successfully used to
reconstruct 3D objects from a single image efficiently. However, reflectance is
still represented by simple material models or needs to be estimated in
additional steps to enable relighting and controlled appearance edits. We
extend a latent video diffusion model to output spatially varying PBR
parameters and surface normals jointly with each generated view based on
explicit camera control. This unique setup allows for relighting and generating
a 3D asset using our model as neural prior. We introduce various mechanisms to
this pipeline that improve quality in this ill-posed setting. We show
state-of-the-art relighting and novel view synthesis performance on multiple
object-centric datasets. Our method generalizes to diverse inputs, enabling the
generation of relightable 3D assets useful in AR/VR, movies, games and other
visual media.

</details>


### [7] [Spectral Prefiltering of Neural Fields](https://arxiv.org/abs/2510.08394)
*Mustafa B. Yaldiz,Ishit Mehta,Nithin Raghavan,Andreas Meuleman,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出了一种优化的神经场方法，能够在单次前向传播中进行预滤波，支持多种参数滤波器，训练和推理速度快。


<details>
  <summary>Details</summary>
Motivation: 神经场在表示连续视觉信号方面表现出色，但通常只能在单一固定分辨率下操作。本文旨在解决这一问题，提出一种优化的预滤波方法。

Method: 通过在输入域中执行卷积滤波，利用傅里叶特征嵌入并缩放滤波器的频率响应；采用单样本蒙特卡洛估计训练神经场。

Result: 在神经场滤波方面，该方法展现了定性和定量的改进，支持训练时未见过的参数滤波器（如Box和Lanczos）。

Conclusion: 该方法在训练和推理速度上表现优异，无需对网络架构施加额外约束，为神经场滤波提供了高效灵活的解决方案。

Abstract: Neural fields excel at representing continuous visual signals but typically
operate at a single, fixed resolution. We present a simple yet powerful method
to optimize neural fields that can be prefiltered in a single forward pass. Key
innovations and features include: (1) We perform convolutional filtering in the
input domain by analytically scaling Fourier feature embeddings with the
filter's frequency response. (2) This closed-form modulation generalizes beyond
Gaussian filtering and supports other parametric filters (Box and Lanczos) that
are unseen at training time. (3) We train the neural field using single-sample
Monte Carlo estimates of the filtered signal. Our method is fast during both
training and inference, and imposes no additional constraints on the network
architecture. We show quantitative and qualitative improvements over existing
methods for neural-field filtering.

</details>


### [8] [Splat the Net: Radiance Fields with Splattable Neural Primitives](https://arxiv.org/abs/2510.08491)
*Xilong Zhou,Bao-Huy Nguyen,Loïc Magne,Vladislav Golyanik,Thomas Leimkühler,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出了一种新的体素表示方法‘splattable neural primitives’，结合了神经模型的表达能力和基于图元的实时渲染效率。


<details>
  <summary>Details</summary>
Motivation: 当前的神经辐射场方法渲染效率低，而基于图元的方法则表达能力有限。为了解决这一问题，研究旨在结合两者的优势。

Method: 通过浅层神经网络参数化有界神经密度场，支持视角精确的计算，无需昂贵的光线行进。

Result: 在基准测试中，新方法达到了与3D高斯泼溅相当的质量和速度，同时减少了图元数量和参数数量。

Conclusion: 该方法在不依赖复杂控制框架的情况下，成功提升了渲染的效率和表达能力。

Abstract: Radiance fields have emerged as a predominant representation for modeling 3D
scene appearance. Neural formulations such as Neural Radiance Fields provide
high expressivity but require costly ray marching for rendering, whereas
primitive-based methods such as 3D Gaussian Splatting offer real-time
efficiency through splatting, yet at the expense of representational power.
Inspired by advances in both these directions, we introduce splattable neural
primitives, a new volumetric representation that reconciles the expressivity of
neural models with the efficiency of primitive-based splatting. Each primitive
encodes a bounded neural density field parameterized by a shallow neural
network. Our formulation admits an exact analytical solution for line
integrals, enabling efficient computation of perspectively accurate splatting
kernels. As a result, our representation supports integration along view rays
without the need for costly ray marching. The primitives flexibly adapt to
scene geometry and, being larger than prior analytic primitives, reduce the
number required per scene. On novel-view synthesis benchmarks, our approach
matches the quality and speed of 3D Gaussian Splatting while using $10\times$
fewer primitives and $6\times$ fewer parameters. These advantages arise
directly from the representation itself, without reliance on complex control or
adaptation frameworks. The project page is
https://vcai.mpi-inf.mpg.de/projects/SplatNet/.

</details>


### [9] [X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](https://arxiv.org/abs/2510.08530)
*Zhitong Huang,Mohan Zhang,Renhan Wang,Rui Tang,Hao Zhu,Jing Liao*

Main category: cs.GR

TL;DR: X2Video是首个利用内在通道（如反照率、法线、粗糙度、金属性和辐照度）和多模态控制（参考图像和文本提示）生成逼真视频的扩散模型，支持对颜色、材质、几何和光照的精确操控。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型缺乏对内在通道和多模态控制的支持，限制了视频内容的精确编辑和直观调整。X2Video旨在填补这一空白，提供更灵活的视频生成和编辑能力。

Method: X2Video扩展了内在通道引导的图像生成模型XRGB，通过混合自注意力机制确保视频帧的时间一致性，并采用掩码交叉注意力分离全局和局部文本提示。此外，递归采样方法结合关键帧预测和帧插值，生成长视频。

Result: X2Video生成的视频在时间一致性和逼真度上表现优异，支持对颜色、材质、几何和光照的编辑。InteriorVideo数据集为训练提供了可靠支持。

Conclusion: X2Video通过内在通道和多模态控制，实现了高质量视频生成与编辑，为视频内容创作提供了强大工具。

Abstract: We present X2Video, the first diffusion model for rendering photorealistic
videos guided by intrinsic channels including albedo, normal, roughness,
metallicity, and irradiance, while supporting intuitive multi-modal controls
with reference images and text prompts for both global and local regions. The
intrinsic guidance allows accurate manipulation of color, material, geometry,
and lighting, while reference images and text prompts provide intuitive
adjustments in the absence of intrinsic information. To enable these
functionalities, we extend the intrinsic-guided image generation model XRGB to
video generation by employing a novel and efficient Hybrid Self-Attention,
which ensures temporal consistency across video frames and also enhances
fidelity to reference images. We further develop a Masked Cross-Attention to
disentangle global and local text prompts, applying them effectively onto
respective local and global regions. For generating long videos, our novel
Recursive Sampling method incorporates progressive frame sampling, combining
keyframe prediction and frame interpolation to maintain long-range temporal
consistency while preventing error accumulation. To support the training of
X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154
rooms from 295 interior scenes, complete with reliable ground-truth intrinsic
channel sequences and smooth camera trajectories. Both qualitative and
quantitative evaluations demonstrate that X2Video can produce long, temporally
consistent, and photorealistic videos guided by intrinsic conditions.
Additionally, X2Video effectively accommodates multi-modal controls with
reference images, global and local text prompts, and simultaneously supports
editing on color, material, geometry, and lighting through parametric tuning.
Project page: https://luckyhzt.github.io/x2video

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Type, Ability, and Effect Systems: Perspectives on Purity, Semantics, and Expressiveness](https://arxiv.org/abs/2510.07582)
*Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 本文提出了一种语义纯净度的定义，并通过表达能力的度量标准（完整性）评估了不同类型的效果和能力系统，证明它们在表达能力上是不可比的。最后，提出了一种综合方法，结合了类型、能力和效果系统的优势。


<details>
  <summary>Details</summary>
Motivation: 编程中纯净计算与有副作用的交互之间的分离是重要的。现有的方法（如单子、类型效果系统和能力系统）在精确性和可用性之间存在张力，各有优缺点。本文旨在提高评估这些系统的标准。

Method: 首先提出了基于上下文等价的语义纯净度定义，然后通过表达能力（即语义纯净的术语能够被类型化为纯净的程度）来评估效果和能力系统。特别关注了最小有意义的效果和能力系统。

Result: 研究表明，最小有意义的效果和能力系统在表达能力上是不可比的，即互不包含。基于此，提出了一种综合方法，结合了类型、能力和效果系统的优势。

Conclusion: 本文通过语义定义和表达能力评估，揭示了效果和能力系统的局限性，并提出了一种综合方法，为多种效果类型学科提供了纯净度证明的工具。

Abstract: Programming benefits from a clear separation between pure, mathematical
computation and impure, effectful interaction with the world. Existing
approaches to enforce this separation include monads, type-and-effect systems,
and capability systems. All share a tension between precision and usability,
and each one has non-obvious strengths and weaknesses.
  This paper aims to raise the bar in assessing such systems. First, we propose
a semantic definition of purity, inspired by contextual equivalence, as a
baseline independent of any specific typing discipline. Second, we propose that
expressiveness should be measured by the degree of completeness, i.e., how many
semantically pure terms can be typed as pure. Using this measure, we focus on
minimal meaningful effect and capability systems and show that they are
incomparable, i.e., neither subsumes the other in terms of expressiveness.
  Based on this result, we propose a synthesis and show that type, ability, and
effect systems combine their respective strengths while avoiding their
weaknesses. As part of our formal model, we provide a logical relation to
facilitate proofs of purity and other properties for a variety of effect typing
disciplines.

</details>


### [11] [The Functional Machine Calculus III: Control](https://arxiv.org/abs/2510.07851)
*Willem Heijltjes*

Main category: cs.PL

TL;DR: 功能性机器演算（FMC）是一种统一命令式和函数式编程范式的新方法，扩展了Lambda演算并支持分支和循环控制流。


<details>
  <summary>Details</summary>
Motivation: 旨在统一命令式和函数式编程范式，同时保留Lambda演算的关键特性（如合流约简和类型终止）。

Method: 通过扩展Krivine机器的操作语义，引入多个操作数栈和延续栈来建模效应和控制流。

Result: 实现了分支和循环控制流的嵌入，支持条件语句、异常处理和迭代等完整命令式语言特性。

Conclusion: FMC提供了一个统一的功能-命令式计算模型，支持简单类型、直观的操作语义和合流约简语义。

Abstract: The Functional Machine Calculus (Heijltjes 2022) is a new approach to
unifying the imperative and functional programming paradigms. It extends the
lambda-calculus, preserving the key features of confluent reduction and typed
termination, to embed computational effects, evaluation strategies, and control
flow operations. The first instalment modelled sequential higher-order
computation with global store, input/output, probabilities, and
non-determinism, and embedded both the call-by-name and call-by-value
lambda-calculus, as well as Moggi's computational metalanguage and Levy's
call-by-push-value. The present paper extends the calculus from sequential to
branching and looping control flow. This allows the faithful embedding of a
minimal but complete imperative language, including conditionals, exception
handling, and iteration, as well as constants and algebraic data types.
  The calculus is defined through a simple operational semantics, extending the
(simplified) Krivine machine for the lambda-calculus with multiple operand
stacks to model effects and a continuation stack to model sequential,
branching, and looping computation. It features a confluent reduction relation
and a system of simple types that guarantees termination of the machine and
strong normalization of reduction (in the absence of iteration). These
properties carry over to the embedded imperative language, providing a unified
functional-imperative model of computation that supports simple types, a direct
and intuitive operational semantics, and a confluent reduction semantics.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [12] [BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats](https://arxiv.org/abs/2510.07430)
*Yang Jiao,Guanpu Chen,Yiguang Hong*

Main category: cs.GT

TL;DR: 本文研究了具有不同偏好的内部人员的进阶持续性威胁（APT），提出了BG-FlipIn框架，通过贝叶斯博弈分析恶意、无意或腐败的内部人员，并提供了均衡解和决策指导。


<details>
  <summary>Details</summary>
Motivation: 针对内部人员偏好不确定性带来的挑战，研究如何通过博弈论框架解决APT中的内部威胁问题。

Method: 提出BG-FlipIn框架，基于贝叶斯博弈模型计算均衡解，并对确定性内部人员的三种极端情况进行分析。

Result: 发现了APT中与防御者行为频率、成本和内部人员偏好相关的现象，并提供了不同参数条件下的决策指导。

Conclusion: 应用验证表明，BG-FlipIn框架能帮助防御者无需频繁调整策略或探测内部人员偏好即可做出一致决策。

Abstract: In this paper, we study advanced persistent threats (APT) with an insider who
has different preferences. To address the uncertainty of the insider's
preference, we propose the BG-FlipIn: a Bayesian game framework for
FlipIt-insider models with an investigation on malicious, inadvertent, or
corrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium
expression and further obtain three edge cases with deterministic insiders
corresponding to their Nash Equilibrium expressions. On this basis, we further
discover several phenomena in APT related to the defender's move rate and cost,
as well as the insider's preferences. We then provide decision-making guidance
for the defender, given different parametric conditions. Two applications
validate that our BG-FlipIn framework enables the defender to make decisions
consistently, avoiding detecting the insider's concrete preference or adjusting
its strategy frequently.

</details>


### [13] [Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices](https://arxiv.org/abs/2510.07572)
*Jesse D Wei,Guo Wei*

Main category: cs.GT

TL;DR: 该研究设计了确定性算法，用于通过非齐次伯努利试验计算的博弈中线性或二次时间近似Shapley值，并提供严格的误差分析。


<details>
  <summary>Details</summary>
Motivation: 传统计算Shapley值的方法要么计算复杂度高，要么依赖蒙特卡洛采样性能不稳定。本研究旨在设计高效且确定性强的算法来解决这些问题。

Method: 设计了基于非齐次伯努利试验的确定性算法，能够在线性或二次时间内近似Shapley值，并通过积分和组合分析严格推导Shapley值公式。

Result: 提出的算法显著降低了计算复杂度，并提供了严格的误差分析，填补了Shapley原始证明中的某些理论空白。

Conclusion: 研究不仅改进了Shapley值的计算方法，还通过严谨的数学推导补充了Shapley的原始工作，为相关领域提供了新的理论工具。

Abstract: Suppose that $n$ computer devices are to be connected to a network via
inhomogeneous Bernoulli trials. The Shapley value of a device quantifies how
much the network's value increases due to the participation of that device.
Characteristic functions of such games are naturally taken as the belief
function (containment function) and Choquet capacity (hitting probability) of a
random set (random network of devices).
  Traditionally, the Shapley value is either calculated as the expected
marginal contribution over all possible coalitions (subnetworks), which results
in exponential computational complexity, or approximated by the Monte Carlo
sampling technique, where the performance is highly dependent on the stochastic
sampling process.
  The purpose of this study is to design deterministic algorithms for games
formulated via inhomogeneous Bernoulli trials that approximate the Shapley
value in linear or quadratic time, with rigorous error analysis (Sections 3 and
4). Additionally, we provide a review of relevant literature on existing
calculation methods in Remark 3.1 and Appendix I.
  A further goal is to supplement Shapley's original proof by deriving the
Shapley value formula using a rigorous approach based on definite integrals and
combinatorial analysis. This method explicitly highlights the roles of the
Binomial Theorem and the Beta function in the proof, addressing a gap in
Shapley's work (Appendix II).

</details>


### [14] [Extending Games beyond the Finite Horizon](https://arxiv.org/abs/2510.08453)
*Kiri Sakahara,Takashi Sato*

Main category: cs.GT

TL;DR: 本文提出基于替代集合论（AST）的新框架，解决有限视野悖论，揭示依赖于时间视角和收益评估的新子博弈完美均衡。


<details>
  <summary>Details</summary>
Motivation: 有限视野悖论源于标准数系统在模拟无限认知感知时的局限性，需要通过AST框架解决这一矛盾。

Method: 采用替代集合论（AST）框架，通过不同拓扑表示事件历史的认知视角，利用不可分辨性等价处理巨大且不可区分的数量。

Result: 该框架为长期悖论（如Selten连锁店悖论和Rosenthal的蜈蚣博弈）提供标准依赖的解决方案，并揭示新的子博弈完美均衡。

Conclusion: 通过基于人类认知模式的数学基础，该研究扩展了博弈论在长期场景中的解释力。

Abstract: This paper argues that the finite horizon paradox, where game theory
contradicts intuition, stems from the limitations of standard number systems in
modelling the cognitive perception of infinity. To address this issue, we
propose a new framework based on Alternative Set Theory (AST). This framework
represents different cognitive perspectives on a long history of events using
distinct topologies. These topologies define an indiscernibility equivalence
that formally treats huge, indistinguishable quantities as equivalent. This
offers criterion-dependent resolutions to long-standing paradoxes, such as
Selten's chain store paradox and Rosenthal's centipede game. Our framework
reveals new intuitive subgame perfect equilibria, the characteristics of which
depend on the chosen temporal perspective and payoff evaluation. Ultimately, by
grounding its mathematical foundation in different modes of human cognition,
our work expands the explanatory power of game theory for long-horizon
scenarios.

</details>
