{"id": "2601.04648", "categories": ["cs.GT", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04648", "abs": "https://arxiv.org/abs/2601.04648", "authors": ["Xiang Li", "Bing Luo", "Jianwei Huang", "Yuan Luo"], "title": "Mechanism Design for Federated Learning with Non-Monotonic Network Effects", "comment": "Journal extension of Mobihoc conference version, under review of IEEE TMC", "summary": "Mechanism design is pivotal to federated learning (FL) for maximizing social welfare by coordinating self-interested clients. Existing mechanisms, however, often overlook the network effects of client participation and the diverse model performance requirements (i.e., generalization error) across applications, leading to suboptimal incentives and social welfare, or even inapplicability in real deployments. To address this gap, we explore incentive mechanism design for FL with network effects and application-specific requirements of model performance. We develop a theoretical model to quantify the impact of network effects on heterogeneous client participation, revealing the non-monotonic nature of such effects. Based on these insights, we propose a Model Trading and Sharing (MoTS) framework, which enables clients to obtain FL models through either participation or purchase. To further address clients' strategic behaviors, we design a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism, exploiting model customer payments for incentivization. Experimental results on a hardware prototype demonstrate that our SWAN mechanism outperforms existing FL mechanisms, improving social welfare by up to $352.42\\%$ and reducing extra incentive costs by $93.07\\%$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7f51\u7edc\u6548\u5e94\u548c\u5e94\u7528\u7279\u5b9a\u9700\u6c42\u7684\u8054\u90a6\u5b66\u4e60\u6fc0\u52b1\u673a\u5236\u8bbe\u8ba1SWAN\uff0c\u901a\u8fc7\u6a21\u578b\u4ea4\u6613\u4e0e\u5171\u4eab\u6846\u67b6MoTS\u4f18\u5316\u793e\u4f1a\u798f\u5229\u548c\u6fc0\u52b1\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6fc0\u52b1\u673a\u5236\u5ffd\u89c6\u4e86\u7f51\u7edc\u6548\u5e94\u548c\u4e0d\u540c\u5e94\u7528\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u591a\u6837\u5316\u9700\u6c42\uff0c\u5bfc\u81f4\u6fc0\u52b1\u6548\u679c\u4e0d\u4f73\u548c\u793e\u4f1a\u798f\u5229\u4f4e\u4e0b\uff0c\u751a\u81f3\u4e0d\u9002\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u6a21\u578b\u4ea4\u6613\u4e0e\u5171\u4eab\u6846\u67b6MoTS\uff0c\u5e76\u8bbe\u8ba1\u4e86SWAN\u673a\u5236\uff0c\u901a\u8fc7\u91cf\u5316\u7f51\u7edc\u6548\u5e94\u5bf9\u5f02\u6784\u5ba2\u6237\u53c2\u4e0e\u7684\u5f71\u54cd\uff0c\u5e76\u7ed3\u5408\u5ba2\u6237\u652f\u4ed8\u6a21\u5f0f\u8fdb\u884c\u6fc0\u52b1\u3002", "result": "\u5728\u786c\u4ef6\u539f\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSWAN\u673a\u5236\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u673a\u5236\uff0c\u793e\u4f1a\u798f\u5229\u63d0\u5347\u9ad8\u8fbe352.42%\uff0c\u989d\u5916\u6fc0\u52b1\u6210\u672c\u964d\u4f4e93.07%\u3002", "conclusion": "SWAN\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u7f51\u7edc\u6548\u5e94\u548c\u5e94\u7528\u7279\u5b9a\u9700\u6c42\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6fc0\u52b1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04382", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04382", "abs": "https://arxiv.org/abs/2601.04382", "authors": ["Zulkhuu Tuya", "Ignacio Alzugaray", "Nicholas Fry", "Andrew J. Davison"], "title": "In-SRAM Radiant Foam Rendering on a Graph Processor", "comment": "24 pages, 26 figures", "summary": "Many emerging many-core accelerators replace a single large device memory with hundreds to thousands of lightweight cores, each owning only a small local SRAM and exchanging data via explicit on-chip communication. This organization offers high aggregate bandwidth, but it breaks a key assumption behind many volumetric rendering techniques: that rays can randomly access a large, unified scene representation. Rendering efficiently on such hardware therefore requires distributing both data and computation, keeping ray traversal mostly local, and structuring communication into predictable routes.\n  We present a fully in-SRAM, distributed renderer for the \\emph{Radiant Foam} Voronoi-cell volumetric representation on the Graphcore Mk2 IPU, a many-core accelerator with tile-local SRAM and explicit inter-tile communication. Our system shards the scene across tiles and forwards rays between shards through a hierarchical routing overlay, enabling ray marching entirely from on-chip SRAM with predictable communication. On Mip-NeRF~360 scenes, the system attains near-interactive throughput (\\(\\approx\\)1\\,fps at \\mbox{$640\\times480$}) with image and depth quality close to the original GPU-based Radiant Foam implementation, while keeping all scene data and ray state in on-chip SRAM. Beyond demonstrating feasibility, we analyze routing, memory, and scheduling bottlenecks that inform how future distributed-memory accelerators can better support irregular, data-movement-heavy rendering workloads.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Graphcore Mk2 IPU\u4e0a\u5b9e\u73b0\u7684\u5b8c\u5168\u5728SRAM\u4e2d\u7684\u5206\u5e03\u5f0f\u4f53\u79ef\u6e32\u67d3\u7cfb\u7edf\uff0c\u5229\u7528\u5c42\u6b21\u5316\u8def\u7531\u8986\u76d6\u9ad8\u6548\u5904\u7406\u5149\u7ebf\u8ffd\u8e2a\uff0c\u4fdd\u6301\u6570\u636e\u548c\u8ba1\u7b97\u7684\u672c\u5730\u5316\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1GPU\u7684\u6027\u80fd\u3002", "motivation": "\u65b0\u5174\u591a\u6838\u52a0\u901f\u5668\u7684\u8bbe\u8ba1\u6253\u7834\u4e86\u4f20\u7edf\u4f53\u79ef\u6e32\u67d3\u6280\u672f\u4f9d\u8d56\u7edf\u4e00\u5927\u5185\u5b58\u7684\u5047\u8bbe\uff0c\u56e0\u6b64\u9700\u8981\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u67b6\u6784\u4e0a\u5f00\u53d1\u9ad8\u6548\u7684\u6e32\u67d3\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86Radiant Foam Voronoi-cell\u4f53\u79ef\u8868\u793a\u6cd5\uff0c\u5e76\u5728Graphcore Mk2 IPU\u4e0a\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u5168\u5728SRAM\u4e2d\u7684\u5206\u5e03\u5f0f\u6e32\u67d3\u7cfb\u7edf\uff0c\u5229\u7528\u5c42\u6b21\u5316\u8def\u7531\u8986\u76d6\u7ba1\u7406\u548c\u8c03\u5ea6\u5149\u7ebf\u8ffd\u8e2a\u3002", "result": "\u7cfb\u7edf\u5728Mip-NeRF~360\u573a\u666f\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4ea4\u4e92\u5f0f\u7684\u6e32\u67d3\u901f\u7387\uff08\u7ea61\u5e27/\u79d2\uff0c640x480\u5206\u8fa8\u7387\uff09\uff0c\u56fe\u50cf\u548c\u6df1\u5ea6\u8d28\u91cf\u63a5\u8fd1GPU\u5b9e\u73b0\uff0c\u540c\u65f6\u5c06\u6240\u6709\u573a\u666f\u6570\u636e\u548c\u5149\u7ebf\u72b6\u6001\u4fdd\u7559\u5728SRAM\u4e2d\u3002", "conclusion": "\u8bba\u6587\u4e0d\u4ec5\u8bc1\u660e\u4e86\u5728\u5206\u5e03\u5f0f\u5185\u5b58\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0\u9ad8\u6548\u4f53\u79ef\u6e32\u67d3\u7684\u53ef\u884c\u6027\uff0c\u8fd8\u5206\u6790\u4e86\u8def\u7531\u3001\u5185\u5b58\u548c\u8c03\u5ea6\u7684\u74f6\u9888\uff0c\u4e3a\u672a\u6765\u652f\u6301\u4e0d\u89c4\u5219\u3001\u6570\u636e\u5bc6\u96c6\u578b\u6e32\u67d3\u4efb\u52a1\u7684\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2601.04492", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04492", "abs": "https://arxiv.org/abs/2601.04492", "authors": ["Yuanzhuo Zhang", "Zhoulai Fu", "Binoy Ravindran"], "title": "Scalable Floating-Point Satisfiability via Staged Optimization", "comment": null, "summary": "This work introduces StageSAT, a new approach to solving floating-point satisfiability that bridges SMT solving with numerical optimization. StageSAT reframes a floating-point formula as a series of optimization problems in three stages of increasing precision. It begins with a fast, projection-aided descent objective to guide the search toward a feasible region, proceeding to bit-level accuracy with ULP$^2$ optimization and a final $n$-ULP lattice refinement.\n  By construction, the final stage uses a representing function that is zero if and only if a candidate satisfies all constraints. Thus, when optimization drives the objective to zero, the resulting assignment is a valid solution, providing a built-in guarantee of soundness.\n  To improve search, StageSAT introduces a partial monotone descent property on linear constraints via orthogonal projection, preventing the optimizer from stalling on flat or misleading landscapes. Critically, this solver requires no heavy bit-level reasoning or specialized abstractions; it treats complex arithmetic as a black-box, using runtime evaluations to navigate the input space.\n  We implement StageSAT and evaluate it on extensive benchmarks, including SMT-COMP'25 suites and difficult cases from prior work. StageSAT proved more scalable and accurate than state-of-the-art optimization-based alternatives. It solved strictly more formulas than any competing solver under the same time budget, finding most satisfiable instances without producing spurious models. This amounts to 99.4% recall on satisfiable cases with 0% false SAT, exceeding the reliability of prior optimization-based solvers. StageSAT also delivered significant speedups (often 5--10$\\times$) over traditional bit-precise SMT and numeric solvers. These results demonstrate that staged optimization significantly improves performance and correctness of floating-point satisfiability solving.", "AI": {"tldr": "StageSAT\u662f\u4e00\u79cd\u5c06SMT\u6c42\u89e3\u4e0e\u6570\u503c\u4f18\u5316\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u4f18\u5316\u89e3\u51b3\u6d6e\u70b9\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u6b63\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6d6e\u70b9\u53ef\u6ee1\u8db3\u6027\u6c42\u89e3\u65b9\u6cd5\u5728\u590d\u6742\u7b97\u672f\u548c\u641c\u7d22\u6548\u7387\u4e0a\u5b58\u5728\u5c40\u9650\uff0cStageSAT\u65e8\u5728\u901a\u8fc7\u5206\u9636\u6bb5\u4f18\u5316\u548c\u6295\u5f71\u8f85\u52a9\u4e0b\u964d\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "StageSAT\u5c06\u6d6e\u70b9\u516c\u5f0f\u91cd\u6784\u4e3a\u4e09\u4e2a\u7cbe\u5ea6\u9012\u589e\u7684\u4f18\u5316\u95ee\u9898\u9636\u6bb5\uff1a\u5feb\u901f\u6295\u5f71\u8f85\u52a9\u4e0b\u964d\u3001ULP\u00b2\u4f18\u5316\u548cn-ULP\u6676\u683c\u7ec6\u5316\uff0c\u5e76\u5f15\u5165\u6b63\u4ea4\u6295\u5f71\u9632\u6b62\u641c\u7d22\u505c\u6ede\u3002", "result": "StageSAT\u5728\u5e7f\u6cdb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u66f4\u591a\u516c\u5f0f\uff0c99.4%\u7684\u53ec\u56de\u7387\u548c0%\u5047SAT\uff0c\u901f\u5ea6\u63d0\u5347\u4e865-10\u500d\u3002", "conclusion": "\u5206\u9636\u6bb5\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u6d6e\u70b9\u53ef\u6ee1\u8db3\u6027\u6c42\u89e3\u7684\u6027\u80fd\u548c\u6b63\u786e\u6027\uff0cStageSAT\u4e3a\u590d\u6742\u7b97\u672f\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04494", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.04494", "abs": "https://arxiv.org/abs/2601.04494", "authors": ["Julian Knodt", "Seung-Hwan Baek"], "title": "Differential Locally Injective Grid Deformation and Optimization", "comment": null, "summary": "Grids are a general representation for capturing regularly-spaced information, but since they are uniform in space, they cannot dynamically allocate resolution to regions with varying levels of detail. There has been some exploration of indirect grid adaptivity by replacing uniform grids with tetrahedral meshes or locally subdivided grids, as inversion-free deformation of grids is difficult. This work develops an inversion-free grid deformation method that optimizes differential weight to adaptively compress space. The method is the first to optimize grid vertices as differential elements using vertex-colorings, decomposing a dense input linear system into many independent sets of vertices which can be optimized concurrently. This method is then also extended to optimize UV meshes with convex boundaries. Experimentally, this differential representation leads to a smoother optimization manifold than updating extrinsic vertex coordinates. By optimizing each sets of vertices in a coloring separately, local injectivity checks are straightforward since the valid region for each vertex is fixed. This enables the use of optimizers such as Adam, as each vertex can be optimized independently of other vertices. We demonstrate the generality and efficacy of this approach through applications in isosurface extraction for inverse rendering, image compaction, and mesh parameterization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u53cd\u8f6c\u7684\u7f51\u683c\u53d8\u5f62\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u5dee\u5206\u6743\u91cd\u81ea\u9002\u5e94\u538b\u7f29\u7a7a\u95f4\uff0c\u662f\u9996\u4e2a\u5229\u7528\u9876\u70b9\u7740\u8272\u5c06\u5bc6\u96c6\u7ebf\u6027\u7cfb\u7edf\u5206\u89e3\u4e3a\u591a\u4e2a\u72ec\u7acb\u9876\u70b9\u96c6\u4ee5\u5e76\u884c\u4f18\u5316\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7f51\u683c\u5728\u7a7a\u95f4\u4e0a\u662f\u5747\u5300\u7684\uff0c\u65e0\u6cd5\u52a8\u6001\u8c03\u6574\u5206\u8fa8\u7387\u4ee5\u9002\u5e94\u7ec6\u8282\u53d8\u5316\u533a\u57df\u3002\u73b0\u6709\u7684\u95f4\u63a5\u7f51\u683c\u81ea\u9002\u5e94\u65b9\u6cd5\uff08\u5982\u56db\u9762\u4f53\u7f51\u683c\u6216\u5c40\u90e8\u7ec6\u5206\u7f51\u683c\uff09\u96be\u4ee5\u5b9e\u73b0\u65e0\u53cd\u8f6c\u53d8\u5f62\u3002", "method": "\u901a\u8fc7\u9876\u70b9\u7740\u8272\u5c06\u5bc6\u96c6\u8f93\u5165\u7ebf\u6027\u7cfb\u7edf\u5206\u89e3\u4e3a\u591a\u4e2a\u72ec\u7acb\u9876\u70b9\u96c6\uff0c\u4f18\u5316\u5dee\u5206\u6743\u91cd\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u7a7a\u95f4\u538b\u7f29\uff0c\u5e76\u6269\u5c55\u5230\u4f18\u5316\u5177\u6709\u51f8\u8fb9\u754c\u7684UV\u7f51\u683c\u3002", "result": "\u5dee\u5206\u8868\u793a\u6cd5\u6bd4\u66f4\u65b0\u9876\u70b9\u5916\u5750\u6807\u5177\u6709\u66f4\u5e73\u6ed1\u7684\u4f18\u5316\u6d41\u5f62\uff0c\u4e14\u901a\u8fc7\u72ec\u7acb\u4f18\u5316\u9876\u70b9\u96c6\uff0c\u5c40\u90e8\u5355\u5c04\u6027\u68c0\u67e5\u66f4\u7b80\u5355\uff0c\u53ef\u4f7f\u7528Adam\u7b49\u4f18\u5316\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7b49\u503c\u9762\u63d0\u53d6\u3001\u56fe\u50cf\u538b\u7f29\u548c\u7f51\u683c\u53c2\u6570\u5316\u4e2d\u5c55\u793a\u4e86\u5176\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.04573", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.04573", "abs": "https://arxiv.org/abs/2601.04573", "authors": ["Kazutaka Matsuda", "Minh Nguyen", "Meng Wang"], "title": "Lenses for Partially-Specified States (Extended Version)", "comment": "Extended version of our paper to appear in ESOP 2026", "summary": "A bidirectional transformation is a pair of transformations satisfying certain well-behavedness properties: one maps source data into view data, and the other translates changes on the view back to the source. However, when multiple views share a source, an update on one view may affect the others, making it hard to maintain correspondence while preserving the user's update, especially when multiple views are changed at once. Ensuring these properties within a compositional framework is even more challenging. In this paper, we propose partial-state lenses, which allow source and view states to be partially specified to precisely represent the user's update intentions. These intentions are partially ordered, providing clear semantics for merging intentions of updates coming from multiple views and a refined notion of update preservation compatible with this merging. We formalize partial-state lenses, together with partial-specifiedness-aware well-behavedness that supports compositional reasoning and ensures update preservation. In addition, we demonstrate the utility of the proposed system through examples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u90e8\u5206\u72b6\u6001\u900f\u955c\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u591a\u4e2a\u89c6\u56fe\u5171\u4eab\u540c\u4e00\u6e90\u65f6\u7684\u66f4\u65b0\u95ee\u9898\uff0c\u901a\u8fc7\u90e8\u5206\u6307\u5b9a\u72b6\u6001\u6765\u7cbe\u786e\u8868\u8fbe\u7528\u6237\u610f\u56fe\uff0c\u5e76\u652f\u6301\u7ec4\u5408\u63a8\u7406\u548c\u66f4\u65b0\u4fdd\u6301\u3002", "motivation": "\u5f53\u591a\u4e2a\u89c6\u56fe\u5171\u4eab\u540c\u4e00\u6e90\u6570\u636e\u65f6\uff0c\u4e00\u4e2a\u89c6\u56fe\u7684\u66f4\u65b0\u53ef\u80fd\u4f1a\u5f71\u54cd\u5176\u4ed6\u89c6\u56fe\uff0c\u8fd9\u4f7f\u5f97\u5728\u4fdd\u6301\u7528\u6237\u66f4\u65b0\u7684\u540c\u65f6\u7ef4\u62a4\u4e00\u81f4\u6027\u53d8\u5f97\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u591a\u4e2a\u89c6\u56fe\u540c\u65f6\u66f4\u65b0\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u90e8\u5206\u72b6\u6001\u900f\u955c\u6846\u67b6\uff0c\u5141\u8bb8\u90e8\u5206\u6307\u5b9a\u6e90\u548c\u89c6\u56fe\u72b6\u6001\uff0c\u4ee5\u7cbe\u786e\u8868\u8fbe\u7528\u6237\u66f4\u65b0\u610f\u56fe\u3002\u8fd9\u4e9b\u610f\u56fe\u88ab\u90e8\u5206\u6392\u5e8f\uff0c\u4e3a\u5408\u5e76\u6765\u81ea\u591a\u4e2a\u89c6\u56fe\u7684\u66f4\u65b0\u610f\u56fe\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8bed\u4e49\u3002", "result": "\u5f62\u5f0f\u5316\u4e86\u90e8\u5206\u72b6\u6001\u900f\u955c\uff0c\u5e76\u63d0\u51fa\u4e86\u652f\u6301\u7ec4\u5408\u63a8\u7406\u548c\u786e\u4fdd\u66f4\u65b0\u4fdd\u6301\u7684\u90e8\u5206\u6307\u5b9a\u611f\u77e5\u826f\u597d\u884c\u4e3a\u6027\u3002\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u90e8\u5206\u72b6\u6001\u900f\u955c\u4e3a\u89e3\u51b3\u591a\u89c6\u56fe\u5171\u4eab\u6e90\u6570\u636e\u7684\u66f4\u65b0\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u7ec4\u5408\u63a8\u7406\u548c\u66f4\u65b0\u4fdd\u6301\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2601.05127", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.05127", "abs": "https://arxiv.org/abs/2601.05127", "authors": ["Etai Sella", "Yoav Baron", "Hadar Averbuch-Elor", "Daniel Cohen-Or", "Or Patashnik"], "title": "LooseRoPE: Content-aware Attention Manipulation for Semantic Harmonization", "comment": "Project Page: https://snap-research.github.io/LooseRoPE/", "summary": "Recent diffusion-based image editing methods commonly rely on text or high-level instructions to guide the generation process, offering intuitive but coarse control. In contrast, we focus on explicit, prompt-free editing, where the user directly specifies the modification by cropping and pasting an object or sub-object into a chosen location within an image. This operation affords precise spatial and visual control, yet it introduces a fundamental challenge: preserving the identity of the pasted object while harmonizing it with its new context. We observe that attention maps in diffusion-based editing models inherently govern whether image regions are preserved or adapted for coherence. Building on this insight, we introduce LooseRoPE, a saliency-guided modulation of rotational positional encoding (RoPE) that loosens the positional constraints to continuously control the attention field of view. By relaxing RoPE in this manner, our method smoothly steers the model's focus between faithful preservation of the input image and coherent harmonization of the inserted object, enabling a balanced trade-off between identity retention and contextual blending. Our approach provides a flexible and intuitive framework for image editing, achieving seamless compositional results without textual descriptions or complex user input.", "AI": {"tldr": "LooseRoPE \u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u677e\u89e3\u4f4d\u7f6e\u7f16\u7801\u7684\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u6587\u672c\u63d0\u793a\u7684\u7cbe\u786e\u56fe\u50cf\u7f16\u8f91\uff0c\u5e73\u8861\u4e86\u5bf9\u8f93\u5165\u56fe\u50cf\u7684\u5fe0\u5b9e\u4fdd\u7559\u4e0e\u65b0\u63d2\u5165\u5bf9\u8c61\u7684\u4e0a\u4e0b\u6587\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u6587\u672c\u6216\u9ad8\u7ea7\u6307\u4ee4\uff0c\u63d0\u4f9b\u4e86\u76f4\u89c2\u4f46\u7c97\u7cd9\u7684\u63a7\u5236\u3002\u672c\u6587\u65e8\u5728\u5b9e\u73b0\u65e0\u9700\u63d0\u793a\u7684\u7cbe\u786e\u7f16\u8f91\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u76f4\u63a5\u901a\u8fc7\u88c1\u526a\u548c\u7c98\u8d34\u64cd\u4f5c\u6307\u5b9a\u4fee\u6539\uff0c\u540c\u65f6\u89e3\u51b3\u4fdd\u7559\u7c98\u8d34\u5bf9\u8c61\u8eab\u4efd\u4e0e\u4e0a\u4e0b\u6587\u534f\u8c03\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u89c2\u5bdf\u6269\u6563\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u56fe\u7684\u4f5c\u7528\uff0c\u63d0\u51fa LooseRoPE \u65b9\u6cd5\uff0c\u901a\u8fc7\u677e\u89e3\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\uff08RoPE\uff09\u7684\u7ea6\u675f\u6765\u63a7\u5236\u6ce8\u610f\u529b\u89c6\u91ce\uff0c\u4ece\u800c\u5e73\u8861\u8f93\u5165\u56fe\u50cf\u7684\u4fdd\u7559\u4e0e\u65b0\u5bf9\u8c61\u7684\u4e0a\u4e0b\u6587\u5316\u3002", "result": "LooseRoPE \u80fd\u591f\u7075\u6d3b\u5730\u5728\u4fdd\u7559\u8f93\u5165\u56fe\u50cf\u548c\u63d2\u5165\u5bf9\u8c61\u7684\u4e0a\u4e0b\u6587\u5316\u4e4b\u95f4\u5e73\u6ed1\u8c03\u8282\uff0c\u5b9e\u73b0\u4e86\u65e0\u7f1d\u7684\u5408\u6210\u6548\u679c\uff0c\u65e0\u9700\u6587\u672c\u63cf\u8ff0\u6216\u590d\u6742\u7684\u7528\u6237\u8f93\u5165\u3002", "conclusion": "LooseRoPE \u4e3a\u56fe\u50cf\u7f16\u8f91\u63d0\u4f9b\u4e86\u4e00\u4e2a\u76f4\u89c2\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u63a7\u6ce8\u610f\u529b\u89c6\u91ce\uff0c\u5b9e\u73b0\u4e86\u8eab\u4efd\u4fdd\u7559\u548c\u4e0a\u4e0b\u6587\u534f\u8c03\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u56fe\u50cf\u5408\u6210\u4efb\u52a1\u3002"}}
{"id": "2601.05012", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.05012", "abs": "https://arxiv.org/abs/2601.05012", "authors": ["Luke A. D. Hutchison"], "title": "The Squirrel Parser: A Linear-Time PEG Packrat Parser Capable of Left Recursion and Optimal Error Recovery", "comment": null, "summary": "We present the squirrel parser, a PEG packrat parser that directly handles all forms of left recursion with optimal error recovery, while maintaining linear time complexity in the length of the input even in the presence of an arbitrary number of errors. Traditional approaches to handling left recursion in a recursive descent parser require grammar rewriting or complex algorithmic extensions. We derive a minimal algorithm from first principles: cycle detection via per-position state tracking and $O(1)$-per-LR-cycle communication from descendant to ancestor recursion frames, and fixed-point search via iterative expansion. For error recovery, we derived a set of four axioms and twelve constraints that must be imposed upon an optimal error recovery design to ensure completeness, correctness, optimality of performance, and intuitiveness of behavior. We utilized a constraint satisfaction mechanism to search the space of all possibilities, arriving at a provably optimal and robust error recovery strategy that maintains perfect performance linearity.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u677e\u9f20\u89e3\u6790\u5668\uff0c\u4e00\u79cdPEG\u6253\u5305\u89e3\u6790\u5668\uff0c\u80fd\u591f\u76f4\u63a5\u5904\u7406\u6240\u6709\u5f62\u5f0f\u7684\u5de6\u9012\u5f52\uff0c\u5e76\u5177\u6709\u6700\u4f73\u7684\u9519\u8bef\u6062\u590d\u80fd\u529b\uff0c\u540c\u65f6\u5728\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u5185\u5b8c\u6210\u8f93\u5165\u5904\u7406\u3002", "motivation": "\u4f20\u7edf\u7684\u9012\u5f52\u4e0b\u964d\u89e3\u6790\u5668\u5728\u5904\u7406\u5de6\u9012\u5f52\u65f6\u9700\u8981\u91cd\u5199\u8bed\u6cd5\u6216\u4f7f\u7528\u590d\u6742\u7684\u7b97\u6cd5\u6269\u5c55\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u7b80\u6d01\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u4f4d\u7f6e\u7684\u72b6\u6001\u8ddf\u8e2a\u548c$O(1)$\u6bcfLR\u5468\u671f\u7684\u901a\u4fe1\u6765\u68c0\u6d4b\u5faa\u73af\uff0c\u4ee5\u53ca\u56fa\u5b9a\u70b9\u641c\u7d22\u7684\u8fed\u4ee3\u6269\u5c55\uff0c\u5b9e\u73b0\u4e86\u6700\u5c0f\u5316\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u5229\u7528\u7ea6\u675f\u6ee1\u8db3\u673a\u5236\u641c\u7d22\u6700\u4f73\u9519\u8bef\u6062\u590d\u7b56\u7565\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u89e3\u6790\u5668\u5728\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u9519\u8bef\u6062\u590d\uff0c\u5e76\u901a\u8fc7\u4e00\u7ec4\u516c\u7406\u548c\u7ea6\u675f\u786e\u4fdd\u4e86\u8bbe\u8ba1\u7684\u5b8c\u6574\u6027\u3001\u6b63\u786e\u6027\u548c\u76f4\u89c2\u6027\u3002", "conclusion": "\u677e\u9f20\u89e3\u6790\u5668\u4e3a\u5904\u7406\u5de6\u9012\u5f52\u548c\u9519\u8bef\u6062\u590d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7406\u8bba\u4e0a\u6709\u4fdd\u969c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05162", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05162", "abs": "https://arxiv.org/abs/2601.05162", "authors": ["Jinze Yu", "Dayuan Jiang"], "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation", "comment": null, "summary": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.", "AI": {"tldr": "GenAI-DrawIO-Creator\u662f\u4e00\u4e2a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u751f\u6210\u548c\u4fee\u6539draw.io\u56fe\u7684\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u521b\u5efa\u65f6\u95f4\u5e76\u63d0\u9ad8\u4e86\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u56fe\u5728\u4f20\u9012\u590d\u6742\u4fe1\u606f\u65b9\u9762\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u548c\u4fee\u6539\u56fe\u4ecd\u7136\u662f\u4e00\u9879\u52b3\u52a8\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "method": "\u8be5\u6846\u67b6\u96c6\u6210Claude 3.7\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u63d0\u793a\u5de5\u7a0b\u548c\u9519\u8bef\u68c0\u67e5\u751f\u6210\u7ed3\u6784\u5316\u7684XML\u683c\u5f0f\u56fe\uff0c\u652f\u6301\u4ece\u81ea\u7136\u8bed\u8a00\u6216\u4ee3\u7801\u751f\u6210\u56fe\uff0c\u5e76\u80fd\u4ece\u56fe\u50cf\u590d\u5236\u56fe\u3002", "result": "\u6a21\u62df\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u56fe\u7684\u521b\u5efa\u65f6\u95f4\uff0c\u5e76\u751f\u6210\u4e86\u5177\u6709\u9ad8\u7ed3\u6784\u4fdd\u771f\u5ea6\u7684\u8f93\u51fa\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86Claude 3.7\u5728\u5904\u7406\u7ed3\u6784\u5316\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765AI\u8f85\u52a9\u56fe\u5e94\u7528\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
