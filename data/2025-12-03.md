<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [CoatFusion: Controllable Material Coating in Images](https://arxiv.org/abs/2512.02143)
*Sagie Levy,Elad Aharoni,Matan Levy,Ariel Shamir,Dani Lischinski*

Main category: cs.GR

TL;DR: 本文提出了Material Coating这一新型图像编辑任务，旨在模拟将薄材料层应用于物体表面，同时保留其底层几何细节。作者构建了大规模合成数据集DataCoat110K，并提出CoatFusion架构，通过结合2D反照率纹理和PBR参数控制实现任务表现。实验表明该方法显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有材料转移方法通常会覆盖物体的固有材质细节，而非保留和增强其几何特征。Material Coating任务的目标是为物体添加薄材料层，同时确保其几何细节的完整性。

Method: 作者构建了大规模合成数据集DataCoat110K，包含11万张图像。并提出CoatFusion架构，利用扩散模型结合2D反照率纹理和PBR参数（如粗糙度、金属度、透射和厚度）实现材料涂层的模拟。

Result: 实验和用户研究表明，CoatFusion能够生成真实且可控的材料涂层效果，显著优于现有的材料编辑和转移方法。

Conclusion: Material Coating任务及其解决方案CoatFusion为图像编辑提供了新的可能性，能够在保留物体几何细节的同时实现高质量的材料涂层效果。

Abstract: We introduce Material Coating, a novel image editing task that simulates applying a thin material layer onto an object while preserving its underlying coarse and fine geometry. Material coating is fundamentally different from existing "material transfer" methods, which are designed to replace an object's intrinsic material, often overwriting fine details. To address this new task, we construct a large-scale synthetic dataset (110K images) of 3D objects with varied, physically-based coatings, named DataCoat110K. We then propose CoatFusion, a novel architecture that enables this task by conditioning a diffusion model on both a 2D albedo texture and granular, PBR-style parametric controls, including roughness, metalness, transmission, and a key thickness parameter. Experiments and user studies show CoatFusion produces realistic, controllable coatings and significantly outperforms existing material editing and transfer methods on this new task.

</details>


### [2] [SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control](https://arxiv.org/abs/2512.03028)
*Yuxuan Mu,Ziyu Zhang,Yi Shi,Minami Matsumoto,Kotaro Imamura,Guy Tevet,Chuan Guo,Michael Taylor,Chang Shu,Pengcheng Xi,Xue Bin Peng*

Main category: cs.GR

TL;DR: 本文提出了一种名为Score-Matching Motion Priors (SMP)的方法，利用预训练的运动扩散模型和分数蒸馏采样（SDS）创建可重用且任务无关的运动先验，避免了现有对抗模仿学习方法需要为每个新控制器重新训练的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于对抗模仿学习的运动先验方法需要为每个新控制器重新训练，限制了其可重用性，并且需要在下游任务训练时保留参考运动数据。SMP旨在通过可重用和任务无关的运动先验解决这一问题。

Method: SMP利用预训练的运动扩散模型和分数蒸馏采样（SDS）技术，构建可独立于任何控制策略或任务预训练的运动先验。训练完成后，这些先验可以作为通用奖励函数用于生成自然行为的下游任务。

Result: 实验表明，SMP能够在大规模数据集上训练通用运动先验，并将其重新用于多种风格特定的先验。此外，SMP还能组合不同风格以合成原始数据集中未包含的新风格，并生成与最先进的对抗模仿学习方法相当的高质量运动。

Conclusion: SMP提供了一种可重用、模块化且任务无关的运动先验方法，能够有效应用于多种控制任务，并通过物理模拟人形角色展示了其有效性。

Abstract: Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at https://youtu.be/ravlZJteS20

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language](https://arxiv.org/abs/2512.02371)
*Yihong Zhang,Derek Gerstmann,Andrew Adams,Maaz Bin Safeer Ahmad*

Main category: cs.PL

TL;DR: 本文展示了如何通过编译器技术将张量加速器应用于图像处理等领域，并显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有张量加速器编程困难，限制了其应用范围，主要用于传统机器学习和科学计算负载。本文旨在扩展其应用领域，如图像处理。

Method: 使用Halide语言和基于等式饱和的张量指令选择器，支持CPU和GPU上的张量加速器，并与现有调度操作（如生产者-消费者融合）协同工作。

Result: 实验表明，图像处理管道（如滤波、重采样和去噪）利用张量加速器后性能显著提升，例如在Nvidia RTX 4070 GPU上实现了6.1倍的加速。

Conclusion: 本文证明了张量加速器在传统领域之外的潜力，并通过编译器技术降低了编程难度，开发者仅需少量代码即可实现高效应用。

Abstract: Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads.
  In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines.
  Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.

</details>


### [4] [Probabilistic energy profiler for statically typed JVM-based programming languages](https://arxiv.org/abs/2512.02738)
*Joel Nyholm,Wojciech Mostowski,Christoph Reichenbach*

Main category: cs.PL

TL;DR: 提出了一种基于贝叶斯统计的新方法，用于预测静态类型JVM编程语言（如Java和Scala）的能耗，通过测量Bytecode模式的能耗并构建统计模型，分析了数据大小、数据类型、操作和设备四个因素的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注CPU能耗的点估计，忽略了其他硬件影响和统计分析的需求，尤其是在静态类型JVM编程语言中。

Method: 通过测量Bytecode模式的能耗，构建基于贝叶斯统计的模型，纳入数据大小、数据类型、操作和设备四个静态和动态因素。

Result: 实验表明，四个因素均显著影响能耗，尤其是在相同型号设备间的差异以及操作和数据类型的能耗差异；模型的预测与实际能耗高度吻合。

Conclusion: 该方法为构建能耗模型提供了新思路，未来可应用于验证工具等场景。

Abstract: Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

</details>


### [5] [Lumos: Let there be Language Model System Certification](https://arxiv.org/abs/2512.02966)
*Isha Chaudhary,Vedaant Jain,Avaljot Singh,Kavya Sachdeva,Sayan Ranu,Gagandeep Singh*

Main category: cs.PL

TL;DR: Lumos是一个用于规范和形式化认证语言模型系统（LMS）行为的首个原则性框架，支持通过图结构和概率编程生成随机提示，并提供混合语义。它能够编码现有LMS规范，并揭示最新视觉语言模型在自动驾驶场景中的严重安全问题。


<details>
  <summary>Details</summary>
Motivation: 为解决语言模型系统（LMS）行为的规范和认证问题，Lumos框架旨在提供一种系统化、可扩展的方法，以应对快速演变的威胁环境。

Method: Lumos基于图的概率编程领域特定语言（DSL），支持生成独立同分布的提示，并与统计认证工具集成，实现LMS行为的严格认证。

Result: 通过Lumos，发现先进视觉语言模型Qwen-VL在雨天右转场景中至少90%的概率会产生不安全响应，揭示了严重风险。此外，Lumos能够轻松修改规范以适配新威胁。

Conclusion: Lumos是首个系统化、基于语言的框架，为LMS行为的规范和认证开辟了新途径，推动了LMS认证的更广泛应用。

Abstract: We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Characterizing Off-Chain Influence Proof Transaction Fee Mechanisms](https://arxiv.org/abs/2512.02354)
*Aadityan Ganesh,Clayton Thomas,S. Matthew Weinberg*

Main category: cs.GT

TL;DR: 本研究分析了离链影响证明（OffCIP）的交易费用机制（TFMs），提出了燃烧规则与分配规则之间的燃烧恒等式，并证明了确定性OffCIP和OnCS TFMs必须是无限制供应且依赖先验的固定价格机制。此外，随机化TFMs在有限供应下也存在满足条件的机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究提出了交易费用机制应满足离链影响证明（OffCIP）和链上简单（OnCS）的特性，但对非加密机制是否能满足这些特性尚未明确。本文旨在填补这一空白。

Method: 通过引入燃烧恒等式，将OffCIP TFMs视为多物品拍卖中的分配规则与定价规则，并分析了确定性和随机化TFMs的可行性。

Result: 确定了确定性OffCIP和OnCS TFMs必须是无限制供应且依赖先验的固定价格机制，而随机化TFMs在有限供应下也能满足条件。

Conclusion: 尽管OffCIP是一个严格要求，但在各种设定下仍能找到满足条件的TFMs家族，特别是在随机化机制中。

Abstract: Roughgarden (2020) initiates the study of Transaction Fee Mechanisms (TFMs), and posits that the on-chain game of a ``good'' TFM should be on-chain simple (OnCS), i.e., incentive compatible for users and the miner. Recent work of Ganesh, Thomas and Weinberg (2024) posits that they should additionally be Off-Chain Influence Proof (OffCIP), which means that the miner cannot achieve any additional revenue by separately conducting an off-chain auction to determine on-chain inclusion. They observe that a cryptographic second-price auction satisfies both properties, but leave open the question of whether other mechanisms (e.g, non-cryptographic) satisfy these properties.
  In this paper, we characterize OffCIP TFMs: They are those satisfying a burn identity relating the burn rule to the allocation rule. In particular, we show that auction is OffCIP if and only if its (induced direct-revelation) allocation rule $\bar{X}(\cdot)$ and burn rule $\bar{B}(\cdot)$ (both of which take as input users' values $v_1, \dots, v_n$) are truthful when viewing $\big(\bar{X}(\cdot), \bar{B}(\cdot)\big)$ as the allocation and pricing rule of a multi-item auction for a single additive buyer with values $\big(\varphi(v_1),\ldots, \varphi(v_n)\big)$ equal to the users' virtual values.
  Building on this burn identity, we characterize deterministic OffCIP and OnCS TFMs that do not use cryptography: They are posted-price mechanisms with specially-tuned burns. As a corollary, we show that such TFMs can only exist with infinite supply and prior-dependence. However, we show that for randomized TFMs, there are additional OnCS and OffCIP auctions that do not use cryptography (even when there is finite supply, under prior-dependence with a bounded prior distribution). Holistically, our results show that while OffCIP is a fairly stringent requirement, families of OffCIP mechanisms can be found for a variety of settings.

</details>


### [7] [Posted Pricing for Online Selection: Limited Price Changes and Risk Sensitivity](https://arxiv.org/abs/2512.02427)
*Hossein Nekouyan,Bo Sun,Raouf Boutaba,Xiaoqi Tan*

Main category: cs.GT

TL;DR: 该论文研究了在线资源分配中限制价格变动次数的定价机制，同时引入风险敏感性指标（CVaR），提出了一种新问题类别kSelection-$(δ,Δ)$，并通过相关定价机制优化尾部性能。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配中，动态定价虽然性能优越，但可能导致价格歧视和操作成本增加。论文旨在解决这些问题，同时关注风险敏感性。

Method: 论文提出了kSelection-$(δ,Δ)$问题类别，并提出一种相关定价机制，使用单一随机种子关联定价，以限制价格变动次数并优化尾部性能。

Result: 分析表明价格变动次数与算法风险敏感性之间存在权衡关系，并在多个特殊情况下给出了最优性结果。

Conclusion: 该研究为在线资源分配中的定价机制提供了新的视角，平衡了价格变动限制与风险敏感性，并在理论和实践中具有重要意义。

Abstract: Posted-price mechanisms (PPMs) are a widely adopted strategy for online resource allocation due to their simplicity, intuitive nature, and incentive compatibility. To manage the uncertainty inherent in online settings, PPMs commonly employ dynamically increasing prices. While this adaptive pricing achieves strong performance, it introduces practical challenges: dynamically changing prices can lead to fairness concerns stemming from price discrimination and incur operational costs associated with frequent updates. This paper addresses these issues by investigating posted pricing constrained by a limited, pre-specified number of allowed price changes, denoted by $Δ$. We further extend this framework by incorporating a second critical dimension: risk sensitivity. Instead of evaluating performance based solely on expectation, we utilize a tail-risk objective-specifically, the Conditional Value at Risk (CVaR) of the total social welfare, parameterized by a risk level $δ\in [0, 1]$.
  We formally introduce a novel problem class kSelection-$(δ,Δ)$ in online adversarial selection and propose a correlated PPM that utilizes a single random seed to correlate posted prices. This correlation scheme is designed to address both the limited price changes and simultaneously enhance the tail performance of the online algorithm. Our subsequent analysis provides performance guarantees under these joint constraints, revealing a clear trade-off between the number of allowed price changes and the algorithm's risk sensitivity. We also establish optimality results for several important special cases of the problem.

</details>


### [8] [Monotone Near-Zero-Sum Games: A Generalization of Convex-Concave Minimax](https://arxiv.org/abs/2512.02690)
*Ruichen Luo,Sebastian U. Stich,Krishnendu Chatterjee*

Main category: cs.GT

TL;DR: 论文提出了一种新的单调近零和博弈类别，填补了单调零和与一般单调博弈之间的梯度复杂度差距，并通过算法改进梯度复杂度。


<details>
  <summary>Details</summary>
Motivation: 在许多应用场景中，零和博弈的假设需要放宽，而一般非零和博弈计算复杂，研究者集中在单调博弈的特殊类上。然而，单调零和与单调一般博弈之间存在梯度复杂度的显著差距。

Method: 定义了一个新的中间类别——单调近零和博弈，并提出了一个新颖算法，将这类博弈转化为一系列零和子问题，改善了梯度复杂度。

Result: 展示了新类别在建模实际博弈场景中的适用性，并从文献中验证了其动机。

Conclusion: 单调近零和博弈类别为解决实际博弈问题提供了新的理论和算法支持。

Abstract: Zero-sum and non-zero-sum (aka general-sum) games are relevant in a wide range of applications. While general non-zero-sum games are computationally hard, researchers focus on the special class of monotone games for gradient-based algorithms. However, there is a substantial gap between the gradient complexity of monotone zero-sum and monotone general-sum games. Moreover, in many practical scenarios of games the zero-sum assumption needs to be relaxed. To address these issues, we define a new intermediate class of monotone near-zero-sum games that contains monotone zero-sum games as a special case. Then, we present a novel algorithm that transforms the near-zero-sum games into a sequence of zero-sum subproblems, improving the gradient-based complexity for the class. Finally, we demonstrate the applicability of this new class to model practical scenarios of games motivated from the literature.

</details>
