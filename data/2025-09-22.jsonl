{"id": "2509.15812", "categories": ["cs.GT", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.15812", "abs": "https://arxiv.org/abs/2509.15812", "authors": ["Piotr Faliszewski", "Krzysztof Sornat", "Stanisław Szufa", "Tomasz Wąs"], "title": "Diversity of Structured Domains via k-Kemeny Scores", "comment": null, "summary": "In the k-Kemeny problem, we are given an ordinal election, i.e., a collection\nof votes ranking the candidates from best to worst, and we seek the smallest\nnumber of swaps of adjacent candidates that ensure that the election has at\nmost k different rankings. We study this problem for a number of structured\ndomains, including the single-peaked, single-crossing, group-separable, and\nEuclidean ones. We obtain two kinds of results: (1) We show that k-Kemeny\nremains intractable under most of these domains, even for k=2, and (2) we use\nk-Kemeny to rank these domains in terms of their diversity."}
{"id": "2509.16075", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2509.16075", "abs": "https://arxiv.org/abs/2509.16075", "authors": ["Matthew Maat"], "title": "Strategy Improvement, the Simplex Algorithm and Lopsidedness", "comment": null, "summary": "The strategy improvement algorithm for mean payoff games and parity games is\na local improvement algorithm, just like the simplex algorithm for linear\nprograms. Their similarity has turned out very useful: many lower bounds on\nrunning time for the simplex method have been created from lower bounds for\nstrategy improvement. However, earlier connections between these algorithms\nrequired constructing an intermediate Markov decision process, which is not\nalways possible. We prove a formal, direct connection between the two\nalgorithms, showing that many variants of strategy improvement for parity and\nmean payoff games are truly an instance of the simplex algorithm, under mild\nnondegeneracy assumptions. As a result of this, we derive some combinatorial\nproperties of the structure of strategy sets of various related games on\ngraphs. In particular, we show a connection to lopsided sets."}
{"id": "2509.16157", "categories": ["cs.GT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16157", "abs": "https://arxiv.org/abs/2509.16157", "authors": ["Bruno Llacer Trotti", "Weizhao Tang", "Rachid El-Azouzi", "Giulia Fanti", "Daniel Sadoc Menasche"], "title": "Strategic Analysis of Just-In-Time Liquidity Provision in Concentrated Liquidity Market Makers", "comment": "Advances in Financial Technologies 2025 (AFT 2025), Pittsburgh, USA", "summary": "Liquidity providers (LPs) are essential figures in the operation of automated\nmarket makers (AMMs); in exchange for transaction fees, LPs lend the liquidity\nthat allows AMMs to operate. While many prior works have studied the incentive\nstructures of LPs in general, we currently lack a principled understanding of a\nspecial class of LPs known as Just-In-Time (JIT) LPs. These are strategic\nagents who momentarily supply liquidity for a single swap, in an attempt to\nextract disproportionately high fees relative to the remaining passive LPs.\nThis paper provides the first formal, transaction-level model of JIT liquidity\nprovision for a widespread class of AMMs known as Concentrated Liquidity Market\nMakers (CLMMs), as seen in Uniswap V3, for instance. We characterize the\nlandscape of price impact and fee allocation in these systems, formulate and\nanalyze a non-linear optimization problem faced by JIT LPs, and prove the\nexistence of an optimal strategy. By fitting our optimal solution for JIT LPs\nto real-world CLMMs, we observe that in liquidity pools (particularly those\nwith risky assets), there is a significant gap between observed and optimal JIT\nbehavior. Existing JIT LPs often fail to account for price impact; doing so, we\nestimate they could increase earnings by up to 69% on average over small time\nwindows. We also show that JIT liquidity, when deployed strategically, can\nimprove market efficiency by reducing slippage for traders, albeit at the cost\nof eroding average passive LP profits by up to 44% per trade."}
{"id": "2509.15236", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15236", "abs": "https://arxiv.org/abs/2509.15236", "authors": ["Shubham Kavane", "Kajol Kulkarni", "Harald Koestler"], "title": "ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows", "comment": null, "summary": "We present ChannelFlow-Tools, a configuration-driven framework that\nstandardizes the end-to-end path from programmatic CAD solid generation to\nML-ready inputs and targets for 3D obstructed channel flows. The toolchain\nintegrates geometry synthesis with feasibility checks, signed distance field\n(SDF) voxelization, automated solver orchestration on HPC (waLBerla LBM), and\nCartesian resampling to co-registered multi-resolution tensors. A single\nHydra/OmegaConf configuration governs all stages, enabling deterministic\nreproduction and controlled ablations. As a case study, we generate 10k+ scenes\nspanning Re=100-15000 with diverse shapes and poses. An end-to-end evaluation\nof storage trade-offs directly from the emitted artifacts, a minimal 3D U-Net\nat 128x32x32, and example surrogate models with dataset size illustrate that\nthe standardized representations support reproducible ML training.\nChannelFlow-Tools turns one-off dataset creation into a reproducible,\nconfigurable pipeline for CFD surrogate modeling."}
{"id": "2509.15834", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.15834", "abs": "https://arxiv.org/abs/2509.15834", "authors": ["Shardul Chiplunkar", "Clément Pit-Claudel"], "title": "Automatic layout of railroad diagrams", "comment": "24 pages (+2 appendix, +3 references); 22 figures (+4 appendix); 3\n  tables", "summary": "Railroad diagrams (also called \"syntax diagrams\") are a common, intuitive\nvisualization of grammars, but limited tooling and a lack of formal attention\nto their layout mostly confines them to hand-drawn documentation. We present\nthe first formal treatment of railroad diagram layout along with a principled,\npractical implementation. We characterize the problem as compiling a *diagram\nlanguage* (specifying conceptual components and how they connect and compose)\nto a *layout language* (specifying basic graphical shapes and their sizes and\npositions). We then implement a compiler that performs *line wrapping* to meet\na target width, as well as vertical *alignment* and horizontal *justification*\nper user-specified policies. We frame line wrapping as an optimization problem,\nwhere we describe principled dimensions of optimality and implement\ncorresponding heuristics. For front-end evaluation, we show that our diagram\nlanguage is well-suited for common applications by describing how regular\nexpressions and Backus-Naur form can be compiled to it. For back-end\nevaluation, we argue that our compiler is practical by comparing its output to\ndiagrams laid out by hand and by other tools."}
{"id": "2509.15246", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15246", "abs": "https://arxiv.org/abs/2509.15246", "authors": ["Nomi Yu", "Md Ferdous Alam", "A. John Hart", "Faez Ahmed"], "title": "GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing", "comment": "9 figures, 15 pages. Accepted and soon published in the ASME Journal\n  of Mechanical Design", "summary": "CAD programs, structured as parametric sequences of commands that compile\ninto precise 3D geometries, are fundamental to accurate and efficient\nengineering design processes. Generating these programs from nonparametric data\nsuch as point clouds and meshes remains a crucial yet challenging task,\ntypically requiring extensive manual intervention. Current deep generative\nmodels aimed at automating CAD generation are significantly limited by\nimbalanced and insufficiently large datasets, particularly those lacking\nrepresentation for complex CAD programs. To address this, we introduce\nGenCAD-3D, a multimodal generative framework utilizing contrastive learning for\naligning latent embeddings between CAD and geometric encoders, combined with\nlatent diffusion models for CAD sequence generation and retrieval.\nAdditionally, we present SynthBal, a synthetic data augmentation strategy\nspecifically designed to balance and expand datasets, notably enhancing\nrepresentation of complex CAD geometries. Our experiments show that SynthBal\nsignificantly boosts reconstruction accuracy, reduces the generation of invalid\nCAD models, and markedly improves performance on high-complexity geometries,\nsurpassing existing benchmarks. These advancements hold substantial\nimplications for streamlining reverse engineering and enhancing automation in\nengineering design. We will publicly release our datasets and code, including a\nset of 51 3D-printed and laser-scanned parts on our project site."}
{"id": "2509.15249", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15249", "abs": "https://arxiv.org/abs/2509.15249", "authors": ["Shen Chen", "Ruiyu Zhao", "Jiale Zhou", "Zongkai Wu", "Jenq-Neng Hwang", "Lei Li"], "title": "Causal Reasoning Elicits Controllable 3D Scene Generation", "comment": null, "summary": "Existing 3D scene generation methods often struggle to model the complex\nlogical dependencies and physical constraints between objects, limiting their\nability to adapt to dynamic and realistic environments. We propose\nCausalStruct, a novel framework that embeds causal reasoning into 3D scene\ngeneration. Utilizing large language models (LLMs), We construct causal graphs\nwhere nodes represent objects and attributes, while edges encode causal\ndependencies and physical constraints. CausalStruct iteratively refines the\nscene layout by enforcing causal order to determine the placement order of\nobjects and applies causal intervention to adjust the spatial configuration\naccording to physics-driven constraints, ensuring consistency with textual\ndescriptions and real-world dynamics. The refined scene causal graph informs\nsubsequent optimization steps, employing a\nProportional-Integral-Derivative(PID) controller to iteratively tune object\nscales and positions. Our method uses text or images to guide object placement\nand layout in 3D scenes, with 3D Gaussian Splatting and Score Distillation\nSampling improving shape accuracy and rendering stability. Extensive\nexperiments show that CausalStruct generates 3D scenes with enhanced logical\ncoherence, realistic spatial interactions, and robust adaptability."}
{"id": "2509.15538", "categories": ["cs.GR", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.15538", "abs": "https://arxiv.org/abs/2509.15538", "authors": ["Daniel Meister", "Takahiro Harada"], "title": "Geometric Integration for Neural Control Variates", "comment": null, "summary": "Control variates are a variance-reduction technique for Monte Carlo\nintegration. The principle involves approximating the integrand by a function\nthat can be analytically integrated, and integrating using the Monte Carlo\nmethod only the residual difference between the integrand and the\napproximation, to obtain an unbiased estimate. Neural networks are universal\napproximators that could potentially be used as a control variate. However, the\nchallenge lies in the analytic integration, which is not possible in general.\nIn this manuscript, we study one of the simplest neural network models, the\nmultilayered perceptron (MLP) with continuous piecewise linear activation\nfunctions, and its possible analytic integration. We propose an integration\nmethod based on integration domain subdivision, employing techniques from\ncomputational geometry to solve this problem in 2D. We demonstrate that an MLP\ncan be used as a control variate in combination with our integration method,\nshowing applications in the light transport simulation."}
{"id": "2509.15562", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.15562", "abs": "https://arxiv.org/abs/2509.15562", "authors": ["Charles Wade", "Devon Beck", "Robert MacCurdy"], "title": "Implicit Modeling for 3D-printed Multi-material Computational Object Design via Python", "comment": null, "summary": "This paper introduces open-source contributions designed to accelerate\nresearch in volumetric multi-material additive manufacturing and metamaterial\ndesign. We present a flexible Python-based API facilitating parametric\nexpression of multi-material gradients, integration with external libraries,\nmulti-material lattice structure design, and interoperability with finite\nelement modeling. Novel implicit multi-material modeling techniques enable\ndetailed spatial grading at multiple scales within lattice structures.\nAdditionally, our framework integrates with finite element analysis, offering\npredictive simulations via adaptive mesh sizing and direct import of simulation\nresults to guide material distributions. Practical case studies illustrate the\nutility of these contributions, including functionally graded lattices,\nalgorithmically generated structures, and simulation-informed designs,\nexemplified by a multi-material bicycle seat optimized for mechanical\nperformance and rider comfort. Finally, we introduce a mesh export strategy\ncompatible with standard slicing software, significantly broadening the\naccessibility and adoption of functionality graded computational design\nmethodologies for multi-material fabrication."}
{"id": "2509.15691", "categories": ["cs.GR", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.15691", "abs": "https://arxiv.org/abs/2509.15691", "authors": ["Paweł Woźny", "Filip Chudy"], "title": "Fast subdivision of Bézier curves", "comment": null, "summary": "It is well-known that a $d$-dimensional polynomial B\\'{e}zier curve of degree\n$n$ can be subdivided into two segments using the famous de Casteljau algorithm\nin $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper,\nwe show that it is possible to do this in $O(dn\\log{n})$ time using the fast\nFourier transform and its inverse. Experiments show that the direct application\nof the new method performs well only for small values of $n$, as the algorithm\nis numerically unstable. However, a slightly modified version -- which still\nhas $O(dn\\log{n})$ computational complexity -- offers good numerical quality,\nwhich is confirmed by numerical experiments conducted in \\textsf{Python}.\nMoreover, the new method has a nice property: if a B\\'{e}zier curve is extended\nby an additional control point, the subdivision can be updated in $O(d)$ time.\n  A similar idea can be applied to speed up the subdivision of rational\nB\\'{e}zier curves and rectangular B\\'{e}zier surfaces, as well as to compute\nthe derivatives of B\\'{e}zier curves more efficiently."}
{"id": "2509.15892", "categories": ["cs.GR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.15892", "abs": "https://arxiv.org/abs/2509.15892", "authors": ["Mohamed Ebbed", "Zorah Lähner"], "title": "MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes", "comment": null, "summary": "Dynamic scene reconstruction from multi-view videos remains a fundamental\nchallenge in computer vision. While recent neural surface reconstruction\nmethods have achieved remarkable results in static 3D reconstruction, extending\nthese approaches with comparable quality for dynamic scenes introduces\nsignificant computational and representational challenges. Existing dynamic\nmethods focus on novel-view synthesis, therefore, their extracted meshes tend\nto be noisy. Even approaches aiming for geometric fidelity often result in too\nsmooth meshes due to the ill-posedness of the problem. We present a novel\nframework for highly detailed dynamic reconstruction that extends the static 3D\nreconstruction method NeuralAngelo to work in dynamic settings. To that end, we\nstart with a high-quality template scene reconstruction from the initial frame\nusing NeuralAngelo, and then jointly optimize deformation fields that track the\ntemplate and refine it based on the temporal sequence. This flexible template\nallows updating the geometry to include changes that cannot be modeled with the\ndeformation field, for instance occluded parts or the changes in the topology.\nWe show superior reconstruction accuracy in comparison to previous\nstate-of-the-art methods on the ActorsHQ dataset."}
{"id": "2509.16064", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.16064", "abs": "https://arxiv.org/abs/2509.16064", "authors": ["Purvi Goel", "Guy Tevet", "C. K. Liu", "Kayvon Fatahalian"], "title": "Generating Detailed Character Motion from Blocking Poses", "comment": null, "summary": "We focus on the problem of using generative diffusion models for the task of\nmotion detailing: converting a rough version of a character animation,\nrepresented by a sparse set of coarsely posed, and imprecisely timed blocking\nposes, into a detailed, natural looking character animation. Current diffusion\nmodels can address the problem of correcting the timing of imprecisely timed\nposes, but we find that no good solution exists for leveraging the diffusion\nprior to enhance a sparse set of blocking poses with additional pose detail. We\novercome this challenge using a simple inference-time trick. At certain\ndiffusion steps, we blend the outputs of an unconditioned diffusion model with\ninput blocking pose constraints using per-blocking-pose tolerance weights, and\npass this result in as the input condition to an pre-existing motion retiming\nmodel. We find this approach works significantly better than existing\napproaches that attempt to add detail by blending model outputs or via\nexpressing blocking pose constraints as guidance. The result is the first\ndiffusion model that can robustly convert blocking-level poses into plausible\ndetailed character animations."}
