<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS](https://arxiv.org/abs/2601.01288)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.GR

TL;DR: PyBatchRender 是一个基于 Panda3D 的高性能批量 3D 渲染 Python 库，专为像素强化学习设计，实现了每秒超过 100 万帧的渲染速度，简化了场景创建流程。


<details>
  <summary>Details</summary>
Motivation: 强化学习的像素输入通常受限于 3D 渲染环境的性能与复杂性，现有工具在速度和易用性之间存在取舍。PyBatchRender 旨在解决这一问题，提供高性能且易用的渲染工具。

Method: PyBatchRender 基于 Panda3D 游戏引擎，通过优化批量渲染技术实现了高达 1000 倍的加速，支持完全用 Python 快速创建自定义场景。

Result: PyBatchRender 在简单场景中实现了每秒超过 100 万帧的渲染速度，速度和灵活性优于现有工具，同时简化了场景设置流程。

Conclusion: PyBatchRender 为强化学习研究者提供了一种高性能、易用的批量 3D 渲染解决方案，显著提升了像素输入训练的效率和可扩展性。

Abstract: Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.

</details>


### [2] [VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data](https://arxiv.org/abs/2601.01361)
*Duosi Jin,Jianqiu Xu,Guidong Zhang*

Main category: cs.GR

TL;DR: VARTS是一款交互式可视化分析工具，用于选择和可视化代表性时间序列，通过减少冗余并保留关键数据模式，提升大规模时间序列分析的视觉清晰度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大规模时间序列可视化常因过多的视觉混乱和冗余模式而难以理解，VARTS旨在解决这一问题。

Method: VARTS基于M4-Greedy框架，整合了M4采样、DTW相似性计算和贪心选择，形成一个统一的代表性序列识别和可视化工作流。

Result: 工具提供了响应式图形界面，支持用户导入数据、执行代表性选择，并通过多视图可视化原始和简化数据，显著提升了分析的清晰度。

Conclusion: VARTS通过去冗余和保留关键模式，有效提升了大规时间序列分析的视觉清晰度和可解释性。

Abstract: Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.

</details>


### [3] [SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes](https://arxiv.org/abs/2601.02072)
*Haato Watanabe,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: 该论文提出了一种从用户草图输入中提取高斯溅射场景中细长物体折线表示的方法。


<details>
  <summary>Details</summary>
Motivation: 高斯溅射缺乏连接信息且包含噪声，难以直接构建折线表示，需要一种稳健的方法来提取细长部分的折线网格。

Method: 通过屏幕空间最短路径分析并结合动态规划，有效地构建了表示细长部分的折线网格。

Result: 在多个实际场景中验证了该方法的有效性。

Conclusion: 该方法能够高效且稳健地从高斯溅射场景中提取细长物体的折线表示，解决了传统方法的挑战。

Abstract: Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.

</details>


### [4] [Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs](https://arxiv.org/abs/2601.02096)
*Peizhuo Li,Sebastian Starke,Yuting Ye,Olga Sorkine-Hornung*

Main category: cs.GR

TL;DR: 利用VR设备的三点轨迹作为舞蹈动作描述符，简化了舞伴间全身动作的建模和合成，通过低维度和高效的MLP网络预测跟随者的轨迹，避免了过拟合并提供了数据高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 标准舞动作多样且交互复杂，传统方法建模和合成挑战大，因此探索使用VR设备的三点轨迹作为简化描述符。

Method: 采用低维的三点轨迹描述符和MLP网络，直接从领导者的三点输入预测跟随者的轨迹，通过自回归过程实现虚拟化身的动作合成。

Result: 该方法在标准舞和小型结构化数据集上表现良好，也能泛化到LaFAN等大规模多样化数据集，展示了确定性和高效性。

Conclusion: 通过三点轨迹的紧凑表示和确定性神经网络，提供了一种计算和数据高效的舞蹈交互建模方法，为沉浸式舞蹈应用开辟了新可能。

Abstract: Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [BALI: Branch-Aware Loop Invariant Inference with Large Language Models](https://arxiv.org/abs/2601.00882)
*Mingxiu Wang,Jiawei Wang,Xiao Cheng*

Main category: cs.PL

TL;DR: BALI是一个结合大语言模型（LLMs）的分支感知框架，用于改进循环不变量的推理和验证。


<details>
  <summary>Details</summary>
Motivation: 循环不变量对于验证迭代算法的正确性至关重要，但推导合适的不变量仍然是复杂且通常需要手动完成的任务。

Method: BALI结合了自动推理和分支感知静态程序分析，先通过SMT验证分支序列级的子句，再将其组合成程序级的不变量。

Result: 初步结果表明BALI在精确性和可扩展性方面有所改进。

Conclusion: 未来方向是实现完全自动化的不变量发现。

Abstract: Loop invariants are fundamental for reasoning about the correctness of iterative algorithms. However, deriving suitable invariants remains a challenging and often manual task, particularly for complex programs. In this paper, we introduce BALI, a branch-aware framework that integrates large language models (LLMs) to enhance the inference and verification of loop invariants. Our approach combines automated reasoning with branch-aware static program analysis to improve both precision and scalability. Specifically, unlike prior LLM-only guess-and-check methods, BALI first verifies branch-sequence-level (path-level) clauses with SMT and then composes them into program-level invariants. We outline its key components, present preliminary results, and discuss future directions toward fully automated invariant discovery.

</details>


### [6] [The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers](https://arxiv.org/abs/2601.02045)
*Shuoming Zhang,Jiacheng Zhao,Qiuchu Yu,Chunwei Xia,Zheng Wang,Xiaobing Feng,Huimin Cui*

Main category: cs.PL

TL;DR: 本文综述了LLM在编译领域的应用，提出了多维分类法，总结了三大优势，并指出了未来发展的挑战与方向。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM如何融入编译领域，为研究人员和实践者提供系统性指导。

Method: 通过多维分类法（设计理念、LLM方法、代码抽象层次和任务类型）分析LLM在编译中的应用。

Result: 总结了LLM带来的三大优势：降低编译器开发门槛、发现新优化策略、拓宽编译器传统范围。

Conclusion: 未来发展需解决正确性和可扩展性问题，开发混合系统是前景最广阔的路径。

Abstract: This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.

</details>


### [7] [Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming](https://arxiv.org/abs/2601.02060)
*Nguyet-Anh H. Lang,Eric Lang,Thanh Le-Cong,Bach Le,Quyet-Thang Huynh*

Main category: cs.PL

TL;DR: FPEval是一个基于FPBench的全新评估框架，用于评估LLM在Haskell、Ocaml和Scala等函数式编程语言中的代码生成能力。研究显示，尽管LLM在函数式编程中的表现随模型进步显著提升，但纯函数式语言的错误率仍较高，且LLM常生成不符合函数式风格的代码。


<details>
  <summary>Details</summary>
Motivation: 函数式编程为开发可靠和安全的软件系统提供了坚实基础，但其陡峭的学习曲线限制了广泛应用。LLM在代码生成方面的进展为降低这一门槛提供了新机会，但目前对LLM在函数式编程语言中的能力评估不足。

Method: 研究引入FPEval框架，基于FPBench的721个编程任务，评估LLM在Haskell、Ocaml和Scala中的代码生成能力，并结合测试验证和静态分析工具评估功能正确性及代码风格。

Result: 结果显示，LLM在函数式编程中的性能随模型进步显著提升，但纯函数式语言的错误率仍高于混合或命令式语言。此外，LLM常生成不符合函数式风格的代码。但LLM可通过反馈部分自修复问题。

Conclusion: LLM在函数式编程中的表现有潜力，但需解决错误率和代码风格问题。未来可通过改进模型或结合反馈机制进一步提升性能。

Abstract: Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.

</details>


### [8] [MLIR-Smith: A Novel Random Program Generator for Evaluating Compiler Pipelines](https://arxiv.org/abs/2601.02218)
*Berke Ates,Filip Dobrosavljević,Theodoros Theodoridis,Zhendong Su*

Main category: cs.PL

TL;DR: 本文提出MLIR-Smith，一种专为测试和评估MLIR编译器优化而设计的随机程序生成器，填补了现有编译测试工具的空白。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏适用于MLIR扩展性的测试工具，现有方法无法满足需求。

Method: 研究团队开发了MLIR-Smith，一种新型随机程序生成器，用于测试MLIR编译器的优化功能。

Result: 通过在MLIR、LLVM、DaCe和DCIR上进行差分测试，发现了多个编译器流水线中的错误。

Conclusion: MLIR-Smith不仅填补了编译器测试领域的空白，还为未来软件测试和质量保障工具的发展奠定了基础。

Abstract: Compilers are essential for the performance and correct execution of software and hold universal relevance across various scientific disciplines. Despite this, there is a notable lack of tools for testing and evaluating them, especially within the adaptable Multi-Level Intermediate Representation (MLIR) context. This paper addresses the need for a tool that can accommodate MLIR's extensibility, a feature not provided by previous methods such as Csmith. Here we introduce MLIR-Smith, a novel random program generator specifically designed to test and evaluate MLIR-based compiler optimizations. We demonstrate the utility of MLIR-Smith by conducting differential testing on MLIR, LLVM, DaCe, and DCIR, which led to the discovery of multiple bugs in these compiler pipelines. The introduction of MLIR-Smith not only fills a void in the realm of compiler testing but also emphasizes the importance of comprehensive testing within these systems. By providing a tool that can generate random MLIR programs, this paper enhances our ability to evaluate and improve compilers and paves the way for future tools, potentially shaping the wider landscape of software testing and quality assurance.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Bad News for Couples: Tight Lower Bounds for Fair Division of Indivisible Items](https://arxiv.org/abs/2601.01012)
*Max Dupré la Tour*

Main category: cs.GT

TL;DR: 研究不可分割物品在夫妻对间的公平分配问题，发现存在某些情况下无法保证做到每个夫妻对所嫉妒的物品数量不超过$Ω(\sqrt{n})$个，这与Manurangsi和Suksompong的上界相匹配。


<details>
  <summary>Details</summary>
Motivation: 探讨不可分割物品在夫妻对间的公平分配问题，特别是在每对夫妻的两个代理人具有不同附加估值的情况下，公平性的上限是否存在。

Method: 通过理论分析，研究了将不可分割物品分配给$n$对夫妻的场景，展示了在某些实例中无法保证嫉妒度不超过$Ω(\sqrt{n})$个物品。

Result: 发现确存在某些实例中嫉妒度无法低于$Ω(\sqrt{n})$个物品的上限，这与之前的上界猜想相吻合。

Conclusion: 研究结果表明，即使是在仅由小群体组成的实例中，之前的上界猜想也可能是紧的，这对公平分配理论具有重要启示。

Abstract: We consider the problem of fairly allocating indivisible goods to couples, where each couple consists of two agents with distinct additive valuations. We show that there exist instances of allocating indivisible items to $n$ couples for which envy-freeness up to $Ω(\sqrt{n})$ items cannot be guaranteed. This closes the gap by matching the upper bound of Manurangsi and Suksompong, which applies to arbitrary instances with $n$ agents in total. This result is somewhat surprising, as that upper bound was conjectured not to be tight for instances consisting only of small groups.

</details>


### [10] [Carroll Mechanisms: Opportunities, Challenges, and Agenda](https://arxiv.org/abs/2601.01013)
*Philip N. Brown,Connor McCormick*

Main category: cs.GT

TL;DR: Carroll Mechanisms旨在通过激励参与者透明化其推理过程，并赋能那些已知能够改变观点的参与者，从而促进自主群体感知和理性决策。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决群体决策中的透明度和灵活性需求，通过市场评分规则和自动化做市商的优势来实现这一目标。

Method: 方法基于网络化的组合LMSR框架，继承了市场评分规则和自动化做市商的理想特性。

Result: 2025年秋季已在此框架的构建上取得显著进展，但仍存在多个重要问题和由此衍生的新问题。

Conclusion: 本文档旨在记录理论基础，明确问题，并提出研究计划以解决这些问题。

Abstract: The purpose of Carroll Mechanisms is to facilitate autonomous group sensemaking and reasoned decisionmaking by incentivizing participants to be transparent about their reasoning process, and to empower participants who are known to be capable of changing their minds. We envision Carroll Mechanisms to be built on top of a networked combinatorial LMSR foundation and thus to inherit the desriable properties of market scoring rules and automated market-makers. While we have made great strides during Fall 2025 in building out this foundation, several significant questions remain and several major new questions have arisen as a result of this work. The purpose of this document is to document the theoretical foundation, frame these questions clearly, and propose a research plan to address the questions.

</details>


### [11] [The Optimal Sample Complexity of Linear Contracts](https://arxiv.org/abs/2601.01496)
*Mikael Møller Høgsgaard*

Main category: cs.GT

TL;DR: 该论文解决了在离线设置下从数据中学习最优线性合同的问题，证明了经验效用最大化（EUM）算法能以最优样本复杂度实现ε-近似最优解。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为未知代理类型分布下的最优线性合同设计提供一个理论上高效的解决方案，以最大化主体的期望效用。

Method: 采用经验效用最大化（EUM）算法，利用线性合同期望奖励非递减的结构特性，构建精细的网络链式分析，实现最优样本复杂度。

Result: 结果表明，EUM算法能以O(ln(1/δ)/ε²)的样本复杂度，以1-δ的概率实现ε-近似最优线性合同，且结果与现有下界匹配。

Conclusion: 论文证明了EUM算法在最优样本复杂度下的高效性，并通过均匀收敛性进一步验证了算法的鲁棒性。

Abstract: In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\ln(1/δ) / \varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\ln(1/δ) / \varepsilon^2)$ sample complexity.

</details>


### [12] [Existence of Optimal Mechanisms for Selling Multiple Goods: An Elementary Proof](https://arxiv.org/abs/2601.01607)
*Sergiu Hart,Noam Nisan*

Main category: cs.GT

TL;DR: 本文提供了一个基础证明，表明在多参数环境下，只要估值分布具有有限期望，就存在收益最大化的机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在多参数环境中证明收益最大化机制的存在性，特别是在估值分布具有有限期望的情况下。

Method: 方法是通过基础证明，不依赖复杂的数学工具，直接展示在多参数设置中收益最大化机制的存在性。

Result: 结果表明，只要估值分布的期望是有限的，就可以构造出收益最大化的机制。

Conclusion: 结论是，在多参数环境中，有限期望的估值分布确保了收益最大化机制的存在性，为机制设计提供了理论支持。

Abstract: We provide an elementary proof that revenue-maximizing mechanisms exist in multi-parameter settings whenever the distribution of valuations has finite expectation.

</details>


### [13] [Metric Distortion with Preference Intensities](https://arxiv.org/abs/2601.02095)
*Mehrad Abbaszadeh,Ali Ansarifar,Mohamad Latifian,Masoud Seddighin*

Main category: cs.GT

TL;DR: 该论文研究了在排名投票中加入强度偏好的新选票格式，设计了一种名为位置评分匹配规则的投票规则，并在度量失真框架下证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统严格排名选票格式可能无法充分表达代理人的偏好强度，因此需要一种更具表达力的选票格式来改进投票规则的效果。

Method: 引入带有强度偏好的排名选票格式，设计位置评分匹配规则，并通过零和游戏找到最优规则。

Result: 新规则能够将失真度降低到3以下，并且忽略强度偏好可能导致较大的失真损失。

Conclusion: 研究表明，加入强度偏好的排名选票格式在度量失真框架下具有显著优势，为投票规则设计提供了新的思路。

Abstract: In voting with ranked ballots, each agent submits a strict ranking of the form $a \succ b \succ c \succ d$ over the alternatives, and the voting rule decides on the winner based on these rankings. Although this ballot format has desirable characteristics, there is a question of whether it is expressive enough for the agents. Kahng, Latifian, and Shah address this issue by adding intensities to the rankings. They introduce the ranking with intensities ballot format, where agents can use both $\succ\!\!\succ$ and $\succ$ in their rankings to express intensive and normal preferences between consecutive alternatives in their rankings. While they focus on analyzing this ballot format in the utilitarian distortion framework, in this work, we look at the potential of using this ballot format from the metric distortion viewpoint. We design a class of voting rules coined Positional Scoring Matching rules, which can be used for different problems in the metric setting, and show that by solving a zero-sum game, we can find the optimal member of this class for our problem. This rule takes intensities into account and achieves a distortion lower than $3$. In addition, by proving a bound on the price of ignoring intensities, we show that we might lose a great deal in terms of distortion by not taking the intensities into account.

</details>
