<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
*Sunjae Yoon,Gwanhyeong Koo,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: 提出了一种基于光流的遮挡鲁棒边缘引导框架（OSF），用于解决绘图风格在3D动画中的退化问题，尤其是遮挡导致的轮廓闪烁和笔画模糊。


<details>
  <summary>Details</summary>
Motivation: 传统3D动画方法在保留艺术家独特绘图风格（如粗糙轮廓和笔画）时，由于遮挡导致的训练与推理姿势差异（“风格化姿势差距”），会出现质量退化问题。

Method: 提出了遮挡鲁棒风格化框架（OSF），利用光流提供遮挡鲁棒的边缘引导，避免边缘信息在遮挡情况下的不准确性，并实现了单次运行，提高了效率。

Result: OSF在遮挡情况下保持一致的风格化效果，相比两阶段方法实现了2.4倍的推理速度提升和2.1倍的内存减少。

Conclusion: OSF有效地解决了绘图风格在动态运动和遮挡下的退化问题，同时显著提升了计算效率和内存使用。

Abstract: 3D animation aims to generate a 3D animated video from an input image and a
target 3D motion sequence. Recent advances in image-to-3D models enable the
creation of animations directly from user-hand drawings. Distinguished from
conventional 3D animation, drawing-based 3D animation is crucial to preserve
artist's unique style properties, such as rough contours and distinct stroke
patterns. However, recent methods still exhibit quality deterioration in style
properties, especially under occlusions caused by overlapping body parts,
leading to contour flickering and stroke blurring. This occurs due to a
`stylization pose gap' between training and inference in stylization networks
designed to preserve drawing styles in drawing-based 3D animation systems. The
stylization pose gap denotes that input target poses used to train the
stylization network are always in occlusion-free poses, while target poses
encountered in an inference include diverse occlusions under dynamic motions.
To this end, we propose Occlusion-robust Stylization Framework (OSF) for
drawing-based 3D animation. We found that while employing object's edge can be
effective input prior for guiding stylization, it becomes notably inaccurate
when occlusions occur at inference. Thus, our proposed OSF provides
occlusion-robust edge guidance for stylization network using optical flow,
ensuring a consistent stylization even under occlusions. Furthermore, OSF
operates in a single run instead of the previous two-stage method, achieving
2.4x faster inference and 2.1x less memory.

</details>


### [2] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
*Kresimir Matkovic,Rainer Splechtna,Denis Gracanin,Helwig Hauser*

Main category: cs.GR

TL;DR: 本文提出了一种名为CrossSet的新方法，用于交互式可视分析两类集合类型数据的联合研究及其相互关系。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要针对单个集合类型数据的分析，缺乏对两类集合类型数据及其相互作用的联合研究需求的支持。

Method: 通过任务分析，提出了一个多尺度的交互式可视化方法，使用分层矩阵布局联合可视化两类集合类型数据。

Result: CrossSet通过紧凑的大规模概览和详细钻取功能，支持多尺度交互式分析，并在多个应用场景中验证了其有效性和高效性。

Conclusion: CrossSet为集合类型数据的联合分析和交互提供了新的可视化方法，有效扩展了现有研究的能力。

Abstract: The interactive visual analysis of set-typed data, i.e., data with attributes
that are of type set, is a rewarding area of research and applications.
Valuable prior work has contributed solutions that enable the study of such
data with individual set-typed dimensions. In this paper, we present CrossSet,
a novel method for the joint study of two set-typed dimensions and their
interplay. Based on a task analysis, we describe a new, multi-scale approach to
the interactive visual exploration and analysis of such data. Two set-typed
data dimensions are jointly visualized using a hierarchical matrix layout,
enabling the analysis of the interactions between two set-typed attributes at
several levels, in addition to the analysis of individual such dimensions.
CrossSet is anchored at a compact, large-scale overview that is complemented by
drill-down opportunities to study the relations between and within the
set-typed dimensions, enabling an interactive visual multi-scale exploration
and analysis of bivariate set-typed data. Such an interactive approach makes it
possible to study single set-typed dimensions in detail, to gain an overview of
the interaction and association between two such dimensions, to refine one of
the dimensions to gain additional details at several levels, and to drill down
to the specific interactions of individual set-elements from the set-typed
dimensions. To demonstrate the effectiveness and efficiency of CrossSet, we
have evaluated the new method in the context of several application scenarios.

</details>


### [3] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
*Nan Xiang,Tianyi Liang,Haiwen Huang,Shiqi Jiang,Hao Huang,Yifei Huang,Liangyu Chen,Changbo Wang,Chenhui Li*

Main category: cs.GR

TL;DR: Sel3DCraft是一个用于文本到3D生成的视觉提示工程系统，通过双分支结构、多视图混合评分和可视化分析套件，显著提升了生成效果和设计师的创造力。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到3D生成技术受限于盲目的试错提示过程，导致结果不可预测。视觉提示工程在文本到图像领域已有进展，但在3D生成中面临多视图一致性和空间理解等独特挑战。

Method: Sel3DCraft引入了双分支结构（检索与生成结合）、多视图混合评分方法（利用MLLM和高层次指标评估3D模型的一致性）以及可视化分析套件（实现直观的缺陷识别与改进）。

Result: 经过广泛测试和用户研究，Sel3DCraft在支持设计师创造力方面超越了其他文本到3D生成系统。

Conclusion: Sel3DCraft成功将无结构的探索转化为引导式的视觉过程，显著提升了3D生成的效果和用户满意度。

Abstract: Text-to-3D (T23D) generation has transformed digital content creation, yet
remains bottlenecked by blind trial-and-error prompting processes that yield
unpredictable results. While visual prompt engineering has advanced in
text-to-image domains, its application to 3D generation presents unique
challenges requiring multi-view consistency evaluation and spatial
understanding. We present Sel3DCraft, a visual prompt engineering system for
T23D that transforms unstructured exploration into a guided visual process. Our
approach introduces three key innovations: a dual-branch structure combining
retrieval and generation for diverse candidate exploration; a multi-view hybrid
scoring approach that leverages MLLMs with innovative high-level metrics to
assess 3D models with human-expert consistency; and a prompt-driven visual
analytics suite that enables intuitive defect identification and refinement.
Extensive testing and user studies demonstrate that Sel3DCraft surpasses other
T23D systems in supporting creativity for designers.

</details>


### [4] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
*Kien T. Pham,Yingqing He,Yazhou Xing,Qifeng Chen,Long Chen*

Main category: cs.GR

TL;DR: SpA2V是一个基于音频驱动的视频生成框架，通过利用音频中的空间和语义线索生成与输入音频在语义和空间上对齐的视频。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注音频的语义信息，而忽略了空间属性（如位置和运动方向），这限制了生成视频的内容和空间准确性。SpA2V通过利用空间听觉线索解决了这一问题。

Method: SpA2V分两阶段生成视频：1) 音频引导的视频规划，利用MLLM从音频中提取空间和语义线索构建视频场景布局（VSL）；2) 布局引导的视频生成，将VSL作为条件输入预训练的扩散模型，无需额外训练即可生成视频。

Result: 实验表明，SpA2V能生成与输入音频在语义和空间上高度对齐的现实视频。

Conclusion: SpA2V通过显式利用空间听觉线索，显著提升了音频驱动视频生成的语义和空间准确性。

Abstract: Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
*Tilman Hinnerichs,Bart Swinkels,Jaap de Jong,Reuben Gardos Reid,Tudor Magirescu,Neil Yorke-Smith,Sebastijan Dumancic*

Main category: cs.PL

TL;DR: 论文提出了一种利用语法约束来缩小程序搜索空间的方法，并引入了BART求解器以高效处理和解决这些约束，显著减少了程序空间枚举时间和范围。


<details>
  <summary>Details</summary>
Motivation: 程序合成的核心挑战在于处理庞大的程序空间。尽管现有的方法利用了组合约束求解器来表达程序语义，但未能有效移除不想要的程序。因此，作者希望通过引入语法约束来进一步优化程序空间。

Method: 作者提出了BART求解器，利用语法约束来建模程序空间，不仅能表达可行的解决方案，还能识别可能有用的程序。这些约束无需执行程序即可检查和传播，适用于任意操作符。

Result: 在程序空间枚举任务中，BART通过语法约束消除了高达99%的程序空间，并显著减少了枚举时间。

Conclusion: 通过语法约束建模程序空间是一种有效的方法，能够显著提升程序合成的效率，BART求解器在这一任务中表现出色。

Abstract: A core challenge in program synthesis is taming the large space of possible
programs. Since program synthesis is essentially a combinatorial search, the
community has sought to leverage powerful combinatorial constraint solvers.
Here, constraints are used to express the program semantics, but not as a
potentially potent tool to remove unwanted programs. Recent inductive logic
programming approaches introduce constraints on the program's syntax to be
synthesized. These syntactic constraints allow for checking and propagating a
constraint without executing the program, and thus for arbitrary operators. In
this work, we leverage syntactic constraints to model program spaces, defining
not just solutions that are feasible, but also ones that are likely useful. To
demonstrate this idea, we introduce BART, a solver that efficiently propagates
and solves these constraints. We evaluate BART on program space enumeration
tasks, finding that the constraints eliminate up to 99 percent of the program
space, and that modeling program spaces significantly reduces enumeration time.

</details>


### [6] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
*Zurabi Kobaladze,Anna Arnania,Tamar Sanikidze*

Main category: cs.PL

TL;DR: 论文综述了程序合成领域五十年来的主要方法，从基于形式逻辑的方法到现代大规模神经模型，分析了五种关键方法的优缺点及其演进。


<details>
  <summary>Details</summary>
Motivation: 程序合成是计算机科学的核心目标之一，本文旨在通过比较文献回顾，探讨该领域的演进及其主要方法的优缺点，推动可靠且可扩展的程序合成方法的发展。

Method: 通过比较五种关键方法：基于逻辑的演绎合成、基于示例的归纳合成、基于草图/模式的合成、基于大规模语言模型的合成以及神经符号混合方法，分析各自的原理、系统和应用。

Result: 研究总结了程序合成从形式化验证工具（如KIDS和Coq）到数据驱动模型（如Codex）的演进，强调了从符号方法到神经符号混合方法的转变及其挑战。

Conclusion: 论文提出了程序合成的未来研究方向，强调了可靠性和可扩展性的重要性，并指出神经符号混合方法是未来发展的关键方向。

Abstract: Program synthesis--the automated generation of executable code from
high-level specifications--has been a central goal of computer science for over
fifty years. This thesis provides a comparative literature review of the main
paradigms that have shaped the field, tracing its evolution from formal logic
based methods to recent advances using large scale neural models. We examine
five key approaches: logic based (deductive) synthesis, inductive (example
based) synthesis, sketch/schema based synthesis, large language model based
synthesis, and neuro-symbolic hybrids. For each, we analyze foundational
principles, notable systems, and practical applications, highlighting trade
offs between correctness guarantees, specification requirements, search
complexity, and expressive power. By reviewing developments from formally
verified synthesis tools such as KIDS and Coq to data driven models generating
probabilistic code from natural language like Codex, we present a comprehensive
narrative of progress and ongoing challenges. This work emphasizes the
transition from symbolic to hybrid neuro-symbolic methods and outlines future
directions for reliable and scalable program synthesis.

</details>


### [7] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
*Matt Kaufmann,Yahya Sohail,Warren A. Hunt Jr*

Main category: cs.PL

TL;DR: 该论文介绍了ACL2中的一个新特性attach-stobj，它允许对抽象stobj进行不同的可执行操作，而无需重新认证相关的书籍或定理。


<details>
  <summary>Details</summary>
Motivation: 为了解决在ACL2中对抽象stobj进行操作时需要进行繁琐的重新认证的问题，论文提出了attach-stobj这一新特性。

Method: 论文通过提供背景信息、用户层面的概述以及一些实现说明，详细介绍了attach-stobj特性。

Result: 论文展示了attach-stobj如何在不需重新认证的情况下支持对抽象stobj的不同操作。

Conclusion: 论文总结认为attach-stobj是一个有效的解决方案，能够提高ACL2中操作的灵活性和效率。

Abstract: This extended abstract outlines an ACL2 feature, attach-stobj, that first
appeared in ACL2 Version 8.6 (October, 2024). This feature supports different
executable operations for a given abstract stobj, without requiring
recertification of the book that introduces that stobj or theorems about it.
The paper provides background as well as a user-level overview and some
implementation notes.

</details>


### [8] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.PL

TL;DR: 利用LLMs自动生成Python类型注释，通过生成-检查-修复流程，相比传统方法更高效且无需额外训练数据。


<details>
  <summary>Details</summary>
Motivation: 手动生成Python类型注释耗时且易错，传统自动化方法因词汇限制、行为过度近似和依赖大量标注数据而受限。

Method: 开发了一种生成-检查-修复流程：LLMs基于语法树生成注释，Mypy验证，错误则反馈以迭代完善。评估了四种LLM变体。

Result: GPT 4.1mini和O3Mini表现最佳，一致性和准确性最高，分别达到88.6%一致性和70.5%精确匹配，平均修复次数少于一次。

Conclusion: 通用和推理优化的LLMs在无需任务特定微调或额外训练的情况下，能有效生成一致的类型注释，性能与传统深度学习方法竞争。

Abstract: Type annotations in Python enhance maintainability and error detection.
However, generating these annotations manually is error prone and requires
extra effort. Traditional automation approaches like static analysis, machine
learning, and deep learning struggle with limited type vocabularies, behavioral
over approximation, and reliance on large labeled datasets. In this work, we
explore the use of LLMs for generating type annotations in Python. We develop a
generate check repair pipeline: the LLM proposes annotations guided by a
Concrete Syntax Tree representation, a static type checker (Mypy) verifies
them, and any errors are fed back for iterative refinement. We evaluate four
LLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini
(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.
We first measure the proportion of code snippets annotated by LLMs for which
MyPy reported no errors (i.e., consistent results): GPT 4oMini achieved
consistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,
and O4Mini each reached approximately 88.6% consistency (around 11.4%
failures). To measure annotation quality, we then compute exact-match and
base-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini
perform the best, achieving up to 70.5% exact match and 79.1% base type
accuracy, requiring under one repair iteration on average. Our results
demonstrate that general-purpose and reasoning optimized LLMs, without any task
specific fine tuning or additional training can be effective in generating
consistent type annotations.They perform competitively with traditional deep
learning techniques which require large labeled dataset for training. While our
work focuses on Python, the pipeline can be extended to other optionally typed
imperative languages like Ruby

</details>


### [9] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
*Erdem Yildirim,Albert Schimpf,Stefan Wehr,Annette Bieniusa*

Main category: cs.PL

TL;DR: 本文构建了一个包含类型变量、基类型、集合论类型和映射类型的集合论模型，并基于集合包含关系定义了语义子类型关系。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为了在Erlang语言中定义映射类型的语义子类型关系，特别是针对参数化映射类型的新颖子类型定义。

Method: 通过构造一个包含多种类型的集合论模型，并利用集合包含关系来定义语义子类型关系。

Result: 成功定义了一个适用于Erlang映射类型的语义子类型关系，特别是针对参数化映射类型的子类型关系。

Conclusion: 本文提出的集合论模型和子类型定义方法为Erlang语言的类型系统提供了新的理论基础，尤其是在处理参数化映射类型时表现出创新性。

Abstract: In this paper we will construct a set-theoretic model of types featuring type
variables, base types, set-theoretic types and map types. Syntax of map types
spans all the map types available in Erlang. The model of types is used to
define a semantic subtyping relation based on set containment. The novelty of
this work is the definition of subtyping over parameteric map types.

</details>


### [10] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 本文通过系统性文献综述，探讨了多范式语言的分类方法及其局限性，并提出了基于数学框架的重构方法。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起对传统分类方法提出了挑战，导致如互操作性缺陷等实际软件工程问题。

Method: 基于74项主要研究的综述，分析了现有分类法的不足，并提出了基于类型理论、范畴理论和统一编程理论（UTP）的原子原语重构方法。

Result: 研究发现现有分类法缺乏概念粒度与统一的形式基础，而重构方法则展示了更强的组合性保证。

Conclusion: 文献反映出从分类转向形式化重构框架的显著趋势，本文为此提出了研究议程。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [Computation of Approximately Stable Committees in Approval-based Elections](https://arxiv.org/abs/2508.00130)
*Drew Gao,Yihang Sun,Jan Vondrák*

Main category: cs.GT

TL;DR: 论文研究了基于批准的委员会选择模型中的近似稳定性准则，证明了在这种设置下可以算法化地计算出一个3.65近似稳定的委员会。


<details>
  <summary>Details</summary>
Motivation: 基于批准的委员会选择模型在社会选择理论中具有重要意义。研究旨在找到一个能够代表选民偏好的委员会，满足近似稳定性条件，以提高选择的公平性和合理性。

Method: 通过寻找Lindahl均衡并从与之相关的强Rayleigh分布中采样，实现了近似稳定性委员会的算法化计算。

Result: 证明了在这种设置下，一个3.65近似稳定的委员会总是存在，并且可以通过算法计算出来。

Conclusion: 该研究为基于批准的委员会选择提供了一种有效的近似稳定性解决方案，并通过算法实现了实际应用。

Abstract: Approval-based committee selection is a model of significant interest in
social choice theory. In this model, we have a set of voters $\mathcal{V}$, a
set of candidates $\mathcal{C}$, and each voter has a set $A_v \subset
\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to
choose $K$ candidates to represent the voters' preferences. We study a
criterion known as \emph{approximate stability}, where a committee is
$\lambda$-approximately-stable if there is no other committee $T$ preferred by
at least $\frac{\lambda|T|}{k} |\mathcal{V}| $ voters. We prove that a
$3.65$-approximately stable committee always exists and can be computed
algorithmically in this setting. Our approach is based on finding a Lindahl
equilibrium and sampling from a strongly Rayleigh distribution associated with
it.

</details>


### [12] [On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings](https://arxiv.org/abs/2508.00349)
*Yuga Kanaya,Kenjiro Takazawa*

Main category: cs.GT

TL;DR: 本文研究了二分图中基于偏好的流行匹配问题，通过两种表征方法的直接连接提供了全面的理解。


<details>
  <summary>Details</summary>
Motivation: 流行匹配在投票系统中类似于孔多塞胜者，但其算法问题是确定匹配的流行性需要指数时间，因此需要更高效的表征方法。

Method: 研究了三类问题：单边偏好、允许偏好中的平局和双边偏好，并通过图结构表征和优化表征的直接连接来分析问题。

Result: 证明了两种表征方法可以相互推导，且不依赖于它们对流行匹配的表征性质，揭示了对偶最优解的新解释。

Conclusion: 研究为流行匹配的表征提供了统一的视角，强化了对图结构表征与优化表征之间关系的理解。

Abstract: Popular matchings provide a model of matching under preferences in which a
solution corresponds to a Condorcet winner in voting systems. In a bipartite
graph in which the vertices have preferences over their neighbours, a matching
is defined to be popular if it does not lose in a majority vote against any
matching. In this paper, we study the following three primary problems: only
the vertices on one side have preferences; a generalization of this problem
allowing ties in the preferences; and the vertices on both sides have
preferences. A principal issue in the algorithmic aspects of popular matchings
is how to determine the popularity of a matching, because it requires
exponential time if the definition is simply applied. In the literature, we
have the following two types of characterizations: a graph-structural
characterization; and an optimization-based characterization described by
maximum-weight matchings. The graph-structural characterizations are
specifically designed for each problem and provide a combinatorial structure of
the popular matchings. The optimization-based characterizations work in the
same manner for all problems, while they do not reveal the structure of the
popular matchings. A main contribution of this paper is to provide a direct
connection of the above two types of characterizations for all of the three
problems. Specifically, we prove that each characterization can be derived from
the other, without relying on the fact that they characterize popular
matchings. Our proofs offer a comprehensive understanding of the equivalence of
the two types of characterizations, and suggest a new interpretation of the
graph-structural characterization in terms of the dual optimal solution for the
maximum-weight matching problem.

</details>


### [13] [Justified Representation: From Hare to Droop](https://arxiv.org/abs/2508.00811)
*Matthew M. Casey,Edith Elkind*

Main category: cs.GT

TL;DR: 该论文系统性研究了在批准投票中使用Droop配额而非Hare配额的比例正义公理及其满足规则，填补了现有研究的空白，并扩展了可满足的比例正义公理范围。


<details>
  <summary>Details</summary>
Motivation: 目前，比例正义公理在批准投票中的研究主要基于Hare配额，而对更严格的Droop配额的研究较少且不全面。论文旨在填补这一空白，并探索Droop配额下的比例正义公理及其规则。

Method: 论文对每个标准JR公理（如JR、PJR、EJR等）提出了Droop配额版本，并找到或修改了相应的投票规则以满足这些公理。部分情况下修改现有规则，部分情况下需要全新设计。

Result: 研究结果显示，Droop配额下的公理更难满足，但成功找到或设计了满足每个公理的投票规则，并进行了实验验证。实验表明，Droop配额下的比例正义公理比Hare配额更为严格。

Conclusion: 论文通过系统性研究Droop配额下的比例正义公理及其规则，扩展了可满足的公理范围，为多赢家投票中的比例正义研究提供了新的视角和工具。

Abstract: The study of proportionality in multiwinner voting with approval ballots has
received much attention in recent years. Typically, proportionality is captured
by variants of the Justified Representation axiom, which say that cohesive
groups of at least $\ell\cdot\frac{n}{k}$ voters (where $n$ is the total number
of voters and $k$ is the desired number of winners) deserve $\ell$
representatives. The quantity $\frac{n}{k}$ is known as the Hare quota in the
social choice literature. Another -- more demanding -- choice of quota is the
Droop quota, defined as $\lfloor\frac{n}{k+1}\rfloor+1$. This quota is often
used in multiwinner voting with ranked ballots: in algorithms such as Single
Transferable Voting, and in proportionality axioms, such as Droop's
Proportionality Criterion. A few authors have considered it in the context of
approval ballots, but the existing analysis is far from comprehensive. The
contribution of our work is a systematic study of JR-style axioms (and voting
rules that satisfy them) defined using the Droop quota instead of the Hare
quota. For each of the standard JR axioms (namely, JR, PJR, EJR, FPJR, FJR,
PJR+ and EJR+), we identify a voting rule that satisfies the Droop version of
this axiom. In some cases, it suffices to consider known rules (modifying the
corresponding Hare proof, sometimes quite substantially), and in other cases it
is necessary to modify the rules from prior work. Each axiom is more difficult
to satisfy when defined using the Droop quota, so our results expand the
frontier of satisfiable proportionality axioms. We complement our theoretical
results with an experimental study, showing that for many probabilistic models
of voter approvals, Droop JR/EJR+ are considerably more demanding than standard
(Hare) JR/EJR+.

</details>
