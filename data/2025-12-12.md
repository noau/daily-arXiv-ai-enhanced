<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 7]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering](https://arxiv.org/abs/2512.10424)
*Hai-Long Qin,Sixian Wang,Guo Lu,Jincheng Dai*

Main category: cs.GR

TL;DR: NeHaD是一种基于哈密顿力学的神经变形场方法，用于动态高斯泼溅，实现了物理上逼真的动态场景渲染。


<details>
  <summary>Details</summary>
Motivation: 当前动态视图合成方法在渲染质量上虽高，但常产生物理不真实的运动，NeHaD通过引入物理先验解决这一问题。

Method: NeHaD利用哈密顿力学建模高斯变形场，结合哈密顿神经网络学习变形物理规律，并引入Boltzmann平衡分解和二阶辛积分等技术。

Result: NeHaD实现了物理上逼真的动态场景渲染，并在渲染质量和效率之间取得平衡。

Conclusion: NeHaD是首个利用哈密顿力学实现神经高斯变形的方法，为动态场景渲染提供了物理真实性和流媒体支持。

Abstract: Representing and rendering dynamic scenes with complex motions remains challenging in computer vision and graphics. Recent dynamic view synthesis methods achieve high-quality rendering but often produce physically implausible motions. We introduce NeHaD, a neural deformation field for dynamic Gaussian Splatting governed by Hamiltonian mechanics. Our key observation is that existing methods using MLPs to predict deformation fields introduce inevitable biases, resulting in unnatural dynamics. By incorporating physics priors, we achieve robust and realistic dynamic scene rendering. Hamiltonian mechanics provides an ideal framework for modeling Gaussian deformation fields due to their shared phase-space structure, where primitives evolve along energy-conserving trajectories. We employ Hamiltonian neural networks to implicitly learn underlying physical laws governing deformation. Meanwhile, we introduce Boltzmann equilibrium decomposition, an energy-aware mechanism that adaptively separates static and dynamic Gaussians based on their spatial-temporal energy states for flexible rendering. To handle real-world dissipation, we employ second-order symplectic integration and local rigidity regularization as physics-informed constraints for robust dynamics modeling. Additionally, we extend NeHaD to adaptive streaming through scale-aware mipmapping and progressive optimization. Extensive experiments demonstrate that NeHaD achieves physically plausible results with a rendering quality-efficiency trade-off. To our knowledge, this is the first exploration leveraging Hamiltonian mechanics for neural Gaussian deformation, enabling physically realistic dynamic scene rendering with streaming capabilities.

</details>


### [2] [DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting](https://arxiv.org/abs/2512.10572)
*Shuyi Zhou,Shengze Zhong,Kenshi Takayama,Takafumi Taketomi,Takeshi Oishi*

Main category: cs.GR

TL;DR: DeMapGS通过结合可变形表面和表面附着的2D高斯斑点，优化了高斯斑点方法的拓扑不一致性和编辑灵活性问题。


<details>
  <summary>Details</summary>
Motivation: 目标是通过统一表示解决先前高斯斑点方法中独立处理点导致的拓扑不一致和编辑灵活性不足的问题。

Method: 采用结构化高斯斑点框架，将斑点锚定到可变形模板网格上，并通过梯度扩散策略和交替2D/3D渲染方案支持稳健优化。

Result: 实验表明DeMapGS实现了最先进的网格重建质量，并支持通过共享参数表面进行高斯斑点的编辑和跨对象操作。

Conclusion: DeMapGS通过统一表示和优化策略，显著提升了高斯斑点方法在重建质量和应用灵活性方面的表现。

Abstract: We propose DeMapGS, a structured Gaussian Splatting framework that jointly optimizes deformable surfaces and surface-attached 2D Gaussian splats. By anchoring splats to a deformable template mesh, our method overcomes topological inconsistencies and enhances editing flexibility, addressing limitations of prior Gaussian Splatting methods that treat points independently. The unified representation in our method supports extraction of high-fidelity diffuse, normal, and displacement maps, enabling the reconstructed mesh to inherit the photorealistic rendering quality of Gaussian Splatting. To support robust optimization, we introduce a gradient diffusion strategy that propagates supervision across the surface, along with an alternating 2D/3D rendering scheme to handle concave regions. Experiments demonstrate that DeMapGS achieves state-of-the-art mesh reconstruction quality and enables downstream applications for Gaussian splats such as editing and cross-object manipulation through a shared parametric surface.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Intrinsically Correct Algorithms and Recursive Coalgebras](https://arxiv.org/abs/2512.10748)
*Cass Alexandru,Henning Urbat,Thorsten Wißmann*

Main category: cs.PL

TL;DR: 递归代数提供了一种优雅的范畴工具，用于建模递归算法并分析其终止性和正确性。本文通过引入一种框架，构造出本质递归的代数，从而简化递归性和终止性的证明。


<details>
  <summary>Details</summary>
Motivation: 现有的递归代数证明通常是非系统的，且难以在证明助手中形式化。本文旨在提供一个统一的框架，直接从类型层面保证递归性。

Method: 本文基于新颖的“良基函子”概念，证明了每个良基函子的代数都是递归的，并通过多个案例研究验证了方法的通用性。

Result: 主要理论结果表明，良基函子的代数天然具有递归性，且传统技术（如排序函数）可纳入这一抽象框架中。案例研究包括快速排序、欧几里得算法和CYK解析。

Conclusion: 本文提出的框架不仅简化了递归代数的构造和证明过程，还成功形式化了一些经典算法，展示了方法的实际有效性。

Abstract: Recursive coalgebras provide an elegant categorical tool for modelling recursive algorithms and analysing their termination and correctness. By considering coalgebras over categories of suitably indexed families, the correctness of the corresponding algorithms follows intrinsically just from the type of the computed maps. However, proving recursivity of the underlying coalgebras is non-trivial, and proofs are typically ad hoc. This layer of complexity impedes the formalization of coalgebraically defined recursive algorithms in proof assistants. We introduce a framework for constructing coalgebras which are intrinsically recursive in the sense that the type of the coalgebra guarantees recursivity from the outset. Our approach is based on the novel concept of a well-founded functor on a category of families indexed by a well-founded relation. We show as our main result that every coalgebra for a well-founded functor is recursive, and demonstrate that well-known techniques for proving recursivity and termination such as ranking functions are subsumed by this abstract setup. We present a number of case studies, including Quicksort, the Euclidian algorithm, and CYK parsing. Both the main theoretical result and selected case studies have been formalized in Cubical Agda.

</details>


### [4] [Towards Cumulative Abstract Semantics via Handlers](https://arxiv.org/abs/2512.10861)
*Cade Lueker,Andrew Fox,Bor-Yuh Evan Chang*

Main category: cs.PL

TL;DR: 本文提出了一种利用作用域效应的累积抽象语义方法，以实现模块化的控制流分析框架。


<details>
  <summary>Details</summary>
Motivation: 现有的通用抽象解释框架在路径敏感性、流敏感性等方面缺乏灵活性，且通常将语法和语义紧密耦合，不利于模块化设计。复杂的模块化数据结构（如单子变换器）虽能提供模块化，但往往难以操作。

Method: 通过将效应分为语法消除和域语义引入处理程序两大类，使用作用域效应在解释器中累积语义片段，从而实现模块化设计。

Result: 结果表明，这种方法能够从一个解释器中创建多种动态评估器和静态分析工具，展示了模块化设计的优势。

Conclusion: 本文证明了利用效应作为工具设计清洁、优雅且模块化的抽象解释框架的潜力。

Abstract: We consider the problem of modularizing control flow in a generic abstract interpretation framework. A generic abstract interpretation framework is not truly flexible if it does not allow interpreting with different path- and flow-sensitivities, by going forwards or backwards, and over- or under-approximately. Most interpreters inherently intertwine syntax and semantics, making the implementation antagonistic to modularity. Current approaches to modular designs require the use of complex data structures (e.g., monad transformers), providing modularity but often proving unwieldy (e.g., lifts). We observe that leveraging scoped effects within an interpreter facilitates the accumulation of semantic fragments against a fixed syntax. In this paper, we define cumulative abstract semantics, illustrating the potential for creating multiple dynamic evaluators and static analyses from one interpreter. This modularity is achieved by grouping effects into two categories: syntax elimination and domain-semantic introduction handlers. Our contribution shows the benefits of using effects as an instrument for designing a clean, elegant, and modular abstract interpretation framework.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [5] [Does Timeboost Reduce MEV-Related Spam? Theory and Evidence from Layer-2 Transactions](https://arxiv.org/abs/2512.10094)
*Brian Zhu*

Main category: cs.GT

TL;DR: 论文研究了Layer-2区块链中的最大可提取价值（MEV）机会导致的垃圾交易问题，并分析了Timeboost机制如何通过拍卖时间戳优势来减少垃圾交易并提升收益。


<details>
  <summary>Details</summary>
Motivation: Layer-2区块链中最大可提取价值（MEV）机会会导致大量相同的交易在短时间内提交，其中大多数会被撤销，浪费区块空间。论文旨在研究Timeboost机制如何解决这一问题。

Method: 论文通过博弈论模型分析用户在Timeboost机制下的交易提交行为，模拟了Timeboost拍卖及其对交易行为的影响。同时，通过收集多个Layer-2网络的mempool数据，实证分析了Timeboost的采用效果。

Result: 研究发现，Timeboost机制在均衡状态下减少了垃圾交易，并将用户支付从撤销成本转移到拍卖竞标上，从而增加了排序器/DAO的收入。实证数据表明，Arbitrum在采用Timeboost后，MEV相关的垃圾交易减少，收入增加。

Conclusion: Timeboost机制能够有效减少Layer-2区块链中的垃圾交易，并提高收入，模型预测与实证结果一致。

Abstract: Maximal extractable value opportunities often induce spam in Layer-2 blockchains: many identical transactions are submitted near simultaneously, most of which revert, wasting blockspace. We study Timeboost, a mechanism on Arbitrum that auctions a timestamp advantage, crucial under first-come first-served sequencing rules. We develop a game-theoretic model in which users choose the number of transaction copies to submit, and extend upon the baseline setting by modeling the Timeboost auction and subsequent transaction submission behavior. We show that Timeboost reduces spam and increases sequencer/DAO revenue in equilibrium relative to the baseline, transferring user payments from revert costs to auction bids. Empirically, we assemble mempool data from multiple Layer-2 networks, measuring spam via identical transactions submitted in narrow time intervals, and conduct an event study around Timeboost adoption on Arbitrum using other L2s as contemporaneous benchmarks. We find a decline in MEV-related spam and an increase in revenue on Arbitrum post-adoption, consistent with model predictions.

</details>


### [6] [Computing Evolutionarily Stable Strategies in Imperfect-Information Games](https://arxiv.org/abs/2512.10279)
*Sam Ganzfried*

Main category: cs.GT

TL;DR: 提出了一种计算对称完美记忆不完全信息扩展形式游戏中进化稳定策略（ESS）的算法，适用于两人游戏并支持多人游戏扩展。


<details>
  <summary>Details</summary>
Motivation: 解决对称不完全信息扩展游戏中进化稳定策略的计算问题，填补现有方法的空白。

Method: 主要针对两人游戏设计算法，可扩展到多人游戏，支持随时停止并返回部分结果。

Result: 在非退化游戏中计算所有ESS，在退化游戏中计算部分ESS，通过实验验证了算法的可扩展性。

Conclusion: 该算法在计算ESS方面具有有效性和扩展性，适用于复杂游戏场景。

Abstract: We present an algorithm for computing evolutionarily stable strategies (ESSs) in symmetric perfect-recall extensive-form games of imperfect information. Our main algorithm is for two-player games, and we describe how it can be extended to multiplayer games. The algorithm is sound and computes all ESSs in nondegenerate games and a subset of them in degenerate games which contain an infinite continuum of symmetric Nash equilibria. The algorithm is anytime and can be stopped early to find one or more ESSs. We experiment on an imperfect-information cancer signaling game as well as random games to demonstrate scalability.

</details>


### [7] [Certifying Concavity and Monotonicity in Games via Sum-of-Squares Hierarchies](https://arxiv.org/abs/2512.10292)
*Vincent Leon,Iosif Sakos,Ryann Sim,Antonios Varvitsiotis*

Main category: cs.GT

TL;DR: 研究团队探讨了多人游戏中凹性和单调性的验证问题，证明这些验证是NP难的，但提出了多项式时间内可求解的层次化算法来近似验证，并证明了几乎所有凹性/单调性游戏可在有限层次内验证。


<details>
  <summary>Details</summary>
Motivation: 凹性和单调性在多人游戏中能提供强保证性（如纳什均衡的存在性和唯一性），但验证这些性质的计算难度未知。

Method: 开发了两种基于平方和规划（SOS）的层次化算法，用于验证游戏的凹性和单调性，并证明这些层次在多项式时间内可求解。

Result: 证明几乎所有凹性/单调性游戏可在有限层次内验证，并提出近似方法（SOS-凹性/单调性游戏）以多项式时间计算最近的近似游戏。

Conclusion: 通过SOS层次化算法和近似方法，为复杂游戏的性质验证提供了可行的多项式时间解决方案。

Abstract: Concavity and its refinements underpin tractability in multiplayer games, where players independently choose actions to maximize their own payoffs which depend on other players' actions. In concave games, where players' strategy sets are compact and convex, and their payoffs are concave in their own actions, strong guarantees follow: Nash equilibria always exist and decentralized algorithms converge to equilibria. If the game is furthermore monotone, an even stronger guarantee holds: Nash equilibria are unique under strictness assumptions. Unfortunately, we show that certifying concavity or monotonicity is NP-hard, already for games where utilities are multivariate polynomials and compact, convex basic semialgebraic strategy sets -- an expressive class that captures extensive-form games with imperfect recall. On the positive side, we develop two hierarchies of sum-of-squares programs that certify concavity and monotonicity of a given game, and each level of the hierarchies can be solved in polynomial time. We show that almost all concave/monotone games are certified at some finite level of the hierarchies. Subsequently, we introduce SOS-concave/monotone games, which globally approximate concave/monotone games, and show that for any given game we can compute the closest SOS-concave/monotone game in polynomial time. Finally, we apply our techniques to canonical examples of imperfect recall extensive-form games.

</details>


### [8] [The $k$-flip Ising game](https://arxiv.org/abs/2512.10389)
*Kovalenko Aleksandr,Andrey Leonidov*

Main category: cs.GT

TL;DR: 文章研究了在完全图上，N个玩家参与的部分并行动态噪声二元选择（Ising）游戏，称为k-flip Ising游戏。分析了游戏的转移矩阵以及策略分布的前两个矩，讨论了从亚稳态和不稳态过渡到稳态的首次命中时间分布的前两个矩。


<details>
  <summary>Details</summary>
Motivation: 研究k-flip Ising游戏的动态行为和统计特性，特别是在不同k值下游戏的状态转移和稳定性，以理解噪声和玩家策略变化对游戏动态的影响。

Method: 通过分析游戏的转移矩阵和策略分布的前两个矩，以及首次命中时间分布的前两个矩，研究了游戏在不同k值下的行为。

Result: 研究发现，亚稳态衰减的矩对k值存在非平凡依赖，特别是在某些k*值处出现极小值，这与k依赖的扩散和恢复力之间的竞争有关。

Conclusion: 研究揭示了k-flip Ising游戏在不同k值下的动力学特性，特别是在亚稳态衰减过程中k值变化对游戏行为的关键影响。

Abstract: A partially parallel dynamical noisy binary choice (Ising) game in discrete time of $N$ players on complete graphs with $k$ players having a possibility of changing their strategies at each time moment called $k$-flip Ising game is considered. Analytical calculation of the transition matrix of game as well as the first two moments of the distribution of $\varphi=N^+/N$, where $N^+$ is a number of players adhering to one of the two strategies, is presented. First two moments of the first hitting time distribution for sample trajectories corresponding to transition from a metastable and unstable states to a stable one are considered. A nontrivial dependence of these moments on $k$ for the decay of a metastable state is discussed. A presence of the minima at certain $k^*$ is attributed to a competition between $k$-dependent diffusion and restoring forces.

</details>


### [9] [LLM-Auction: Generative Auction towards LLM-Native Advertising](https://arxiv.org/abs/2512.10551)
*Chujie Zhao,Qun Hu,Shiping Song,Dagui Chen,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.GT

TL;DR: 本文提出LLM-Auction，一种基于学习的生成拍卖机制，首次将拍卖与LLM生成结合，解决了LLM原生广告中拍卖与生成分离的问题，显著提升了分配效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLM)的快速发展，LLM原生广告成为一种有前景的商业模式。然而，传统拍卖机制无法适应LLM输出的连续性，现有的方法要么忽略外部性，要么需要多次LLM推理，不适合工业场景。

Method: 作者提出了LLM-Auction，通过将分配优化问题建模为LLM输出与机制目标（广告商价值和用户体验）的偏好对齐，并引入IRPO算法交替优化奖励模型和LLM，从而在不增加额外推理成本的情况下建模分配外部性。

Result: 实验表明，LLM-Auction在分配效率和机制特性上显著优于现有基线，同时证明了其分配单调性和连续性，使得简单的首价支付规则具有理想的激励性质。

Conclusion: LLM-Auction为LLM原生广告提供了一种高效且实用的拍卖机制，通过整合拍卖与生成，解决了现有方法的局限性，并为未来研究提供了仿真环境支持。

Abstract: The rapid advancement of large language models (LLMs) necessitates novel monetization strategies, among which LLM-native advertising has emerged as a promising paradigm by naturally integrating advertisement within LLM-generated responses. However, this paradigm fundamentally shifts the auction object from discrete ad slots to the distribution over LLM outputs, posing new challenges for designing auction mechanisms. Existing mechanisms for LLM-native advertising adopt frameworks that decouple auction and generation, which either ignore externalities or require multiple LLM inferences for ad allocation, rendering them impractical for industrial scenarios. To address these challenges, we propose LLM-Auction, which to the best of our knowledge is the first learning-based generative auction mechanism that integrates auction and LLM generation for LLM-native advertising. By formulating the allocation optimization as a preference alignment problem between LLM outputs and the mechanism's objective which reflects both advertisers' expected value and user experience, we introduce Iterative Reward-Preference Optimization (IRPO) algorithm that alternately optimizes the reward model and the LLM. This approach enables the LLM to inherently model allocation externalities without any extra inference cost. We further identify the allocation monotonicity and continuity of LLM-Auction, which allows us to prove that a simple first-price payment rule exhibits favorable incentive properties. Additionally, we design an LLM-as-a-judge simulation environment to facilitate large-scale data construction and enable comprehensive quantitative evaluation of the mechanism's performance. Extensive quantitative and qualitative experiments demonstrate that LLM-Auction significantly outperforms existing baselines in allocation efficiency, while achieving the desired mechanism properties.

</details>


### [10] [Dynamics of multidimensional Simple Clock Auctions](https://arxiv.org/abs/2512.10614)
*Jad Zeroual,Marianne Akian,Aurélien Bechler,Matthieu Chardy,Stéphane Gaubert*

Main category: cs.GT

TL;DR: 研究了简单时钟拍卖（SCA）在有玩家拥有完全信息时的最优投标策略，证明在连续时间模型中存在唯一解，并分析了2017年澳大利亚多频段频谱拍卖的简化版本。


<details>
  <summary>Details</summary>
Motivation: 研究简单时钟拍卖在有玩家拥有完全信息时的行为，以及这种拍卖在连续时间模型中的表现。

Method: 通过连续时间版本的SCA拍卖，使用微分包含和分段常数动态来描述价格变化，并证明在Filippov意义下存在唯一解。

Result: 展示了连续时间模型与离散时间拍卖的极限一致，且价值函数是分段线性的（可能不连续），并通过2017年澳大利亚频谱拍卖的简化版本验证了结果。

Conclusion: 在满足普通替代条件的情况下，玩家最优策略是固定时间段内投标，连续时间模型与离散时间拍卖的极限行为一致。

Abstract: Simple Clock Auctions (SCA) are a mechanism commonly used in spectrum auctions to sell lots of frequency bandwidths. We study such an auction with one player having access to perfect information against straightforward bidders. When the opponents' valuations satisfy the ordinary substitutes condition, we show that it is optimal to bid on a fixed lot overtime. In this setting, we consider a continuous-time version of the SCA auction in which the prices follow a differential inclusion with a piecewise-constant dynamics. We show that there exists a unique solution in the sense of Filippov. This guarantees that the continuous-time model coincides with the limit of the discrete-time auction when price increments tend to zero. Moreover, we show that the value function of this limit auction is piecewise linear (though possibly discontinuous). Finally, we illustrate these results by analyzing a simplified version of the multiband Australian spectrum auction of 2017.

</details>


### [11] [Designing Truthful Mechanisms for Asymptotic Fair Division](https://arxiv.org/abs/2512.10892)
*Jugal Garg,Vishnu V. Narayan,Yuang Eric Shen*

Main category: cs.GT

TL;DR: 研究了在渐近设定下公平分配m个物品给n个代理的问题，提出了一个新的随机机制，该机制在期望上是真实的，可高效实现，并以高概率输出无嫉妒分配。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖于非策略性机制，限制了在战略性代理环境中的适用性，因此需要扩展理论以适用于更广泛的联合价值分布。

Method: 提出了一个新的随机机制，适用于具有相关性、原子性和不等概率的更广泛联合价值分布，并在多项式时间内高效实现。

Result: 证明了在高概率下存在无嫉妒分配，同时机制在期望上是真实的并适用于多种代理和物品类型的扩展场景。

Conclusion: 扩展了公平分配的理论，解决了在更广泛和实际场景中的应用问题，并提供了高效和真实的解决方案。

Abstract: We study the problem of fairly allocating a set of $m$ goods among $n$ agents in the asymptotic setting, where each item's value for each agent is drawn from an underlying joint distribution. Prior works have shown that if this distribution is well-behaved, then an envy-free allocation exists with high probability when $m=Ω(n\log{n})$ [Dickerson et al., 2014]. Under the stronger assumption that item values are independently and identically distributed (i.i.d.) across agents, this requirement improves to $m=Ω(n\log{n}/\log{\log{n}})$, which is tight [Manurangsi and Suksompong, 2021]. However, these results rely on non-strategyproof mechanisms, such as maximum-welfare allocation or the round-robin algorithm, limiting their applicability in settings with strategic agents.
  In this work, we extend the theory to a broader, more realistic class of joint value distributions, allowing for correlations among agents, atomicity, and unequal probabilities of having the highest value for an item. We show that envy-free allocations continue to exist with a high probability when $m=Ω(n\log{n})$. More importantly, we give a new randomized mechanism that is truthful in expectation, efficiently implementable in polynomial time, and outputs envy-free allocations with high probability, answering an open question posed by [Manurangsi and Suksompong, 2017]. We further extend our mechanism to settings with asymptotic weighted fair division and multiple agent types and good types, proving new results in each case.

</details>
