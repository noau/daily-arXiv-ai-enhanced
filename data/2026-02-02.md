<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Screen, Match, and Cache: A Training-Free Causality-Consistent Reference Frame Framework for Human Animation](https://arxiv.org/abs/2601.22160)
*Jianan Wang,Nailei Hei,Li He,Huanzhen Wang,Aoxing Li,Haofen Wang,Yan Wang,Wenqiang Zhang*

Main category: cs.GR

TL;DR: FrameCache是一个免训练的三阶段框架，通过动态选择信息帧、维护参考池和匹配行为特征来提升人类动画的时序一致性和视觉稳定性。


<details>
  <summary>Details</summary>
Motivation: 人类动画的目标是生成长时间序列中时序一致且视觉连贯的视频，但建模长距离依赖关系同时保持帧质量仍具挑战性。研究受人类利用过去观察解释行为的能力启发，提出了FrameCache。

Method: 框架包括三个阶段：Screen（动态选择信息帧）、Cache（维护多样且相关的参考池）和Match（匹配行为特征以指导动画）。

Result: 在标准基准测试中，FrameCache显著提升了时序一致性和视觉稳定性，并能无缝集成到多种基线中。

Conclusion: 尽管效果显著，但FrameCache的有效性依赖于基线的时序推理能力和真实-合成一致性，未来研究应关注兼容性条件和自适应缓存机制。

Abstract: Human animation aims to generate temporally coherent and visually consistent videos over long sequences, yet modeling long-range dependencies while preserving frame quality remains challenging. Inspired by the human ability to leverage past observations for interpreting ongoing actions, we propose FrameCache, a training-free three-stage framework consisting of Screen, Cache, and Match. In the Screen stage, a multi-dimensional, quality-aware mechanism with adaptive thresholds dynamically selects informative frames; the Cache stage maintains a reference pool using a dynamic replacement-hit strategy, preserving both diversity and relevance; and the Match stage extracts behavioral features to perform motion-consistent reference matching for coherent animation guidance. Extensive experiments on standard benchmarks demonstrate that FrameCache consistently improves temporal coherence and visual stability while integrating seamlessly with diverse baselines. Despite these encouraging results, further analysis reveals that its effectiveness depends on baseline temporal reasoning and real-synthetic consistency, motivating future work on compatibility conditions and adaptive cache mechanisms. Code will be made publicly available.

</details>


### [2] [HeatMat: Simulation of City Material Impact on Urban Heat Island Effect](https://arxiv.org/abs/2601.22796)
*Marie Reinbigler,Romain Rouffet,Peter Naylor,Mikolaj Czerkawski,Nikolaos Dionelis,Elisabeth Brunet,Catalin Fetita,Rosalie Martin*

Main category: cs.GR

TL;DR: HeatMat通过开放数据和高分辨率模拟分析城市材料对城市热岛效应的个体影响，结合街景图像和预训练视觉语言模型估计建筑材料，并通过2.5D模拟器实现快速温度预测。


<details>
  <summary>Details</summary>
Motivation: 传统传感器数据在城市热岛效应研究中由于分辨率和时间尺度限制难以提供高精度分析，且建筑材料对热岛效应的影响尚未充分量化。

Method: 利用街景图像和预训练视觉语言模型补充OpenStreetMap数据，生成描述城市垂直结构和材料特性的2D地图，并通过2.5D模拟器模拟热传递。

Result: HeatMat实现了高分辨率的城市热岛效应分析，模拟速度比传统3D模型快20倍。

Conclusion: HeatMat为城市热岛效应的材料影响分析提供了高效、高分辨率的解决方案，可支持城市规划决策。

Abstract: The Urban Heat Island (UHI) effect, defined as a significant increase in temperature in urban environments compared to surrounding areas, is difficult to study in real cities using sensor data (satellites or in-situ stations) due to their coarse spatial and temporal resolution. Among the factors contributing to this effect are the properties of urban materials, which differ from those in rural areas. To analyze their individual impact and to test new material configurations, a high-resolution simulation at the city scale is required. Estimating the current materials used in a city, including those on building facades, is also challenging. We propose HeatMat, an approach to analyze at high resolution the individual impact of urban materials on the UHI effect in a real city, relying only on open data. We estimate building materials using street-view images and a pre-trained vision-language model (VLM) to supplement existing OpenStreetMap data, which describes the 2D geometry and features of buildings. We further encode this information into a set of 2D maps that represent the city's vertical structure and material characteristics. These maps serve as inputs for our 2.5D simulator, which models coupled heat transfers and enables random-access surface temperature estimation at multiple resolutions, reaching an x20 speedup compared to an equivalent simulation in 3D.

</details>


### [3] [Learning to Build Shapes by Extrusion](https://arxiv.org/abs/2601.22858)
*Thor Vestergaard Christiansen,Karran Pandey,Alba Reinders,Karan Singh,Morten Rieger Hannemose,J. Andreas Bærentzen*

Main category: cs.GR

TL;DR: TEE是一种基于文本表示的3D网格构造方法，通过面挤出序列而非多边形列表描述网格，利用大语言模型生成3D网格，支持任意面数和流形网格的生成与编辑。


<details>
  <summary>Details</summary>
Motivation: 传统基于transformer的模型在生成3D网格时存在限制，无法自然支持任意面数和流形网格。TEE通过学习面挤出序列，模仿艺术家构造网格的方法，克服了这些局限性。

Method: 将四边形网格分解为非自交面环，作为构建块，并通过大语言模型学习通过挤出序列重新组装网格的步骤。

Result: 实验表明，TEE支持网格重建、新形状合成以及对现有网格添加新特征。

Conclusion: TEE通过面挤出序列的文本表示，实现了灵活且高效的3D网格生成与编辑，为3D建模提供了新思路。

Abstract: We introduce Text Encoded Extrusion (TEE), a text-based representation that expresses mesh construction as sequences of face extrusions rather than polygon lists, and a method for generating 3D meshes from TEE using a large language model (LLM). By learning extrusion sequences that assemble a mesh, similar to the way artists create meshes, our approach naturally supports arbitrary output face counts and produces manifold meshes by design, in contrast to recent transformer-based models. The learnt extrusion sequences can also be applied to existing meshes - enabling editing in addition to generation. To train our model, we decompose a library of quadrilateral meshes with non-self-intersecting face loops into constituent loops, which can be viewed as their building blocks, and finetune an LLM on the steps for reassembling the meshes by performing a sequence of extrusions. We demonstrate that our representation enables reconstruction, novel shape synthesis, and the addition of new features to existing meshes.

</details>


### [4] [EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing](https://arxiv.org/abs/2601.23065)
*Xijie Yang,Mulin Yu,Changjian Jiang,Kerui Ren,Tao Lu,Jiangmiao Pang,Dahua Lin,Bo Dai,Linning Xu*

Main category: cs.GR

TL;DR: 提出了一种名为EAG-PT的方法，结合2D高斯表示和路径追踪，实现了基于物理的光传输，同时解决了场景编辑中的光照和几何问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于辐射场的方法（如NeRF和3DGS）在室内场景重建中视觉保真度高，但在场景编辑时因光照固定和缺乏显式光传输而失效；而基于网格的物理逆渲染虽能保证正确光传输，但对几何精度要求过高。因此，需要一种既能实现物理光传输又能避免网格局限的方法。

Method: EAG-PT采用2D高斯作为统一的场景表示和传输友好几何代理，明确分离发光和非发光组件，并通过单次反弹优化和高质量多重反弹路径追踪实现重建与渲染的解耦。

Result: 在合成和真实室内场景的实验中，EAG-PT在编辑后产生的渲染效果比辐射场重建更自然且物理一致，同时保留了更精细的几何细节并避免了网格引起的伪影。

Conclusion: EAG-PT为室内设计、XR内容创作和具身AI提供了有前景的方向，结合了物理光传输和高斯表示的优势。

Abstract: Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation. Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using efficient single-bounce optimization and high-quality multi-bounce path tracing after scene editing. Experiments on synthetic and real indoor scenes show that EAG-PT produces more natural and physically consistent renders after editing than radiant scene reconstructions, while preserving finer geometric detail and avoiding mesh-induced artifacts compared to mesh-based inverse path tracing. These results suggest promising directions for future use in interior design, XR content creation, and embodied AI.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Recursive Mutexes in Separation Logic](https://arxiv.org/abs/2601.22557)
*Ke Du,William Mansky,Paolo G. Giarrusso,Gregory Malecha*

Main category: cs.PL

TL;DR: 本文在分离逻辑中开发了递归互斥锁的规范，类似普通互斥锁的保护不变量或原子状态变化方式。


<details>
  <summary>Details</summary>
Motivation: 递归互斥锁在面向对象语言（如C++和Java）中常见，目前对其在分离逻辑中的规范缺乏统一理解。

Method: 采用与普通互斥锁类似的规范方式，通过保护不变量或原子状态变化来描述递归互斥锁的行为。

Result: 提出了适用于递归互斥锁的统一规范，客户端只需确定是否持有锁即可访问锁不变量。

Conclusion: 递归互斥锁可以通过类似于普通互斥锁的规范方式来描述，为面向对象语言中的锁机制提供了理论基础。

Abstract: Mutexes (i.e., locks) are well understood in separation logic, and can be specified in terms of either protecting an invariant or atomically changing the state of the lock. In this abstract, we develop the same styles of specifications for \emph{recursive} mutexes, a common variant of mutexes in object-oriented languages such as C++ and Java. A recursive mutex can be acquired any number of times by the same thread, and our specifications treat all acquires/releases uniformly, with clients only needing to determine whether they hold the mutex when accessing the lock invariant.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Tacit Coordination of Large Language Models](https://arxiv.org/abs/2601.22184)
*Ido Aharon,Emanuele La Malfa,Michael Wooldridge,Sarit Kraus*

Main category: cs.GT

TL;DR: 大型语言模型（LLMs）在隐性协调游戏中显示出卓越的协调能力，尤其在竞争与合作游戏中表现优异，但在涉及数字或文化的常识协调中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在隐性协调游戏中的表现，探索焦点理论在非人类玩家中的应用，填补理论和实践的空白。

Method: 比较和分析LLMs（如Llama、Qwen、GPT-oss）在竞争与合作游戏中的表现，引入无学习策略以提高LLMs之间以及与人类的协调能力。

Result: LLMs在多数情况下表现出色，甚至优于人类，但对涉及数字或文化原型的常识协调任务表现不佳。

Conclusion: 首次在焦点理论框架下对LLMs的隐性协调能力进行了大规模评估，展示了其在某些任务中的潜力与局限性。

Abstract: In tacit coordination games with multiple outcomes, purely rational solution concepts, such as Nash equilibria, provide no guidance for which equilibrium to choose. Shelling's theory explains how, in these settings, humans coordinate by relying on focal points: solutions or outcomes that naturally arise because they stand out in some way as salient or prominent to all players. This work studies Large Language Models (LLMs) as players in tacit coordination games, and addresses how, when, and why focal points emerge. We compare and quantify the coordination capabilities of LLMs in cooperative and competitive games for which human experiments are available. We also introduce several learning-free strategies to improve the coordination of LLMs, with themselves and with humans. On a selection of heterogeneous open-source models, including Llama, Qwen, and GPT-oss, we discover that LLMs have a remarkable capability to coordinate and often outperform humans, yet fail on common-sense coordination that involves numbers or nuanced cultural archetypes. This paper constitutes the first large-scale assessment of LLMs' tacit coordination within the theoretical and psychological framework of focal points.

</details>


### [7] [FAIRFORMER: A transformer architecture for discrete fair division](https://arxiv.org/abs/2601.22346)
*Chris Mascioli,Satyam Goyal,Mithun Chakraborty*

Main category: cs.GT

TL;DR: 介绍FairFormer，一种基于深度神经网络的解决方案，用于在不涉及货币转移的情况下分配不可分割物品，平衡经济效率和基于嫉妒的公平性。该方法在测试时实现了接近最优的福利。


<details>
  <summary>Details</summary>
Motivation: 解决不可分割物品分配问题，同时平衡经济效率和公平性，特别是在不涉及货币转移的情况下。

Method: 提出FairFormer，一种双塔变换器，通过自注意力和交叉注意力机制生成物品分配分布，并通过端到端训练最大化预期对数Nash福利。

Result: FairFormer在测试时表现出色，实现了接近最优的Nash福利和功利福利（96-97%和95-96%），并在质量和运行时优于基线方法。

Conclusion: FairFormer在不依赖求解器监督或公平标签的情况下，成功解决了不可分割物品分配问题，并在效率和公平性上表现出色。

Abstract: We propose a deep neural network-based solution to the problem of allocating indivisible goods under additive subjective valuations without monetary transfers, trading off economic efficiency with envy-based fairness. We introduce FairFormer, an amortized, permutation-equivariant two-tower transformer that encodes items and agents as unordered token sets, applies self-attention within each set, and uses item-to-agent cross-attention to produce per-item assignment distributions in a single forward pass. FairFormer is trained end-to-end to maximize expected log-Nash welfare on sampled instances, requiring no solver supervision, unrolled allocation procedures, or fairness labels. At test time, we discretize by row-wise $\arg\max$ and apply a lightweight post-processing routine that transfers items to eliminate violations of envy-freeness up to one item while prioritizing improvements in Nash welfare. Our approach generalizes beyond its training regime and achieves near-optimal welfare (e.g., for uniformly sampled valuations, $96$--$97\%$ for Nash welfare; $95$--$96\%$ for utilitarian welfare), outperforming strong baselines in solution quality and/or runtime.

</details>


### [8] [Dynamic Welfare-Maximizing Pooled Testing](https://arxiv.org/abs/2601.22419)
*Nicholas Lopez,Francisco Marmolejo-Cossío,Jose Roberto Tello Ayala,David C. Parkes*

Main category: cs.GT

TL;DR: 研究动态福利最大化池测试策略，旨在通过顺序测试分配最大化社会福祉，结果显示动态测试在低预算情况下显著优于静态策略。


<details>
  <summary>Details</summary>
Motivation: 探索动态和福利最大化的池测试策略，以解决传统静态测试分配的不足，提高公共健康筛查的效率和效果。

Method: 采用动态优化方法，包括贪婪启发式、混合整数规划松弛和学习策略，通过合成实验评估其性能和权衡。

Result: 动态测试在低预算情况下比静态基线显著提升社会福利，贪婪策略表现优异且计算高效。

Conclusion: 动态测试在公共健康筛查中有重要意义，贪婪策略实用且高效，学习策略未能显著改进启发式方法。

Abstract: Pooled testing is a common strategy for public health disease screening under limited testing resources, allowing multiple biological samples to be tested together with the resources of a single test, at the cost of reduced individual resolution. While dynamic and adaptive strategies have been extensively studied in the classical pooled testing literature, where the goal is to minimize the number of tests required for full diagnosis of a given population, much of the existing work on welfare-maximizing pooled testing adopts static formulations in which all tests are assigned in advance. In this paper, we study dynamic welfare-maximizing pooled testing strategies in which a limited number of tests are performed sequentially to maximize social welfare, defined as the aggregate utility of individuals who are confirmed to be healthy. We formally define the dynamic problem and study algorithmic approaches for sequential test assignment. Because exact dynamic optimization is computationally infeasible beyond small instances, we evaluate a range of strategies (including exact optimization baselines, greedy heuristics, mixed-integer programming relaxations, and learning-based policies) and empirically characterize their performance and tradeoffs using synthetic experiments. Our results show that dynamic testing can yield substantial welfare improvements over static baselines in low-budget regimes. We find that much of the benefit of dynamic testing is captured by simple greedy policies, which substantially outperform static approaches while remaining computationally efficient. Learning-based methods are included as flexible baselines, but in our experiments they do not reliably improve upon these heuristics. Overall, this work provides a principled computational perspective on dynamic pooled testing and clarifies when dynamic assignment meaningfully improves welfare in public health screening.

</details>


### [9] [Do AI Overviews Benefit Search Engines? An Ecosystem Perspective](https://arxiv.org/abs/2601.22493)
*Yihang Wu,Jiajun Tang,Jinfei Liu,Haifeng Xu,Fan Yao*

Main category: cs.GT

TL;DR: 论文提出了一种博弈论模型和两种激励机制（引用和补偿），以解决AI概述在搜索引擎中对内容创作者流量和长期利润的负面影响。


<details>
  <summary>Details</summary>
Motivation: AI概述虽提升用户体验，但分流内容创作者流量，影响高质量内容创作和搜索引擎长期利润。需要解决这一问题。

Method: 提出博弈论模型，分析创作者竞争行为，并设计了两种激励机制：引用机制和补偿机制。

Result: 实验表明，尽管AI概述损害长期利润，但提出的干预机制能提升现实场景中的长期利润。

Conclusion: 研究为AI增强的搜索生态系统提供了可持续的发展方向，强调激励机制的重要性。

Abstract: The integration of AI Overviews into search engines enhances user experience but diverts traffic from content creators, potentially discouraging high-quality content creation and causing user attrition that undermines long-term search engine profit. To address this issue, we propose a game-theoretic model of creator competition with costly effort, characterize equilibrium behavior, and design two incentive mechanisms: a citation mechanism that references sources within an AI Overview, and a compensation mechanism that offers monetary rewards to creators. For both cases, we provide structural insights and near-optimal profit-maximizing mechanisms. Evaluations on real click data show that although AI Overviews harm long-term search engine profit, interventions based on our proposed mechanisms can increase long-term profit across a range of realistic scenarios, pointing toward a more sustainable trajectory for AI-enhanced search ecosystems.

</details>


### [10] [Greedy Routing Reachability Games](https://arxiv.org/abs/2601.23126)
*Pascal Lenzner,Paraskevi Machaira*

Main category: cs.GT

TL;DR: 论文研究了自治代理在网络中形成支持贪心路由的拓扑结构的博弈论模型，分析了有向和无向边两种情况的性质和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现代网络中自治实体各自为政，需要依赖本地路由协议（如贪心路由）进行数据传输。研究目标是理解贪心路由网络如何在缺乏全局信息的情况下形成。

Method: 提出了一个博弈论模型，代理在度量空间中形成网络拓扑，尽量减少连接数同时确保贪心路由可行。研究了有向和无向边的两种模型变体。

Result: 有向边模型中，均衡存在且总成本最优，但在欧几里得度量中计算最优策略是NP难的；无向边模型中，价格无政府状态在1.75到1.8之间，高维空间中低于2。

Conclusion: 贪心路由网络在自治代理博弈中可形成高效均衡，尤其是无向边模型在现实2D空间中表现优于Delaunay三角剖分。

Abstract: Today's networks consist of many autonomous entities that follow their own objectives, i.e., smart devices or parts of large AI systems, that are interconnected. Given the size and complexity of most communication networks, each entity typically only has a local view and thus must rely on a local routing protocol for sending and forwarding packets. A common solution for this is greedy routing, where packets are locally forwarded to a neighbor in the network that is closer to the packet's destination.
  In this paper we investigate a game-theoretic model with autonomous agents that aim at forming a network where greedy routing is enabled. The agents are positioned in a metric space and each agent tries to establish as few links as possible, while maintaining that it can reach every other agent via greedy routing. Thus, this model captures how greedy routing networks are formed without any assumption on the distribution of the agents or the specific employed greedy routing protocol. Hence, it distills the essence that makes greedy routing work.
  We study two variants of the model: with directed edges or with undirected edges. For the former, we show that equilibria exist, have optimal total cost, and that in Euclidean metrics they can be found efficiently. However, even for this simple setting computing optimal strategies is NP-hard. For the much more challenging setting with undirected edges, we show for the realistic setting with agents in 2D Euclidean space that the price of anarchy is between 1.75 and 1.8 and for higher dimensions it is less than 2. Also, we show that best response dynamics may cycle, but that in Euclidean space almost optimal approximate equilibria can be computed in polynomial time. Moreover, for 2D Euclidean space, these approximate equilibria outperform the well-known Delaunay triangulation.

</details>


### [11] [(Doubly) Exponential Lower Bounds for Follow the Regularized Leader in Potential Games](https://arxiv.org/abs/2601.23248)
*Ioannis Anagnostides,Ioannis Panageas,Nikolas Patris,Tuomas Sandholm*

Main category: cs.GT

TL;DR: FTRL算法在两人势博弈中可能需指数时间收敛到纳什均衡，但通过懒散交替执行可获得指数上界。虚构博弈在多玩家势博弈中需双重指数时间收敛。


<details>
  <summary>Details</summary>
Motivation: 尽管FTRL算法在在线优化中被广泛研究，但其在约束优化（尤其是势博弈）中的收敛行为仍未被充分理解。

Method: 分析了FTRL在两人势博弈中的收敛时间，并通过懒散交替执行方式研究了其收敛行为。

Result: 发现FTRL在两人势博弈中需指数时间收敛到纳什均衡，懒散交替执行可获得指数上界；虚构博弈在多玩家势博弈中收敛时间更慢。

Conclusion: 研究揭示了FTRL在势博弈中的收敛复杂性，为相关学习算法的设计提供了重要启示。

Abstract: Follow the regularized leader FTRL is the premier algorithm for online optimization. However, despite decades of research on its convergence in constrained optimization -- and potential games in particular -- its behavior remained hitherto poorly understood. In this paper, we establish that FTRL can take exponential time to converge to a Nash equilibrium in two-player potential games for any (permutation-invariant) regularizer and potentially vanishing learning rate. By known equivalences, this translates to an exponential lower bound for certain mirror descent counterparts, most notably multiplicative weights update. On the positive side, we establish the potential property for FTRL and obtain an exponential upper bound $\exp(O_ε(1/ε^2))$ for any no-regret dynamics executed in a lazy, alternating fashion, matching our lower bound up to factors in the exponent. Finally, in multi-player potential games, we show that fictitious play -- the extreme version of FTRL -- can take doubly exponential time to reach a Nash equilibrium. This constitutes an exponentially stronger lower bound for the foundational learning algorithm in games.

</details>
