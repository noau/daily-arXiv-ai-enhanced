{"id": "2507.12493", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.12493", "abs": "https://arxiv.org/abs/2507.12493", "authors": ["Seyed Rasoul Hosseini", "Omid Ahmadieh", "Jeremy Dawson", "Nasser Nasrabadi"], "title": "WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation", "comment": null, "summary": "Biometric face morphing poses a critical challenge to identity verification\nsystems, undermining their security and robustness. To address this issue, we\npropose WaFusion, a novel framework combining wavelet decomposition and\ndiffusion models to generate high-quality, realistic morphed face images\nefficiently. WaFusion leverages the structural details captured by wavelet\ntransforms and the generative capabilities of diffusion models, producing face\nmorphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and\nWVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art\nmethods, producing high-resolution morphs with fewer artifacts. Our framework\nexcels across key biometric metrics, including the Attack Presentation\nClassification Error Rate (APCER), Bona Fide Presentation Classification Error\nRate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in\nbiometric morph generation, offering a cutting-edge and efficient solution to\nenhance biometric security systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u6ce2\u5206\u89e3\u548c\u6269\u6563\u6a21\u578b\u7684WaFusion\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u903c\u771f\u7684\u4eba\u8138\u878d\u5408\u56fe\u50cf\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4f2a\u5f71\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u751f\u7269\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u4eba\u8138\u878d\u5408\u6280\u672f\u5bf9\u8eab\u4efd\u9a8c\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u6784\u6210\u4e86\u4e25\u91cd\u5a01\u80c1\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "WaFusion\u6846\u67b6\u7ed3\u5408\u4e86\u5c0f\u6ce2\u5206\u89e3\u548c\u6269\u6563\u6a21\u578b\uff0c\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u6355\u6349\u7ed3\u6784\u7ec6\u8282\u548c\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u4eba\u8138\u878d\u5408\u56fe\u50cf\u751f\u6210\u3002", "result": "\u5728FERET\u3001FRGC\u3001FRLL\u548cWVU Twin\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cWaFusion\u5728\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u878d\u5408\u56fe\u50cf\u65f6\u4f2a\u5f71\u66f4\u5c11\uff0c\u5e76\u5728APCER\u3001BPCER\u548cEER\u7b49\u5173\u952e\u751f\u7269\u8bc6\u522b\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "WaFusion\u4e3a\u751f\u7269\u8bc6\u522b\u878d\u5408\u56fe\u50cf\u7684\u751f\u6210\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5148\u8fdb\u7684\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u7269\u8bc6\u522b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.12498", "categories": ["cs.GR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.12498", "abs": "https://arxiv.org/abs/2507.12498", "authors": ["Beizhen Zhao", "Yifan Zhou", "Sicheng Yu", "Zijian Wang", "Hao Wang"], "title": "Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition", "comment": "9 pages", "summary": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,\nwhich effectively balances rendering quality, efficiency, and speed. However,\nexisting 3DGS approaches usually generate plausible outputs and face\nsignificant challenges in complex scene reconstruction, manifesting as\nincomplete holistic structural outlines and unclear local lighting effects. To\naddress these issues simultaneously, we propose a novel decoupled optimization\nframework, which integrates wavelet decomposition into 3D Gaussian Splatting\nand 2D sampling. Technically, through 3D wavelet decomposition, our approach\ndivides point clouds into high-frequency and low-frequency components, enabling\ntargeted optimization for each. The low-frequency component captures global\nstructural outlines and manages the distribution of Gaussians through\nvoxelization. In contrast, the high-frequency component restores intricate\ngeometric and textural details while incorporating a relight module to mitigate\nlighting artifacts and enhance photorealistic rendering. Additionally, a 2D\nwavelet decomposition is applied to the training images, simulating radiance\nvariations. This provides critical guidance for high-frequency detail\nreconstruction, ensuring seamless integration of details with the global\nstructure. Extensive experiments on challenging datasets demonstrate our method\nachieves state-of-the-art performance across various metrics, surpassing\nexisting approaches and advancing the field of 3D scene reconstruction.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u5206\u89e3\u7684\u89e3\u8026\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53473D\u9ad8\u65af\u55b7\u5c04\u6280\u672f\u5728\u590d\u6742\u573a\u666f\u91cd\u5efa\u4e2d\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u7ed3\u6784\u4e0d\u5b8c\u6574\u548c\u5c40\u90e8\u5149\u7167\u6548\u679c\u4e0d\u6e05\u6670\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u67093D\u9ad8\u65af\u55b7\u5c04\u6280\u672f\u5728\u5904\u7406\u590d\u6742\u573a\u666f\u65f6\uff0c\u5e38\u51fa\u73b0\u7ed3\u6784\u8f6e\u5ed3\u4e0d\u5b8c\u6574\u548c\u5c40\u90e8\u5149\u7167\u6548\u679c\u4e0d\u6e05\u6670\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528\u6548\u679c\u3002", "method": "\u901a\u8fc73D\u5c0f\u6ce2\u5206\u89e3\u5c06\u70b9\u4e91\u5206\u4e3a\u9ad8\u9891\u548c\u4f4e\u9891\u90e8\u5206\uff0c\u5206\u522b\u4f18\u5316\uff1a\u4f4e\u9891\u90e8\u5206\u8d1f\u8d23\u5168\u5c40\u7ed3\u6784\u548c\u5927\u8303\u56f4\u5206\u5e03\uff0c\u9ad8\u9891\u90e8\u5206\u6062\u590d\u7ec6\u8282\u5e76\u5f15\u5165\u5149\u7167\u6a21\u5757\uff1b\u540c\u65f6\uff0c\u5bf9\u8bad\u7ec3\u56fe\u50cf\u8fdb\u884c2D\u5c0f\u6ce2\u5206\u89e3\u4ee5\u6a21\u62df\u8f90\u5c04\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u573a\u666f\u91cd\u5efa\u4e0e\u6e32\u67d3\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u573a\u666f\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u4e3a3D\u573a\u666f\u91cd\u5efa\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u601d\u8def\u3002"}}
{"id": "2507.12600", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.12600", "abs": "https://arxiv.org/abs/2507.12600", "authors": ["Joy Xiaoji Zhang", "Jingsen Zhu", "Hanyu Chen", "Steve Marschner"], "title": "HairFormer: Transformer-Based Dynamic Neural Hair Simulation", "comment": null, "summary": "Simulating hair dynamics that generalize across arbitrary hairstyles, body\nshapes, and motions is a critical challenge. Our novel two-stage neural\nsolution is the first to leverage Transformer-based architectures for such a\nbroad generalization. We propose a Transformer-powered static network that\npredicts static draped shapes for any hairstyle, effectively resolving\nhair-body penetrations and preserving hair fidelity. Subsequently, a dynamic\nnetwork with a novel cross-attention mechanism fuses static hair features with\nkinematic input to generate expressive dynamics and complex secondary motions.\nThis dynamic network also allows for efficient fine-tuning of challenging\nmotion sequences, such as abrupt head movements. Our method offers real-time\ninference for both static single-frame drapes and dynamic drapes over pose\nsequences. Our method demonstrates high-fidelity and generalizable dynamic hair\nacross various styles, guided by physics-informed losses, and can resolve\npenetrations even for complex, unseen long hairstyles, highlighting its broad\ngeneralization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u795e\u7ecf\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528Transformer\u67b6\u6784\u5728\u4efb\u610f\u53d1\u578b\u3001\u4f53\u578b\u548c\u8fd0\u52a8\u4e2d\u8fdb\u884c\u5934\u53d1\u52a8\u6001\u6a21\u62df\uff0c\u89e3\u51b3\u4e86\u5934\u53d1\u4e0e\u8eab\u4f53\u7684\u7a7f\u900f\u95ee\u9898\u5e76\u4fdd\u6301\u4e86\u5934\u53d1\u7684\u4fdd\u771f\u5ea6\u3002", "motivation": "\u6a21\u62df\u5934\u53d1\u52a8\u6001\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u8de8\u4efb\u610f\u53d1\u578b\u3001\u4f53\u578b\u548c\u8fd0\u52a8\u8fdb\u884c\u6cdb\u5316\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u5305\u62ec\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u9759\u6001\u7f51\u7edc\u7528\u4e8e\u9884\u6d4b\u9759\u6001\u53d1\u578b\uff0c\u4ee5\u53ca\u4e00\u4e2a\u52a8\u6001\u7f51\u7edc\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u9759\u6001\u7279\u5f81\u548c\u8fd0\u52a8\u8f93\u5165\u4ee5\u751f\u6210\u52a8\u6001\u6548\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u65f6\u63a8\u7406\u9759\u6001\u548c\u52a8\u6001\u53d1\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u9ad8\u4fdd\u771f\u5ea6\u548c\u5e7f\u6cdb\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u957f\u53d1\u578b\u4e2d\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7269\u7406\u5b66\u635f\u5931\u51fd\u6570\u9a71\u52a8\u7684\u4e24\u9636\u6bb5\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u5934\u53d1\u52a8\u6001\u6a21\u62df\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u573a\u666f\u4e2d\u7684\u7a7f\u900f\u95ee\u9898\u3002"}}
{"id": "2507.12667", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.12667", "abs": "https://arxiv.org/abs/2507.12667", "authors": ["Siyuan Yao", "Chaoli Wang"], "title": "VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians", "comment": null, "summary": "Visualization of large-scale time-dependent simulation data is crucial for\ndomain scientists to analyze complex phenomena, but it demands significant I/O\nbandwidth, storage, and computational resources. To enable effective\nvisualization on local, low-end machines, recent advances in view synthesis\ntechniques, such as neural radiance fields, utilize neural networks to generate\nnovel visualizations for volumetric scenes. However, these methods focus on\nreconstruction quality rather than facilitating interactive visualization\nexploration, such as feature extraction and tracking. We introduce VolSegGS, a\nnovel Gaussian splatting framework that supports interactive segmentation and\ntracking in dynamic volumetric scenes for exploratory visualization and\nanalysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic\nvolumetric scene, allowing for real-time novel view synthesis. For accurate\nsegmentation, we leverage the view-independent colors of Gaussians for\ncoarse-level segmentation and refine the results with an affinity field network\nfor fine-level segmentation. Additionally, by embedding segmentation results\nwithin the Gaussians, we ensure that their deformation enables continuous\ntracking of segmented regions over time. We demonstrate the effectiveness of\nVolSegGS with several time-varying datasets and compare our solutions against\nstate-of-the-art methods. With the ability to interact with a dynamic scene in\nreal time and provide flexible segmentation and tracking capabilities, VolSegGS\noffers a powerful solution under low computational demands. This framework\nunlocks exciting new possibilities for time-varying volumetric data analysis\nand visualization.", "AI": {"tldr": "VolSegGS\u662f\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u55b7\u6d12\u7684\u65b0\u6846\u67b6\uff0c\u652f\u6301\u52a8\u6001\u4f53\u79ef\u573a\u666f\u4e2d\u7684\u4ea4\u4e92\u5f0f\u5206\u5272\u548c\u8ddf\u8e2a\uff0c\u4e3a\u63a2\u7d22\u6027\u53ef\u89c6\u5316\u548c\u5206\u6790\u63d0\u4f9b\u5b9e\u65f6\u65b0\u89c6\u89d2\u5408\u6210\u80fd\u529b\u3002", "motivation": "\u5927\u89c4\u6a21\u65f6\u53d8\u6a21\u62df\u6570\u636e\u7684\u53ef\u89c6\u5316\u5bf9\u9886\u57df\u79d1\u5b66\u5bb6\u5206\u6790\u590d\u6742\u73b0\u8c61\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u63a2\u7d22\uff08\u5982\u7279\u5f81\u63d0\u53d6\u548c\u8ddf\u8e2a\uff09\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u53ef\u53d8\u5f623D\u9ad8\u65af\u6a21\u578b\u8868\u793a\u52a8\u6001\u4f53\u79ef\u573a\u666f\uff0c\u5229\u7528\u9ad8\u65af\u89c6\u56fe\u65e0\u5173\u989c\u8272\u8fdb\u884c\u7c97\u5206\u5272\uff0c\u5e76\u901a\u8fc7\u4eb2\u548c\u529b\u573a\u7f51\u7edc\u7ec6\u5316\u7ed3\u679c\uff0c\u540c\u65f6\u5c06\u5206\u5272\u7ed3\u679c\u5d4c\u5165\u9ad8\u65af\u4e2d\u4ee5\u5b9e\u73b0\u8fde\u7eed\u8ddf\u8e2a\u3002", "result": "VolSegGS\u5728\u591a\u4e2a\u65f6\u53d8\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6709\u6548\u6027\uff0c\u4e0e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5177\u6709\u5b9e\u65f6\u4ea4\u4e92\u548c\u7075\u6d3b\u5206\u5272\u8ddf\u8e2a\u80fd\u529b\uff0c\u8ba1\u7b97\u9700\u6c42\u4f4e\u3002", "conclusion": "VolSegGS\u4e3a\u65f6\u53d8\u4f53\u79ef\u6570\u636e\u7684\u5206\u6790\u548c\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u542f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.12733", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.12733", "abs": "https://arxiv.org/abs/2507.12733", "authors": ["Houshuang Chen", "Yaonan Jin", "Pinyan Lu", "Chihao Zhang"], "title": "Competition Erases Simplicity: Tight Regret Bounds for Uniform Pricing with Multiple Buyers", "comment": null, "summary": "We study repeated \\textsf{Uniform Pricing} mechanisms with multiple buyers.\nIn each round, the platform sets a uniform price for all buyers; a transaction\noccurs if at least one buyer bids at or above this price. Prior work\ndemonstrates that structural assumptions on bid distributions -- such as\nregularity or monotone hazard rate (MHR) property -- enable significant\nimprovements in pricing query complexity (from\n$\\Theta\\left(\\varepsilon^{-3}\\right)$ to\n$\\widetilde\\Theta\\left(\\varepsilon^{-2}\\right)$\\footnote{The $\\widetilde\n\\Theta$ notation omits polylogarithmic factors.}) and regret bounds (from\n$\\Theta\\left(T^{2/3}\\right)$ to $\\widetilde\\Theta\\left(T^{1/2}\\right)$) for\nsingle-buyer settings. Strikingly, we demonstrate that these improvements\nvanish with multiple buyers: both general and structured distributions\n(including regular/MHR) share identical asymptotic performance, achieving\npricing query complexity of $\\widetilde\\Theta\\left(\\varepsilon^{-3}\\right)$ and\nregret of $\\widetilde\\Theta\\left(T^{2/3}\\right)$.\n  This result reveals a dichotomy between single-agent and multi-agent\nenvironments. While the special structure of distributions simplifies learning\nfor a single buyer, competition among multiple buyers erases these benefits,\nforcing platforms to adopt universally robust pricing strategies. Our findings\nchallenge conventional wisdom from single-buyer theory and underscore the\nnecessity of revisiting mechanism design principles in more competitive\nsettings.", "AI": {"tldr": "\u7814\u7a76\u591a\u4e70\u5bb6\u73af\u5883\u4e0b\u7684\u7edf\u4e00\u5b9a\u4ef7\u673a\u5236\uff0c\u53d1\u73b0\u5355\u4e70\u5bb6\u4e0e\u591a\u4e70\u5bb6\u73af\u5883\u5728\u6027\u80fd\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7ed3\u6784\u5316\u5206\u5e03\u7684\u4f18\u52bf\u5728\u591a\u4e70\u5bb6\u73af\u5883\u4e2d\u6d88\u5931\u3002", "motivation": "\u63a2\u7d22\u591a\u4e70\u5bb6\u73af\u5883\u4e2d\u7edf\u4e00\u5b9a\u4ef7\u673a\u5236\u7684\u6027\u80fd\uff0c\u6311\u6218\u5355\u4e70\u5bb6\u7406\u8bba\u4e2d\u7684\u5e38\u89c4\u89c2\u70b9\uff0c\u5e76\u91cd\u65b0\u5ba1\u89c6\u7ade\u4e89\u73af\u5883\u4e0b\u673a\u5236\u8bbe\u8ba1\u7684\u539f\u5219\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5355\u4e70\u5bb6\u548c\u591a\u4e70\u5bb6\u73af\u5883\u4e2d\u7684\u5b9a\u4ef7\u67e5\u8be2\u590d\u6742\u6027\u548c\u9057\u61be\u754c\u9650\uff0c\u5206\u6790\u7ed3\u6784\u5316\u5206\u5e03\uff08\u5982\u89c4\u5219\u6027\u6216\u5355\u8c03\u98ce\u9669\u7387\uff09\u5728\u591a\u4e70\u5bb6\u73af\u5883\u4e2d\u7684\u5f71\u54cd\u3002", "result": "\u5728\u591a\u4e70\u5bb6\u73af\u5883\u4e0b\uff0c\u7ed3\u6784\u5316\u5206\u5e03\u7684\u4f18\u52bf\u6d88\u5931\uff0c\u5b9a\u4ef7\u67e5\u8be2\u590d\u6742\u6027\u548c\u9057\u61be\u754c\u9650\u4e0e\u666e\u901a\u5206\u5e03\u76f8\u540c\uff0c\u5206\u522b\u4e3a\\(\\widetilde\\Theta\\left(\\varepsilon^{-3}\\right)\\)\u548c\\(\\widetilde\\Theta\\left(T^{2/3}\\right)\\)\u3002", "conclusion": "\u7ade\u4e89\u73af\u5883\u524a\u5f31\u4e86\u7ed3\u6784\u5316\u5206\u5e03\u7684\u4f18\u52bf\uff0c\u5e73\u53f0\u9700\u91c7\u7528\u66f4\u9c81\u68d2\u7684\u5b9a\u4ef7\u7b56\u7565\uff0c\u91cd\u65b0\u8bc4\u4f30\u673a\u5236\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.12640", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.12640", "abs": "https://arxiv.org/abs/2507.12640", "authors": ["Tom Smeding", "Miko\u0142aj Konarski", "Simon Peyton Jones", "Andrew Fitzgibbon"], "title": "Dual-Numbers Reverse AD for Functional Array Languages", "comment": null, "summary": "The standard dual-numbers construction works well for forward-mode automatic\ndifferentiation (AD) and is attractive due to its simplicity; recently, it also\nhas been adapted to reverse-mode AD, but practical performance, especially on\narray programs, leaves a lot to be desired. In this paper we introduce\nfirst-class support for multidimensional arrays in dual-numbers reverse-mode AD\nwith little to no performance overhead. The algorithm consists of three\nloosely-coupled components: a semantics-preserving vectorisation code\ntransformation (the bulk-operation transform or BOT), a fairly straightforward\nlifting of the basic dual-numbers reverse AD algorithm to a mostly first-order\narray language, and symbolic interpretation to achieve an end-to-end\ncompilation pipeline. Unfortunately, we lose some of the nice generalisable\naspects of dual-numbers AD in the process, most importantly support for\nhigher-order code.\n  We do support some higher-order array combinators, but only a\ncarefully-chosen set: 'build' (elementwise array construction), 'gather' and\n'scatter'. In return, the BOT can eliminate the essential (for AD)\nhigher-orderness of the input program, meaning that AD gets essentially\npresented with a first-order program. This allows the naive trick of lifting\ndual numbers to \"dual arrays\" to work without much modification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u53cc\u6570\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\u4e2d\u5b9e\u73b0\u591a\u7ef4\u6570\u7ec4\u7684\u4e00\u6d41\u652f\u6301\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7BOT\u53d8\u6362\u3001\u53cc\u6570\u7b97\u6cd5\u7684\u6269\u5c55\u548c\u7b26\u53f7\u89e3\u91ca\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7f16\u8bd1\u6d41\u7a0b\uff0c\u5c3d\u7ba1\u727a\u7272\u4e86\u90e8\u5206\u9ad8\u9636\u4ee3\u7801\u7684\u901a\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u53cc\u6570\u6784\u9020\u5728\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5728\u6570\u7ec4\u7a0b\u5e8f\u4e0a\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u591a\u7ef4\u6570\u7ec4\u7684\u4e00\u6d41\u652f\u6301\uff0c\u63d0\u5347\u5176\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u7b97\u6cd5\u7684\u7b80\u6d01\u6027\u3002", "method": "\u8bba\u6587\u91c7\u7528\u5305\u62ecBOT\u53d8\u6362\uff08\u4e00\u79cd\u8bed\u4e49\u4fdd\u6301\u7684\u77e2\u91cf\u5316\u4ee3\u7801\u8f6c\u6362\uff09\u3001\u53cc\u6570\u53cd\u5411AD\u7b97\u6cd5\u5230\u4e00\u9636\u6570\u7ec4\u8bed\u8a00\u7684\u6269\u5c55\uff0c\u4ee5\u53ca\u7b26\u53f7\u89e3\u91ca\u7684\u4e09\u90e8\u5206\u677e\u6563\u8026\u5408\u7ec4\u4ef6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u7f16\u8bd1\u6d41\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5728\u591a\u7ef4\u6570\u7ec4\u4e0a\u7684\u9ad8\u6548\u53cd\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206\uff0c\u4e14\u6027\u80fd\u5f00\u9500\u6781\u4f4e\u3002\u867d\u7136\u5931\u53bb\u4e86\u90e8\u5206\u9ad8\u9636\u4ee3\u7801\u7684\u652f\u6301\uff0c\u4f46\u5bf9\u90e8\u5206\u9ad8\u9636\u6570\u7ec4\u7ec4\u5408\u5668\uff08\u5982'build'\u3001'gather'\u548c'scatter'\uff09\u7684\u652f\u6301\u5f97\u4ee5\u4fdd\u7559\u3002", "conclusion": "\u901a\u8fc7BOT\u53d8\u6362\u548c\u5176\u4ed6\u6280\u672f\uff0c\u8bba\u6587\u6210\u529f\u5730\u4e3a\u53cc\u6570\u53cd\u5411AD\u5f15\u5165\u4e86\u591a\u7ef4\u6570\u7ec4\u7684\u4e00\u6d41\u652f\u6301\uff0c\u5c3d\u7ba1\u727a\u7272\u4e86\u90e8\u5206\u901a\u7528\u6027\uff0c\u4f46\u5728\u6027\u80fd\u63d0\u5347\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002"}}
{"id": "2507.12984", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.12984", "abs": "https://arxiv.org/abs/2507.12984", "authors": ["Masoud Seddighin", "Saeed Seddighin"], "title": "Lower Bound for Online MMS Assignment of Indivisible Chores", "comment": null, "summary": "We consider the problem of online assignment of indivisible chores under\n\\MMS\\ criteria. The previous work proves that any deterministic online\nalgorithm for chore division has a competitive ratio of at least 2. In this\nwork, we improve this bound by showing that no deterministic online algorithm\ncan obtain a competitive ratio better than $n$ for $n$ agents.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86\u4e0d\u53ef\u5206\u5272\u6742\u52a1\u5728\u7ebf\u5206\u914d\u7684\u7ade\u4e89\u6bd4\u7387\u4e0b\u754c\uff0c\u8bc1\u660e\u786e\u5b9a\u6027\u7684\u5728\u7ebf\u7b97\u6cd5\u65e0\u6cd5\u8fbe\u5230\u4f18\u4e8en\u7684\u7ade\u4e89\u6bd4\u7387\u3002", "motivation": "\u7814\u7a76\u4e0d\u53ef\u5206\u5272\u6742\u52a1\u5728\u7ebf\u5206\u914d\u95ee\u9898\uff0c\u76ee\u6807\u662f\u6539\u8fdb\u5148\u524d\u5de5\u4f5c\u4e2d\u786e\u5b9a\u7684\u7ade\u4e89\u6bd4\u7387\u4e0b\u754c\uff08\u81f3\u5c11\u4e3a2\uff09\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5728n\u4e2a\u4ee3\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u4efb\u4f55\u786e\u5b9a\u6027\u5728\u7ebf\u7b97\u6cd5\u7684\u7ade\u4e89\u6bd4\u7387\u90fd\u65e0\u6cd5\u4f18\u4e8en\u3002", "result": "\u8bc1\u660e\u4e86\u7ade\u4e89\u6bd4\u7387\u7684\u4e0b\u754c\u4e3an\uff0c\u6bd4\u4e4b\u524d\u7684\u7ed3\u679c\uff082\uff09\u66f4\u4e25\u683c\u3002", "conclusion": "\u786e\u5b9a\u6027\u5728\u7ebf\u7b97\u6cd5\u5728\u4e0d\u53ef\u5206\u5272\u6742\u52a1\u5206\u914d\u4e2d\u7684\u6027\u80fd\u53d7\u5230\u9650\u5236\uff0c\u7ade\u4e89\u6bd4\u7387\u7684\u4e0b\u754c\u4e3an\uff0c\u65e0\u6cd5\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2507.13091", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.13091", "abs": "https://arxiv.org/abs/2507.13091", "authors": ["Aur\u00e8le Barri\u00e8re", "Victor Deng", "Cl\u00e9ment Pit-Claudel"], "title": "Formal Verification for JavaScript Regular Expressions: a Proven Semantics and its Applications", "comment": "25 pages, 3 pages of references, 6 pages of appendix", "summary": "We present the first mechanized, succinct, practical, complete, and\nproven-faithful semantics for a modern regular expression language with\nbacktracking semantics. We ensure its faithfulness by proving it equivalent to\na preexisting line-by-line embedding of the official ECMAScript specification\nof JavaScript regular expressions. We demonstrate its practicality by\npresenting two real-world applications. First, a new notion of contextual\nequivalence for modern regular expressions, which we use to prove or disprove\nrewrites drawn from previous work. Second, the first formal proof of the PikeVM\nalgorithm used in many real-world engines. In contrast with the specification\nand other formalization work, our semantics captures not only the top-priority\nmatch, but a full backtracking tree recording all possible matches and their\nrespective priority. All our definitions and results have been mechanized in\nthe Rocq proof assistant.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u673a\u68b0\u5316\u3001\u7b80\u6d01\u3001\u5b9e\u7528\u4e14\u5b8c\u6574\u7684\u73b0\u4ee3\u6b63\u5219\u8868\u8fbe\u5f0f\u8bed\u8a00\u8bed\u4e49\uff0c\u5e76\u901a\u8fc7\u4e0eECMAScript\u89c4\u8303\u7684\u7b49\u4ef7\u6027\u8bc1\u660e\u786e\u4fdd\u5176\u5fe0\u5b9e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u4ee3\u6b63\u5219\u8868\u8fbe\u5f0f\u8bed\u8a00\u7684\u8bed\u4e49\u95ee\u9898\uff0c\u7279\u522b\u662f\u56de\u6eaf\u8bed\u4e49\u7684\u590d\u6742\u6027\uff0c\u5e76\u63d0\u4f9b\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u673a\u68b0\u5316\u5b9a\u4e49\u548c\u8bc1\u660e\uff0c\u7ed3\u5408Rocq\u8bc1\u660e\u52a9\u624b\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u8bed\u4e49\u6a21\u578b\uff0c\u5e76\u4e0eECMAScript\u89c4\u8303\u8fdb\u884c\u7b49\u4ef7\u6027\u9a8c\u8bc1\u3002", "result": "\u5c55\u793a\u4e86\u4e24\u4e2a\u5b9e\u9645\u5e94\u7528\uff1a\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0a\u4e0b\u6587\u7b49\u4ef7\u6982\u5ff5\uff0c\u5e76\u9996\u6b21\u5f62\u5f0f\u5316\u8bc1\u660e\u4e86PikeVM\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u3002\u540c\u65f6\uff0c\u8bed\u4e49\u6a21\u578b\u6355\u6349\u4e86\u5b8c\u6574\u7684\u56de\u6eaf\u6811\u3002", "conclusion": "\u672c\u6587\u7684\u8bed\u4e49\u6a21\u578b\u4e0d\u4ec5\u5177\u6709\u7406\u8bba\u4ef7\u503c\uff0c\u8fd8\u901a\u8fc7\u5b9e\u9645\u5e94\u7528\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u6027\uff0c\u4e3a\u73b0\u4ee3\u6b63\u5219\u8868\u8fbe\u5f0f\u8bed\u8a00\u7684\u7814\u7a76\u548c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.13290", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13290", "abs": "https://arxiv.org/abs/2507.13290", "authors": ["Aaron Councilman", "David Fu", "Aryan Gupta", "Chengxiao Wang", "David Grove", "Yu-Xiong Wang", "Vikram Adve"], "title": "Towards Formal Verification of LLM-Generated Code from Natural Language Prompts", "comment": "31 pages, 9 figures", "summary": "In the past few years LLMs have emerged as a tool that can aid programmers by\ntaking natural language descriptions and generating code based on it. However,\nLLMs often generate incorrect code that users need to fix and the literature\nsuggests users often struggle to detect these errors. In this work we seek to\noffer formal guarantees of correctness to LLM generated code; such guarantees\ncould improve the experience of using AI Code Assistants and potentially enable\nnatural language programming for users with little or no programming knowledge.\nTo address this challenge we propose to incorporate a formal query language\nthat can represent a user's intent in a formally defined but natural\nlanguage-like manner that a user can confirm matches their intent. Then, using\nsuch a query we propose to verify LLM generated code to ensure it matches the\nuser's intent. We implement these ideas in our system, Astrogator, for the\nAnsible programming language which includes such a formal query language, a\ncalculus for representing the behavior of Ansible programs, and a symbolic\ninterpreter which is used for the verification. On a benchmark suite of 21\ncode-generation tasks, our verifier is able to verify correct code in 83% of\ncases and identify incorrect code in 92%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5f62\u5f0f\u5316\u67e5\u8be2\u8bed\u8a00\u6765\u9a8c\u8bc1LLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u4ee5\u63d0\u9ad8AI\u4ee3\u7801\u52a9\u624b\u7684\u53ef\u9760\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u5c3d\u7ba1LLM\u80fd\u591f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u4ee3\u7801\uff0c\u4f46\u5176\u751f\u6210\u7684\u4ee3\u7801\u5f80\u5f80\u5b58\u5728\u9519\u8bef\u4e14\u7528\u6237\u96be\u4ee5\u68c0\u6d4b\u3002\u4e3a\u4e86\u63d0\u4f9b\u4ee3\u7801\u6b63\u786e\u6027\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u8bba\u6587\u65e8\u5728\u6539\u8fdbAI\u4ee3\u7801\u52a9\u624b\u7684\u4f7f\u7528\u4f53\u9a8c\uff0c\u5e76\u4e3a\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u7684\u53ef\u80fd\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u67e5\u8be2\u8bed\u8a00\uff0c\u7528\u4e8e\u8868\u793a\u7528\u6237\u7684\u610f\u56fe\u5e76\u4ee5\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u786e\u8ba4\u5176\u5339\u914d\u5ea6\u3002\u7136\u540e\uff0c\u901a\u8fc7\u8fd9\u79cd\u67e5\u8be2\u9a8c\u8bc1LLM\u751f\u6210\u7684\u4ee3\u7801\u662f\u5426\u4e0e\u7528\u6237\u610f\u56fe\u4e00\u81f4\u3002\u7814\u7a76\u56e2\u961f\u5728Ansible\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e86\u540d\u4e3aAstrogator\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5305\u62ec\u5f62\u5f0f\u5316\u67e5\u8be2\u8bed\u8a00\u3001\u63cf\u8ff0Ansible\u7a0b\u5e8f\u884c\u4e3a\u7684\u6f14\u7b97\u4ee5\u53ca\u7528\u4e8e\u9a8c\u8bc1\u7684\u7b26\u53f7\u89e3\u91ca\u5668\u3002", "result": "\u572821\u4e2a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9a8c\u8bc1\u5668\u80fd\u591f\u572883%\u7684\u60c5\u51b5\u4e0b\u9a8c\u8bc1\u6b63\u786e\u4ee3\u7801\uff0c\u5e76\u572892%\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u9519\u8bef\u4ee3\u7801\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5\u9a8c\u8bc1LLM\u751f\u6210\u7684\u4ee3\u7801\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u5176\u6b63\u786e\u6027\uff0c\u4e3aAI\u4ee3\u7801\u52a9\u624b\u548c\u975e\u4e13\u4e1a\u7f16\u7a0b\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
