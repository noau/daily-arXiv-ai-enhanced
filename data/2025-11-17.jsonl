{"id": "2511.10718", "categories": ["cs.GT", "math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10718", "abs": "https://arxiv.org/abs/2511.10718", "authors": ["Daniele Bracale", "Moulinath Banerjee", "Cong Shi", "Yuekai Sun"], "title": "Online Price Competition under Generalized Linear Demands", "comment": null, "summary": "We study sequential price competition among $N$ sellers, each influenced by the pricing decisions of their rivals. Specifically, the demand function for each seller $i$ follows the single index model $λ_i(\\mathbf{p}) = μ_i(\\langle \\boldsymbolθ_{i,0}, \\mathbf{p} \\rangle)$, with known increasing link $μ_i$ and unknown parameter $\\boldsymbolθ_{i,0}$, where the vector $\\mathbf{p}$ denotes the vector of prices offered by all the sellers simultaneously at a given instant. Each seller observes only their own realized demand -- unobservable to competitors -- and the prices set by rivals. Our framework generalizes existing approaches that focus solely on linear demand models. We propose a novel decentralized policy, PML-GLUCB, that combines penalized MLE with an upper-confidence pricing rule, removing the need for coordinated exploration phases across sellers -- which is integral to previous linear models -- and accommodating both binary and real-valued demand observations. Relative to a dynamic benchmark policy, each seller achieves $O(N^{2}\\sqrt{T}\\log(T))$ regret, which essentially matches the optimal rate known in the linear setting. A significant technical contribution of our work is the development of a variant of the elliptical potential lemma -- typically applied in single-agent systems -- adapted to our competitive multi-agent environment."}
{"id": "2511.10845", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10845", "abs": "https://arxiv.org/abs/2511.10845", "authors": ["Natan Doubez", "Pascal Lenzner", "Marcus Wunderlich"], "title": "Optimal Welfare in Noncooperative Network Formation under Attack", "comment": "Accepted at AAAI 2026 -- full version", "summary": "Communication networks are essential for our economy and our everyday lives. This makes them lucrative targets for attacks. Today, we see an ongoing battle between criminals that try to disrupt our key communication networks and security professionals that try to mitigate these attacks. However, today's networks, like the Internet or peer-to-peer networks among smart devices, are not controlled by a single authority, but instead consist of many independently administrated entities that are interconnected. Thus, both the decisions of how to interconnect and how to secure against potential attacks are taken in a decentralized way by selfish agents.\n  This strategic setting, with agents that want to interconnect and potential attackers that want to disrupt the network, was captured via an influential game-theoretic model by Goyal, Jabbari, Kearns, Khanna, and Morgenstern (WINE 2016). We revisit this model and show improved tight bounds on the achieved robustness of networks created by selfish agents. As our main result, we show that such networks can resist attacks of a large class of potential attackers, i.e., these networks maintain asymptotically optimal welfare post attack. This improves several bounds and resolves an open problem. Along the way, we show the counter-intuitive result, that attackers that aim at minimizing the social welfare post attack do not actually inflict the greatest possible damage."}
{"id": "2511.10854", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.10854", "abs": "https://arxiv.org/abs/2511.10854", "authors": ["Vade Shah", "Jason R. Marden"], "title": "Playing with Peaks: A Game-Theoretic Comparison of Electricity Pricing Mechanisms", "comment": null, "summary": "As electricity consumption grows, reducing peak demand--the maximum load on the grid--has become critical for preventing infrastructure strain and blackouts. Pricing mechanisms that incentivize consumers with flexible loads to shift consumption away from high-demand periods have emerged as effective tools, yet different mechanisms are used in practice with unclear relative performance. This work compares two widely implemented approaches: anytime peak pricing (AP), where consumers pay for their individual maximum consumption, and coincident peak pricing (CP), where consumers pay for their consumption during the system-wide peak period. To compare these mechanisms, we model the electricity market as a strategic game and characterize the peak demand in equilibrium under both AP and CP. Our main result demonstrates that with perfect information, equilibrium peak demand under CP never exceeds that under AP; on the other hand, with imperfect information, the coordination introduced by CP can backfire and induce larger equilibrium peaks than AP. These findings demonstrate that potential gains from coupling users' costs (as done in CP) must be weighed against these miscoordination risks. We conclude with preliminary results indicating that progressive demand cost structures--rather than per-unit charges--may mitigate these risks while preserving coordination benefits, achieving desirable performance in both deterministic and stochastic settings."}
{"id": "2511.11023", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.11023", "abs": "https://arxiv.org/abs/2511.11023", "authors": ["Yaoxin Ge", "Yao Zhang", "Dengji Zhao"], "title": "Fair Incentives for Early Arrival in 0-1 Cooperative Games", "comment": "Accepted by AAAI2026", "summary": "Incentives for early arrival (I4EA) was recently proposed for studying online cooperative games. In an online cooperative game, players arrive in an unknown order, and the value increase after each player arrived should be distributed immediately among all the arrived players. Although there is only one arriving order in the game, we also hope that the value distribution is equal to their Shapley value in expectation. To achieve these goals, the early solutions ignored the fairness in each single arriving order. More specifically, an important player may receive nothing in a game, which seems unfair in reality. To combat this, we propose refined fairness in this paper and design new solutions in 0-1 value games. Specifically, we compute the distance of the distribution in each order to the Shapley value and aim to minimize it. We propose a new mechanism called Egalitarian Value-Sharing (EVS) to do so. We also show that the mechanism can maximize the egalitarian welfare among all the players who made contributions."}
{"id": "2511.11055", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.11055", "abs": "https://arxiv.org/abs/2511.11055", "authors": ["Michael Schwarz", "Julian Erhard"], "title": "Data Race Detection by Digest-Driven Abstract Interpretation (Extended Version)", "comment": "Extended of paper accepted to appear at VMCAI'26; 29 Pages, including 2 Appendices", "summary": "Sound static analysis can prove the absence of data races by establishing that no two conflicting memory accesses can occur at the same time. We repurpose the concept of digests -- summaries of computational histories originally introduced to bring tunable concurrency-sensitivity to thread-modular value analysis by abstract interpretation, extending this idea to race detection: We use digests to capture the conditions under which conflicting accesses may not happen in parallel. To formalize this, we give a definition of data races in the thread-modular local trace semantics and show how exclusion criteria for potential conflicts can be expressed as digests. We report on our implementation of digest-driven data race detection in the static analyzer Goblint, and evaluate it on the SV-COMP benchmark suite. Combining the lockset digest with digests reasoning on thread ids and thread joins increases the number of correctly solved tasks by more than a factor of five compared to lockset reasoning alone."}
{"id": "2511.11282", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.11282", "abs": "https://arxiv.org/abs/2511.11282", "authors": ["Erwan Christian Escudie", "Matthia Sabatelli", "Olivier Buffet", "Jilles Steeve Dibangoye"], "title": "ε-Optimally Solving Two-Player Zero-Sum POSGs", "comment": null, "summary": "We present a novel framework for ε-optimally solving two-player zero-sum partially observable stochastic games (zs-POSGs). These games pose a major challenge due to the absence of a principled connection with dynamic programming (DP) techniques developed for two-player zero-sum stochastic games (zs-SGs). Prior attempts at transferring solution methods have lacked a lossless reduction, defined here as a transformation that preserves value functions, equilibrium strategies, and optimality structure, thereby limiting generalisation to ad-hoc algorithms. This work introduces the first lossless reduction from zs-POSGs to transition-independent zs-SGs, enabling the principled application of a broad class of DP-based methods. We show empirically that point-based value iteration (PBVI) algorithms, applied via this reduction, produce ε-optimal strategies across a range of benchmark domains, consistently matching or outperforming existing state-of-the-art methods. Our results open a systematic pathway for algorithmic and theoretical transfer from SGs to partially observable settings."}
{"id": "2511.11070", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.11070", "abs": "https://arxiv.org/abs/2511.11070", "authors": ["Sangho Lim", "Hyoungjin Lim", "Wonyeol Lee", "Xavier Rival", "Hongseok Yang"], "title": "Optimising Density Computations in Probabilistic Programs via Automatic Loop Vectorisation", "comment": "70 pages, 19 figures, the first two authors contributed equally to this work, accepted at POPL'26", "summary": "Probabilistic programming languages (PPLs) are a popular tool for high-level modelling across many fields. They provide a range of algorithms for probabilistic inference, which analyse models by learning their parameters from a dataset or estimating their posterior distributions. However, probabilistic inference is known to be very costly. One of the bottlenecks of probabilistic inference stems from the iteration over entries of a large dataset or a long series of random samples. Vectorisation can mitigate this cost, but manual vectorisation is error-prone, and existing automatic techniques are often ad-hoc and limited, unable to handle general repetition structures, such as nested loops and loops with data-dependent control flow, without significant user intervention. To address this bottleneck, we propose a sound and effective method for automatically vectorising loops in probabilistic programs. Our method achieves high throughput using speculative parallel execution of loop iterations, while preserving the semantics of the original loop through a fixed-point check. We formalise our method as a translation from an imperative PPL into a lower-level target language with primitives geared towards vectorisation. We implemented our method for the Pyro PPL and evaluated it on a range of probabilistic models. Our experiments show significant performance gains against an existing vectorisation baseline, achieving $1.1$--$6\\times$ speedups and reducing GPU memory usage in many cases. Unlike the baseline, which is limited to a subset of models, our method effectively handled all the tested models."}
{"id": "2511.11365", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.11365", "abs": "https://arxiv.org/abs/2511.11365", "authors": ["Piotr Faliszewski", "Stanislaw Kazmierowski", "Grzegorz Lisowski", "Ildiko Schlotter", "Paolo Turrini"], "title": "Computing Equilibrium Nominations in Presidential Elections", "comment": null, "summary": "We study strategic candidate nomination by parties in elections decided by Plurality voting. Each party selects a nominee before the election, and the winner is chosen from the nominated candidates based on the voters' preferences. We introduce a new restriction on these preferences, which we call party-aligned single-peakedness: all voters agree on a common ordering of the parties along an ideological axis, but may differ in their perceptions of the positions of individual candidates within each party. The preferences of each voter are single-peaked with respect to their own axis over the candidates, which is consistent with the global ordering of the parties. We present a polynomial-time algorithm for recognizing whether a preference profile satisfies party-aligned single-peakedness. In this domain, we give polynomial-time algorithms for deciding whether a given party can become the winner under some (or all) nominations, and whether this can occur in some pure Nash equilibrium. We also prove a tight result about the guaranteed existence of pure strategy Nash equilibria for elections with up to three parties for single-peaked and party-aligned single-peaked preference profiles."}
{"id": "2511.11264", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.11264", "abs": "https://arxiv.org/abs/2511.11264", "authors": ["Tobias Kappé", "Alexandra Silva", "Jana Wagemaker"], "title": "Kleene Algebra", "comment": null, "summary": "This booklet serves as an introduction to Kleene Algebra (KA), a set of laws that can be used to study general equivalences between programs. It discusses how general programs can be modeled using regular expressions, how those expressions correspond to automata, and how this correspondence can be exploited to obtain the central result of KA, namely that an equivalence of regular expressions is true if and only if it can be proved using the laws of KA. Each chapter closes with a set of exercises to further build intuition and understanding, and there is an optional chapter that develops automata theory through the lens of coalgebra."}
{"id": "2511.11371", "categories": ["cs.GT", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.11371", "abs": "https://arxiv.org/abs/2511.11371", "authors": ["Daniel Ebert", "Antonia Ellerbrock"], "title": "Nucleolus, Happy Nucleolus, and Vehicle Routing", "comment": "14 pages, 8 figures", "summary": "We study the recently introduced fair division concept of the happy nucleolus for cost allocation among players in a cooperative game, with special focus on its computation. The happy nucleolus applies the same fairness criterion as the well-established nucleolus but with reduced total value. Still, we show that the relation between the two concepts is quite involved, and intuitive properties do not hold - e.g., the entry of a player in the happy nucleolus can be larger than the entry of the same player in the nucleolus, even for monotone and subadditive games. This refutes conjectures of Meir, Rosenschein and Malizia (2011).\n  Further, we study the separation problem of the linear programs appearing in the MPS scheme for computing the (happy) nucleolus. It includes linear subspace avoidance constraints, which can be handled efficiently for problems with a certain dynamic programming formulation due to Köhnemann and Toth (2020). We show how to get rid of these constraints for all monotone games if we allow for an arbitrarily small error of epsilon, thus conserving known approximation guarantees for the same problem without subspace avoidance.\n  Finally, we focus on practical results at the example of vehicle routing games by designing an efficient heuristic based on our previous insights and past work, and demonstrate its power."}
{"id": "2511.11292", "categories": ["cs.PL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.11292", "abs": "https://arxiv.org/abs/2511.11292", "authors": ["Santiago Arranz-Olmos", "Gilles Barthe", "Lionel Blatter", "Benjamin Grégoire", "Vincent Laporte", "Paolo Torrini"], "title": "The Jasmin Compiler Preserves Cryptographic Security", "comment": null, "summary": "Jasmin is a programming and verification framework for developing efficient, formally verified, cryptographic implementations. A main component of the framework is the Jasmin compiler, which empowers programmers to write efficient implementations of state-of-the-art cryptographic primitives, including post-quantum cryptographic standards. The Jasmin compiler is proven functionally correct in the Rocq prover. However, this functional correctness statement does not apply to nonterminating or probabilistic computations, which are essential features in cryptography.\n  In this paper, we significantly enhance the guarantees of the compiler by showing, in the Rocq prover, that its front-end (25 out of 30 passes) preserves cryptographic security. To this end, we first define a Relational Hoare Logic tailored for compiler correctness proofs. We prove the soundness of our logic w.r.t. a new denotational semantics of Jasmin programs based on interaction trees. Secondly, we use our program logic to prove the functional correctness of the (unmodified) Jasmin compiler w.r.t. said semantics. Lastly, we formalize cryptographic security -- focusing on IND-CCA -- with interaction trees and prove that the Jasmin compiler preserves cryptographic security."}
{"id": "2511.11475", "categories": ["cs.GT", "cs.DS", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.11475", "abs": "https://arxiv.org/abs/2511.11475", "authors": ["Argyrios Deligkas", "Gregory Gutin", "Mark Jones", "Philip R. Neary", "Anders Yeo"], "title": "Public Goods Games in Directed Networks with Constraints on Sharing", "comment": null, "summary": "In a public goods game, every player chooses whether or not to buy a good that all neighboring players will have access to. We consider a setting in which the good is indivisible, neighboring players are out-neighbors in a directed graph, and there is a capacity constraint on their number, k, that can benefit from the good. This means that each player makes a two-pronged decision: decide whether or not to buy and, conditional on buying, choose which k out-neighbors to share access. We examine both pure and mixed Nash equilibria in the model from the perspective of existence, computation, and efficiency. We perform a comprehensive study for these three dimensions with respect to both sharing capacity (k) and the network structure (the underlying directed graph), and establish sharp complexity dichotomies for each."}
{"id": "2511.11531", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.11531", "abs": "https://arxiv.org/abs/2511.11531", "authors": ["Valentin Zech", "Martin Bullinger"], "title": "Deviation Dynamics in Cardinal Hedonic Games", "comment": "Appears in the 40th AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "Computing stable partitions in hedonic games is a challenging task because there exist games in which stable outcomes do not exist. Even more, these No-instances can often be leveraged to prove computational hardness results. We make this impression rigorous in a dynamic model of cardinal hedonic games by providing meta theorems. These imply hardness of deciding about the possible or necessary convergence of deviation dynamics based on the mere existence of No-instances. Our results hold for additively separable, fractional, and modified fractional hedonic games (ASHGs, FHGs, and MFHGs). Moreover, they encompass essentially all reasonable stability notions based on single-agent deviations. In addition, we propose dynamics as a method to find individually rational and contractually individual stable (CIS) partitions in ASHGs. In particular, we find that CIS dynamics from the singleton partition possibly converge after a linear number of deviations but may require an exponential number of deviations in the worst case."}
{"id": "2511.11545", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.11545", "abs": "https://arxiv.org/abs/2511.11545", "authors": ["Irmak Sağlam", "Mahdi Nazeri", "Alessandro Abate", "Sadegh Soudjani", "Anne-Kathrin Schmuck"], "title": "Incremental Data-Driven Policy Synthesis via Game Abstractions", "comment": "To be presented at the 40th Annual AAAI Conference on Artificial Intelligence AAAI'26 (Oral)", "summary": "We address the synthesis of control policies for unknown discrete-time stochastic dynamical systems to satisfy temporal logic objectives. We present a data-driven, abstraction-based control framework that integrates online learning with novel incremental game-solving. Under appropriate continuity assumptions, our method abstracts the system dynamics into a finite stochastic (2.5-player) game graph derived from data. Given a requirement over time on this graph, we compute the winning region -- i.e., the set of initial states from which the objective is satisfiable -- in the resulting game, together with a corresponding control policy.\n  Our main contribution is the construction of abstractions, winning regions and control policies incrementally, as data about the system dynamics accumulates. Concretely, our algorithm refines under- and over-approximations of reachable sets for each state-action pair as new data samples arrive. These refinements induce structural modifications in the game graph abstraction -- such as the addition or removal of nodes and edges -- which in turn modify the winning region. Crucially, we show that these updates are inherently monotonic: under-approximations can only grow, over-approximations can only shrink, and the winning region can only expand.\n  We exploit this monotonicity by defining an objective-induced ranking function on the nodes of the abstract game that increases monotonically as new data samples are incorporated. These ranks underpin our novel incremental game-solving algorithm, which employs customized gadgets (DAG-like subgames) within a rank-lifting algorithm to efficiently update the winning region. Numerical case studies demonstrate significant computational savings compared to the baseline approach, which resolves the entire game from scratch whenever new data samples arrive."}
