{"id": "2601.19901", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.19901", "abs": "https://arxiv.org/abs/2601.19901", "authors": ["Ajinkya Gavane", "Benjamin Watson"], "title": "Light Field Display Point Rendering", "comment": "18 pages, 11 figures, Published in Proceedings of the ACM on Computer Graphics and Interactive Techniques, Vol. 7, Issue. 1 (May 2024)", "summary": "Rendering for light field displays (LFDs) requires rendering of dozens or hundreds of views, which must then be combined into a single image on the display, making real-time LFD rendering extremely difficult. We introduce light field display point rendering (LFDPR), which meets these challenges by improving eye-based point rendering [Gavane and Watson 2023] with texture-based splatting, which avoids oversampling of triangles mapped to only a few texels; and with LFD-biased sampling, which adjusts horizontal and vertical triangle sampling to match the sampling of the LFD itself. To improve image quality, we introduce multiview mipmapping, which reduces texture aliasing even though compute shaders do not support hardware mipmapping. We also introduce angular supersampling and reconstruction to combat LFD view aliasing and crosstalk. The resulting LFDPR is 2-8x times faster than multiview rendering, with similar comparable quality."}
{"id": "2601.20429", "categories": ["cs.GR", "cs.AR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20429", "abs": "https://arxiv.org/abs/2601.20429", "authors": ["Junseo Lee", "Sangyun Jeon", "Jungi Lee", "Junyong Park", "Jaewoong Sim"], "title": "GRTX: Efficient Ray Tracing for 3D Gaussian-Based Rendering", "comment": "To appear at the 32nd International Symposium on High-Performance Computer Architecture (HPCA 2026)", "summary": "3D Gaussian Splatting has gained widespread adoption across diverse applications due to its exceptional rendering performance and visual quality. While most existing methods rely on rasterization to render Gaussians, recent research has started investigating ray tracing approaches to overcome the fundamental limitations inherent in rasterization. However, current Gaussian ray tracing methods suffer from inefficiencies such as bloated acceleration structures and redundant node traversals, which greatly degrade ray tracing performance.\n  In this work, we present GRTX, a set of software and hardware optimizations that enable efficient ray tracing for 3D Gaussian-based rendering. First, we introduce a novel approach for constructing streamlined acceleration structures for Gaussian primitives. Our key insight is that anisotropic Gaussians can be treated as unit spheres through ray space transformations, which substantially reduces BVH size and traversal overhead. Second, we propose dedicated hardware support for traversal checkpointing within ray tracing units. This eliminates redundant node visits during multi-round tracing by resuming traversal from checkpointed nodes rather than restarting from the root node in each subsequent round. Our evaluation shows that GRTX significantly improves ray tracing performance compared to the baseline ray tracing method with a negligible hardware cost."}
{"id": "2601.20722", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2601.20722", "abs": "https://arxiv.org/abs/2601.20722", "authors": ["Milan van Zanten"], "title": "Rendering Portals in Virtual Reality", "comment": null, "summary": "Portals have many applications in the field of computer graphics. Recently, they have found use as a way of artificially increasing the available space in a virtual reality (VR) environment. In this paper, we will cover a technique for making the transition through a portal unnoticeable to the user. Additionally, we will measure the performance impact of rendering portals in a test scene and provide some insight into possible optimisations."}
{"id": "2601.19950", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2601.19950", "abs": "https://arxiv.org/abs/2601.19950", "authors": ["Sam Devorsetz", "Maurice Herlihy"], "title": "Defensive Rebalancing for Automated Market Makers", "comment": null, "summary": "This paper introduces and analyzes \\emph{defensive rebalancing}, a novel mechanism for protecting constant-function market makers (CFMMs) from value leakage due to arbitrage. A \\emph{rebalancing} transfers assets directly from one CFMM's pool to another's, bypassing the CFMMs' standard trading protocols. In any \\emph{arbitrage-prone} configuration, we prove there exists a rebalancing to an \\textit{arbitrage-free} configuration that strictly increases some CFMMs' liquidities without reducing the liquidities of the others. Moreover, we prove that a configuration is arbitrage-free if and only if it is \\emph{Pareto efficient} under rebalancing, meaning that any further direct asset transfers must decrease some CFMM's liquidity. We prove that for any log-concave trading function, including the ubiquitous constant product market maker, the search for an optimal, arbitrage-free rebalancing that maximizes global liquidity while ensuring no participant is worse off can be cast as a convex optimization problem with a unique, computationally tractable solution. We extend this framework to \\emph{mixed rebalancing}, where a subset of participating CFMMs use a combination of direct transfers and standard trades to transition to an arbitrage-free configuration while harvesting arbitrage profits from non-participating CFMMs, and from price oracle market makers such as centralized exchanges. Our results provide a rigorous foundation for future AMM protocols that proactively defend liquidity providers against arbitrage."}
{"id": "2601.20422", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20422", "abs": "https://arxiv.org/abs/2601.20422", "authors": ["Yumou Liu", "Zhenzhe Zheng", "Jiang Rong", "Yao Hu", "Fan Wu", "Guihai Chen"], "title": "Guiding the Recommender: Information-Aware Auto-Bidding for Content Promotion", "comment": "Accepted by SIGMETRICS 2026", "summary": "Modern content platforms offer paid promotion to mitigate cold start by allocating exposure via auctions. Our empirical analysis reveals a counterintuitive flaw in this paradigm: while promotion rescues low-to-medium quality content, it can harm high-quality content by forcing exposure to suboptimal audiences, polluting engagement signals and downgrading future recommendation. We recast content promotion as a dual-objective optimization that balances short-term value acquisition with long-term model improvement. To make this tractable at bid time in content promotion, we introduce a decomposable surrogate objective, gradient coverage, and establish its formal connection to Fisher Information and optimal experimental design. We design a two-stage auto-bidding algorithm based on Lagrange duality that dynamically paces budget through a shadow price and optimizes impression-level bids using per-impression marginal utilities. To address missing labels at bid time, we propose a confidence-gated gradient heuristic, paired with a zeroth-order variant for black-box models that reliably estimates learning signals in real time. We provide theoretical guarantees, proving monotone submodularity of the composite objective, sublinear regret in online auction, and budget feasibility. Extensive offline experiments on synthetic and real-world datasets validate the framework: it outperforms baselines, achieves superior final AUC/LogLoss, adheres closely to budget targets, and remains effective when gradients are approximated zeroth-order. These results show that strategic, information-aware promotion can improve long-term model performance and organic outcomes beyond naive impression-maximization strategies."}
{"id": "2601.20578", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20578", "abs": "https://arxiv.org/abs/2601.20578", "authors": ["Dimitris Michailidis", "Sennay Ghebreab", "Fernando P. Santos"], "title": "Inequality in Congestion Games with Learning Agents", "comment": "Full version of the extended abstract version appearing in Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "Who benefits from expanding transport networks? While designed to improve mobility, such interventions can also create inequality. In this paper, we show that disparities arise not only from the structure of the network itself but also from differences in how commuters adapt to it. We model commuters as reinforcement learning agents who adapt their travel choices at different learning rates, reflecting unequal access to resources and information. To capture potential efficiency-fairness tradeoffs, we introduce the Price of Learning (PoL), a measure of inefficiency during learning. We analyze both a stylized network -- inspired in the well-known Braess's paradox, yet with two-source nodes -- and an abstraction of a real-world metro system (Amsterdam). Our simulations show that network expansions can simultaneously increase efficiency and amplify inequality, especially when faster learners disproportionately benefit from new routes before others adapt. These results highlight that transport policies must account not only for equilibrium outcomes but also for the heterogeneous ways commuters adapt, since both shape the balance between efficiency and fairness."}
{"id": "2601.20779", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20779", "abs": "https://arxiv.org/abs/2601.20779", "authors": ["Th√©o Delemazure"], "title": "Independence of Approximate Clones", "comment": null, "summary": "In an ordinal election, two candidates are said to be perfect clones if every voter ranks them adjacently. The independence of clones axiom then states that removing one of the two clones should not change the election outcome. This axiom has been extensively studied in social choice theory, and several voting rules are known to satisfy it (such as IRV, Ranked Pairs and Schulze). However, perfect clones are unlikely to occur in practice, especially for political elections with many voters.\n  In this work, we study different notions of approximate clones in ordinal elections. Informally, two candidates are approximate clones in a preference profile if they are close to being perfect clones. We discuss two measures to quantify this proximity, and we show under which conditions the voting rules that are known to be independent of clones are also independent of approximate clones. In particular, we show that for elections with at least four candidates, none of these rules are independent of approximate clones in the general case. However, we find a more positive result for the case of three candidates. Finally, we conduct an empirical study of approximate clones and independence of approximate clones based on three real-world datasets: votes in local Scottish elections, votes in mini-jury deliberations, and votes of judges in figure skating competitions. We find that approximate clones are common in some contexts, and that the closest two candidates are to being perfect clones, the less likely their removal is to change the election outcome, especially for voting rules that are independent of perfect clones."}
