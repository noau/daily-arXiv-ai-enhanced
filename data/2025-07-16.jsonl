{"id": "2507.10567", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10567", "abs": "https://arxiv.org/abs/2507.10567", "authors": ["Miranda Christ", "Daniel Reichman", "Jonathan Shafer"], "title": "Protocols for Verifying Smooth Strategies in Bandits and Games", "comment": null, "summary": "We study protocols for verifying approximate optimality of strategies in\nmulti-armed bandits and normal-form games. As the number of actions available\nto each player is often large, we seek protocols where the number of queries to\nthe utility oracle is sublinear in the number of actions. We prove that such\nverification is possible for sufficiently smooth strategies that do not put too\nmuch probability mass on any specific action. We provide protocols for\nverifying that a smooth policy for a multi-armed bandit is\n$\\varepsilon$-optimal. Our verification protocols require provably fewer arm\nqueries than learning. Furthermore, we establish a nearly-tight lower bound on\nthe query complexity of verification in our settings. As an application, we\nshow how to use verification for bandits to achieve verification in normal-form\ngames. This gives a protocol for verifying whether a given strategy profile is\nan approximate strong smooth Nash equilibrium, with a query complexity that is\nsublinear in the number of actions."}
{"id": "2507.10872", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.10872", "abs": "https://arxiv.org/abs/2507.10872", "authors": ["Yannai A. Gonczarowski", "Gary Qiurui Ma", "David C. Parkes"], "title": "Pricing with Tips in Three-Sided Delivery Platforms", "comment": null, "summary": "We model a delivery platform facilitating transactions among three sides:\nbuyers, stores, and couriers. In addition to buyers paying store-specific\npurchase prices and couriers receiving store--buyer-specific delivery\ncompensation from the platform, each buyer has the option to directly tip for\ndelivery from a specific store. An equilibrium consists of prices,\ncompensations, tips, and transactions that clear the market, such that buyers\nreceive deliveries from preferred stores considering the prices and tips they\npay, and couriers deliver preferred orders considering the compensations and\ntips they receive.\n  We illustrate the role of tips in pricing: Without tips, an equilibrium is\nonly guaranteed to exist when there are at least as many couriers as buyers or\nstores. In contrast, with tips an equilibrium always exists. From an efficiency\nperspective, the optimal with-tip equilibrium welfare is always weakly larger\nthan the optimal without-tip equilibrium welfare. However, we show that even\nwith tips, efficient equilibria may not exist, and calculating the optimal\nequilibrium welfare is NP-hard. To address these challenges, we identify\nnatural conditions on market structure that ensure the existence of efficient\nwith-tip equilibria and allow these efficient equilibria to be computed in\npolynomial time."}
{"id": "2507.11214", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.11214", "abs": "https://arxiv.org/abs/2507.11214", "authors": ["Matteo Castiglioni", "Junjie Chen", "Yingkai Li"], "title": "Fair Contracts", "comment": null, "summary": "We introduce and study the problem of designing optimal contracts under\nfairness constraints on the task assignments and compensations. We adopt the\nnotion of envy-free (EF) and its relaxations, $\\epsilon$-EF and envy-free up to\none item (EF1), in contract design settings. Unlike fair allocations, EF\ncontracts are guaranteed to exist. However, computing any constant-factor\napproximation to the optimal EF contract is NP-hard in general, even using\n$\\epsilon$-EF contracts. For this reason, we consider settings in which the\nnumber of agents or tasks is constant. Notably, while even with three agents,\nfinding an EF contract better than $2/5$ approximation of the optimal is\nNP-hard, we are able to design an FPTAS when the number of agents is constant,\nunder relaxed notions of $\\epsilon$-EF and EF1. Moreover, we present a\npolynomial-time algorithm for computing the optimal EF contract when the number\nof tasks is constant. Finally, we analyze the price of fairness in contract\ndesign. We show that the price of fairness for exact EF contracts can be\nunbounded, even with a single task and two agents. In contrast, for EF1\ncontracts, the price of fairness is bounded between $\\Omega(\\sqrt{n})$ and\n$O(n^2)$, where $n$ is the number of agents."}
{"id": "2507.10799", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.10799", "abs": "https://arxiv.org/abs/2507.10799", "authors": ["Tyler Hou", "Michael Arntzenius", "Max Willsey"], "title": "Stream programs are monoid homomorphisms with state", "comment": null, "summary": "We define a broad class of deterministic stream functions and show they can\nbe implemented as homomorphisms into a \"state\" monoid. The homomorphism laws\nare simpler than the conditions of previous semantic frameworks for stream\nprogram optimization, yet retain support for rich equational reasoning over\nexpressive dataflow programs, including sequential composition, parallel\ncomposition, and feedback. We demonstrate this using examples of partitioned\ndatabase joins, stratified negation, and a simplified model of TCP."}
{"id": "2507.11366", "categories": ["cs.GT", "cs.LG", "90C47, 91A05, 91A26, 68Q32"], "pdf": "https://arxiv.org/pdf/2507.11366", "abs": "https://arxiv.org/abs/2507.11366", "authors": ["Taemin Kim", "James P. Bailey"], "title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent", "comment": null, "summary": "We study online optimization methods for zero-sum games, a fundamental\nproblem in adversarial learning in machine learning, economics, and many other\ndomains. Traditional methods approximate Nash equilibria (NE) using either\nregret-based methods (time-average convergence) or contraction-map-based\nmethods (last-iterate convergence). We propose a new method based on\nHamiltonian dynamics in physics and prove that it can characterize the set of\nNE in a finite (linear) number of iterations of alternating gradient descent in\nthe unbounded setting, modulo degeneracy, a first in online optimization.\nUnlike standard methods for computing NE, our proposed approach can be\nparallelized and works with arbitrary learning rates, both firsts in\nalgorithmic game theory. Experimentally, we support our results by showing our\napproach drastically outperforms standard methods."}
{"id": "2507.11282", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.11282", "abs": "https://arxiv.org/abs/2507.11282", "authors": ["René Rydhof Hansen", "Andreas Stenbæk Larsen", "Aslan Askarov"], "title": "The downgrading semantics of memory safety", "comment": "56 pages, 27 figures", "summary": "Memory safety is traditionally characterized in terms of bad things that\ncannot happen, an approach that is often criticized as unprincipled. Prior work\nsuggest a connection between memory safety and noninterference, but no\nsatisfactory semantic notion of memory safety is currently known.\n  This work proposes a notion of gradual allocator independence that accurately\ncaptures many allocator-specific aspects of memory safety. We consider a\nlow-level language with access to an allocator that provides malloc and free\nprimitives in a flat memory model. Pointers are just integers, and as such it\nis trivial to write memory-unsafe programs. The basic intuition of gradual\nallocator independence is that of noninterference, namely that allocators must\nnot influence program execution. This intuition is refined in two important\nways to account for the allocators running out-of-memory and for programs to\nhave pointer-to-integer casts. The key insight of the definition is to treat\nthese extensions as forms of downgrading and give them satisfactory technical\ntreatment using the state-of-the-art information flow machinery."}
{"id": "2507.10883", "categories": ["cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10883", "abs": "https://arxiv.org/abs/2507.10883", "authors": ["Juhee Bae", "Benjamin Watson"], "title": "Developing and evaluating quilts for the depiction of large layered graphs", "comment": null, "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions)."}
{"id": "2507.11419", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11419", "abs": "https://arxiv.org/abs/2507.11419", "authors": ["Anna Lunghi", "Matteo Castiglioni", "Alberto Marchesi"], "title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation", "comment": null, "summary": "Bilateral trade is a central problem in algorithmic economics, and recent\nwork has explored how to design trading mechanisms using no-regret learning\nalgorithms. However, no-regret learning is impossible when budget balance has\nto be enforced at each time step. Bernasconi et al. [Ber+24] show how this\nimpossibility can be circumvented by relaxing the budget balance constraint to\nhold only globally over all time steps. In particular, they design an algorithm\nachieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound\nof $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the\noptimal regret rate varies with the allowed violation of the global budget\nbalance constraint. Specifically, we design an algorithm that, by violating the\nconstraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4},\n\\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this\nresult with a matching lower bound, thus fully characterizing the trade-off\nbetween regret and budget violation. Our results show that both the $\\tilde\nO(T^{3/4})$ upper bound in the global budget balance case and the\n$\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation\nobtained by Bernasconi et al. [Ber+24] are tight."}
{"id": "2507.10924", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.10924", "abs": "https://arxiv.org/abs/2507.10924", "authors": ["Zihan Zhao", "Pengfei Wang", "Minfeng Xu", "Shuangmin Chen", "Shiqing Xin", "Changhe Tu", "Wenping Wang"], "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams", "comment": null, "summary": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling\nball, play a crucial role in geometry processing, with applications ranging\nfrom coverage motion planning to brush modeling. While considerable progress\nhas been made in computing constant-radius offset surfaces, computing\nvariable-radius offset surfaces remains a challenging problem. In this paper,\nwe present OffsetCrust, a novel framework that efficiently addresses the\nvariable-radius offsetting problem by computing a power diagram. Let $R$ denote\nthe radius function defined on the base surface $S$. The power diagram is\nconstructed from contributing sites, consisting of carefully sampled base\npoints on $S$ and their corresponding off-surface points, displaced along\n$R$-dependent directions. In the constant-radius case only, these displacement\ndirections align exactly with the surface normals of $S$. Moreover, our method\nmitigates the misalignment issues commonly seen in crust-based approaches\nthrough a lightweight fine-tuning procedure. We validate the accuracy and\nefficiency of OffsetCrust through extensive experiments, and demonstrate its\npractical utility in applications such as reconstructing original boundary\nsurfaces from medial axis transform (MAT) representations."}
{"id": "2507.11509", "categories": ["cs.GT", "cs.CC", "F.2.0"], "pdf": "https://arxiv.org/pdf/2507.11509", "abs": "https://arxiv.org/abs/2507.11509", "authors": ["Vincent Cheval", "Florian Horn", "Soumyajit Paul", "Mahsa Shirmohammadi"], "title": "On the Complexity of the Optimal Correlated Equilibria in Extensive-Form Games", "comment": null, "summary": "A major open question in algorithmic game theory is whether normal-form\ncorrelated equilibria (NFCE) can be computed efficiently in succinct games such\nas extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this\nquestion, we study the associated Threshold problem: deciding whether there\nexists a correlated equilibrium whose value exceeds a given threshold. We prove\nthat this problem is PSPACE-hard for NFCE in multiplayer extensive-form games\nwith perfect recall, even for fixed thresholds. To contextualize this result,\nwe also establish the complexity of the Threshold problem for Nash equilibria\nin this setting, showing it is ER-complete. These results uncover a surprising\ncomplexity reversal: while optimal correlated equilibria are computationally\nsimpler than optimal Nash in normal-form games, the opposite holds in\nextensive-form games, where computing optimal correlated equilibria is provably\nharder. Building on this line of inquiry, we also address a related question by\n[VSF08], who introduced the notions of extensive-form correlated equilibrium\n(EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult\nthe Threshold problem is for AFCE; we answer this question by proving that it\nis NP-hard, even in two-player games without chance nodes. Complementing our\nhardness results, we establish tight complexity classifications for the\nThreshold problem across several correlated equilibrium concepts - including\nEFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse\ncorrelated equilibria. For each of these solution concepts in multiplayer\nstochastic extensive-form games with perfect recall, we prove NP-completeness\nby providing matching NP upper bounds to the previously known hardness results.\nTogether, our results provide the most complete landscape to date for the\ncomplexity of optimal equilibrium computation in extensive-form games."}
{"id": "2507.11465", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11465", "abs": "https://arxiv.org/abs/2507.11465", "authors": ["Nuri Ryu", "Jiyun Won", "Jooeun Son", "Minsu Gong", "Joo-Haeng Lee", "Sunghyun Cho"], "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "comment": "Accepted to SIGGRAPH 2025. For the project page, see\n  https://cg.postech.ac.kr/research/Elevate3D/", "summary": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets."}
