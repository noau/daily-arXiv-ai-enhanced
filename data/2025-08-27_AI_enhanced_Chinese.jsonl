{"id": "2508.18587", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18587", "abs": "https://arxiv.org/abs/2508.18587", "authors": ["Bar\u0131\u015f Bayaz\u0131t", "Yao Li", "Xujie Si"], "title": "A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants", "comment": "Accepted by LMPL 2025", "summary": "Large language models (LLMs) can potentially help with verification using\nproof assistants by automating proofs. However, it is unclear how effective\nLLMs are in this task. In this paper, we perform a case study based on two\nmature Rocq projects: the hs-to-coq tool and Verdi. We evaluate the\neffectiveness of LLMs in generating proofs by both quantitative and qualitative\nanalysis. Our study finds that: (1) external dependencies and context in the\nsame source file can significantly help proof generation; (2) LLMs perform\ngreat on small proofs but can also generate large proofs; (3) LLMs perform\ndifferently on different verification projects; and (4) LLMs can generate\nconcise and smart proofs, apply classical techniques to new definitions, but\ncan also make odd mistakes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9a8c\u8bc1\u4e2d\u4f7f\u7528\u8bc1\u660e\u52a9\u624b\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u5bf9Rocq\u9879\u76ee\u7684\u6848\u4f8b\u5206\u6790\uff0c\u53d1\u73b0\u5916\u90e8\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u5bf9\u8bc1\u660e\u751f\u6210\u6709\u5e2e\u52a9\uff0cLLMs\u5728\u5c0f\u8bc1\u660e\u4e2d\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u4e0d\u540c\u9879\u76ee\u4e2d\u6709\u5dee\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5316\u8bc1\u660e\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3002", "method": "\u8bba\u6587\u57fa\u4e8e\u4e24\u4e2a\u6210\u719f\u7684Rocq\u9879\u76ee\uff08hs-to-coq\u5de5\u5177\u548cVerdi\uff09\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u901a\u8fc7\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8bc4\u4f30LLMs\u751f\u6210\u8bc1\u660e\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1)\u5916\u90e8\u4f9d\u8d56\u548c\u540c\u4e00\u6e90\u6587\u4ef6\u4e2d\u7684\u4e0a\u4e0b\u6587\u6709\u52a9\u4e8e\u8bc1\u660e\u751f\u6210\uff1b(2)LLMs\u64c5\u957f\u5c0f\u8bc1\u660e\uff0c\u4f46\u4e5f\u80fd\u591f\u751f\u6210\u5927\u578b\u8bc1\u660e\uff1b(3)\u4e0d\u540c\u9a8c\u8bc1\u9879\u76ee\u4e2dLLMs\u8868\u73b0\u4e0d\u540c\uff1b(4)LLMs\u80fd\u751f\u6210\u7b80\u6d01\u806a\u660e\u7684\u8bc1\u660e\uff0c\u4f46\u5728\u65b0\u5b9a\u4e49\u4e2d\u5e94\u7528\u7ecf\u5178\u6280\u672f\u65f6\u4e5f\u53ef\u80fd\u51fa\u73b0\u9519\u8bef\u3002", "conclusion": "LLMs\u5728\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u5177\u6709\u4e00\u5b9a\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u5c0f\u8bc1\u660e\u751f\u6210\u548c\u5229\u7528\u4e0a\u4e0b\u6587\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4e0d\u540c\u9879\u76ee\u548c\u590d\u6742\u60c5\u5883\u4e2d\u7684\u8868\u73b0\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.18325", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.18325", "abs": "https://arxiv.org/abs/2508.18325", "authors": ["Yohai Trabelsi", "Abhijin Adiga", "Yonatan Aumann", "Sarit Kraus", "S. S. Ravi"], "title": "Facilitating Matches on Allocation Platforms", "comment": null, "summary": "We consider a setting where goods are allocated to agents by way of an\nallocation platform (e.g., a matching platform). An ``allocation facilitator''\naims to increase the overall utility/social-good of the allocation by\nencouraging (some of the) agents to relax (some of) their restrictions. At the\nsame time, the advice must not hurt agents who would otherwise be better off.\nAdditionally, the facilitator may be constrained by a ``bound'' (a.k.a.\n`budget'), limiting the number and/or type of restrictions it may seek to\nrelax. We consider the facilitator's optimization problem of choosing an\noptimal set of restrictions to request to relax under the aforementioned\nconstraints. Our contributions are three-fold: (i) We provide a formal\ndefinition of the problem, including the participation guarantees to which the\nfacilitator should adhere. We define a hierarchy of participation guarantees\nand also consider several social-good functions. (ii) We provide polynomial\nalgorithms for solving various versions of the associated optimization\nproblems, including one-to-one and many-to-one allocation settings. (iii) We\ndemonstrate the benefits of such facilitation and relaxation, and the\nimplications of the different participation guarantees, using extensive\nexperimentation on three real-world datasets.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8d44\u6e90\u5206\u914d\u5e73\u53f0\u4e2d\uff0c\u901a\u8fc7\u9f13\u52b1\u4ee3\u7406\u4eba\u653e\u677e\u9650\u5236\u4ee5\u63d0\u9ad8\u6574\u4f53\u6548\u7528\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u7b97\u6cd5\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u8d44\u6e90\u5206\u914d\u5e73\u53f0\u4e2d\u901a\u8fc7\u4f18\u5316\u4ee3\u7406\u4eba\u9650\u5236\u7684\u653e\u677e\uff0c\u4ee5\u63d0\u9ad8\u6574\u4f53\u6548\u7528\uff0c\u540c\u65f6\u786e\u4fdd\u4e0d\u635f\u5bb3\u90a3\u4e9b\u539f\u672c\u66f4\u597d\u7684\u4ee3\u7406\u4eba\u5229\u76ca\u3002", "method": "\u8bba\u6587\u63d0\u4f9b\u4e86\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u548c\u53c2\u4e0e\u4fdd\u969c\u7684\u5c42\u7ea7\uff0c\u5f00\u53d1\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5904\u7406\u4e86\u4e00\u5bf9\u4e00\u548c\u591a\u5bf9\u4e00\u5206\u914d\u573a\u666f\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u653e\u677e\u9650\u5236\u7684\u76ca\u5904\u4ee5\u53ca\u4e0d\u540c\u53c2\u4e0e\u4fdd\u969c\u7684\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u4f18\u5316\u653e\u677e\u9650\u5236\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u793e\u4f1a\u6548\u76ca\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u53c2\u4e0e\u4fdd\u969c\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.18525", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18525", "abs": "https://arxiv.org/abs/2508.18525", "authors": ["Eleni Tselepi", "Spyridon Thermos", "Gerasimos Potamianos"], "title": "Controllable Single-shot Animation Blending with Temporal Conditioning", "comment": "Accepted to the AI for Visual Arts Workshop at ICCV 2025", "summary": "Training a generative model on a single human skeletal motion sequence\nwithout being bound to a specific kinematic tree has drawn significant\nattention from the animation community. Unlike text-to-motion generation,\nsingle-shot models allow animators to controllably generate variations of\nexisting motion patterns without requiring additional data or extensive\nretraining. However, existing single-shot methods do not explicitly offer a\ncontrollable framework for blending two or more motions within a single\ngenerative pass. In this paper, we present the first single-shot motion\nblending framework that enables seamless blending by temporally conditioning\nthe generation process. Our method introduces a skeleton-aware normalization\nmechanism to guide the transition between motions, allowing smooth, data-driven\ncontrol over when and how motions blend. We perform extensive quantitative and\nqualitative evaluations across various animation styles and different kinematic\nskeletons, demonstrating that our approach produces plausible, smooth, and\ncontrollable motion blends in a unified and efficient manner.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u6b21\u8fd0\u52a8\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u5728\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u591a\u4e2a\u8fd0\u52a8\u7684\u65e0\u7f1d\u6df7\u5408\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u6761\u4ef6\u5316\u751f\u6210\u8fc7\u7a0b\u63d0\u4f9b\u53ef\u63a7\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u6b21\u8fd0\u52a8\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u660e\u786e\u7684\u6846\u67b6\u6765\u63a7\u5236\u591a\u4e2a\u8fd0\u52a8\u7684\u6df7\u5408\uff0c\u8fd9\u5728\u52a8\u753b\u5236\u4f5c\u4e2d\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u63a7\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u9aa8\u67b6\u611f\u77e5\u7684\u5f52\u4e00\u5316\u673a\u5236\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u65f6\u95f4\u6761\u4ef6\u5316\uff0c\u6307\u5bfc\u4e0d\u540c\u8fd0\u52a8\u4e4b\u95f4\u7684\u8fc7\u6e21\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u6df7\u5408\u65f6\u95f4\u548c\u65b9\u5f0f\u7684\u5e73\u6ed1\u63a7\u5236\u3002", "result": "\u6a21\u578b\u5728\u591a\u79cd\u52a8\u753b\u98ce\u683c\u548c\u4e0d\u540c\u9aa8\u67b6\u7ed3\u6784\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u591f\u4ee5\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\u751f\u6210\u903c\u771f\u3001\u5e73\u6ed1\u4e14\u53ef\u63a7\u7684\u8fd0\u52a8\u6df7\u5408\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5355\u6b21\u8fd0\u52a8\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u63a7\u7684\u6df7\u5408\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u753b\u5236\u4f5c\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.18449", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.18449", "abs": "https://arxiv.org/abs/2508.18449", "authors": ["Jiehua Chen", "Christian Hatschka", "Sofia Simola"], "title": "Partitioned Combinatorial Optimization Games", "comment": "Extended abstract accepted at ECAI 2025", "summary": "We propose a class of cooperative games, called d Partitioned Compbinatorial\nOptimization Games (PCOGs). The input of PCOG consists of a set of agents and a\ncombinatorial structure (typically a graph) with a fixed optimization goal on\nthis structure (e.g., finding a minimum dominating set on a graph) such that\nthe structure is divided among the agents. The value of each coalition of\nagents is derived from the optimal solution for the part of the structure\npossessed by the coalition. We study two fundamental questions related to the\ncore: Core Stability Verification and Core Stability Existence. We analyze the\nalgorithmic complexity of both questions for four classic graph optimization\ntasks: minimum vertex cover, minimum dominating set, minimum spanning tree, and\nmaximum matching.", "AI": {"tldr": "\u63d0\u51fa\u4e86dPartitionedCombinatorial Optimization Games\uff08PCOGs\uff09\u8fd9\u79cd\u5408\u4f5c\u535a\u5f08\u6a21\u578b\uff0c\u5e76\u7814\u7a76\u4e86\u6838\u5fc3\u7684\u7a33\u5b9a\u6027\u548c\u7b97\u6cd5\u590d\u6742\u6027\u3002", "motivation": "\u7814\u7a76\u5408\u4f5c\u535a\u5f08\u4e2d\u7ec4\u5408\u7ed3\u6784\uff08\u5982\u56fe\uff09\u7684\u4f18\u5316\u95ee\u9898\uff0c\u6838\u5fc3\u7a33\u5b9a\u6027\u662f\u5176\u4e2d\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86PCOGs\u6a21\u578b\uff0c\u5b9a\u4e49\u4e86\u6bcf\u4e2a\u8054\u76df\u7684\u4ef7\u503c\uff0c\u5e76\u5206\u6790\u4e86\u6838\u5fc3\u7a33\u5b9a\u6027\u9a8c\u8bc1\u548c\u5b58\u5728\u6027\u7684\u7b97\u6cd5\u590d\u6742\u6027\u3002", "result": "\u5bf9\u56db\u79cd\u7ecf\u5178\u7684\u56fe\u4f18\u5316\u4efb\u52a1\uff08\u6700\u5c0f\u9876\u70b9\u8986\u76d6\u3001\u6700\u5c0f\u652f\u914d\u96c6\u3001\u6700\u5c0f\u751f\u6210\u6811\u548c\u6700\u5927\u5339\u914d\uff09\u7684\u6838\u5fc3\u7a33\u5b9a\u6027\u95ee\u9898\u8fdb\u884c\u4e86\u590d\u6742\u6027\u5206\u6790\u3002", "conclusion": "PCOGs\u6a21\u578b\u4e3a\u7814\u7a76\u5408\u4f5c\u535a\u5f08\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\uff0c\u6838\u5fc3\u7a33\u5b9a\u6027\u7684\u590d\u6742\u6027\u5206\u6790\u4e3a\u5176\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2508.18540", "categories": ["cs.GR", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.18540", "abs": "https://arxiv.org/abs/2508.18540", "authors": ["Jonghyun Kim", "Cheng Sun", "Michael Stengel", "Matthew Chan", "Andrew Russell", "Jaehyun Jung", "Wil Braithwaite", "Shalini De Mello", "David Luebke"], "title": "Real-time 3D Visualization of Radiance Fields on Light Field Displays", "comment": "10 pages, 14 figures. J. Kim, C. Sun, and M. Stengel contributed\n  equally", "summary": "Radiance fields have revolutionized photo-realistic 3D scene visualization by\nenabling high-fidelity reconstruction of complex environments, making them an\nideal match for light field displays. However, integrating these technologies\npresents significant computational challenges, as light field displays require\nmultiple high-resolution renderings from slightly shifted viewpoints, while\nradiance fields rely on computationally intensive volume rendering. In this\npaper, we propose a unified and efficient framework for real-time radiance\nfield rendering on light field displays. Our method supports a wide range of\nradiance field representations, including NeRFs, 3D Gaussian Splatting, and\nSparse Voxels, within a shared architecture based on a single-pass plane\nsweeping strategy and caching of shared, non-directional components. The\nframework generalizes across different scene formats without retraining, and\navoids redundant computation across views. We further demonstrate a real-time\ninteractive application on a Looking Glass display, achieving 200+ FPS at 512p\nacross 45 views, enabling seamless, immersive 3D interaction. On standard\nbenchmarks, our method achieves up to 22x speedup compared to independently\nrendering each view, while preserving image quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5149\u573a\u663e\u793a\u5668\u4e0a\u5b9e\u65f6\u6e32\u67d3\u8f90\u5c04\u573a\uff0c\u652f\u6301\u591a\u79cd\u8f90\u5c04\u573a\u8868\u793a\uff0c\u5e76\u5728\u4e0d\u635f\u5931\u56fe\u50cf\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u8f90\u5c04\u573a\u867d\u7136\u57283D\u573a\u666f\u53ef\u89c6\u5316\u65b9\u9762\u5177\u6709\u9769\u547d\u6027\u610f\u4e49\uff0c\u4f46\u5728\u4e0e\u5149\u573a\u663e\u793a\u5668\u96c6\u6210\u65f6\u9762\u4e34\u5de8\u5927\u7684\u8ba1\u7b97\u6311\u6218\u3002\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5355\u901a\u9053\u5e73\u9762\u626b\u63cf\u7b56\u7565\u548c\u5171\u4eab\u975e\u65b9\u5411\u6027\u7ec4\u4ef6\u7f13\u5b58\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u652f\u6301\u591a\u79cd\u8f90\u5c04\u573a\u8868\u793a\uff08\u5982NeRFs\u30013D\u9ad8\u65af\u6cfc\u6e85\u548c\u7a00\u758f\u4f53\u7d20\uff09\uff0c\u907f\u514d\u8de8\u89c6\u56fe\u7684\u5197\u4f59\u8ba1\u7b97\u3002", "result": "\u5728Looking Glass\u663e\u793a\u5668\u4e0a\u5b9e\u73b0\u4e86200+ FPS\u7684\u5b9e\u65f6\u4ea4\u4e92\u5e94\u7528\uff0c512p\u5206\u8fa8\u7387\u4e0b\u652f\u630145\u4e2a\u89c6\u56fe\u3002\u6807\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u72ec\u7acb\u6e32\u67d3\u6bcf\u4e2a\u89c6\u56fe\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe22\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5149\u573a\u663e\u793a\u5668\u4e0a\u7684\u8f90\u5c04\u573a\u6e32\u67d3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u4ea4\u4e92\u548c\u9ad8\u8d28\u91cf\u76843D\u53ef\u89c6\u5316\u6548\u679c\u3002"}}
{"id": "2508.18600", "categories": ["cs.GT", "cs.MA", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2508.18600", "abs": "https://arxiv.org/abs/2508.18600", "authors": ["Ayato Kitadai", "Yusuke Fukasawa", "Nariaki Nishino"], "title": "Bias-Adjusted LLM Agents for Human-Like Decision-Making via Behavioral Economics", "comment": "8 pages, 4 figures", "summary": "Large language models (LLMs) are increasingly used to simulate human\ndecision-making, but their intrinsic biases often diverge from real human\nbehavior--limiting their ability to reflect population-level diversity. We\naddress this challenge with a persona-based approach that leverages\nindividual-level behavioral data from behavioral economics to adjust model\nbiases. Applying this method to the ultimatum game--a standard but difficult\nbenchmark for LLMs--we observe improved alignment between simulated and\nempirical behavior, particularly on the responder side. While further\nrefinement of trait representations is needed, our results demonstrate the\npromise of persona-conditioned LLMs for simulating human-like decision patterns\nat scale.", "AI": {"tldr": "\u901a\u8fc7\u57fa\u4e8e\u89d2\u8272\u7684\u65b9\u6cd5\u8c03\u6574\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u504f\u89c1\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\u65f6\u5b58\u5728\u5185\u5728\u504f\u89c1\uff0c\u4e0e\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff0c\u9650\u5236\u4e86\u5176\u53cd\u6620\u7fa4\u4f53\u591a\u6837\u6027\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u89d2\u8272\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u884c\u4e3a\u7ecf\u6d4e\u5b66\u7684\u4e2a\u4f53\u884c\u4e3a\u6570\u636e\u8c03\u6574\u6a21\u578b\u504f\u89c1\uff0c\u5e76\u5e94\u7528\u4e8e\u6700\u540e\u901a\u7252\u6e38\u620f\u4e2d\u3002", "result": "\u5728\u6700\u540e\u901a\u7252\u6e38\u620f\u4e2d\uff0c\u6a21\u62df\u884c\u4e3a\u4e0e\u5b9e\u8bc1\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u5f97\u5230\u6539\u5584\uff0c\u7279\u522b\u662f\u5728\u56de\u5e94\u8005\u65b9\u9762\u3002", "conclusion": "\u89d2\u8272\u6761\u4ef6\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u5927\u89c4\u6a21\u4eba\u7c7b\u51b3\u7b56\u6a21\u5f0f\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u7279\u5f81\u8868\u793a\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2508.18597", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18597", "abs": "https://arxiv.org/abs/2508.18597", "authors": ["Xiaohao Sun", "Divyam Goel", "Angle X. Chang"], "title": "SemLayoutDiff: Semantic Layout Generation with Diffusion Model for Indoor Scene Synthesis", "comment": "Project page: https://3dlg-hcvc.github.io/SemLayoutDiff/", "summary": "We present SemLayoutDiff, a unified model for synthesizing diverse 3D indoor\nscenes across multiple room types. The model introduces a scene layout\nrepresentation combining a top-down semantic map and attributes for each\nobject. Unlike prior approaches, which cannot condition on architectural\nconstraints, SemLayoutDiff employs a categorical diffusion model capable of\nconditioning scene synthesis explicitly on room masks. It first generates a\ncoherent semantic map, followed by a cross-attention-based network to predict\nfurniture placements that respect the synthesized layout. Our method also\naccounts for architectural elements such as doors and windows, ensuring that\ngenerated furniture arrangements remain practical and unobstructed. Experiments\non the 3D-FRONT dataset show that SemLayoutDiff produces spatially coherent,\nrealistic, and varied scenes, outperforming previous methods.", "AI": {"tldr": "SemLayoutDiff\u662f\u4e00\u4e2a\u7edf\u4e00\u6a21\u578b\uff0c\u7528\u4e8e\u5408\u6210\u591a\u79cd3D\u5ba4\u5185\u573a\u666f\uff0c\u7ed3\u5408\u4e86\u8bed\u4e49\u56fe\u548c\u7269\u4f53\u5c5e\u6027\u7684\u5e03\u5c40\u8868\u793a\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u8bed\u4e49\u56fe\u5e76\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u7f51\u7edc\u9884\u6d4b\u5bb6\u5177\u5e03\u5c40\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u8003\u8651\u5efa\u7b51\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u57fa\u4e8e\u623f\u95f4\u63a9\u7801\u663e\u5f0f\u751f\u6210\u573a\u666f\u7684\u6a21\u578b\u3002", "method": "\u6a21\u578b\u91c7\u7528\u7c7b\u522b\u6269\u6563\u6a21\u578b\u751f\u6210\u8bed\u4e49\u56fe\uff0c\u5e76\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u7f51\u7edc\u9884\u6d4b\u5bb6\u5177\u5e03\u5c40\uff0c\u540c\u65f6\u8003\u8651\u95e8\u7a97\u7b49\u5efa\u7b51\u5143\u7d20\u3002", "result": "\u57283D-FRONT\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u751f\u6210\u7684\u7a7a\u95f4\u8fde\u8d2f\u3001\u771f\u5b9e\u4e14\u591a\u6837\u5316\u7684\u573a\u666f\u4f18\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "SemLayoutDiff\u901a\u8fc7\u663e\u5f0f\u7ed3\u5408\u5efa\u7b51\u7ea6\u675f\uff0c\u80fd\u591f\u9ad8\u6548\u751f\u6210\u5b9e\u7528\u4e14\u65e0\u969c\u788d\u76843D\u5ba4\u5185\u573a\u666f\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2508.18944", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.18944", "abs": "https://arxiv.org/abs/2508.18944", "authors": ["Shashikant Verma", "Shanmuganathan Raman"], "title": "PanoHair: Detailed Hair Strand Synthesis on Volumetric Heads", "comment": null, "summary": "Achieving realistic hair strand synthesis is essential for creating lifelike\ndigital humans, but producing high-fidelity hair strand geometry remains a\nsignificant challenge. Existing methods require a complex setup for data\nacquisition, involving multi-view images captured in constrained studio\nenvironments. Additionally, these methods have longer hair volume estimation\nand strand synthesis times, which hinder efficiency. We introduce PanoHair, a\nmodel that estimates head geometry as signed distance fields using knowledge\ndistillation from a pre-trained generative teacher model for head synthesis.\nOur approach enables the prediction of semantic segmentation masks and 3D\norientations specifically for the hair region of the estimated geometry. Our\nmethod is generative and can generate diverse hairstyles with latent space\nmanipulations. For real images, our approach involves an inversion process to\ninfer latent codes and produces visually appealing hair strands, offering a\nstreamlined alternative to complex multi-view data acquisition setups. Given\nthe latent code, PanoHair generates a clean manifold mesh for the hair region\nin under 5 seconds, along with semantic and orientation maps, marking a\nsignificant improvement over existing methods, as demonstrated in our\nexperiments.", "AI": {"tldr": "PanoHair\u662f\u4e00\u79cd\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u751f\u6210\u5f0f\u65b9\u6cd5\u5feb\u901f\u751f\u6210\u9ad8\u4fdd\u771f\u5934\u53d1\u51e0\u4f55\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u591a\u6837\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u5934\u53d1\u5408\u6210\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u591a\u89c6\u56fe\u6570\u636e\u91c7\u96c6\uff0c\u8017\u65f6\u4e14\u6548\u7387\u4f4e\u4e0b\uff0cPanoHair\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PanoHair\u5229\u7528\u9884\u8bad\u7ec3\u7684\u751f\u6210\u5f0f\u6559\u5e08\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\uff0c\u9884\u6d4b\u5934\u53d1\u533a\u57df\u7684\u8bed\u4e49\u5206\u5272\u63a9\u7801\u548c3D\u65b9\u5411\uff0c\u5e76\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u64cd\u4f5c\u751f\u6210\u591a\u6837\u5316\u7684\u53d1\u578b\u3002", "result": "PanoHair\u80fd\u591f\u57285\u79d2\u5185\u751f\u6210\u5e72\u51c0\u7684\u5934\u53d1\u533a\u57df\u7f51\u683c\u4ee5\u53ca\u8bed\u4e49\u548c\u65b9\u5411\u56fe\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PanoHair\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5934\u53d1\u5408\u6210\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u590d\u6742\u6570\u636e\u91c7\u96c6\u7684\u9700\u6c42\uff0c\u4e3a\u751f\u6210\u903c\u771f\u6570\u5b57\u4eba\u7c7b\u5934\u53d1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.19140", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.19140", "abs": "https://arxiv.org/abs/2508.19140", "authors": ["Florian Hahlbohm", "Linus Franke", "Leon Overk\u00e4mping", "Paula Wespe", "Susana Castillo", "Martin Eisemann", "Marcus Magnor"], "title": "A Bag of Tricks for Efficient Implicit Neural Point Clouds", "comment": "Project page: https://fhahlbohm.github.io/inpc_v2/", "summary": "Implicit Neural Point Cloud (INPC) is a recent hybrid representation that\ncombines the expressiveness of neural fields with the efficiency of point-based\nrendering, achieving state-of-the-art image quality in novel view synthesis.\nHowever, as with other high-quality approaches that query neural networks\nduring rendering, the practical usability of INPC is limited by comparatively\nslow rendering. In this work, we present a collection of optimizations that\nsignificantly improve both the training and inference performance of INPC\nwithout sacrificing visual fidelity. The most significant modifications are an\nimproved rasterizer implementation, more effective sampling techniques, and the\nincorporation of pre-training for the convolutional neural network used for\nhole-filling. Furthermore, we demonstrate that points can be modeled as small\nGaussians during inference to further improve quality in extrapolated, e.g.,\nclose-up views of the scene. We design our implementations to be broadly\napplicable beyond INPC and systematically evaluate each modification in a\nseries of experiments. Our optimized INPC pipeline achieves up to 25% faster\ntraining, 2x faster rendering, and 20% reduced VRAM usage paired with slight\nimage quality improvements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u5f0f\u795e\u7ecf\u70b9\u4e91\uff08INPC\uff09\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u70b9\u4e91\uff08INPC\uff09\u7ed3\u5408\u4e86\u795e\u7ecf\u573a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u70b9\u4e91\u6e32\u67d3\u7684\u6548\u7387\uff0c\u5728\u65b0\u89c6\u89d2\u5408\u6210\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u56fe\u50cf\u8d28\u91cf\u3002\u7136\u800c\uff0c\u7531\u4e8e\u6e32\u67d3\u8fc7\u7a0b\u4e2d\u9700\u8981\u67e5\u8be2\u795e\u7ecf\u7f51\u7edc\uff0cINPC\u7684\u5b9e\u9645\u53ef\u7528\u6027\u53d7\u5230\u8f83\u6162\u6e32\u67d3\u901f\u5ea6\u7684\u9650\u5236\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u4f18\u5316\u63aa\u65bd\uff0c\u5305\u62ec\u6539\u8fdb\u7684\u5149\u6805\u5316\u5668\u5b9e\u73b0\u3001\u66f4\u6709\u6548\u7684\u91c7\u6837\u6280\u672f\u3001\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u586b\u5145\u7a7a\u6d1e\uff0c\u4ee5\u53ca\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5c06\u70b9\u5efa\u6a21\u4e3a\u5c0f\u578b\u9ad8\u65af\u5206\u5e03\u4ee5\u63d0\u5347\u8d28\u91cf\u3002", "result": "\u4f18\u5316\u540e\u7684INPC\u7ba1\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u8fbe25%\u7684\u8bad\u7ec3\u52a0\u901f\u30012\u500d\u7684\u6e32\u67d3\u901f\u5ea6\u63d0\u5347\u548c20%\u7684\u663e\u5b58\u4f7f\u7528\u51cf\u5c11\uff0c\u540c\u65f6\u56fe\u50cf\u8d28\u91cf\u7565\u6709\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u7684\u65b9\u6cd5\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86INPC\u7684\u6027\u80fd\uff0c\u8fd8\u4fdd\u6301\u4e86\u5176\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u4f18\u5316\u6280\u672f\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
