{"id": "2511.19532", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19532", "abs": "https://arxiv.org/abs/2511.19532", "authors": ["Thomas Buchholtzer", "Michel de Lara"], "title": "Games in Product Form for Demand Response Modelling", "comment": null, "summary": "Energy systems are changing rapidly. More and more, energy production is becoming decentralized, highly variable and intermittent (solar, wind), while demand is diversifying (electric vehicles). As a result, balancing supply and demand is becoming more complex, making the adjustment of demand an interesting tool. Demand response is a typical leader-follower problem: a consumer (follower) adjusts his energy consumption based on the prices (or any other incentive) set by the supplier (leader). We propose a versatile and modular framework to address any leader-follower problem, focusing on the handling of often overlooked informational issues. First, we introduce a model that defines the rules of the game (W-model): agents are decision-makers, and Nature encapsulates everything beyond their control, such as private knowledge and exogenous factors. Following the so-called Witsenhausen intrinsic model, we present an efficient way to represent - on a product set, equipped with a product $σ$-algebra - the information available to agents when making decisions. Next, we introduce Games in Product Form (W-games) by equipping each player (a group of agents) with preferences (objective function and belief) over different outcomes. Thereby, we incorporate an additional layer of information, the characteristics of the preferences linked to players, which affects the possible definitions of an equilibrium. We make this explicit in Nash and Stackelberg equilibria. Equipped with this framework, we reformulate several papers on demand response, highlighting overlooked informational issues. We also provide an application based on the Thailand demand response program."}
{"id": "2511.19521", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19521", "abs": "https://arxiv.org/abs/2511.19521", "authors": ["Tesla Zhang", "Asher Kornfeld", "Rui Li", "Sonya Simkin", "Yue Yao", "Stephanie Balzer"], "title": "Mechanizing a Proof-Relevant Logical Relation for Timed Message-Passing Protocols", "comment": "15 pages, 9 figures", "summary": "Semantic typing has become a powerful tool for program verification, applying the technique of logical relations as not only a proof method, but also a device for prescribing program behavior. In recent work, Yao et al. scaled semantic typing to the verification of timed message-passing protocols, which are prevalent in, e.g., IoT and real-time systems applications. The appeal of semantic typing in this context is precisely because of its ability to support typed and untyped program components alike -- including physical objects -- which caters to the heterogeneity of these applications. Another demand inherent to these applications is timing: constraining the time or time window within which a message exchange must happen. Yao et al. equipped their logical relation not only with temporal predicates, but also with computable trajectories, to supply the evidence that an inhabitant can step from one time point to another one. While Yao et al. provide the formalization for such a verification tool, it lacks a mechanization. Mechanizing the system would not only provide a machine proof for it, but also facilitate scalability for future extensions and applications.\n  This paper tackles the challenge of mechanizing the resulting proof-relevant logical relation in a proof assistant. allowing trajectories to be interleaved, partitioned, and concatenated, while the intended equality on trajectories is the equality of their graphs when seen as processes indexed by time. Unfortunately, proof assistants based on intensional type theory only have modest support for such equations, forcing a prolific use of transports. This paper reports on the process of mechanizing Yao et al.'s results, comprising the logical relation, the algebra of computable trajectories with supporting lemmas, and the fundamental theorem of the logical relation, in the Rocq theorem prover."}
{"id": "2511.19842", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19842", "abs": "https://arxiv.org/abs/2511.19842", "authors": ["Joon Suk Huh", "Kirthevasan Kandasamy"], "title": "Strategy-robust Online Learning in Contextual Pricing", "comment": "32 pages", "summary": "Learning effective pricing strategies is crucial in digital marketplaces, especially when buyers' valuations are unknown and must be inferred through interaction. We study the online contextual pricing problem, where a seller observes a stream of context-valuation pairs and dynamically sets prices. Moreover, departing from traditional online learning frameworks, we consider a strategic setting in which buyers may misreport valuations to influence future prices, a challenge known as strategic overfitting (Amin et al., 2013).\n  We introduce a strategy-robust notion of regret for multi-buyer online environments, capturing worst-case strategic behavior in the spirit of the Price of Anarchy. Our first contribution is a polynomial-time approximation scheme (PTAS) for learning linear pricing policies in adversarial, adaptive environments, enabled by a novel online sketching technique. Building on this result, we propose our main construction: the Sparse Update Mechanism (SUM), a simple yet effective sequential mechanism that ensures robustness to all Nash equilibria among buyers. Moreover, our construction yields a black-box reduction from online expert algorithms to strategy-robust learners."}
{"id": "2511.19764", "categories": ["cs.PL", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19764", "abs": "https://arxiv.org/abs/2511.19764", "authors": ["Ayaka Yorihiro", "Griffin Berlstein", "Pedro Pontes García", "Kevin Laeufer", "Adrian Sampson"], "title": "Understanding Accelerator Compilers via Performance Profiling", "comment": null, "summary": "Accelerator design languages (ADLs), high-level languages that compile to hardware units, help domain experts quickly design efficient application-specific hardware. ADL compilers optimize datapaths and convert software-like control flow constructs into control paths. Such compilers are necessarily complex and often unpredictable: they must bridge the wide semantic gap between high-level semantics and cycle-level schedules, and they typically rely on advanced heuristics to optimize circuits. The resulting performance can be difficult to control, requiring guesswork to find and resolve performance problems in the generated hardware. We conjecture that ADL compilers will never be perfect: some performance unpredictability is endemic to the problem they solve.\n  In lieu of compiler perfection, we argue for compiler understanding tools that give ADL programmers insight into how the compiler's decisions affect performance. We introduce Petal, a cycle-level Petal for the Calyx intermediate language (IL). Petal instruments the Calyx code with probes and then analyzes the trace from a register-transfer-level simulation. It maps the events in the trace back to high-level control constructs in the Calyx code to track the clock cycles when each construct was active. Using case studies, we demonstrate that Petal's cycle-level profiles can identify performance problems in existing accelerator designs. We show that these insights can also guide developers toward optimizations that the compiler was unable to perform automatically, including a reduction by 46.9\\% of total cycles for one application."}
{"id": "2511.19930", "categories": ["cs.GT", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19930", "abs": "https://arxiv.org/abs/2511.19930", "authors": ["Kenta Yamamoto", "Teruaki Hayashi"], "title": "Designing Reputation Systems for Manufacturing Data Trading Markets: A Multi-Agent Evaluation with Q-Learning and IRL-Estimated Utilities", "comment": "10 pages, 10 figures", "summary": "Recent advances in machine learning and big data analytics have intensified the demand for high-quality cross-domain datasets and accelerated the growth of data trading across organizations. As data become increasingly recognized as an economic asset, data marketplaces have emerged as a key infrastructure for data-driven innovation. However, unlike mature product or service markets, data-trading environments remain nascent and suffer from pronounced information asymmetry. Buyers cannot verify the content or quality before purchasing data, making trust and quality assurance central challenges. To address these issues, this study develops a multi-agent data-market simulator that models participant behavior and evaluates the institutional mechanisms for trust formation. Focusing on the manufacturing sector, where initiatives such as GAIA-X and Catena-X are advancing, the simulator integrates reinforcement learning (RL) for adaptive agent behavior and inverse reinforcement learning (IRL) to estimate utility functions from empirical behavioral data. Using the simulator, we examine the market-level effects of five representative reputation systems-Time-decay, Bayesian-beta, PageRank, PowerTrust, and PeerTrust-and found that PeerTrust achieved the strongest alignment between data price and quality, while preventing monopolistic dominance. Building on these results, we develop a hybrid reputation mechanism that integrates the strengths of existing systems to achieve improved price-quality consistency and overall market stability. This study extends simulation-based data-market analysis by incorporating trust and reputation as endogenous mechanisms and offering methodological and institutional insights into the design of reliable and efficient data ecosystems."}
{"id": "2511.20369", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20369", "abs": "https://arxiv.org/abs/2511.20369", "authors": ["Frank Schüssele", "Matthias Zumkeller", "Miriam Lagunes-Rochin", "Dominik Klumpp"], "title": "The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)", "comment": "39 pages, 10 figures, 1 table. Extended version with proofs of the paper published at POPL'2026 (https://doi.org/10.1145/3776684)", "summary": "Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline."}
{"id": "2511.20110", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.20110", "abs": "https://arxiv.org/abs/2511.20110", "authors": ["Michal Feldman", "Yoav Gal-Tzur", "Tomasz Ponitka", "Maya Schlesinger"], "title": "One Action Too Many: Inapproximability of Budgeted Combinatorial Contracts", "comment": "Accepted to ITCS 2026", "summary": "We study multi-agent contract design with combinatorial actions, under budget constraints, and for a broad class of objective functions, including profit (principal's utility), reward, and welfare. Our first result is a strong impossibility: For submodular reward functions, no randomized poly-time algorithm can approximate the optimal budget-feasible value within \\textit{any finite factor}, even with demand-oracle access. This result rules out extending known constant-factor guarantees from either (i) unbudgeted settings with combinatorial actions or (ii) budgeted settings with binary actions, to their combination. The hardness is tight: It holds even when all but one agent have binary actions and the remaining agent has just one additional action. On the positive side, we show that gross substitutes rewards (a well-studied strict subclass of submodular functions) admit a deterministic poly-time $O(1)$-approximation, using only value queries. Our results thus draw the first sharp separation between budgeted and unbudgeted settings in combinatorial contracts, and identifies gross substitutes as a tractable frontier for budgeted combinatorial contracts. Finally, we present an FPTAS for additive rewards, demonstrating that arbitrary approximation is tractable under any budget. This constitutes the first FPTAS for the multi-agent combinatorial-actions setting, even in the absence of budget constraints."}
{"id": "2511.20289", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.20289", "abs": "https://arxiv.org/abs/2511.20289", "authors": ["Kang Wang", "Renzhe Xu", "Bo Li"], "title": "Lower Bias, Higher Welfare: How Creator Competition Reshapes Bias-Variance Tradeoff in Recommendation Platforms?", "comment": "KDD 2026", "summary": "Understanding the bias-variance tradeoff in user representation learning is essential for improving recommendation quality in modern content platforms. While well studied in static settings, this tradeoff becomes significantly more complex when content creators strategically adapt to platform incentives. To analyze how such competition reshapes the tradeoff for maximizing user welfare, we introduce the Content Creator Competition with Bias-Variance Tradeoff framework, a tractable game-theoretic model that captures the platform's decision on regularization strength in user feature estimation. We derive and compare the platform's optimal policy under two key settings: a non-strategic baseline with fixed content and a strategic environment where creators compete in response to the platform's algorithmic design.\n  Our theoretical analysis in a stylized model shows that, compared to the non-strategic environment, content creator competition shifts the platform's optimal policy toward weaker regularization, thereby favoring lower bias in the bias-variance tradeoff. To validate and assess the robustness of these insights beyond the stylized setting, we conduct extensive experiments on both synthetic and real-world benchmark datasets. The empirical results consistently support our theoretical conclusion: in strategic environments, reducing bias leads to higher user welfare. These findings offer practical implications for the design of real-world recommendation algorithms in the presence of content creator competition."}
