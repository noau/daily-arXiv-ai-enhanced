<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 14]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 7]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Creative synthesis of kinematic mechanisms](https://arxiv.org/abs/2510.03308)
*Jiong Lin,Jialong Ning,Judah Goldfeder,Hod Lipson*

Main category: cs.GR

TL;DR: 论文将平面连杆机构的运动合成问题转化为跨域图像生成任务，并通过共享潜在变分自编码器（VAE）探索图像生成模型在合成新运动曲线和模拟新运动学中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索图像生成模型在机械设计中的应用潜力，特别是合成未见过的运动曲线和模拟新型运动学。

Method: 使用共享潜在变分自编码器（VAE），通过RGB图像表示平面连杆机构，并将轨迹点的绘制速度编码为颜色梯度。

Result: 初步结果表明，基于图像的表示方法在生成机械设计中具有有效性，能够统一表示和合成包括转动副、滑动副以及更复杂机构在内的多种机构。

Conclusion: 图像生成框架为机械设计提供了一种统一且高效的表示和合成方法，展示了其在复杂机构设计中的潜力。

Abstract: In this paper, we formulate the problem of kinematic synthesis for planar
linkages as a cross-domain image generation task. We develop a planar linkages
dataset using RGB image representations, covering a range of mechanisms: from
simple types such as crank-rocker and crank-slider to more complex eight-bar
linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE)
is employed to explore the potential of image generative models for
synthesizing unseen motion curves and simulating novel kinematics. By encoding
the drawing speed of trajectory points as color gradients, the same
architecture also supports kinematic synthesis conditioned on both trajectory
shape and velocity profiles. We validate our method on three datasets of
increasing complexity: a standard four-bar linkage set, a mixed set of four-bar
and crank-slider mechanisms, and a complex set including multi-loop mechanisms.
Preliminary results demonstrate the effectiveness of image-based
representations for generative mechanical design, showing that mechanisms with
revolute and prismatic joints, and potentially cams and gears, can be
represented and synthesized within a unified image generation framework.

</details>


### [2] [Universal Beta Splatting](https://arxiv.org/abs/2510.03312)
*Rong Liu,Zhongpai Gao,Benjamin Planche,Meida Chen,Van Nguyen Nguyen,Meng Zheng,Anwesa Choudhuri,Terrence Chen,Yue Wang,Andrew Feng,Ziyan Wu*

Main category: cs.GR

TL;DR: Universal Beta Splatting（UBS）是一种统一框架，通过N维各向异性Beta核泛化3D高斯泼溅，用于显式辐射场渲染，支持跨空间、角度和时间维度的可控依赖性建模。


<details>
  <summary>Details</summary>
Motivation: 传统的固定高斯基元在建模复杂的空间、角度和时间维度依赖性时存在局限性。UBS旨在通过Beta核提供一种统一的表示方法，实现复杂光传输效果、各向异性视图依赖外观和场景动态建模。

Method: UBS使用N维各向异性Beta核作为通用基元，取代传统的高斯核，并通过CUDA加速实现实时渲染。Beta核能自然分解场景属性为空间、角度和时间维度，无需显式监督。

Result: UBS在静态、视图依赖和动态基准测试中一致优于现有方法，实现了实时渲染，且Beta参数能够自然地解释场景属性。

Conclusion: Beta核作为一种可扩展的通用基元，为辐射场渲染提供了高效且灵活的解决方案，UBS框架在性能和功能上均表现出色。

Abstract: We introduce Universal Beta Splatting (UBS), a unified framework that
generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for
explicit radiance field rendering. Unlike fixed Gaussian primitives, Beta
kernels enable controllable dependency modeling across spatial, angular, and
temporal dimensions within a single representation. Our unified approach
captures complex light transport effects, handles anisotropic view-dependent
appearance, and models scene dynamics without requiring auxiliary networks or
specific color encodings. UBS maintains backward compatibility by approximating
to Gaussian Splatting as a special case, guaranteeing plug-in usability and
lower performance bounds. The learned Beta parameters naturally decompose scene
properties into interpretable without explicit supervision: spatial (surface
vs. texture), angular (diffuse vs. specular), and temporal (static vs.
dynamic). Our CUDA-accelerated implementation achieves real-time rendering
while consistently outperforming existing methods across static,
view-dependent, and dynamic benchmarks, establishing Beta kernels as a scalable
universal primitive for radiance field rendering. Our project website is
available at https://rongliu-leo.github.io/universal-beta-splatting/.

</details>


### [3] [Style Brush: Guided Style Transfer for 3D Objects](https://arxiv.org/abs/2510.03433)
*Áron Samuel Kovács,Pedro Hermosilla,Renata G. Raidou*

Main category: cs.GR

TL;DR: Style Brush是一种新颖的风格迁移方法，专注于纹理网格的精细控制，使艺术家能够更好地进行风格化处理。


<details>
  <summary>Details</summary>
Motivation: 传统3D风格迁移方法缺乏对风格方向性和多风格的精细控制，限制了艺术家的创作自由度。因此，需要一种能够支持多风格、平滑过渡并简化用户交互的方法。

Method: 通过引入一种新颖的损失函数，该方法能够捕捉风格方向性，支持多风格图像或其部分，并在合成纹理中实现风格间的平滑过渡。此外，使用易于生成的引导纹理简化了用户交互。

Result: 在各种网格、风格图像和轮廓形状上的广泛评估显示了该方法的高灵活性，并展示了生成纹理的视觉吸引力。

Conclusion: Style Brush通过其创新的损失函数和用户友好的交互设计，为纹理网格风格迁移提供了高效且灵活的工具，扩展了艺术家的创作可能性。

Abstract: We introduce Style Brush, a novel style transfer method for textured meshes
designed to empower artists with fine-grained control over the stylization
process. Our approach extends traditional 3D style transfer methods by
introducing a novel loss function that captures style directionality, supports
multiple style images or portions thereof, and enables smooth transitions
between styles in the synthesized texture. The use of easily generated guiding
textures streamlines user interaction, making our approach accessible to a
broad audience. Extensive evaluations with various meshes, style images, and
contour shapes demonstrate the flexibility of our method and showcase the
visual appeal of the generated textures.

</details>


### [4] [Paris: A Decentralized Trained Open-Weight Diffusion Model](https://arxiv.org/abs/2510.03434)
*Zhiying Jiang,Raihan Seraj,Marcos Villagra,Bidhan Roy*

Main category: cs.GR

TL;DR: Paris是第一个通过完全分散式计算预训练的公开扩散模型，展示了高质量文本到图像生成无需集中协调基础设施的实现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在证明高质量文本到图像生成可以通过分散式计算实现，无需依赖集中协调的基础设施和专用GPU集群。

Method: 采用Distributed Diffusion Training框架，将数据划分为语义连贯的集群，每个专家模型独立训练其子集，并通过轻量级变压器路由器动态选择专家模型。

Result: Paris在保持生成质量的同时，减少了14倍训练数据和16倍计算资源的需求，优于之前的分散式基线。

Conclusion: Paris证明了分散式计算在高质量文本到图像生成中的可行性，消除了对专用GPU集群的依赖，为研究和商业应用提供了新的可能性。

Abstract: We present Paris, the first publicly released diffusion model pre-trained
entirely through decentralized computation. Paris demonstrates that
high-quality text-to-image generation can be achieved without centrally
coordinated infrastructure. Paris is open for research and commercial use.
Paris required implementing our Distributed Diffusion Training framework from
scratch. The model consists of 8 expert diffusion models (129M-605M parameters
each) trained in complete isolation with no gradient, parameter, or
intermediate activation synchronization. Rather than requiring synchronized
gradient updates across thousands of GPUs, we partition data into semantically
coherent clusters where each expert independently optimizes its subset while
collectively approximating the full distribution. A lightweight transformer
router dynamically selects appropriate experts at inference, achieving
generation quality comparable to centrally coordinated baselines. Eliminating
synchronization enables training on heterogeneous hardware without specialized
interconnects. Empirical validation confirms that Paris's decentralized
training maintains generation quality while removing the dedicated GPU cluster
requirement for large-scale diffusion models. Paris achieves this using
14$\times$ less training data and 16$\times$ less compute than the prior
decentralized baseline.

</details>


### [5] [Neon: Negative Extrapolation From Self-Training Improves Image Generation](https://arxiv.org/abs/2510.03597)
*Sina Alemohammad,Zhangyang Wang,Richard G. Baraniuk*

Main category: cs.GR

TL;DR: Neon是一种新的学习方法，通过反向梯度更新从自身合成的数据中学习，解决了生成模型自我训练导致的退化问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 生成AI模型的扩展受限于高质量训练数据的稀缺性。使用合成数据增强真实数据可能导致模型崩溃（MAD），Neon旨在通过反向梯度更新解决这一问题。

Method: Neon首先在自身合成的数据上微调基础模型，然后反向梯度更新，以避免模型退化。该方法利用了合成数据与真实数据梯度的反对齐特性。

Result: Neon在多种架构（扩散模型、流匹配、自回归等）和数据集（ImageNet、CIFAR-10等）上表现出色，尤其在ImageNet 256x256上将xAR-L模型的FID提升至1.02。

Conclusion: Neon是一种简单高效的方法，能够在极少量合成数据和低计算成本下显著提升生成模型的性能，并适用于多种架构和任务。

Abstract: Scaling generative AI models is bottlenecked by the scarcity of high-quality
training data. The ease of synthesizing from a generative model suggests using
(unverified) synthetic data to augment a limited corpus of real data for the
purpose of fine-tuning in the hope of improving performance. Unfortunately,
however, the resulting positive feedback loop leads to model autophagy disorder
(MAD, aka model collapse) that results in a rapid degradation in sample quality
and/or diversity. In this paper, we introduce Neon (for Negative Extrapolation
frOm self-traiNing), a new learning method that turns the degradation from
self-training into a powerful signal for self-improvement. Given a base model,
Neon first fine-tunes it on its own self-synthesized data but then,
counterintuitively, reverses its gradient updates to extrapolate away from the
degraded weights. We prove that Neon works because typical inference samplers
that favor high-probability regions create a predictable anti-alignment between
the synthetic and real data population gradients, which negative extrapolation
corrects to better align the model with the true data distribution. Neon is
remarkably easy to implement via a simple post-hoc merge that requires no new
real data, works effectively with as few as 1k synthetic samples, and typically
uses less than 1% additional training compute. We demonstrate Neon's
universality across a range of architectures (diffusion, flow matching,
autoregressive, and inductive moment matching models) and datasets (ImageNet,
CIFAR-10, and FFHQ). In particular, on ImageNet 256x256, Neon elevates the
xAR-L model to a new state-of-the-art FID of 1.02 with only 0.36% additional
training compute. Code is available at https://github.com/SinaAlemohammad/Neon

</details>


### [6] [Diverse Text-to-Image Generation via Contrastive Noise Optimization](https://arxiv.org/abs/2510.03813)
*Byungjun Kim,Soobin Um,Jong Chul Ye*

Main category: cs.GR

TL;DR: 该论文提出了一种名为对比噪声优化的方法，通过优化初始噪声来提高文本到图像扩散模型的输出多样性，同时保持高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在强文本引导下容易输出相似的图像，导致多样性不足。现有方法通常通过优化中间潜在表示或文本条件来缓解这一问题，但效果有限且对超参数敏感。

Method: 本文提出对比噪声优化方法，通过在Tweedie数据空间中定义对比损失并优化一批噪声潜在表示，来增加输出多样性。该方法通过对比优化使批次内的实例互相排斥以提高多样性，同时通过锚定参考样本来保持保真度。

Result: 实验证明，该方法在多个文本到图像骨干网络上实现了更高的质量-多样性帕累托前沿，并且对超参数选择具有较强的鲁棒性。

Conclusion: 对比噪声优化是一种简单有效的方法，能够显著提升文本到图像扩散模型的生成多样性，同时保持高保真度，无需复杂的超参数调整。

Abstract: Text-to-image (T2I) diffusion models have demonstrated impressive performance
in generating high-fidelity images, largely enabled by text-guided inference.
However, this advantage often comes with a critical drawback: limited
diversity, as outputs tend to collapse into similar modes under strong text
guidance. Existing approaches typically optimize intermediate latents or text
conditions during inference, but these methods deliver only modest gains or
remain sensitive to hyperparameter tuning. In this work, we introduce
Contrastive Noise Optimization, a simple yet effective method that addresses
the diversity issue from a distinct perspective. Unlike prior techniques that
adapt intermediate latents, our approach shapes the initial noise to promote
diverse outputs. Specifically, we develop a contrastive loss defined in the
Tweedie data space and optimize a batch of noise latents. Our contrastive
optimization repels instances within the batch to maximize diversity while
keeping them anchored to a reference sample to preserve fidelity. We further
provide theoretical insights into the mechanism of this preprocessing to
substantiate its effectiveness. Extensive experiments across multiple T2I
backbones demonstrate that our approach achieves a superior quality-diversity
Pareto frontier while remaining robust to hyperparameter choices.

</details>


### [7] [Joint Neural SDF Reconstruction and Semantic Segmentation for CAD Models](https://arxiv.org/abs/2510.03837)
*Shen Fan,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种简单、高效的数据管道，通过结合神经SDF-Based CAD部件重建网络和部件分割头，生成几何对齐的标签，适用于任意数量部件的网格。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于固定的部件分类，限制了灵活性，无法处理任意数量部件的网格。本研究旨在提供一种灵活且高效的方法，生成语义结构化的CAD网格。

Method: 结合基于神经SDF的CAD部件重建网络和部件分割头，利用PartField生成的监督进行训练，生成几何对齐的标签。

Result: 在ABC数据集上表现优异，重建（CDL1/CDL2, F1-micro, NC）和分割（mIoU, Accuracy）指标均表现良好，分割一致性高。

Conclusion: 该方法为无需依赖固定分类或精确调色板的语义结构化CAD网格提供了一种实用途径，但也指出了边界精度的局限性，并提出了未来改进方向。

Abstract: We propose a simple, data-efficient pipeline that augments an implicit
reconstruction network based on neural SDF-based CAD parts with a
part-segmentation head trained under PartField-generated supervision. Unlike
methods tied to fixed taxonomies, our model accepts meshes with any number of
parts and produces coherent, geometry-aligned labels in a single pass. We
evaluate on randomly sampled CAD meshes from the ABC dataset with intentionally
varied part cardinalities, including over-segmented shapes, and report strong
performance across reconstruction (CDL1/CDL2, F1-micro, NC) and segmentation
(mIoU, Accuracy), together with a new Segmentation Consistency metric that
captures local label smoothness. We attach a lightweight segmentation head to
the Flat-CAD SDF trunk; on a paired evaluation it does not alter reconstruction
while providing accurate part labels for meshes with any number of parts. Even
under degraded reconstructions on thin or intricate geometries, segmentation
remains accurate and label-coherent, often preserving the correct part count.
Our approach therefore offers a practical route to semantically structured CAD
meshes without requiring curated taxonomies or exact palette matches. We
discuss limitations in boundary precision, partly due to per-face supervision,
and outline paths toward boundary-aware training and higher resolution labels.

</details>


### [8] [Enhancing Foveated Rendering with Weighted Reservoir Sampling](https://arxiv.org/abs/2510.03964)
*Ville Cantory,Darya Biparva,Haoyu Tan,Tongyu Nie,John Schroeder,Ruofei Du,Victoria Interrante,Piotr Didyk*

Main category: cs.GR

TL;DR: 论文提出了一种基于加权储层采样的方法，通过重用先前帧中的高质量像素样本来提升图像的感知质量，同时减小每帧渲染的中心区域大小。


<details>
  <summary>Details</summary>
Motivation: 研究发现人眼在高偏心率下对高频信息的时空敏感性降低，而传统的中心凹渲染系统未能有效重用先前帧的高分辨率样本。此外，眼的微小跳动和注视动态变化为利用时间邻近帧的样本提供了机会。

Method: 提出了一种加权储层采样技术，高效维护先前帧中感知相关的高质量像素样本库，并将其整合到当前帧的计算中，以减少每帧的中心像素渲染量。

Result: 该方法在4K分辨率下运行时间少于1毫秒，能够显著提升感知图像质量，同时支持更高水平的中心凹渲染。

Conclusion: 该方法高效且适用于实时VR和AR中心凹渲染系统，通过时间重用像素样本，实现了更高的渲染效率和感知质量。

Abstract: Spatiotemporal sensitivity to high frequency information declines with
increased peripheral eccentricity. Foveated rendering exploits this by
decreasing the spatial resolution of rendered images in peripheral vision,
reducing the rendering cost by omitting high frequency details. As foveation
levels increase, the rendering quality is reduced, and traditional foveated
rendering systems tend not to preserve samples that were previously rendered at
high spatial resolution in previous frames. Additionally, prior research has
shown that saccade landing positions are distributed around a target location
rather than landing at a single point, and that even during fixations, eyes
perform small microsaccades around a fixation point. This creates an
opportunity for sampling from temporally neighbouring frames with differing
foveal locations to reduce the required rendered size of the foveal region
while achieving a higher perceived image quality. We further observe that the
temporal presentation of pixels frame-to-frame can be viewed as a data stream,
presenting a random sampling problem. Following this intuition, we propose a
Weighted Reservoir Sampling technique to efficiently maintain a reservoir of
the perceptually relevant high quality pixel samples from previous frames and
incorporate them into the computation of the current frame. This allows the
renderer to render a smaller region of foveal pixels per frame by temporally
reusing pixel samples that are still relevant to reconstruct a higher perceived
image quality, while allowing for higher levels of foveation. Our method
operates on the output of foveated rendering, and runs in under 1\,ms at 4K
resolution, making it highly efficient and integrable with real-time VR and AR
foveated rendering systems.

</details>


### [9] [3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG](https://arxiv.org/abs/2510.04536)
*Shun-ichiro Hayashi,Daichi Mukunoki,Tetsuya Hoshino,Satoshi Ohshima,Takahiro Katagiri*

Main category: cs.GR

TL;DR: 本文提出了一种名为3Dify的程序化3D计算机图形生成框架，利用大语言模型（LLM）通过自然语言指令生成3D内容。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过自然语言交互简化3D计算机图形的生成过程，提高用户体验和生成效率。

Method: 3Dify基于Dify开源平台，结合Model Context Protocol（MCP）和Retrieval-Augmented Generation（RAG）技术，自动化操作数字内容创作（DCC）工具，并通过Computer-Using Agent（CUA）方法处理不支持MCP的GUI操作。

Result: 框架支持用户通过选择偏好图像反馈优化生成质量，并允许本地部署LLM以减少外部API调用成本。

Conclusion: 3Dify为3D内容生成提供了一种高效、成本可控的解决方案，尤其适合需要自定义模型的用户。

Abstract: This paper proposes "3Dify," a procedural 3D computer graphics (3D-CG)
generation framework utilizing Large Language Models (LLMs). The framework
enables users to generate 3D-CG content solely through natural language
instructions. 3Dify is built upon Dify, an open-source platform for AI
application development, and incorporates several state-of-the-art LLM-related
technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented
Generation (RAG). For 3D-CG generation support, 3Dify automates the operation
of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not
support MCP-based interaction, the framework employs the Computer-Using Agent
(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,
to enhance image generation quality, 3Dify allows users to provide feedback by
selecting preferred images from multiple candidates. The LLM then learns
variable patterns from these selections and applies them to subsequent
generations. Furthermore, 3Dify supports the integration of locally deployed
LLMs, enabling users to utilize custom-developed models and to reduce both time
and monetary costs associated with external API calls by leveraging their own
computational resources.

</details>


### [10] [C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing](https://arxiv.org/abs/2510.04539)
*Zeng Tao,Zheng Ding,Zeyuan Chen,Xiang Zhang,Leizhi Li,Zhuowen Tu*

Main category: cs.GR

TL;DR: C3Editor是一个基于2D提升的3D编辑框架，通过选择性地建立视图一致的2D编辑模型来解决现有方法的多视角不一致性问题，并在定性和定量评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D提升的3D编辑方法在多视角一致性和可控性方面存在不足，C3Editor旨在通过引入视图一致性和用户可控性来解决这些问题。

Method: C3Editor通过选择GT视角及其编辑图像作为优化目标，使用分离的LoRA模块分别针对GT视角拟合和多视角一致性进行微调，以实现视图一致的2D编辑模型。

Result: 该方法在2D和3D编辑结果上表现出更高的一致性和可控性，并在定性和定量评估中优于现有方法。

Conclusion: C3Editor通过引入视图一致性和用户可控性，显著提升了基于2D提升的3D编辑的性能，为未来的3D编辑研究提供了新的方向。

Abstract: Existing 2D-lifting-based 3D editing methods often encounter challenges
related to inconsistency, stemming from the lack of view-consistent 2D editing
models and the difficulty of ensuring consistent editing across multiple views.
To address these issues, we propose C3Editor, a controllable and consistent
2D-lifting-based 3D editing framework. Given an original 3D representation and
a text-based editing prompt, our method selectively establishes a
view-consistent 2D editing model to achieve superior 3D editing results. The
process begins with the controlled selection of a ground truth (GT) view and
its corresponding edited image as the optimization target, allowing for
user-defined manual edits. Next, we fine-tune the 2D editing model within the
GT view and across multiple views to align with the GT-edited image while
ensuring multi-view consistency. To meet the distinct requirements of GT view
fitting and multi-view consistency, we introduce separate LoRA modules for
targeted fine-tuning. Our approach delivers more consistent and controllable 2D
and 3D editing results than existing 2D-lifting-based methods, outperforming
them in both qualitative and quantitative evaluations.

</details>


### [11] [Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents](https://arxiv.org/abs/2510.04637)
*Zeyi Zhang,Yanju Zhou,Heyuan Yao,Tenglong Ao,Xiaohang Zhan,Libin Liu*

Main category: cs.GR

TL;DR: 提出了一个名为Social Agent的新型框架，用于在双向对话中合成现实且情境合适的非语言行为，结合了LLM驱动的对话流和非语言行为生成模型，显著提升了交互质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决双向对话中非语言行为的现实合成问题，特别是如何生成与情境相符的协调行为。

Method: 开发了一个基于LLM的代理系统来控制对话流和行为决策，并提出了一种基于自回归扩散模型的双人手势生成模型，通过语音信号合成协调动作。

Result: 用户研究和定量评估表明，该模型显著提高了双向交互的质量，生成了自然且同步的非语言行为。

Conclusion: Social Agent框架成功实现了动态和响应式的双向互动，为非语言行为的合成提供了一种有效的方法。

Abstract: We present Social Agent, a novel framework for synthesizing realistic and
contextually appropriate co-speech nonverbal behaviors in dyadic conversations.
In this framework, we develop an agentic system driven by a Large Language
Model (LLM) to direct the conversation flow and determine appropriate
interactive behaviors for both participants. Additionally, we propose a novel
dual-person gesture generation model based on an auto-regressive diffusion
model, which synthesizes coordinated motions from speech signals. The output of
the agentic system is translated into high-level guidance for the gesture
generator, resulting in realistic movement at both the behavioral and motion
levels. Furthermore, the agentic system periodically examines the movements of
interlocutors and infers their intentions, forming a continuous feedback loop
that enables dynamic and responsive interactions between the two participants.
User studies and quantitative evaluations show that our model significantly
improves the quality of dyadic interactions, producing natural, synchronized
nonverbal behaviors.

</details>


### [12] [Bridging Text and Video Generation: A Survey](https://arxiv.org/abs/2510.04999)
*Nilay Kumar,Priyansh Bhandari,G. Maragatham*

Main category: cs.GR

TL;DR: 文本到视频（T2V）生成技术在不同领域具有潜力，但仍面临对齐、长期一致性和计算效率等挑战。本文综述了从GAN和VAE到混合DiT架构的发展，并详细讨论了数据集、训练配置和评估指标。


<details>
  <summary>Details</summary>
Motivation: 研究文本到视频生成技术的发展，解决其在质量、一致性和控制方面的挑战，并为未来研究方向提供视角。

Method: 通过系统性综述，分析了从早期GAN和VAE到混合DiT架构的演变，详细记录了数据集、训练配置和评估指标。

Result: 研究表明，DiT架构在质量和一致性方面有所突破，但仍需改进评估方法和解决现有局限性。

Conclusion: 未来研究方向包括改进评估策略、提高模型性能，并探索更广泛的应用场景。

Abstract: Text-to-video (T2V) generation technology holds potential to transform
multiple domains such as education, marketing, entertainment, and assistive
technologies for individuals with visual or reading comprehension challenges,
by creating coherent visual content from natural language prompts. From its
inception, the field has advanced from adversarial models to diffusion-based
models, yielding higher-fidelity, temporally consistent outputs. Yet challenges
persist, such as alignment, long-range coherence, and computational efficiency.
Addressing this evolving landscape, we present a comprehensive survey of
text-to-video generative models, tracing their development from early GANs and
VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these
models work, what limitations they addressed in their predecessors, and why
shifts toward new architectural paradigms were necessary to overcome challenges
in quality, coherence, and control. We provide a systematic account of the
datasets, which the surveyed text-to-video models were trained and evaluated
on, and, to support reproducibility and assess the accessibility of training
such models, we detail their training configurations, including their hardware
specifications, GPU counts, batch sizes, learning rates, optimizers, epochs,
and other key hyperparameters. Further, we outline the evaluation metrics
commonly used for evaluating such models and present their performance across
standard benchmarks, while also discussing the limitations of these metrics and
the emerging shift toward more holistic, perception-aligned evaluation
strategies. Finally, drawing from our analysis, we outline the current open
challenges and propose a few promising future directions, laying out a
perspective for future researchers to explore and build upon in advancing T2V
research and applications.

</details>


### [13] [SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder](https://arxiv.org/abs/2510.05081)
*Ronen Kamenetsky,Sara Dorfman,Daniel Garibi,Roni Paiss,Or Patashnik,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: 论文提出了一种通过文本嵌入的令牌级操作实现解耦和连续编辑的方法，提升了对大型文本到图像扩散模型的控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本提示无法充分控制图像编辑过程，尤其是在解耦和连续控制方面存在不足，因此需要一种更精细的编辑方法。

Method: 使用稀疏自编码器（SAE）识别语义隔离的维度，通过在文本嵌入中沿特定方向操作实现解耦和连续编辑。

Result: 实验表明，该方法能够跨域实现多样化的连续控制，编辑效果直观且高效。

Conclusion: 该方法无需修改扩散过程，实现了对图像合成的通用控制，适用于多种图像生成框架。

Abstract: Large-scale text-to-image diffusion models have become the backbone of modern
image editing, yet text prompts alone do not offer adequate control over the
editing process. Two properties are especially desirable: disentanglement,
where changing one attribute does not unintentionally alter others, and
continuous control, where the strength of an edit can be smoothly adjusted. We
introduce a method for disentangled and continuous editing through token-level
manipulation of text embeddings. The edits are applied by manipulating the
embeddings along carefully chosen directions, which control the strength of the
target attribute. To identify such directions, we employ a Sparse Autoencoder
(SAE), whose sparse latent space exposes semantically isolated dimensions. Our
method operates directly on text embeddings without modifying the diffusion
process, making it model agnostic and broadly applicable to various image
synthesis backbones. Experiments show that it enables intuitive and efficient
manipulations with continuous control across diverse attributes and domains.

</details>


### [14] [Pulp Motion: Framing-aware multimodal camera and human motion generation](https://arxiv.org/abs/2510.05097)
*Robin Courant,Xi Wang,David Loiseaux,Marc Christie,Vicky Kalogeiton*

Main category: cs.GR

TL;DR: 论文提出了一种文本驱动的联合生成框架，用于同步生成人类动作和相机轨迹，以保持屏幕上的一致性构图。


<details>
  <summary>Details</summary>
Motivation: 当前方法将人类动作和相机轨迹生成分开处理，忽视了电影摄影中表演与摄影之间的紧密互动，因此需要一种联合生成方法。

Method: 论文设计了一个共享潜在空间的联合自编码器，并通过辅助采样的线性变换来引导生成一致的构图模态，同时还提出了PulpMotion数据集。

Result: 实验表明，该方法在生成屏幕上一致的人类-相机动作方面具有通用性和有效性，同时在文本对齐方面也有所提升。

Conclusion: 该方法在电影构图意义上实现了最新技术水平的成果，提升了人类动作和相机轨迹生成的同步性和一致性。

Abstract: Treating human motion and camera trajectory generation separately overlooks a
core principle of cinematography: the tight interplay between actor performance
and camera work in the screen space. In this paper, we are the first to cast
this task as a text-conditioned joint generation, aiming to maintain consistent
on-screen framing while producing two heterogeneous, yet intrinsically linked,
modalities: human motion and camera trajectories. We propose a simple,
model-agnostic framework that enforces multimodal coherence via an auxiliary
modality: the on-screen framing induced by projecting human joints onto the
camera. This on-screen framing provides a natural and effective bridge between
modalities, promoting consistency and leading to more precise joint
distribution. We first design a joint autoencoder that learns a shared latent
space, together with a lightweight linear transform from the human and camera
latents to a framing latent. We then introduce auxiliary sampling, which
exploits this linear transform to steer generation toward a coherent framing
modality. To support this task, we also introduce the PulpMotion dataset, a
human-motion and camera-trajectory dataset with rich captions, and high-quality
human motions. Extensive experiments across DiT- and MAR-based architectures
show the generality and effectiveness of our method in generating on-frame
coherent human-camera motions, while also achieving gains on textual alignment
for both modalities. Our qualitative results yield more cinematographically
meaningful framings setting the new state of the art for this task. Code,
models and data are available in our
\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project
page}.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [15] [PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters](https://arxiv.org/abs/2510.03415)
*Aditya Thimmaiah,Jiyang Zhang,Jayanth Srinivasa,Junyi Jessy Li,Milos Gligoric*

Main category: cs.PL

TL;DR: 研究探讨大型语言模型（LLM）能否基于编程语言的正式语义执行程序，结果表明LLM有望成为编程语言解释器，但其语义理解仍不够稳健。


<details>
  <summary>Details</summary>
Motivation: 探索LLM是否能够仅基于编程语言的正式语义执行程序，从而实现新编程语言和特性的快速原型设计。

Method: 通过小步操作语义（SOS）和基于重写的操作语义（K-semantics）形式化IMP语言，设计了三个评估集（Human-Written、LLM-Translated和Fuzzer-Generated），并在三个任务（最终状态预测、语义规则预测和执行轨迹预测）上评估模型表现。

Result: 研究发现，尽管LLM在某些任务上表现优异，但对非标准语义的理解能力明显下降，且在高复杂度程序中的表现不如预期。

Conclusion: LLM有望成为编程语言解释器，但其对语义的稳健理解仍有待提升。研究提供了基准和支持代码以供进一步探索。

Abstract: As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.

</details>


### [16] [Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren](https://arxiv.org/abs/2510.04049)
*Xiangyu Guo,Ajay Bansal*

Main category: cs.PL

TL;DR: 本文介绍了如何在stableKanren中使用完整性约束进行数值计算，并通过SEND+MORE=MONEY谜题展示了注入启发式知识以减少求解时间的方法。


<details>
  <summary>Details</summary>
Motivation: stableKanren是miniKanren的扩展，支持稳定模型语义下的逻辑程序。本文旨在探索如何通过完整性约束实现数值计算，并在关系编程中平衡符号与数值计算。

Method: 通过三种方式扩展关系编程语言的数值计算能力：关系数表示、将数字绑定到符号以及约束存储构建。并以SEND+MORE=MONEY为例，展示程序或查询的不同写法对求解性能的影响。

Result: stableKanren的数值计算具有直观表示，避免了将所有数字绑定到符号的复杂性，语法也更简单。注入启发式知识逐步提升求解性能，并通过外部函数实现混合解决方案。

Conclusion: stableKanren在关系编程中有效结合了符号与数值计算，通过启发式知识和约束优化提高了求解效率。

Abstract: This paper presents examples of using integrity constraints in stableKanren
to encode numeric computations for problem solving. Then, we use one of the
examples to introduce multiple ways to infuse heuristic knowledge and reduce
solving time. stableKanren is an extension of miniKanren that supports normal
logic programs under stable model semantics. stableKanren further supports
numeric computation by constructing a constraint store for integrity
constraints. There are three ways to extend a relational programming language
with numeric computations: relational number representation, grounding numbers
to symbols, and constraint store construction. We demonstrate that the numeric
computations in stableKanren have a straightforward numerical representation
compared to relational number representations. More importantly, stableKanren
balances symbolic and numeric computation in relational programming by avoiding
the grounding of all numbers to symbols. Lastly, it also has simpler syntax
compared to other constraint store construction approaches. stableKanren
supports combinatorial search problem solving under a declarative generate and
test paradigm. Such a paradigm generates all possible combinations of solutions
to the problem, then applies a set of constraints to prune out the unwanted
solutions. We demonstrate that different approaches to writing programs or
queries affect the solver's performance in the SEND+MORE=MONEY puzzle. The
performance gradually improves as more heuristic knowledge is infused through
the programs or queries. Additionally, we show how to use an external function
to achieve a hybrid solution.

</details>


### [17] [Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization](https://arxiv.org/abs/2510.04890)
*Shihan Fang,Wenxin Zheng*

Main category: cs.PL

TL;DR: 论文提出了一种新颖的向量化流水线，通过SIR和VIR两种IR扩展，显著提升了编译器的自动向量化能力，实现了性能的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现代处理器依赖SIMD指令集提升并行性和计算性能，但现有编译器如LLVM和GCC未能充分利用向量化机会，原因在于向量化过程的分散性和有限的可扩展性。

Method: 引入了一种新的向量化流水线，包括SIR（编码高级结构信息）和VIR（通过数据依赖分析显式表示指令依赖关系），并基于此开发了灵活可扩展的向量化框架。

Result: 实验结果表明，该方法相比LLVM和GCC分别实现了53%和58%的性能提升。

Conclusion: 提出的向量化流水线通过改进依赖分析和扩展搜索空间，显著提升了自动向量化的范围和效率。

Abstract: Modern processors increasingly rely on SIMD instruction sets, such as AVX and
RVV, to significantly enhance parallelism and computational performance.
However, production-ready compilers like LLVM and GCC often fail to fully
exploit available vectorization opportunities due to disjoint vectorization
passes and limited extensibility. Although recent attempts in heuristics and
intermediate representation (IR) designs have attempted to address these
problems, efficiently simplifying control flow analysis and accurately
identifying vectorization opportunities remain challenging tasks.
  To address these issues, we introduce a novel vectorization pipeline
featuring two specialized IR extensions: SIR, which encodes high-level
structural information, and VIR, which explicitly represents instruction
dependencies through data dependency analysis. Leveraging the detailed
dependency information provided by VIR, we develop a flexible and extensible
vectorization framework. This approach substantially improves interoperability
across vectorization passes and expands the search space for identifying
isomorphic instructions, ultimately enhancing both the scope and efficiency of
automatic vectorization. Experimental evaluations demonstrate that our proposed
vectorization pipeline achieves significant performance improvements,
delivering speedups of up to 53% and 58% compared to LLVM and GCC,
respectively.

</details>


### [18] [concurrentKanren: miniKanren for parallel execution](https://arxiv.org/abs/2510.04994)
*Sjoerd Dost*

Main category: cs.PL

TL;DR: 本文提出了Go语言中的miniKanren并行实现，展示了其可行性和性能提升潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管并发逻辑编程出现在miniKanren之前，但其并发实现尚未充分探索。本文旨在填补这一空白。

Method: 通过利用隐式并行性，本文实现了一个并行的miniKanren系统，允许遗留程序从并行执行中受益。

Result: 实验证明了并行实现的可行性，并展示了性能改进的潜力。

Conclusion: 本研究为未来的语言无关模型奠定了基础，同时证明了并行miniKanren的实用价值。

Abstract: Concurrent logic programming predates miniKanren, but concurrent
implementations of miniKanren have remained largely unexplored. In this work we
present a parallel implementation of miniKanren in Go, demonstrating its
feasibility and potential for performance improvements. Our approach leverages
implicit parallelism allowing legacy programs to benefit from parallel
execution. We discuss implementation strategies and evaluate the impact of
parallelism, laying groundwork for future language-agnostic models.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [19] [Downside Risk-Aware Equilibria for Strategic Decision-Making](https://arxiv.org/abs/2510.03446)
*Oliver Slumbers,Benjamin Patrick Evans,Sumitra Ganesh,Leo Ardon*

Main category: cs.GT

TL;DR: 本文提出了一种新的博弈论解决方案——下行风险感知均衡（DRAE），专注于限制下行风险，同时允许上行风险，并通过多个游戏实例证明了其适用性和最优性。


<details>
  <summary>Details</summary>
Motivation: 传统的博弈论对风险的理解局限于预期收益受其他玩家行为不确定性的影响，而最近的研究虽然考虑了奖励方差，却未能区分上下行风险。许多领域（如金融）更关注下行风险（潜在损失），而上行风险（潜在收益）并非问题。

Method: 作者提出了一种基于低阶矩的新解决方案概念——下行风险感知均衡（DRAE），该方法限制下行风险但不限制上行风险，并模拟高阶风险偏好。

Result: 研究通过多个游戏实例验证了DRAE的适用性，成功找到了平衡下行风险和预期收益的均衡点，并证明了该均衡的存在性和最优性。

Conclusion: DRAE为博弈论提供了一种更贴合实际需求的解决方案，尤其是在关注下行风险的领域，如金融。

Abstract: Game theory has traditionally had a relatively limited view of risk based on
how a player's expected reward is impacted by the uncertainty of the actions of
other players. Recently, a new game-theoretic approach provides a more holistic
view of risk also considering the reward-variance. However, these
variance-based approaches measure variance of the reward on both the upside and
downside. In many domains, such as finance, downside risk only is of key
importance, as this represents the potential losses associated with a decision.
In contrast, large upside "risk" (e.g. profits) are not an issue. To address
this restrictive view of risk, we propose a novel solution concept, downside
risk aware equilibria (DRAE) based on lower partial moments. DRAE restricts
downside risk, while placing no restrictions on upside risk, and additionally,
models higher-order risk preferences. We demonstrate the applicability of DRAE
on several games, successfully finding equilibria which balance downside risk
with expected reward, and prove the existence and optimality of this
equilibria.

</details>


### [20] [On the $O(1/T)$ Convergence of Alternating Gradient Descent-Ascent in Bilinear Games](https://arxiv.org/abs/2510.03855)
*Tianlong Nan,Shuvomoy Das Gupta,Garud Iyengar,Christian Kroer*

Main category: cs.GT

TL;DR: 研究表明，在两玩家零和博弈中，交替梯度下降上升算法（AltGDA）在内部纳什均衡存在时，能以O(1/T)的收敛速度收敛。


<details>
  <summary>Details</summary>
Motivation: 交替更新策略在游戏中表现优于同时更新策略，但理论理解有限，尤其在约束条件下的研究较少。

Method: 研究在内部纳什均衡存在和不存在的情况下，AltGDA的收敛性能，并开发PEP框架优化步长和收敛速度。

Result: 内部纳什均衡存在时，AltGDA以O(1/T)收敛；不存在时，以O(1/T)局部收敛；PEP框架表明AltGDA可能优于同时GDA。

Conclusion: AltGDA在约束条件下优于同时GDA，为交替算法提供了理论基础。

Abstract: We study the alternating gradient descent-ascent (AltGDA) algorithm in
two-player zero-sum games. Alternating methods, where players take turns to
update their strategies, have long been recognized as simple and practical
approaches for learning in games, exhibiting much better numerical performance
than their simultaneous counterparts. However, our theoretical understanding of
alternating algorithms remains limited, and results are mostly restricted to
the unconstrained setting. We show that for two-player zero-sum games that
admit an interior Nash equilibrium, AltGDA converges at an $O(1/T)$ ergodic
convergence rate when employing a small constant stepsize. This is the first
result showing that alternation improves over the simultaneous counterpart of
GDA in the constrained setting. For games without an interior equilibrium, we
show an $O(1/T)$ local convergence rate with a constant stepsize that is
independent of any game-specific constants. In a more general setting, we
develop a performance estimation programming (PEP) framework to jointly
optimize the AltGDA stepsize along with its worst-case convergence rate. The
PEP results indicate that AltGDA may achieve an $O(1/T)$ convergence rate for a
finite horizon $T$, whereas its simultaneous counterpart appears limited to an
$O(1/\sqrt{T})$ rate.

</details>


### [21] [Robust Optimality of Bundling Goods Beyond Finite Variance](https://arxiv.org/abs/2510.04343)
*Tim S. G. van Eck,Pieter Kleer,Johan S. H. van Leeuwaarden*

Main category: cs.GT

TL;DR: 论文研究在商品价值独立的情况下，销售者如何在有限分布知识下选择最优机制以最大化收益，尤其是在已知均值和平均绝对偏差（MAD）时，捆绑销售仍是最优策略。


<details>
  <summary>Details</summary>
Motivation: 研究销售者在仅知道部分价值分布信息（如均值、方差或MAD）时，如何设计最优销售机制以应对不确定性，尤其是在分布分散或尾部较重的情况下。

Method: 采用分布鲁棒框架，构建一个双玩家博弈模型，销售者选择收益最大化机制，而自然选择符合有限知识的收益最小化分布，并通过分析MAD假设下的情况扩展了现有研究。

Result: 研究发现，捆绑销售在MAD假设下仍是最优机制，但销售者收益严格低于均值；同时博弈顺序对结果无影响，这一点与确定性机制和单独销售显著不同。

Conclusion: 捆绑销售价格具有普遍适用性，不仅能最大化绝对收益，还能在所有捆绑价格中优化绝对遗憾和比率目标，突出了其在分布不确定性下的鲁棒性。

Abstract: When selling many goods with independent valuations, we develop a
distributionally robust framework, consisting of a two-player game between
seller and nature. The seller has only limited knowledge about the value
distribution. The seller selects a revenue-maximizing mechanism, after which
nature chooses a revenue-minimizing distribution from all distributions that
comply with the limited knowledge. When the seller knows the mean and variance
of valuations, bundling is known to be an asymptotically optimal deterministic
mechanism, achieving a normalized revenue close to the mean. Moving beyond this
variance assumption, we assume knowledge of the mean absolute deviation (MAD),
accommodating more dispersion and heavy-tailed valuations with infinite
variance. We show for a large range of MAD values that bundling remains
optimal, but the seller can only guarantee a revenue strictly smaller than the
mean. Another noteworthy finding is indifference to the order of play, as both
the max-min and min-max versions of the problem yield identical values. This
contrasts with deterministic mechanisms and the separate sale of goods, where
the order of play significantly impacts outcomes. We further underscore the
universality of the optimal bundling price by demonstrating its efficacy in
optimizing not only absolute revenue but also the absolute regret and ratio
objective among all bundling prices

</details>


### [22] [Scale-Invariant Regret Matching and Online Learning with Optimal Convergence: Bridging Theory and Practice in Zero-Sum Games](https://arxiv.org/abs/2510.04407)
*Brian Hu Zhang,Ioannis Anagnostides,Tuomas Sandholm*

Main category: cs.GT

TL;DR: 本文提出了一种新的参数无关且尺度不变的PRM$^+$变体IREG-PRM$^+$，填补了理论与实践中零和游戏求解的差距，实现了最佳的收敛保证。


<details>
  <summary>Details</summary>
Motivation: 长期以来，零和游戏求解的理论与实践之间存在显著差距，已有方法的收敛速度不足以匹配实际中最有效的范式（如PRM$^+$）。

Method: 提出了一种名为IREG-PRM$^+$的新算法，通过保持后悔向量范数非递减的尺度不变性，并结合自适应学习率的乐观梯度下降类比。

Result: IREG-PRM$^+$实现了$T^{-1/2}$的最佳迭代收敛和$T^{-1}$的平均迭代收敛，同时在基准游戏中表现与PRM$^+$相当。

Conclusion: IREG-PRM$^+$填补了理论与实践的差距，其设计启发了后悔匹配家族与标准优化技术的联系。

Abstract: A considerable chasm has been looming for decades between theory and practice
in zero-sum game solving through first-order methods. Although a convergence
rate of $T^{-1}$ has long been established since Nemirovski's mirror-prox
algorithm and Nesterov's excessive gap technique in the early 2000s, the most
effective paradigm in practice is *counterfactual regret minimization*, which
is based on *regret matching* and its modern variants. In particular, the state
of the art across most benchmarks is *predictive* regret matching$^+$
(PRM$^+$), in conjunction with non-uniform averaging. Yet, such algorithms can
exhibit slower $\Omega(T^{-1/2})$ convergence even in self-play.
  In this paper, we close the gap between theory and practice. We propose a new
scale-invariant and parameter-free variant of PRM$^+$, which we call
IREG-PRM$^+$. We show that it achieves $T^{-1/2}$ best-iterate and $T^{-1}$
(i.e., optimal) average-iterate convergence guarantees, while also being on par
with PRM$^+$ on benchmark games. From a technical standpoint, we draw an
analogy between IREG-PRM$^+$ and optimistic gradient descent with *adaptive*
learning rate. The basic flaw of PRM$^+$ is that the ($\ell_2$-)norm of the
regret vector -- which can be thought of as the inverse of the learning rate --
can decrease. By contrast, we design IREG-PRM$^+$ so as to maintain the
invariance that the norm of the regret vector is nondecreasing. This enables us
to derive an RVU-type bound for IREG-PRM$^+$, the first such property that does
not rely on introducing additional hyperparameters to enforce smoothness.
  Furthermore, we find that IREG-PRM$^+$ performs on par with an adaptive
version of optimistic gradient descent that we introduce whose learning rate
depends on the misprediction error, demystifying the effectiveness of the
regret matching family *vis-a-vis* more standard optimization techniques.

</details>


### [23] [Bin Packing and Covering: Pushing the Frontier on the Maximin Share Fairness](https://arxiv.org/abs/2510.04425)
*Bo Li,Ankang Sun,Zunyu Wang,Yu Zhou*

Main category: cs.GT

TL;DR: 研究了一个基于装箱或覆盖项目的公平分配问题，通过最大最小份额（MMS）准则评估公平性，并提出了两种近似方法：基数和序数近似。


<details>
  <summary>Details</summary>
Motivation: 该问题的研究不仅源于实际应用需求，还为研究群体公平性提供了一个自然框架。

Method: 采用了两种近似方法：基数近似放宽了对箱子被装箱或覆盖的要求，序数近似放宽了对被装箱或覆盖的箱子数量的要求。

Result: 为所有感兴趣的模型提供了常数近似算法。

Conclusion: 研究表明，通过近似方法可以有效解决MMS准则下的公平分配问题。

Abstract: We study a fundamental fair allocation problem, where the agent's value is
determined by the number of bins either used to pack or cover the items
allocated to them. Fairness is evaluated using the maximin share (MMS)
criterion. This problem is not only motivated by practical applications, but
also serves as a natural framework for studying group fairness. As MMS is not
always satisfiable, we consider two types of approximations: cardinal and
ordinal. For cardinal approximation, we relax the requirements of being packed
or covered for a bin, and for ordinal approximation, we relax the number of
bins that are packed or covered. For all models of interest, we provide
constant approximation algorithms.

</details>


### [24] [Fairness in Repeated Matching: A Maximin Perspective](https://arxiv.org/abs/2510.04624)
*Eugene Lim,Tzeh Yuan Neoh,Nicholas Teh*

Main category: cs.GT

TL;DR: 研究一个序列决策模型，通过多轮匹配同一组代理和项目，目标是最大化最不利代理的效用（最优或每轮最优），并发现该问题通常计算不可行，但提出了近似算法和特殊情况的解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究如何在多轮匹配中优化最不利代理的效用，解决计算上的复杂性并提供可行的解决方案。

Method: 使用序列决策模型，研究最优和每轮最优的匹配问题，提出近似算法和固定参数可解算法，并分析特殊情况。

Result: 发现该问题通常计算不可行，但提供了近似算法和固定参数可解算法，且在某些特殊情况下问题可高效解决。

Conclusion: 研究揭示了多轮匹配问题的计算困难，但通过近似算法和特殊情况分析提供了可行的解决方案。

Abstract: We study a sequential decision-making model where a set of items is
repeatedly matched to the same set of agents over multiple rounds. The
objective is to determine a sequence of matchings that either maximizes the
utility of the least advantaged agent at the end of all rounds (optimal) or at
the end of every individual round (anytime optimal). We investigate the
computational challenges associated with finding (anytime) optimal outcomes and
demonstrate that these problems are generally computationally intractable.
However, we provide approximation algorithms, fixed-parameter tractable
algorithms, and identify several special cases whereby the problem(s) can be
solved efficiently. Along the way, we also establish characterizations of
Pareto-optimal/maximum matchings, which may be of independent interest to works
in matching theory and house allocation.

</details>


### [25] [A Fixed Point Framework for the Existence of EFX Allocations](https://arxiv.org/abs/2510.04915)
*S. Rasoul Etesami*

Main category: cs.GT

TL;DR: 该论文通过固定点框架研究了存在EFX分配的问题，并将其转化为连续空间的优化问题，证明了与DC规划和固定点定理的等价性，提出了一种新的计算方法。


<details>
  <summary>Details</summary>
Motivation: 研究EFX分配的存在性问题，尤其是在线性估值下，通过连接离散约束与连续优化，寻找更系统的解决方法。

Method: 使用随机舍入将离散EFX约束扩展到连续空间，将其转化为DC规划问题，并通过固定点定理证明其存在性。

Result: 证明了EFX分配的存在性与DC规划和固定点问题的等价性，并提出了一种稍加扰动后的连续映射作为代理方法。

Conclusion: 研究结果为EFX分配的存在性提供了新思路，并将离散问题与连续优化框架相结合，为高效计算提供了工具。

Abstract: We consider the problem of the existence of an envy-free allocation up to any
good (EFX) for linear valuations and establish new results by connecting this
problem to a fixed point framework. Specifically, we first use randomized
rounding to extend the discrete EFX constraints into a continuous space and
show that an EFX allocation exists if and only if the optimal value of the
continuously extended objective function is nonpositive. In particular, we
demonstrate that this optimization problem can be formulated as an
unconstrained difference of convex (DC) program, which can be further
simplified to the minimization of a piecewise linear concave function over a
polytope. Leveraging this connection, we show that the proposed DC program has
a nonpositive optimal objective value if and only if a well-defined continuous
vector map admits a fixed point. Crucially, we prove that the reformulated
fixed point problem satisfies all the conditions of Brouwer's fixed point
theorem, except that self-containedness is violated by an arbitrarily small
positive constant. To address this, we propose a slightly perturbed continuous
map that always admits a fixed point. This fixed point serves as a proxy for
the fixed point (if it exists) of the original map, and hence for an EFX
allocation through an appropriate transformation. Our results offer a new
approach to establishing the existence of EFX allocations through fixed point
theorems. Moreover, the equivalence with DC programming enables a more
efficient and systematic method for computing such allocations (if one exists)
using tools from nonlinear optimization. Our findings bridge the discrete
problem of finding an EFX allocation with two continuous frameworks: solving an
unconstrained DC program and identifying a fixed point of a continuous vector
map.

</details>
