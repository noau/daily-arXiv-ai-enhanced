{"id": "2510.00162", "categories": ["cs.GT", "cs.DM", "cs.DS", "F.2.2; G.2.m"], "pdf": "https://arxiv.org/pdf/2510.00162", "abs": "https://arxiv.org/abs/2510.00162", "authors": ["Rishi Advani", "Abolfazl Asudeh", "Mohsen Dehghankar", "Stavros Sintos"], "title": "Dynamic Necklace Splitting", "comment": "20 pages, 5 figures", "summary": "The necklace splitting problem is a classic problem in fair division with\nmany applications, including data-informed fair hash maps. We extend necklace\nsplitting to a dynamic setting, allowing for relocation, insertion, and\ndeletion of beads. We present linear-time, optimal algorithms for the two-color\ncase that support all dynamic updates. For more than two colors, we give\nlinear-time, optimal algorithms for relocation subject to a restriction on the\nnumber of agents. Finally, we propose a randomized algorithm for the two-color\ncase that handles all dynamic updates, guarantees approximate fairness with\nhigh probability, and runs in polylogarithmic time when the number of agents is\nsmall."}
{"id": "2510.00239", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.00239", "abs": "https://arxiv.org/abs/2510.00239", "authors": ["Hans Gawendowicz", "Pascal Lenzner", "Lukas Weyand"], "title": "Cooperation in Bilateral Generalized Network Creation", "comment": "Accepted at WINE 2025; full version", "summary": "Studying the impact of cooperation in strategic settings is one of the\ncornerstones of algorithmic game theory. Intuitively, allowing more cooperation\nyields equilibria that are more beneficial for the society of agents. However,\nfor many games it is still an open question how much cooperation is actually\nneeded to ensure socially good equilibria. We contribute to this research\nendeavor by analyzing the benefits of cooperation in a network formation game\nthat models the creation of communication networks via the interaction of\nselfish agents. In our game, agents that correspond to nodes of a network can\nbuy incident edges of a given weighted host graph to increase their centrality\nin the formed network. The cost of an edge is proportional to its length, and\nboth endpoints must agree and pay for an edge to be created. This setting is\nknown for having a high price of anarchy.\n  To uncover the impact of cooperation, we investigate the price of anarchy of\nour network formation game with respect to multiple solution concepts that\nallow for varying amounts of cooperation. On the negative side, we show that on\nhost graphs with arbitrary edge weights even the strongest form of cooperation\ncannot improve the price of anarchy. In contrast to this, as our main result,\nwe show that cooperation has a significant positive impact if the given host\ngraph has metric edge weights. For this, we prove asymptotically tight bounds\non the price of anarchy via a novel proof technique that might be of\nindependent interest and can be applied in other models with metric weights."}
{"id": "2510.00472", "categories": ["cs.GT", "cs.MA", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.00472", "abs": "https://arxiv.org/abs/2510.00472", "authors": ["Ben Abramowitz"], "title": "Capital Games and Growth Equilibria", "comment": null, "summary": "We examine formal games that we call \"capital games\" in which player payoffs\nare known, but their payoffs are not guaranteed to be von Neumann-Morgenstern\nutilities. In capital games, the dynamics of player payoffs determine their\nutility functions. Different players can have different payoff dynamics. We\nmake no assumptions about where these dynamics come from, but implicitly assume\nthat they come from the players' actions and interactions over time. We define\nan equilibrium concept called \"growth equilibrium\" and show a correspondence\nbetween the growth equilibria of capital games and the Nash equilibria of\nstandard games."}
{"id": "2510.00314", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.00314", "abs": "https://arxiv.org/abs/2510.00314", "authors": ["Xiaotang Zhang", "Ziyi Chang", "Qianhui Men", "Hubert P. H. Shum"], "title": "Motion In-Betweening for Densely Interacting Characters", "comment": null, "summary": "Motion in-betweening is the problem to synthesize movement between keyposes.\nTraditional research focused primarily on single characters. Extending them to\ndensely interacting characters is highly challenging, as it demands precise\nspatial-temporal correspondence between the characters to maintain the\ninteraction, while creating natural transitions towards predefined keyposes. In\nthis research, we present a method for long-horizon interaction in-betweening\nthat enables two characters to engage and respond to one another naturally. To\neffectively represent and synthesize interactions, we propose a novel solution\ncalled Cross-Space In-Betweening, which models the interactions of each\ncharacter across different conditioning representation spaces. We further\nobserve that the significantly increased constraints in interacting characters\nheavily limit the solution space, leading to degraded motion quality and\ndiminished interaction over time. To enable long-horizon synthesis, we present\ntwo solutions to maintain long-term interaction and motion quality, thereby\nkeeping synthesis in the stable region of the solution space.We first sustain\ninteraction quality by identifying periodic interaction patterns through\nadversarial learning. We further maintain the motion quality by learning to\nrefine the drifted latent space and prevent pose error accumulation. We\ndemonstrate that our approach produces realistic, controllable, and\nlong-horizon in-between motions of two characters with dynamic boxing and\ndancing actions across multiple keyposes, supported by extensive quantitative\nevaluations and user studies."}
{"id": "2510.01061", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01061", "abs": "https://arxiv.org/abs/2510.01061", "authors": ["Mark Boss", "Andreas Engelhardt", "Simon Donn√©", "Varun Jampani"], "title": "ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction", "comment": null, "summary": "Distribution matching is central to many vision and graphics tasks, where the\nwidely used Wasserstein distance is too costly to compute for high dimensional\ndistributions. The Sliced Wasserstein Distance (SWD) offers a scalable\nalternative, yet its Monte Carlo estimator suffers from high variance,\nresulting in noisy gradients and slow convergence. We introduce Reservoir SWD\n(ReSWD), which integrates Weighted Reservoir Sampling into SWD to adaptively\nretain informative projection directions in optimization steps, resulting in\nstable gradients while remaining unbiased. Experiments on synthetic benchmarks\nand real-world tasks such as color correction and diffusion guidance show that\nReSWD consistently outperforms standard SWD and other variance reduction\nbaselines. Project page: https://reservoirswd.github.io/"}
{"id": "2510.01176", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.01176", "abs": "https://arxiv.org/abs/2510.01176", "authors": ["Jiye Lee", "Chenghui Li", "Linh Tran", "Shih-En Wei", "Jason Saragih", "Alexander Richard", "Hanbyul Joo", "Shaojie Bai"], "title": "Audio Driven Real-Time Facial Animation for Social Telepresence", "comment": "SIGGRAPH Asia 2025. Project page:\n  https://jiyewise.github.io/projects/AudioRTA", "summary": "We present an audio-driven real-time system for animating photorealistic 3D\nfacial avatars with minimal latency, designed for social interactions in\nvirtual reality for anyone. Central to our approach is an encoder model that\ntransforms audio signals into latent facial expression sequences in real time,\nwhich are then decoded as photorealistic 3D facial avatars. Leveraging the\ngenerative capabilities of diffusion models, we capture the rich spectrum of\nfacial expressions necessary for natural communication while achieving\nreal-time performance (<15ms GPU time). Our novel architecture minimizes\nlatency through two key innovations: an online transformer that eliminates\ndependency on future inputs and a distillation pipeline that accelerates\niterative denoising into a single step. We further address critical design\nchallenges in live scenarios for processing continuous audio signals\nframe-by-frame while maintaining consistent animation quality. The versatility\nof our framework extends to multimodal applications, including semantic\nmodalities such as emotion conditions and multimodal sensors with head-mounted\neye cameras on VR headsets. Experimental results demonstrate significant\nimprovements in facial animation accuracy over existing offline\nstate-of-the-art baselines, achieving 100 to 1000 times faster inference speed.\nWe validate our approach through live VR demonstrations and across various\nscenarios such as multilingual speeches."}
