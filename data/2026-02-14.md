<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 19]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Filmsticking++: Rapid Film Sticking for Explicit Surface Reconstruction](https://arxiv.org/abs/2602.11433)
*Pengfei Wang,Jian Liu,Qiujie Dong,Shiqing Xin,Yuanfeng Zhou,Changhe Tu,Caiming Zhang,Wenping Wang*

Main category: cs.GR

TL;DR: Filmsticking++是一种新的显式表面重建方法，突破了欧几里得距离的限制，实现了对所有点的精准插值，并提高了计算效率、鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于RVD的filmsticking方法在深层内部空腔情况下无法插值所有点，且存在拓扑错误问题，这促使研究者开发了Filmsticking++以解决这些问题。

Method: Filmsticking++采用加权距离的受限功率图（RPD）替代欧几里得距离，并利用虚拟点加速外部中轴的排出，从而重建无法向的点云表面。

Result: 相对于现有最优方法，Filmsticking++显著降低了计算成本，提高了鲁棒性和可扩展性，并确保所有点都能被插值。

Conclusion: Filmsticking++通过创新性的加权距离和虚拟点技术，成功解决了现有方法在深层空腔中的局限，为显式表面重建提供了更高效的解决方案。

Abstract: Explicit surface reconstruction aims to generate a surface mesh that exactly interpolates a given point cloud. This requirement is crucial when the point cloud must lie non-negotiably on the final surface to preserve sharp features and fine geometric details. However, the task becomes substantially challenging with low-quality point clouds, due to inherent reconstruction ambiguities compounded by combinatorial complexity. A previous method using filmsticking technique by iteratively compute restricted Voronoi diagram to address these issues, ensures to produce a watertight manifold, setting a new benchmark as the state-of-the-art (SOTA) technique. Unfortunately, RVD-based filmsticking is inability to interpolate all points in the case of deep internal cavities, resulting in very likely is the generation of faulty topology. The cause of this issue is that RVD-based filmsticking has inherent limitations due to Euclidean distance metrics. In this paper, we extend the filmsticking technique, named Filmsticking++. Filmsticking++ reconstructing an explicit surface from points without normals. On one hand, Filmsticking++ break through the inherent limitations of Euclidean distance by employing a weighted-distance-based Restricted Power Diagram, which guarantees that all points are interpolated. On the other hand, we observe that as the guiding surface increasingly approximates the target shape, the external medial axis is gradually expelled outside the guiding surface. Building on this observation, we propose placing virtual sites inside the guiding surface to accelerate the expulsion of the external medial axis from its interior. To summarize, contrary to the SOTA method, Filmsticking++ demonstrates multiple benefits, including decreases computational cost, improved robustness and scalability.

</details>


### [2] [LeafFit: Plant Assets Creation from 3D Gaussian Splatting](https://arxiv.org/abs/2602.11577)
*Chang Luo,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: LeafFit是一个将3D高斯点云（3DGS）转换为可编辑、实例化网格资产的管道，解决了3DGS在游戏生产中内存占用高和缺乏网格拓扑的问题。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯点云（3DGS）在游戏生产中存在内存占用高和缺乏网格拓扑的问题，导致其无法直接用于工作流程。LeafFit通过利用叶片形状的重复性，将其转换为可编辑的网格资产。

Method: LeafFit首先从无结构的3DGS中分割叶片，可选用户交互作为备用；接着选择一个代表性叶片组并转换为薄而锐利的网格模板；最后通过可微分移动最小二乘（MLS）变形将模板拟合到其他叶片上。

Result: 实验表明，相比现有基线方法，LeafFit在分割质量和变形精度上表现更优，同时显著减少数据量并支持参数级编辑。

Conclusion: LeafFit成功解决了3DGS在游戏生产中的兼容性问题，提供了一种高效且可编辑的植物资产生成方法。

Abstract: We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing.

</details>


### [3] [Variation-aware Flexible 3D Gaussian Editing](https://arxiv.org/abs/2602.11638)
*Hao Qin,Yukai Sun,Meng Wang,Ming Kong,Mengxu Lu,Qiang Zhu*

Main category: cs.GR

TL;DR: VF-Editor是一种通过预测属性变化进行原生编辑的新方法，解决了3D高斯溅射间接编辑中的不一致性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯溅射间接编辑方法在2D空间中编辑后投影回3D，导致视图不一致且编辑过程不够灵活高效。

Method: 设计了VF-Editor，通过新型变化预测器以前馈方式预测属性变化，编码输入生成变化场，并利用并行解码函数迭代推断3D高斯的属性变化。

Result: 在公开和私有数据集上的实验验证了间接编辑方法的固有局限性，并证明了VF-Editor的有效性和灵活性。

Conclusion: VF-Editor能够灵活地从多种2D编辑器和策略中提取知识，实现高效的3D领域知识转移。

Abstract: Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.

</details>


### [4] [OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars](https://arxiv.org/abs/2602.11693)
*Zehao Xia,Yiqun Wang,Zhengda Lu,Kai Liu,Jun Xiao,Peter Wonka*

Main category: cs.GR

TL;DR: OMEGA-Avatar是一种创新的前馈框架，可从单张图像生成360°完整、可动画化的3D高斯头部模型，解决了现有方法无法同时满足三个关键需求的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的方法只能同时满足生成前馈、360°完整或可动画化中的两个需求，无法全面满足用户对高质量3D头像的需求。因此，提出了OMEGA-Avatar框架以弥补这一缺陷。

Method: OMEGA-Avatar通过两个关键模块实现：1）语义感知的网格变形模块，优化带有头发的FLAME头部模型；2）多视角特征散布模块，构建共享的规范UV表示。

Result: 实验表明，OMEGA-Avatar在360°全头部完整性和身份保持方面显著优于现有基线，达到了最先进的性能。

Conclusion: OMEGA-Avatar首次实现了从前馈框架中生成通用、360°完整且可动画化的3D高斯头部模型，为高质量3D头像生成提供了新的解决方案。

Abstract: Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.

</details>


### [5] [Iskra: A System for Inverse Geometry Processing](https://arxiv.org/abs/2602.12105)
*Ana Dodik,Ahmed H. Mahmoud,Justin Solomon*

Main category: cs.GR

TL;DR: 提出了一种用于对几何处理问题解进行微分的系统，支持多种几何算法，并与机器学习框架兼容，为逆几何处理应用开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 几何处理算法的微分在逆几何处理应用中具有重要意义，但现有方法需要重新公式化算法或运行效率低下。本文旨在解决这一问题。

Method: 结合了局部-全局和ADMM求解器等快速问题特定方案，采用散射-聚集方法与基于张量的工作流，并利用伴随方法高效生成反向传播。

Result: 通过微分平均曲率流、谱共形参数化、测地距离计算等应用验证了系统的可用性和性能，实现低实现成本、快速运行和低内存需求。

Conclusion: 该系统允许从业者直接对现有几何处理算法进行微分，无需重新公式化，显著降低了实现难度和计算资源消耗。

Abstract: We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris](https://arxiv.org/abs/2602.11481)
*Minda Li,Bhaskar Krishnamachari*

Main category: cs.PL

TL;DR: GPT-5在低资源或不常用语言（如Idris）中的表现较弱，但通过迭代反馈驱动的提示方法，尤其是结合编译错误的策略，可以显著提升其解决问题的能力。


<details>
  <summary>Details</summary>
Motivation: GPT-5在高资源语言中表现优异，但在低资源或不常用语言中的能力尚未充分探索，因此研究其是否能在陌生语言（如Idris）中通过反馈驱动的提示方法提升表现。

Method: 采用多种细化策略，包括基于平台反馈的迭代提示、添加文档和错误分类指南，以及结合本地编译错误和失败测试用例的迭代提示。

Result: 通过结合编译错误的策略，GPT-5的表现从最初的22/56提升至54/56解决了Idris的题目，效果显著。

Conclusion: 尽管GPT-5在低资源环境中初始表现不佳，但结构化的编译器级别反馈可以显著提升其能力。

Abstract: GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Computing stable limit cycles of learning in games](https://arxiv.org/abs/2602.11315)
*Oliver Biggar,Christos Papadimitriou*

Main category: cs.GT

TL;DR: 论文研究了多玩家游戏中周期性行为的稳定性问题，特别针对虚构博弈和复制动力学这两种动态，提出了一个多项式时间的光谱稳定性测试，并给出了结构上的稳定性充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决多玩家游戏中周期性行为的稳定性问题，尤其是虚构博弈和复制动力学这两种动态下的稳定性。

Method: 论文采用了多项式时间的光谱稳定性测试方法，并结合游戏偏好图的结构条件来分析周期性行为的稳定性。

Result: 研究结果表明，周期性行为在虚构博弈和复制动力学下的稳定性等价，且偏好图中的汇平衡是一种稳定的结构条件。

Conclusion: 论文结论强调了周期性行为在多玩家游戏中的稳定性可以通过偏好图的结构条件来预测，并扩展了Shapley和Jordan的经典理论。

Abstract: Many well-studied learning dynamics, such as fictitious play and the replicator, are known to not converge in general $N$-player games. The simplest mode of non-convergence is cyclical or periodic behavior. Such cycles are fundamental objects, and have inspired a number of significant insights in the field, beginning with the pioneering work of Shapley (1964). However a central question remains unanswered: which cycles are stable under game dynamics? In this paper we give a complete and computational answer to this question for the two best-studied dynamics, fictitious play/best-response dynamics and the replicator dynamic. We show (1) that a periodic sequence of profiles is stable under one of these dynamics if and only it is stable under the other, and (2) we provide a polynomial-time spectral stability test to determine whether a given periodic sequence is stable under either dynamic. Finally, we give an entirely `structural' sufficient condition for stability: every cycle that is a sink equilibrium of the preference graph of the game is stable, and moreover it is an attractor of the replicator dynamic. This result generalizes the famous theorems of Shapley (1964) and Jordan (1993), and extends the frontier of recent work relating the preference graph to the replicator attractors.

</details>


### [8] [When agents choose bundles autonomously: guarantees beyond discrepancy](https://arxiv.org/abs/2602.11330)
*Sushmita Gupta,Pallavi Jain,Sanjay Seetharaman,Meirav Zehavi*

Main category: cs.GT

TL;DR: 本文研究了不可分割物品在代理之间的公平分配问题，目标是使每位代理的价值保证接近其比例份额。研究发现，分区的高价值保证受到$\Theta(\sqrt{n})$差异屏障的限制，但通过动态分区策略和限制估值类别的分析，实现了更强的个体保证。


<details>
  <summary>Details</summary>
Motivation: 研究不可分割物品公平分配的动机是为每位代理提供接近其比例份额的价值保证，同时克服高价值分区的渐进差异限制。

Method: 采用动态分区策略，代理按优先级顺序依次自主选择最高价值的部分。此外，分析了三种受限估值类别：共同物品排序、价值多样性限制和超图限制。

Result: 通过动态分区策略，实现了每位代理的价值保证为$\mathsf{PROP} - \mathcal{O}{(\log n)}$。在受限估值类别中，进一步展示了更强的保证。

Conclusion: 研究成功突破了$\Theta(\sqrt{n})$的差异屏障，并通过受限估值类别的分析，提供了更强的公平分配保证。

Abstract: We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent.
  We prove that partitions where \emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $Θ(\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time.
  Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\mathsf{PROP} - \mathcal{O}{(\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded.

</details>


### [9] [Maximizing Index Diversity in Committee Elections](https://arxiv.org/abs/2602.11400)
*Paula Böhm,Robert Bredereck,Till Fluschnik*

Main category: cs.GT

TL;DR: 引入了两种考虑委员会多样性的多赢选举模型，分别通过评分函数和满意度约束来最大化多样性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在多赢选举中考虑候选人的多样性，通过不同模型和指标量化多样性并分析其计算复杂性。

Method: 提出两种模型：一种是基于评分函数的多样性最大化，另一种是基于满意度的多样性最大化；使用生态学中的多样性指标并提出新指标，分析其性质。

Result: 定义了多样性指标的性质，测试了不同指标的表现，并分析了两种模型的计算复杂性以及满意度约束对多样性的影响。

Conclusion: 通过两种模型和新提出的多样性指标，为多赢选举中的多样性问题提供了理论和实证分析基础。

Abstract: We introduce two models of multiwinner elections with approval preferences and labelled candidates that take the committee's diversity into account. One model aims to find a committee with maximal diversity given a scoring function (e.g. of a scoring-based voting rule) and a lower bound for the score to be respected. The second model seeks to maximize the diversity given a minimal satisfaction for each agent to be respected. To measure the diversity of a committee, we use multiple diversity indices used in ecology and introduce one new index. We define (desirable) properties of diversity indices, test the indices considered against these properties, and characterize the new index. We analyze the computational complexity of computing a committee for both models and scoring functions of well-known voting rules, and investigate the influence of weakening the score or satisfaction constraints on the diversity empirically.

</details>


### [10] [The Distortion of Prior-Independent b-Matching Mechanisms](https://arxiv.org/abs/2602.11404)
*Ioannis Caragiannis,Vasilis Gkatzelis,Sebastian Homrighausen*

Main category: cs.GT

TL;DR: 该论文研究了在多智能体分配物品的情境下，基于序数偏好的机制性能。通过随机生成偏好，分析了期望扭曲度和扭曲差距，并提出了一种达到最优扭曲度的机制。


<details>
  <summary>Details</summary>
Motivation: 传统的序数机制研究多集中在最坏情况分析上，结果过于悲观。本文旨在通过随机生成偏好，更准确地评估机制的期望性能。

Method: 论文首先证明了在任何序数机制下，扭曲度的下限为e/(e-1)。随后提出了一种即使在智能体价值分布未知的情况下也能达到最优扭曲度的机制，并进一步优化了扭曲差距。

Result: 研究表明，提出的序数机制达到了最优扭曲度e/(e-1)，并在扭曲差距上接近最优值1.076。此外，还评估了一种单次结构机制的性能。

Conclusion: 论文通过随机偏好分析改进了序数机制的评估方法，并提出了一种高效的机制设计，为实际应用提供了理论支持。

Abstract: In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure.

</details>


### [11] [Fair Data-Exchange Mechanisms](https://arxiv.org/abs/2602.11417)
*Rashida Hakim,Christos Papadimitriou,Mihalis Yannakakis*

Main category: cs.GT

TL;DR: 该研究提出了一种在无货币转移情况下战略代理之间公平交换数据的合约，以防止搭便车行为，并通过超模博弈结构确保纳什均衡的存在和帕累托最优性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于研究联盟和医疗合作等领域，这些领域中货币转移不可行或受限，需要一种机制既能促进数据共享，又能防止代理因搭便车而减少数据收集投入。

Method: 方法是通过引入一种简单的公平交换合约，每对代理交换的数据点数量等于两者收集水平的最小值。研究表明，这种合约诱导的游戏在策略空间变换下是超模的。

Result: 结果显示，纯纳什均衡存在且形成格子结构，可以以代理数量的二次时间计算。最大均衡在自然执行假设下是可真实实现的，并且在所有策略配置中全局帕累托最优。

Conclusion: 结论是公平交换机制在无支付情况下提供了一种可扩展且激励相容的数据交换方式，适用于图限制模型的扩展情况。

Abstract: We study data exchange among strategic agents without monetary transfers, motivated by domains such as research consortia and healthcare collaborations where payments are infeasible or restricted. The central challenge is to reap the benefits of data-sharing while preventing free-riding that would otherwise lead agents to under invest in data collection. We introduce a simple fair-exchange contract in which, for every pair of agents, each agent receives exactly as many data points as it provides, equal to the minimum of their two collection levels. We show that the game induced by this contract is supermodular under a transformation of the strategy space. This results in a clean structure: pure Nash equilibria exist, they form a lattice, and can be computed in time quadratic in the number of agents. In addition, the maximal equilibrium is truthfully implementable under natural enforcement assumptions and is globally Pareto-optimal across all strategy profiles. In a graph-restricted variant of the model supermodularity fails, but an adaptation of the construction still yields efficiently computable pure Nash equilibria and Pareto-optimal outcomes. Overall, fair exchange provides a tractable and incentive-aligned mechanism for data exchange in the absence of payments.

</details>


### [12] [Dueling over Multiple Pieces of Dessert](https://arxiv.org/abs/2602.11486)
*Simina Brânzei,Reed Phillips*

Main category: cs.GT

TL;DR: 研究Alice和Bob在多轮公平分割蛋糕的博弈中，Alice如何通过策略最小化后悔值，尤其关注她对Bob估值信息的掌握程度对后悔值的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在重复公平分割的动态博弈中，Alice如何通过有限的分割策略降低后悔值，以及在Bob的策略复杂性不同时，她的最优学习策略是什么。

Method: 分析Alice使用不同分割策略（如可测分割和有限切割）时的后悔值表现，并结合Bob的学习率（公共或私有）情景，建立相应的多项式或亚线性后悔界。

Result: 研究发现，使用有限切割可使学习变得可行，而Bob的学习率公开与否直接影响Alice的后悔值表现，私有学习率下她仅能实现亚线性后悔。

Conclusion: 研究表明，Alice的策略和学习效果高度依赖Bob的策略信息，有限切割为她提供了可行的学习路径，但在Bob私有学习率下无法实现多项式后悔。

Abstract: We study the dynamics of repeated fair division between two players, Alice and Bob, where Alice partitions a cake into two subsets and Bob chooses his preferred one over $T$ rounds. Alice aims to minimize her regret relative to the Stackelberg value -- the maximum utility she could achieve if she knew Bob's private valuation.
  We show that if Alice uses arbitrary measurable partitions, achieving strongly sublinear regret is impossible; she suffers a regret of $Ω\Bigl(\frac{T}{\log^2 T}\Bigr)$ regret even against a myopic Bob. However, when Alice uses at most $k$ cuts, the learning landscape becomes tractable. We analyze Alice's performance based on her knowledge of Bob's strategic sophistication (his regret budget). When Bob's learning rate is public, we establish a hierarchy of polynomial regret bounds determined by $k$ and Bob's regret budget. In contrast, when this learning rate is private, Alice can universally guarantee $O\Bigl(\frac{T}{\log T}\Bigr)$ regret, but any attempt to secure a polynomial rate $O(T^β)$ (for $β< 1$) leaves her vulnerable to incurring strictly linear regret against some Bob.
  Finally, as a corollary of our online learning dynamics, we characterize the randomized query complexity of finding approximate Stackelberg allocations with a constant number of cuts in the Robertson-Webb model.

</details>


### [13] [Searching for Optimal Prices in Two-Sided Markets](https://arxiv.org/abs/2602.11691)
*Yiding Feng,Mengfan Ma,Bo Peng,Zongqi Wan*

Main category: cs.GT

TL;DR: 研究双边市场中在线定价，通过不同定价机制（单一定价、双重定价、分段定价）最大化贸易收益或利润，分析了遗憾边界并提出了改进算法。


<details>
  <summary>Details</summary>
Motivation: 探讨在双边市场中如何通过动态定价机制最大化贸易收益或利润，特别是面对不同市场规模和机制复杂性时的挑战。

Method: 设计了基于双重定价机制的算法以优化利润，并引入分段定价机制以解决广义贸易中的低效配对问题。此外，扩展到上下文环境，考虑交易者成本和价值的线性依赖。

Result: 在利润最大化中，双重定价机制可实现$O(n^2 \log\log T)$遗憾；贸易收益最大化中，分段定价机制能将遗憾降至$O(n^2 \log\log T + n^3)$。扩展研究还给出了上下文环境下的遗憾边界。

Conclusion: 研究明确了双边动态定价中可学习和不可学习区域的界限，表明适度的定价表达性提升可以克服根本性困难。

Abstract: We investigate online pricing in two-sided markets where a platform repeatedly posts prices based on binary accept/reject feedback to maximize gains-from-trade (GFT) or profit. We characterize the regret achievable across three mechanism classes: Single-Price, Two-Price, and Segmented-Price.
  For profit maximization, we design an algorithm using Two-Price Mechanisms that achieves $O(n^2 \log\log T)$ regret, where $n$ is the number of traders.
  For GFT maximization, the optimal regret depends critically on both market size and mechanism expressiveness. Constant regret is achievable in bilateral trade, but this guarantee breaks down as the market grows: even in a one-seller, two-buyer market, any algorithm using Single-Price Mechanisms suffers regret at least $Ω\!\big(\frac{\log\log T}{\log\log\log\log T}\big)$, and we provide a nearly matching $O(\log\log T)$ upper bound for general one-to-many markets. In full many-to-many markets, we prove that Two-Price Mechanisms inevitably incur linear regret $Ω(T)$ due to a \emph{mismatch phenomenon}, wherein inefficient pairings prevent near-optimal trade. To overcome this barrier, we introduce \emph{Segmented-Price Mechanisms}, which partition traders into groups and assign distinct prices per group. Using this richer mechanism, we design an algorithm achieving $O(n^2 \log\log T + n^3)$ regret for GFT maximization.
  Finally, we extend our results to the contextual setting, where traders' costs and values depend linearly on observed $d$-dimensional features that vary across rounds, obtaining regret bounds of $O(n^2 d \log\log T + n^2 d \log d)$ for profit and $O(n^2 d^2 \log T)$ for GFT. Our work delineates sharp boundaries between learnable and unlearnable regimes in two-sided dynamic pricing and demonstrates how modest increases in pricing expressiveness can circumvent fundamental hardness barriers.

</details>


### [14] [Achieving EF1 and Epistemic EFX Guarantees Simultaneously](https://arxiv.org/abs/2602.11732)
*Hannaneh Akrami,Ryoga Mahara,Kurt Mehlhorn,Nidhi Rathi*

Main category: cs.GT

TL;DR: 该论文研究了不可分物品在有加性估值代理之间的公平分配问题，解决了EF1和EEFX同时存在的开放性问题，并引入了新的公平概念。


<details>
  <summary>Details</summary>
Motivation: 研究不可分物品的公平分配问题，尤其是解决EFX问题和其松弛问题EF1与EEFX的同时存在性问题，这是该领域的核心开放问题之一。

Method: 引入了一个新的基于份额的公平概念，称为strong EEFX share，证明了其与EF1的兼容性，从而实现了EF1和EEFX的同时存在。

Result: 证明了对于加性估值，总是存在一个同时满足EF1（更严格的EFL）和EEFX的分配方案，解决了Akrami和Rathi（2025）提出的主要开放问题。

Conclusion: 通过引入新的公平概念并证明其兼容性，论文不仅解决了EF1和EEFX同时存在的开放性问题，也为最终解决EFX问题迈出了重要一步。

Abstract: We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved.
  In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.

</details>


### [15] [Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition](https://arxiv.org/abs/2602.11835)
*Yutong Chao,Jalal Etesami*

Main category: cs.GT

TL;DR: 本文研究了在一般和游戏中找到纳什均衡的问题，重点探讨了一阶梯度算法及其变体的性能，提出了一个新的n-sided PL条件来分析收敛性，并提出了适用于标准梯度下降法失效场景的改进算法。


<details>
  <summary>Details</summary>
Motivation: 纳什均衡在博弈论中具有重要意义，但现有的一阶梯度算法在多玩家非凸游戏中的收敛性分析不足，特别是标准梯度下降法在某些场景下无法收敛。

Method: 通过扩展梯度优势和多重凸性的概念，提出了n-sided PL条件，用以分析梯度下降算法的收敛性。在标准方法失效时，提出了改进的梯度下降变体。

Result: 提出的n-sided PL条件适用于多类非凸函数，改进的梯度下降算法在标准方法失效的场景下能够收敛到纳什均衡。

Conclusion: 本文为分析多玩家非凸游戏中的纳什均衡提供了新的理论工具和算法改进，扩展了梯度下降方法的适用范围。

Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-Łojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.

</details>


### [16] [Scale-Invariant Fast Convergence in Games](https://arxiv.org/abs/2602.11857)
*Taira Tsuchiya,Haipeng Luo,Shinji Ito*

Main category: cs.GT

TL;DR: 论文提出了一种既尺度无关（无需效用先验知识）又尺度不变（效用正缩放不影响）的学习动态，用于两类博弈：双人零和博弈和多人一般和博弈，分别实现快速收敛到纳什均衡和相关均衡。


<details>
  <summary>Details</summary>
Motivation: 博弈中的尺度不变性是一个广受重视的理想属性，但现有的快速收敛保证通常需要效用尺度的先验知识。本文的目标是开发无需先验信息且尺度不变的学习动态。

Method: 基于乐观跟随正则化领导者（OFTRL）的方法，采用自适应学习率并结合对手梯度向量的平方路径长度，以及一种新的停止时间分析技术。多人博弈中通过“加倍裁剪”技术实现尺度无关学习。

Result: 对于双人零和博弈，外部遗憾界限为$\\tilde{O}(A_{\\mathrm{diff}})$；对于多人博弈，交换遗憾界限为$O(U_{\\mathrm{max}} \\log T)$，分别实现$\\tilde{O}(A_{\\mathrm{diff}} / T)$和$O(U_{\\mathrm{max}} \\log T / T)$的收敛速率。

Conclusion: 提出的学习动态同时满足尺度无关和尺度不变性，为博弈学习提供了高效的收敛保证，适用于不同类型的博弈场景。

Abstract: Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\tilde{O}(A_{\mathrm{diff}})$, where $A_{\mathrm{diff}}$ is the payoff range, which implies an $\tilde{O}(A_{\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\mathrm{max}} \log T)$, where $U_{\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\mathrm{max}} \log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.

</details>


### [17] [Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection](https://arxiv.org/abs/2602.11914)
*Hanbing Liu,Ningyuan Li,Weian Li,Qi Qi,Changyuan Yu*

Main category: cs.GT

TL;DR: 研究了带有预选和分数线公布的排名竞赛，分析了预选参赛者在不同目标和规模下的均衡行为，发现最优竞赛形式为赢家通吃。


<details>
  <summary>Details</summary>
Motivation: 探讨预选和分数线公布在排名竞赛中对公平性和参赛者行为的影响，以优化竞赛设计。

Method: 通过均衡行为分析，研究了预选参赛者在不同目标和规模下的表现，并比较了有无预选的最高个人表现。

Result: 赢家通吃是最优竞赛形式；最高个人表现的最优预选规模为两人，而总表现的预选规模不影响结果；有预选的最高个人表现是无预选的4/3倍。

Conclusion: 预选和分数线公布在竞赛设计中有显著影响，赢家通吃是最优形式，预选规模的选择取决于竞赛目标。

Abstract: Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.

</details>


### [18] [Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions](https://arxiv.org/abs/2602.11959)
*Moshe Babaioff,Yiding Feng,Zihan Luo*

Main category: cs.GT

TL;DR: 论文探讨了在多单位拍卖中，VCG拍卖的竞争复杂度问题，并通过更强的分布假设和拍卖机制改进显著减少了达到（接近）最优收入所需的额外买家数量。


<details>
  <summary>Details</summary>
Motivation: 传统研究（Bulow和Klemperer，1996）表明，VCG拍卖在某些情况下需要添加大量额外买家才能达到最优收入，这在实际应用中可能效率不足。本文旨在探索如何在更少额外买家条件下实现这一目标。

Method: 研究了两种方法：一是在MHR分布等更强假设下优化竞争复杂度；二是分析了一种限制供应的VCG拍卖变体，通过先验独立方式限制销售单位数量。

Result: 结果表明，在MHR分布下，只需添加约0.4447倍原买家数量的额外买家即可达到最优收入；同时，限制供应的VCG变体进一步减少了所需额外买家数量。

Conclusion: 更强的分布假设和拍卖机制改进可以有效降低实现（接近）最优收入所需的竞争复杂度，为拍卖设计提供了新思路。

Abstract: The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the "competition complexity" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions.
  First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\leq n$, and any target fraction of the optimal revenue.
  Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers.
  Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.

</details>


### [19] [Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare](https://arxiv.org/abs/2602.11967)
*Moshe Babaioff,Sijin Chen,Zhaohua Chen,Yiding Feng*

Main category: cs.GT

TL;DR: 论文研究了贝叶斯单物品拍卖中卖方与买方收益的帕累托前沿，证明了在特定分布假设下，帕累托最优机制是带有保留价的第二价格拍卖，并通过合作博弈论分析了两种公平性解决方案的性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解拍卖中卖方与买方收益的权衡，特别是在独立同分布估值下，帕累托前沿的结构及其公平性与效率的权衡。

Method: 方法包括对帕累托前沿的完整结构刻画，并利用合作博弈论中的Kalai-Smorodinsky解和Nash解进行分析。

Result: 结果表明，在满足特定分布假设时，两种解决方案在大市场中均能实现接近最优的福利；但在最坏情况下，两种方案的性能差异显著。

Conclusion: 结论强调了公平性与效率权衡对分布结构的敏感性，并认为Kalai-Smorodinsky解是更适用于非对称双边市场的公平性标准。

Abstract: A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve.
  Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.

</details>


### [20] [Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089)
*Kehang Zhu,Lithium Thain,Vivian Tsai,James Wexler,Crystal Qian*

Main category: cs.GT

TL;DR: 研究通过在线实验（N=243）探讨AI助手在多人讨价还价游戏中的三种交互模式（主动建议、反应反馈、自主执行）对用户和群体结果的影响，发现用户偏好与性能表现不一致，且自主执行模式能为非使用者带来积极外部效应。


<details>
  <summary>Details</summary>
Motivation: 随着AI在社交场景中的普及，理解代理与用户的互动对设计提升个人和群体结果的系统至关重要。

Method: 实验通过随机顺序呈现三种LLM辅助模式（主动建议、反应反馈、自主执行），参与者决定是否使用AI辅助，并测量其表现与偏好。

Result: 尽管用户偏好主动建议模式，但在自主执行模式下获得最高个体收益；此外，自主执行模式还通过提升报价质量为非用户带来积极外部效应。

Conclusion: 研究发现代理能力与群体福利之间存在差距，建议设计具有内生参与机制的交互模式以最大化自动化辅助对人类福利的积极影响。

Abstract: As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach}, or autonomous execution by a \textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \textit{Advisor} modality, participants achieve the highest mean individual gains with the \textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.

</details>


### [21] [Anonymous Contracts](https://arxiv.org/abs/2602.12118)
*Johannes Brustle,Paul Duetting,Stefano Leonardi,Tomasz Ponitka,Matteo Russo*

Main category: cs.GT

TL;DR: 研究多智能体协作问题中的匿名合同，分析其平衡性、效率性以及在有限责任和无限责任下的不同表现。


<details>
  <summary>Details</summary>
Motivation: 尽管理论上可以通过歧视性合同提取全部社会福利，但这种合同可能被认为不公平。因此，研究匿名合同以确保对智能体的公平性。

Method: 引入并分析匿名合同，其中支付仅取决于成功总数，并识别均匀匿名合同作为子类以保证唯一平衡。

Result: 匿名合同在有限责任下对社会福利的近似性能有限，而移除有限责任能显著提高性能并提取全部社会福利。

Conclusion: 匿名合同在平衡性和公平性上表现良好，但性能取决于责任限制和成功概率分布。

Abstract: We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents.
  We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees.
  In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.

</details>


### [22] [Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria](https://arxiv.org/abs/2602.12181)
*Anas Barakat,Ioannis Panageas,Antonios Varvitsiotis*

Main category: cs.GT

TL;DR: 本文提出了广义效用马尔可夫博弈（GUMGs），扩展了凸马尔可夫博弈（cMGs），并证明了纳什均衡与投影伪梯度动力学的固定点重合。


<details>
  <summary>Details</summary>
Motivation: cMGs虽然扩展了多智能体学习的建模范围，但其理论基础，尤其是纳什均衡的结构和学习算法的保证，尚未被充分理解。本文旨在填补GUMGs的这些理论空白。

Method: 作者证明了在GUMGs中，纳什均衡与投影伪梯度动力学的固定点重合，并通过新的“智能体梯度支配”性质实现了这一点。此外，他们还设计了无模型的策略梯度算法。

Result: 研究结果表明，GUMGs中存在马尔可夫完美均衡，并为潜在GUMGs提供了精确梯度下近似纳什均衡的迭代复杂度保证，以及在生成模型和策略设置中的样本复杂度界限。

Conclusion: 本文首次对共同利益的cMGs进行了理论分析，扩展了此前仅局限于零和cMGs的研究，为GUMGs提供了全面的理论基础。

Abstract: Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.

</details>


### [23] [Bandit Learning in Matching Markets with Interviews](https://arxiv.org/abs/2602.12224)
*Amirmahdi Mirfakhar,Xuchuang Wang,Mengfan Xu,Hedyeh Beyhaghi,Mohammad Hajiesmaili*

Main category: cs.GT

TL;DR: 本文研究了匹配市场中的强盗学习问题，通过将面试建模为低成本的偏好提示，允许企业方的不确定性，并设计了在不同设置下的高效算法。


<details>
  <summary>Details</summary>
Motivation: 匹配市场中的参与者通常只能通过有限的面试获取噪声信息，难以准确评估偏好，且企业方可能对自身偏好也不确定，导致早期雇佣错误。

Method: 文章提出了一种框架，允许企业通过战略延迟（不雇佣）来纠正错误，并设计了集中式和分散式设置下的算法。

Result: 所有设置下的算法均实现了时间独立的遗憾，显著优于现有不稳定匹配学习算法的O(log T)遗憾界限。在结构化市场中，分散式性能与集中式相近。

Conclusion: 该研究通过引入面试作为偏好提示，解决了匹配市场中的学习问题，并展示了在不确定性和分散环境下的高效学习策略。

Abstract: Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.

</details>


### [24] [Adjusted Winner: from Splitting to Selling](https://arxiv.org/abs/2602.12231)
*Robert Bredereck,Bin Sun,Eyal Briman,Nimrod Talmon*

Main category: cs.GT

TL;DR: 论文提出了一种扩展的调整赢家（AW）方法，允许在预算约束下出售部分资源并重新分配收益，以实现尽可能公平的分配。


<details>
  <summary>Details</summary>
Motivation: AW方法在不可分割资源分配中存在依赖分割资源的局限性，可能导致实际操作复杂化，因此需要一种改进方法来解决这一问题。

Method: 通过扩展AW方法，引入资源出售和收益再分配机制，并对公平性和无嫉妒性进行公理化分析。此外，论文还定义了组合问题，分析了计算复杂性，并设计了FPTAS来解决固有难解性。

Result: 论文提出了理论框架，并通过计算机模拟验证了方法的有效性。

Conclusion: 扩展的AW方法在预算约束下实现了更公平的资源分配，并通过理论分析和模拟验证了其可行性和有效性。

Abstract: The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.

</details>


### [25] [Is Online Linear Optimization Sufficient for Strategic Robustness?](https://arxiv.org/abs/2602.12253)
*Yang Cai,Haipeng Luo,Chen-Yu Wei,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文研究了在重复贝叶斯第一价格拍卖中的投标算法，证明了简单的在线线性优化（OLO）算法可以实现战略稳健性和无遗憾性，且在已知和未知价值分布情况下均有效。


<details>
  <summary>Details</summary>
Motivation: 现有的最优遗憾投标算法在战略稳健性方面研究不足，而基于无交换遗憾的算法虽具备稳健性但效率和计算性能较差。本文旨在探索简单OLO算法是否能同时实现这两项理想特性。

Method: 通过构造简单的黑盒缩减方法，将任何OLO算法转换为战略稳健的无遗憾投标算法，适用于已知和未知价值分布的拍卖场景。

Result: 在已知价值分布情况下，算法实现了$O(\sqrt{T \log K})$遗憾度和战略稳健性；在未知分布情况下，算法实现了高概率$O(\sqrt{T (\log K+\log(T/\delta)})$遗憾度，并移除了密度有界假设。

Conclusion: 研究表明，简单的OLO算法足以实现战略稳健性和无遗憾性，且在统计和计算效率上优于现有方法。

Abstract: We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.
  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\sqrt{T \log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\sqrt{T (\log K+\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].

</details>
