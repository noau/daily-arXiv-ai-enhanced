<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 19]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Filmsticking++: Rapid Film Sticking for Explicit Surface Reconstruction](https://arxiv.org/abs/2602.11433)
*Pengfei Wang,Jian Liu,Qiujie Dong,Shiqing Xin,Yuanfeng Zhou,Changhe Tu,Caiming Zhang,Wenping Wang*

Main category: cs.GR

TL;DR: Filmsticking++是一种改进的显式表面重建技术，通过加权距离限制功率图解决了欧几里得距离的内在限制，确保所有点都能插值，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 显式表面重建需要确保给定点云完全插值到最终表面上，但在低质量点云情况下，任务变得极具挑战性。传统RVD-based filmsticking方法存在无法插值所有点的问题，尤其是对深内部空洞的情况。

Method: Filmsticking++采用了加权距离限制功率图，突破了欧几里得距离的限制，并通过在引导表面内部放置虚拟站点来加速外部中轴的排出。

Result: Filmsticking++不仅插值了所有点，还降低了计算成本，提高了鲁棒性和可扩展性，优于现有的SOTA方法。

Conclusion: Filmsticking++通过创新的加权距离限制功率图和虚拟站点技术，解决了传统方法的局限性，为显式表面重建提供了高效且可靠的解决方案。

Abstract: Explicit surface reconstruction aims to generate a surface mesh that exactly interpolates a given point cloud. This requirement is crucial when the point cloud must lie non-negotiably on the final surface to preserve sharp features and fine geometric details. However, the task becomes substantially challenging with low-quality point clouds, due to inherent reconstruction ambiguities compounded by combinatorial complexity. A previous method using filmsticking technique by iteratively compute restricted Voronoi diagram to address these issues, ensures to produce a watertight manifold, setting a new benchmark as the state-of-the-art (SOTA) technique. Unfortunately, RVD-based filmsticking is inability to interpolate all points in the case of deep internal cavities, resulting in very likely is the generation of faulty topology. The cause of this issue is that RVD-based filmsticking has inherent limitations due to Euclidean distance metrics. In this paper, we extend the filmsticking technique, named Filmsticking++. Filmsticking++ reconstructing an explicit surface from points without normals. On one hand, Filmsticking++ break through the inherent limitations of Euclidean distance by employing a weighted-distance-based Restricted Power Diagram, which guarantees that all points are interpolated. On the other hand, we observe that as the guiding surface increasingly approximates the target shape, the external medial axis is gradually expelled outside the guiding surface. Building on this observation, we propose placing virtual sites inside the guiding surface to accelerate the expulsion of the external medial axis from its interior. To summarize, contrary to the SOTA method, Filmsticking++ demonstrates multiple benefits, including decreases computational cost, improved robustness and scalability.

</details>


### [2] [LeafFit: Plant Assets Creation from 3D Gaussian Splatting](https://arxiv.org/abs/2602.11577)
*Chang Luo,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: LeafFit是一种将3D高斯喷洒（3DGS）植物模型转换为可编辑、实例化网格资产的流水线，提高了其在游戏生产中的兼容性。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽然能精确捕捉复杂植物叶片结构，但其高内存占用和缺乏网格拓扑使其无法直接用于传统游戏生产流程。LeafFit旨在解决这一问题。

Method: 方法包括从无结构的3DGS中分割叶片，选择代表性叶片组作为模板，并通过可微分Moving Least Squares（MLS）变形将模板拟合到其他叶片上。运行时通过顶点着色器高效计算变形。

Result: 实验表明，LeafFit在分割质量和变形精度上优于现有基线方法，同时显著减少数据大小并支持参数级编辑。

Conclusion: LeafFit成功地将3DGS转换为适合游戏生产的网格资产，具有高效性和编辑灵活性。

Abstract: We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing.

</details>


### [3] [Variation-aware Flexible 3D Gaussian Editing](https://arxiv.org/abs/2602.11638)
*Hao Qin,Yukai Sun,Meng Wang,Ming Kong,Mengxu Lu,Qiang Zhu*

Main category: cs.GR

TL;DR: VF-Editor通过前馈方式预测高斯基元的属性变化，实现了3D高斯喷绘的直接编辑，解决了间接编辑方法的视图不一致性和灵活性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯喷绘间接编辑方法在2D渲染空间中进行编辑后再投影回3D，导致视图不一致性和编辑灵活性受限。VF-Editor旨在通过直接编辑高斯基元解决这些问题。

Method: VF-Editor设计了一个新型的变化预测器，通过从2D编辑知识中提炼信息，生成变化场，并使用两个可学习的并行解码函数迭代推断3D高斯的属性变化。

Result: 在公共和私有数据集上的实验表明，该方法克服了间接编辑的固有局限性，验证了其高效性和灵活性。

Conclusion: VF-Editor通过统一的设计实现了从多样2D编辑器和策略到3D领域的灵活知识转移，显著提升了编辑效率和灵活性。

Abstract: Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.

</details>


### [4] [OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars](https://arxiv.org/abs/2602.11693)
*Zehao Xia,Yiqun Wang,Zhengda Lu,Kai Liu,Jun Xiao,Peter Wonka*

Main category: cs.GR

TL;DR: OMEGA-Avatar是一种前馈框架，首次实现了从单张图像同时生成可泛化、360°完整且可动画的3D高斯头部模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能同时满足360°全头和可动画性中的两点，而无法兼顾三点。为此，提出了OMEGA-Avatar来解决这一限制。

Method: 通过语义感知网格变形模块优化带头发的FLAME头部，并结合多视角特征喷溅模块构建共享的UV表示，确保360°一致性和高频细节。

Result: OMEGA-Avatar在实验中表现优异，不仅在360°全头完整性上优于现有基线，还能在不同视角下保持身份一致性。

Conclusion: OMEGA-Avatar是首个同时满足前馈性、360°完整性和可动画性的方法，显著提升了单图像生成3D头像的逼真度和实用性。

Abstract: Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.

</details>


### [5] [Iskra: A System for Inverse Geometry Processing](https://arxiv.org/abs/2602.12105)
*Ana Dodik,Ahmed H. Mahmoud,Justin Solomon*

Main category: cs.GR

TL;DR: 提出了一种通过几何处理问题解决方案进行微分的系统，支持多种几何算法，并与机器学习框架兼容，为逆几何处理应用开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 几何处理算法的微分对于逆几何处理应用具有重要意义，但现有方法往往需要重新设计算法，增加了实现难度和计算成本。

Method: 结合散点-聚集方法和基于张量的工作流，利用伴随方法对用户指定的命令式代码进行高效反向传播。

Result: 通过平均曲率流、光谱共形参数化等应用验证了系统的易用性和高效性，相较于非定制化的微分优化工具，实现了更低的实现成本和内存需求。

Conclusion: 该系统为几何处理算法的微分提供了高效且通用的解决方案，显著降低了实现难度和计算资源需求。

Abstract: We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris](https://arxiv.org/abs/2602.11481)
*Minda Li,Bhaskar Krishnamachari*

Main category: cs.PL

TL;DR: 该研究探讨了GPT-5在低资源或小众语言（如Idris）中的能力，通过反馈驱动的提示策略显著提升了其表现。


<details>
  <summary>Details</summary>
Motivation: GPT-5在主流编程语言（如Python、C++、Java）中表现优异，但在小众或低资源语言中的能力尚未充分研究。本研究旨在验证GPT-5能否通过反馈驱动的提示策略在小众语言Idris中取得类似效果。

Method: 研究首先通过零样本提示测试GPT-5在Idris语言中的初始表现，随后评估了多种改进策略，包括基于平台反馈的迭代提示、增加文档和错误分类指南的提示，以及利用本地编译错误和失败测试案例的迭代提示。

Result: 最初的零样本提示下，GPT-5仅解决了56个Idris练习中的22个；而通过引入本地编译错误的反馈循环，其表现显著提升至54个练习的成功解决。

Conclusion: 研究表明，尽管大型语言模型在低资源环境中可能表现不佳，但结构化的编译器级别反馈可以显著释放其潜力。

Abstract: GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Computing stable limit cycles of learning in games](https://arxiv.org/abs/2602.11315)
*Oliver Biggar,Christos Papadimitriou*

Main category: cs.GT

TL;DR: 本文解决了N人游戏中循环行为的稳定性问题，提出了虚构博弈和复制动态的稳定性测试方法，并给出了结构化的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究游戏动态中循环行为的稳定性问题，填补了此前Shapley和Jordan研究中未解决的问题。

Method: 通过对虚构博弈和复制动态的分析，提供多项式时间的谱稳定性测试，并引入偏好图的结构化条件。

Result: 研究发现周期性序列在两种动态下的稳定性一致，且所有作为偏好图汇平衡的循环均是稳定的。

Conclusion: 研究结果扩展了Shapley和Jordan的经典理论，并为游戏动态稳定性提供了新的结构化条件。

Abstract: Many well-studied learning dynamics, such as fictitious play and the replicator, are known to not converge in general $N$-player games. The simplest mode of non-convergence is cyclical or periodic behavior. Such cycles are fundamental objects, and have inspired a number of significant insights in the field, beginning with the pioneering work of Shapley (1964). However a central question remains unanswered: which cycles are stable under game dynamics? In this paper we give a complete and computational answer to this question for the two best-studied dynamics, fictitious play/best-response dynamics and the replicator dynamic. We show (1) that a periodic sequence of profiles is stable under one of these dynamics if and only it is stable under the other, and (2) we provide a polynomial-time spectral stability test to determine whether a given periodic sequence is stable under either dynamic. Finally, we give an entirely `structural' sufficient condition for stability: every cycle that is a sink equilibrium of the preference graph of the game is stable, and moreover it is an attractor of the replicator dynamic. This result generalizes the famous theorems of Shapley (1964) and Jordan (1993), and extends the frontier of recent work relating the preference graph to the replicator attractors.

</details>


### [8] [When agents choose bundles autonomously: guarantees beyond discrepancy](https://arxiv.org/abs/2602.11330)
*Sushmita Gupta,Pallavi Jain,Sanjay Seetharaman,Meirav Zehavi*

Main category: cs.GT

TL;DR: 该论文研究了不可分割物品的公平分配问题，旨在克服渐进限制的$Θ(\sqrt{n})$差异障碍，并提出了多项改进方法，包括在线分配和特定估值类的更强保证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决不可分割物品在多个代理间的公平分配问题，确保每个代理获得接近其比例份额的高价值保证。

Method: 论文通过在线分配和特定估值类的限制（如公共物品顺序、价值多样性限制和超图结构），设计了多项式时间算法，以克服渐进限制的差异障碍。

Result: 研究结果表明，在线分配方法可为每个代理提供至少$\mathsf{PROP} - \mathcal{O}{(\log n)}$的价值保证，并在三种受限估值类中实现更强的个体保证。

Conclusion: 论文得出结论，通过特定方法和限制条件，可以显著提高公平分配中的个体价值保证，打破了渐进差异障碍的限制。

Abstract: We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent.
  We prove that partitions where \emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $Θ(\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time.
  Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\mathsf{PROP} - \mathcal{O}{(\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded.

</details>


### [9] [Maximizing Index Diversity in Committee Elections](https://arxiv.org/abs/2602.11400)
*Paula Böhm,Robert Bredereck,Till Fluschnik*

Main category: cs.GT

TL;DR: 介绍了两种考虑多样性的多赢选举模型，分别通过最大化多样性和满足最小满意度来解决选举中的多样性问题，并提出了一种新的多样性指数。


<details>
  <summary>Details</summary>
Motivation: 解决多赢选举中对候选人多样性的需求，结合生态学中的多样性指数来衡量委员会多样性。

Method: 提出了两种模型，一种基于评分函数和分数下限最大化多样性，另一种基于最小满意度最大化多样性；同时引入新的多样性指数并分析其性质。

Result: 分析了模型的复杂性，并通过实验研究了削弱评分或满意度约束对多样性的影响。

Conclusion: 提出的模型和多样性指数有效解决了选举中的多样性问题，并提供了量化多样性的新方法。

Abstract: We introduce two models of multiwinner elections with approval preferences and labelled candidates that take the committee's diversity into account. One model aims to find a committee with maximal diversity given a scoring function (e.g. of a scoring-based voting rule) and a lower bound for the score to be respected. The second model seeks to maximize the diversity given a minimal satisfaction for each agent to be respected. To measure the diversity of a committee, we use multiple diversity indices used in ecology and introduce one new index. We define (desirable) properties of diversity indices, test the indices considered against these properties, and characterize the new index. We analyze the computational complexity of computing a committee for both models and scoring functions of well-known voting rules, and investigate the influence of weakening the score or satisfaction constraints on the diversity empirically.

</details>


### [10] [The Distortion of Prior-Independent b-Matching Mechanisms](https://arxiv.org/abs/2602.11404)
*Ioannis Caragiannis,Vasilis Gkatzelis,Sebastian Homrighausen*

Main category: cs.GT

TL;DR: 本文研究了在物品分配问题中基于代理序数偏好的机制性能，提出了最优失真度和失真差距的分析方法。


<details>
  <summary>Details</summary>
Motivation: 传统的最坏情况分析导致了对序数机制性能的悲观结论，本文通过随机生成代理偏好的方式评估机制的预期性能，旨在提供更现实的性能指标。

Method: 本文首先证明了序数机制在特定条件下的最优失真度下限，并提出了一个能达到最优失真度的序数机制，即使代理的偏好分布未知。此外，还提出了一个具有近最优失真差距的机制。

Result: 结果表明，最优失真度为$e/(e-1)\approx 1.582$，提出的机制能实现这一目标，且在某些条件下失真差距可优化至1.076。

Conclusion: 本文证明了在随机偏好生成下序数机制的性能极限，并提出了高效的实现方法，为未来的机制设计提供了理论基础。

Abstract: In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure.

</details>


### [11] [Fair Data-Exchange Mechanisms](https://arxiv.org/abs/2602.11417)
*Rashida Hakim,Christos Papadimitriou,Mihalis Yannakakis*

Main category: cs.GT

TL;DR: 论文提出了一种无货币转移的战略代理数据交换机制，通过公平交换合约防止搭便车行为，实现高效且激励相容的数据共享。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于研究联盟和医疗合作等领域，这些领域因支付不可行或受限，需要在不使用货币的情况下实现数据共享，同时避免代理的搭便车行为。

Method: 方法是通过引入公平交换合约，要求每对代理交换的数据点数量等于两者收集水平的最小值，从而诱导游戏成为超模游戏，确保纯纳什均衡的存在性和可计算性。

Result: 结果显示，该合约在游戏结构上具有超模性，纯纳什均衡存在且构成格结构，最大均衡在自然执行假设下可真实实施且全局帕累托最优。在图的受限模型中，虽然超模性失效，但调整后的结构仍能高效计算均衡和帕累托最优解。

Conclusion: 结论是公平交换合约在无支付环境下提供了可计算且激励相容的数据共享机制，有效解决了数据共享的挑战。

Abstract: We study data exchange among strategic agents without monetary transfers, motivated by domains such as research consortia and healthcare collaborations where payments are infeasible or restricted. The central challenge is to reap the benefits of data-sharing while preventing free-riding that would otherwise lead agents to under invest in data collection. We introduce a simple fair-exchange contract in which, for every pair of agents, each agent receives exactly as many data points as it provides, equal to the minimum of their two collection levels. We show that the game induced by this contract is supermodular under a transformation of the strategy space. This results in a clean structure: pure Nash equilibria exist, they form a lattice, and can be computed in time quadratic in the number of agents. In addition, the maximal equilibrium is truthfully implementable under natural enforcement assumptions and is globally Pareto-optimal across all strategy profiles. In a graph-restricted variant of the model supermodularity fails, but an adaptation of the construction still yields efficiently computable pure Nash equilibria and Pareto-optimal outcomes. Overall, fair exchange provides a tractable and incentive-aligned mechanism for data exchange in the absence of payments.

</details>


### [12] [Dueling over Multiple Pieces of Dessert](https://arxiv.org/abs/2602.11486)
*Simina Brânzei,Reed Phillips*

Main category: cs.GT

TL;DR: 研究了Alice和Bob之间在多轮公平分割问题中的动态博弈，探讨了Alice在最小化后悔值和Bob的策略复杂性之间寻找平衡的方法及其结果。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探索在重复公平分割问题中，Alice如何通过策略性地分割资源和应对Bob的不同学习策略，以最小化自己的后悔值，尤其是在Bob的估值和学习速率不同情况下的表现。

Method: 研究方法包括分析Alice使用不同分割策略（如任意可测分割或有限分割）时的后悔值，以及Bob的学习速率（公开或私有）对Alice策略的影响。

Result: 研究结果表明，当Alice使用任意可测分割时，无法实现强次线性后悔值；而当使用有限分割时，后悔值界可由Bob的学习速率和分割方式决定。此外，当Bob的学习速率私有时，Alice只能保证某种形式的后悔值界限。

Conclusion: 结论是Alice的策略和学习鲍勃的动态行为密切相关，且分割方式和Bob的私有信息对后悔值的界限有显著影响。同时，该研究还为近似Stackelberg分配的随机查询复杂度提供了新的见解。

Abstract: We study the dynamics of repeated fair division between two players, Alice and Bob, where Alice partitions a cake into two subsets and Bob chooses his preferred one over $T$ rounds. Alice aims to minimize her regret relative to the Stackelberg value -- the maximum utility she could achieve if she knew Bob's private valuation.
  We show that if Alice uses arbitrary measurable partitions, achieving strongly sublinear regret is impossible; she suffers a regret of $Ω\Bigl(\frac{T}{\log^2 T}\Bigr)$ regret even against a myopic Bob. However, when Alice uses at most $k$ cuts, the learning landscape becomes tractable. We analyze Alice's performance based on her knowledge of Bob's strategic sophistication (his regret budget). When Bob's learning rate is public, we establish a hierarchy of polynomial regret bounds determined by $k$ and Bob's regret budget. In contrast, when this learning rate is private, Alice can universally guarantee $O\Bigl(\frac{T}{\log T}\Bigr)$ regret, but any attempt to secure a polynomial rate $O(T^β)$ (for $β< 1$) leaves her vulnerable to incurring strictly linear regret against some Bob.
  Finally, as a corollary of our online learning dynamics, we characterize the randomized query complexity of finding approximate Stackelberg allocations with a constant number of cuts in the Robertson-Webb model.

</details>


### [13] [Searching for Optimal Prices in Two-Sided Markets](https://arxiv.org/abs/2602.11691)
*Yiding Feng,Mengfan Ma,Bo Peng,Zongqi Wan*

Main category: cs.GT

TL;DR: 研究了双边市场中在线定价问题，通过二元反馈优化收益或利润，提出了三种定价机制的后悔边界，并证明分段定价机制可突破学习困难。


<details>
  <summary>Details</summary>
Motivation: 双边市场的动态定价对平台收益和交易增益至关重要，但现有方法在机制表达性和市场扩展性上存在局限，亟需新的解决方案。

Method: 设计了基于双价机制和分段定价机制的算法，分别优化利润和交易增益，并在不同市场规模和情境下分析其有效性。

Result: 在利润最大化上实现了$O(n^2 \log\log T)$后悔边界；交易增益优化中，分段定价机制突破了线性后悔的限制，达到了$O(n^2 \log\log T + n^3)$。

Conclusion: 研究表明定价机制的适度扩展可突破学习困难，为双边市场动态定价提供了理论和算法基础。

Abstract: We investigate online pricing in two-sided markets where a platform repeatedly posts prices based on binary accept/reject feedback to maximize gains-from-trade (GFT) or profit. We characterize the regret achievable across three mechanism classes: Single-Price, Two-Price, and Segmented-Price.
  For profit maximization, we design an algorithm using Two-Price Mechanisms that achieves $O(n^2 \log\log T)$ regret, where $n$ is the number of traders.
  For GFT maximization, the optimal regret depends critically on both market size and mechanism expressiveness. Constant regret is achievable in bilateral trade, but this guarantee breaks down as the market grows: even in a one-seller, two-buyer market, any algorithm using Single-Price Mechanisms suffers regret at least $Ω\!\big(\frac{\log\log T}{\log\log\log\log T}\big)$, and we provide a nearly matching $O(\log\log T)$ upper bound for general one-to-many markets. In full many-to-many markets, we prove that Two-Price Mechanisms inevitably incur linear regret $Ω(T)$ due to a \emph{mismatch phenomenon}, wherein inefficient pairings prevent near-optimal trade. To overcome this barrier, we introduce \emph{Segmented-Price Mechanisms}, which partition traders into groups and assign distinct prices per group. Using this richer mechanism, we design an algorithm achieving $O(n^2 \log\log T + n^3)$ regret for GFT maximization.
  Finally, we extend our results to the contextual setting, where traders' costs and values depend linearly on observed $d$-dimensional features that vary across rounds, obtaining regret bounds of $O(n^2 d \log\log T + n^2 d \log d)$ for profit and $O(n^2 d^2 \log T)$ for GFT. Our work delineates sharp boundaries between learnable and unlearnable regimes in two-sided dynamic pricing and demonstrates how modest increases in pricing expressiveness can circumvent fundamental hardness barriers.

</details>


### [14] [Achieving EF1 and Epistemic EFX Guarantees Simultaneously](https://arxiv.org/abs/2602.11732)
*Hannaneh Akrami,Ryoga Mahara,Kurt Mehlhorn,Nidhi Rathi*

Main category: cs.GT

TL;DR: 该论文研究了在不可分割物品分配中，如何同时满足EF1和EEFX两种公平性概念的问题，并通过引入新概念‘strong EEFX share’，证明了在加法估值下存在同时满足两者的分配方案。


<details>
  <summary>Details</summary>
Motivation: EFX的存在性是该领域最重要的开放问题之一，尽管EF1和EEFX各自已被证明存在，但能否同时满足两者仍未解决。本文旨在填补这一空白。

Method: 作者引入了一个新的公平性概念‘strong EEFX share’，它隐含了EEFX的可行性，并证明了这一概念与EF1兼容。

Result: 论文证明了在加法估值下，存在一个分配方案同时满足EF1（更严格的EFL）和EEFX，解决了Akrami和Rathi提出的主要开放问题。

Conclusion: 这一研究不仅解决了EF1和EEFX的同时存在性问题，还引入了新的公平性概念，为最终解决EFX问题迈出了重要一步。

Abstract: We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved.
  In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.

</details>


### [15] [Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition](https://arxiv.org/abs/2602.11835)
*Yutong Chao,Jalal Etesami*

Main category: cs.GT

TL;DR: 研究了在一般和博弈中寻找纳什均衡（NE）的问题，提出了一种新的条件（n-sided PL条件）以分析梯度下降算法的收敛性，并讨论了标准方法失效时的改进算法。


<details>
  <summary>Details</summary>
Motivation: 在一般和博弈中，传统的梯度下降方法可能无法收敛到纳什均衡，因此需要新的条件和算法来解决这一问题。

Method: 引入n-sided PL条件，扩展梯度优势条件（PL条件）和多凸性概念，并提出改进的梯度下降算法（如BCD）。

Result: 研究表明，满足n-sided PL条件的非凸函数类可以被有效分析，且改进算法在某些情况下能收敛到纳什均衡。

Conclusion: 提出的n-sided PL条件和改进算法为分析非凸函数及其收敛性提供了新工具，并在实验中验证了其有效性。

Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-Łojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.

</details>


### [16] [Scale-Invariant Fast Convergence in Games](https://arxiv.org/abs/2602.11857)
*Taira Tsuchiya,Haipeng Luo,Shinji Ito*

Main category: cs.GT

TL;DR: 提出了无需效用尺度先验知识的尺度无关且尺度不变的动态学习算法，适用于二人零和博弈和多玩家一般和博弈，实现了快速收敛到纳什均衡或相关均衡。


<details>
  <summary>Details</summary>
Motivation: 解决现有学习算法在博弈中需要先验效用尺度信息的问题，提出一种尺度无关且尺度不变的学习动态。

Method: 基于乐观跟随正则化领导者（OFTRL）的自适应学习率方法，结合对手梯度向量的平方路径长度，以及新的停止时间分析技术。

Result: 在二人零和博弈中实现了$\tilde{O}(A_{\mathrm{diff}} / T)$的收敛速率；在多玩家一般和博弈中实现了$O(U_{\mathrm{max}} \log T / T)$的收敛速率。

Conclusion: 提出的尺度无关和尺度不变算法在多种博弈场景中实现了快速收敛，无需先验效用信息。

Abstract: Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\tilde{O}(A_{\mathrm{diff}})$, where $A_{\mathrm{diff}}$ is the payoff range, which implies an $\tilde{O}(A_{\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\mathrm{max}} \log T)$, where $U_{\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\mathrm{max}} \log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.

</details>


### [17] [Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection](https://arxiv.org/abs/2602.11914)
*Hanbing Liu,Ningyuan Li,Weian Li,Qi Qi,Changyuan Yu*

Main category: cs.GT

TL;DR: 研究了带有短名单和截止分数披露的排名竞赛，分析了短名单参赛者的均衡行为，并比较了两种目标函数下的最优竞赛形式。


<details>
  <summary>Details</summary>
Motivation: 短名单是竞赛中常见的预选方法，但如何确保公平性和最优表现尚未充分研究，因此本文探讨了这一问题。

Method: 通过建模和分析，研究了短名单竞赛中的均衡行为，并比较了两种目标函数（最高个体表现和总表现）下的最优竞赛形式。

Result: 对于最高个体表现，最优短名单大小为两人；而对于总表现，短名单大小不影响结果。与无短名单相比，最高个体表现提高了4/3倍。

Conclusion: 短名单竞赛的最优形式取决于目标函数，最高个体表现的最优短名单大小为两人，而总表现不受短名单大小影响。

Abstract: Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.

</details>


### [18] [Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions](https://arxiv.org/abs/2602.11959)
*Moshe Babaioff,Yiding Feng,Zihan Luo*

Main category: cs.GT

TL;DR: 在多单位拍卖中，通过更强的分布假设或改良的VCG拍卖机制，可以显著减少为实现（接近）最优收入所需的额外买家数量。


<details>
  <summary>Details</summary>
Motivation: Bulow和Klemperer（1996）的经典结果表明，在某些条件下，VCG拍卖需要增加m个额外买家才能达到最优收入。本文旨在探索在更强的分布假设或改良的拍卖机制下，是否能减少这一竞争复杂度。

Method: 首先，在更强的分布假设（如MHR分布）下，证明了VCG拍卖的竞争复杂度显著下降；其次，分析了一种供应限制的VCG拍卖变体，该变体通过限制售卖单位数量来减少所需额外买家。

Result: 在MHR分布下，额外买家数量可以降至0.4447n；供应限制的VCG拍卖变体进一步减少了所需额外买家数量。两种方法均显著降低了竞争复杂度。

Conclusion: 本文通过更强的分布假设和改良的拍卖机制，成功降低了VCG拍卖的竞争复杂度，为实现最优收入提供了更高效的方法。

Abstract: The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the "competition complexity" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions.
  First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\leq n$, and any target fraction of the optimal revenue.
  Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers.
  Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.

</details>


### [19] [Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare](https://arxiv.org/abs/2602.11967)
*Moshe Babaioff,Sijin Chen,Zhaohua Chen,Yiding Feng*

Main category: cs.GT

TL;DR: 研究了贝叶斯单物品拍卖中真实机制的帕累托前沿，揭示了在独立同分布买家估值下帕累托最优机制的结构，并分析了两类帕累托最优解的性能差异。


<details>
  <summary>Details</summary>
Motivation: 探究贝叶斯单物品拍卖中真实机制如何影响卖家和买家的效用前沿，特别是在独立同分布估值假设下。

Method: 通过结构分析和对帕累托前沿的完整描述，研究了Kalai-Smorodinsky和Nash两类解的性能。

Result: 在正则和反MHR分布下，两种解在大市场中表现接近最优；但在最坏MHR分布下，KS解表现稳健，而Nash解可能表现极差。

Conclusion: 研究强调了公平与效率权衡对分布结构的敏感性，证实KS解在非对称双边市场中更具鲁棒性。

Abstract: A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve.
  Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.

</details>


### [20] [Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089)
*Kehang Zhu,Lithium Thain,Vivian Tsai,James Wexler,Crystal Qian*

Main category: cs.GT

TL;DR: 研究通过在线行为实验（N = 243）探索AI代理在社交环境中的交互效果，发现尽管用户偏好推荐型帮助，但委托型代理能为个体和群体带来更高的效益。


<details>
  <summary>Details</summary>
Motivation: 随着AI在社交场景中日益普及，理解代理与用户的交互对设计提升个体和群体效果的系统至关重要。

Method: 参与者以三人一组的形式参与多轮谈判游戏，随机接触三种LLM协助模式：主动推荐的顾问、被动反馈的教练或自主执行的委托代理。

Result: 尽管用户更偏好顾问模式，但委托代理带来最高的个体收益，并产生正向外部效应，提升非使用者的交易质量。

Conclusion: 研究表明，代理能力与实际群体效益之间存在差距，设计兼容用户采纳的交互机制是提升人类福祉的关键。

Abstract: As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach}, or autonomous execution by a \textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \textit{Advisor} modality, participants achieve the highest mean individual gains with the \textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.

</details>


### [21] [Anonymous Contracts](https://arxiv.org/abs/2602.12118)
*Johannes Brustle,Paul Duetting,Stefano Leonardi,Tomasz Ponitka,Matteo Russo*

Main category: cs.GT

TL;DR: 论文研究了多代理合同问题，引入匿名合同以避免不公平感知，分析了其均衡性和效率限制。


<details>
  <summary>Details</summary>
Motivation: 在多代理合同中，理论上的歧视性合同可以提取全部社会福利，但可能被视为不公平，因此探索匿名合同的可行性。

Method: 引入匿名合同，支付仅取决于总成功数，确保代理人的公平待遇，并分析其均衡性和效率限制。

Result: 匿名合同存在纯纳什均衡，但可能有多重均衡；统一匿名合同保证唯一均衡。效率上，匿名合同在有限责任下无法近似社会福利。

Conclusion: 匿名合同在公平性上有优势，但在效率上受限于有限责任；取消有限责任可显著提升性能。

Abstract: We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents.
  We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees.
  In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.

</details>


### [22] [Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria](https://arxiv.org/abs/2602.12181)
*Anas Barakat,Ioannis Panageas,Antonios Varvitsiotis*

Main category: cs.GT

TL;DR: 本文介绍了广义效用马尔可夫博弈（GUMGs），扩展了凸马尔可夫博弈（cMGs）的理论框架，填补了其在纳什均衡结构和学习算法保证方面的空白。


<details>
  <summary>Details</summary>
Motivation: 凸马尔可夫博弈（cMGs）虽然扩展了多智能体学习的建模范围，但其理论基础，尤其是纳什均衡结构和学习算法的保证尚未充分理解。本文旨在填补这一空白。

Method: 通过引入广义效用马尔可夫博弈（GUMGs），分析了纳什均衡与投影伪梯度动态固定点之间的关系，并设计了一种无模型的策略梯度算法。

Result: 证明了GUMGs中纳什均衡的存在性，并提供了精确梯度和生成模型下的迭代复杂度和样本复杂度边界。

Conclusion: 本文扩展了之前局限于零和cMGs的研究，首次对共同利益cMGs进行了理论分析。

Abstract: Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.

</details>


### [23] [Bandit Learning in Matching Markets with Interviews](https://arxiv.org/abs/2602.12224)
*Amirmahdi Mirfakhar,Xuchuang Wang,Mengfan Xu,Hedyeh Beyhaghi,Mohammad Hajiesmaili*

Main category: cs.GT

TL;DR: 研究了带有面试的匹配市场中的多臂老虎机学习，面试被视为低成本提示，帮助双方获取部分偏好信息，并允许企业战略性地延迟招聘以提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 传统的双边匹配市场通常需要双方完全明确的偏好，但实践中难以实现。通过面试获取早期噪音信息，本研究旨在探索如何在双方不确定性下优化匹配决策。

Method: 提出了一个框架，允许企业在招聘过程中战略性延迟，以纠正早期错误；设计了集中式和分散式算法，分别考虑了全知面试分配器和企业侧反馈。

Result: 算法实现了时间无关的遗憾，显著优于传统匹配学习中的$O(\log T)$遗憾界限；在结构化市场中，分散式算法性能接近集中式算法。

Conclusion: 研究表明，战略性延迟和面试信息可以有效支持分散式学习，提升匹配市场的决策效率，尤其在偏好不确定的情况下。

Abstract: Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.

</details>


### [24] [Adjusted Winner: from Splitting to Selling](https://arxiv.org/abs/2602.12231)
*Robert Bredereck,Bin Sun,Eyal Briman,Nimrod Talmon*

Main category: cs.GT

TL;DR: 论文提出了一种扩展的Adjusted Winner方法，通过允许在预算约束下出售选定资源并重新分配收益，以解决原有方法中资源分割带来的问题，旨在实现尽可能公平的分配。


<details>
  <summary>Details</summary>
Motivation: 原有的Adjusted Winner方法在分配不可分割资源时依赖资源分割，可能导致实际操作中的困难。为此，论文提出了一种扩展方法，以解决这一问题。

Method: 论文扩展了Adjusted Winner方法，引入资源出售和收益再分配的机制，并通过公理化分析研究公平性和无嫉妒性的变化。同时，定义了组合问题并设计了FPTAS以应对其计算复杂性。

Result: 论文理论结果表明，扩展方法可以在预算约束下实现更公平的分配，并通过计算机模拟验证了方法的有效性。

Conclusion: 通过扩展Adjusted Winner方法并引入资源出售机制，论文解决了原有方法的局限性，同时在理论上和实践中验证了其可行性和有效性。

Abstract: The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.

</details>


### [25] [Is Online Linear Optimization Sufficient for Strategic Robustness?](https://arxiv.org/abs/2602.12253)
*Yang Cai,Haipeng Luo,Chen-Yu Wei,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 论文研究了在重复贝叶斯第一价格拍卖中的投标算法，提出通过简单的在线线性优化（OLO）算法实现策略稳健性和无遗憾投标。


<details>
  <summary>Details</summary>
Motivation: 现有最优遗憾投标算法对卖方的策略操纵缺乏足够稳健性，而基于无交换遗憾的算法虽能兼顾稳健性，但在统计和计算效率上表现不佳。

Method: 通过构建简单的黑盒归约方法，将任何OLO算法转化为策略稳健的无遗憾投标算法，适用于已知和未知价值分布的场景。

Result: 在已知价值分布的情况下，算法实现了$O(\sqrt{T \log K})$的遗憾和策略稳健性；在未知分布下，去除了密度有界假设，实现了高概率的$O(\sqrt{T (\log K+\log(T/\delta)})$遗憾和稳健性。

Conclusion: 研究表明，简单的在线线性优化算法足以实现策略稳健的无遗憾投标，显著提升了算法在稳健性和效率方面的表现。

Abstract: We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.
  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\sqrt{T \log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\sqrt{T (\log K+\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].

</details>
