<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 10]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction](https://arxiv.org/abs/2601.18475)
*Xinhui Liu,Can Wang,Lei Liu,Zhenghao Chen,Wei Jiang,Wei Wang,Dong Xu*

Main category: cs.GR

TL;DR: 论文提出StreamLoD-GS框架，通过分层高斯剔除、动态静态内容分离和量化残差精炼，解决了自由视点视频实时流媒体中的优化、存储和渲染质量瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 自由视点视频重建在实时流媒体应用中面临稀疏输入、高昂训练成本和带宽限制等挑战。3D高斯泼溅技术虽提升了渲染速度，但仍需满足快速优化、高保真重建和低存储需求的要求。

Method: StreamLoD-GS框架包含三个核心创新：基于锚点和八叉树的层次化高斯剔除技术，GMM运动分区机制，以及量化残差精炼框架。旨在高效优化、动态内容分离和减少存储占用。

Result: 实验表明，StreamLoD-GS在质量、效率和存储方面具备竞争性或最优性能。

Conclusion: StreamLoD-GS通过创新技术有效解决了自由视点视频流媒体的关键瓶颈，实现了高质量、高效和低存储需求的目标。

Abstract: Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop](https://arxiv.org/abs/2601.17670)
*Roberto Rossi,Steven D. Prestwich*

Main category: cs.PL

TL;DR: SyntAGM是一个端到端系统，通过自然语言问题描述生成PyOPL模型，并利用编译器反馈和LLM对齐评估来优化模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过代数建模语言（AMLs）和编译器引导的模型合成，实现生成式数学编程。

Method: 利用PyOPL编译器提供语法诊断，通过生成-编译-评估-修订循环，结合上下文学习和少量示例检索，使用编译器反馈和LLM对齐评估生成有效的PyOPL模型。

Result: SyntAGM在准确性上与基线方法竞争，同时在令牌、成本和延迟方面表现更优。

Conclusion: SyntAGM展示了利用编译器反馈和上下文学习在生成数学编程模型中的有效性。

Abstract: This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.

</details>


### [3] [Types for Grassroots Logic Programs](https://arxiv.org/abs/2601.17957)
*Ehud Shapiro*

Main category: cs.PL

TL;DR: GLP是一种并发逻辑编程语言，通过将逻辑变量分为配对的读写器实现丰富的多向通信模式。本文通过定义基于模式路径的类型系统，扩展了GLP的类型化能力，并证明其与程序语义的协变和逆变条件等价。


<details>
  <summary>Details</summary>
Motivation: GLP自然无类型，但在与AI合作编程复杂通信模式时，无类型系统可能导致策略不稳定。因此，通过类型系统为GLLP建立规范，实现人类与AI的协同开发。

Method: 定义类型为模式路径的规则集合，其中模式捕获通信方向性（消费或生产），并基于此提供语法定义的类型检查，证明程序与类型的协变和逆变条件等价。

Result: 实现了GLP的类型系统，从数学规范生成英语规范，再自动生成Dart代码，验证了类型系统的有效性。

Conclusion: 通过类型化的GLP系统，人类与AI可以协同开发复杂通信模式，提升编程的可靠性和可维护性。

Abstract: Grassroots Logic Programs (GLP) is a concurrent logic programming language in which logic variables are partitioned into paired readers and writers. An assignment is produced at most once via a writer and consumed at most once via its paired reader, and may contain additional readers and/or writers. This enables the concise expression of rich multidirectional communication modalities.
  ``Logic Programs as Types for Logic Programs'' (LICS'91) defined types as regular sets of paths over derivable ground atoms. Here, we define types to be regular sets of moded paths, where a mode captures directionality of communication -- whether a subterm is consumed from or produced to the environment -- enabling the typing of interactive partial computations including those that eventually deadlock or fail, or never terminate. We provide a syntactic definition of well-typing and prove that a program is well-typed iff the path abstraction of its moded-atom semantics satisfies covariance and contravariance conditions with respect to its type.
  The GLP type system was implemented in Dart by AI, starting from a mathematical specification of Typed GLP (this paper), deriving from it an English spec (written by AI), and from the spec deriving Dart code (by AI). While GLP is naturally untyped, the motivation for Typed GLP comes from programming with AI: Asking AI to program complex communication modalities in GLP (and in general) and hoping for the best is a tenuous strategy. The emerging discipline we advocate and employ is for the human designer and AI to jointly develop and agree upon (1)~GLP types; (2)~GLP procedure type declarations; (3)~informal (English) descriptions of the procedures; and only then let AI attempt to write (4)~GLP code based on those.

</details>


### [4] [Handling Scope Checks (Extended Version)](https://arxiv.org/abs/2601.18793)
*Michael Lee,Ningning Xie,Oleg Kiselyov,Jeremy Yallop*

Main category: cs.PL

TL;DR: 论文研究了元编程和效果处理程序中作用域挤出的动态检查，提出了一个新的动态检查方法 "Cause-for-Concern"，并证明了其正确性和优势。


<details>
  <summary>Details</summary>
Motivation: 元编程和效果处理程序的交互可能导致作用域挤出等问题，但目前的理论和实践缺乏对动态检查的深入研究。

Method: 提出了一种新的演算 $λ_{\langle\langle\text{op}\rangle\rangle}$ 来描述和评估动态检查，并引入了 "Cause-for-Concern" 检查方法。

Result: 证明了 "Cause-for-Concern" 的正确性，并通过扩展框架比较了动态检查和静态类型系统的表现力。

Conclusion: 研究表明动态检查在作用域挤出问题中具有优势，为金属语言的设计提供了理论指导和实践参考。

Abstract: Metaprogramming and effect handlers interact in unexpected, and sometimes undesirable, ways. One example is scope extrusion: the generation of ill-scoped code. Scope extrusion can either be preemptively prevented, via static type systems, or retroactively detected, via dynamic checks. Static type systems exist in theory, but struggle with a range of implementation and usability problems in practice. In contrast, dynamic checks exist in practice (e.g. in MetaOCaml), but are understudied in theory. Designers of metalanguages are thus given little guidance regarding the design and implementation of checks. We present the first formal study of dynamic scope extrusion checks, introducing a calculus ($λ_{\langle\langle\text{op}\rangle\rangle}$) for describing and evaluating checks. Further, we introduce a novel dynamic check $\unicode{x2014}$ the "Cause-for-Concern" check $\unicode{x2014}$ which we prove correct, characterise without reference to its implementation, and argue combines the advantages of existing dynamic checks. Finally, we extend our framework with refined environment classifiers, which statically prevent scope extrusion, and compare their expressivity with the dynamic checks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [5] [Equilibrium Refinements Improve Subgame Solving in Imperfect-Information Games](https://arxiv.org/abs/2601.17131)
*Ondrej Kubicek,Viliam Lisy,Tuomas Sandholm*

Main category: cs.GT

TL;DR: 本文研究了不完全信息博弈中的子博弈求解技术，提出了改良的Gadget游戏序列均衡作为优选解决方案，通过调整线性规划和反事实遗憾最小化方法，显著降低了整体策略的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 在不完全信息博弈中，子博弈求解需要处理隐藏状态和对手策略的不确定性。现有方法（如Gadget游戏）虽然有效，但存在许多纳什均衡，导致在实际博弈中表现不佳。

Method: 作者提出了Gadget游戏序列均衡的概念，并对序列形式线性规划和反事实遗憾最小化方法进行了修改，以收敛到这些精炼解，计算成本仅略有增加。

Result: 实验表明，改良的序列均衡在实际博弈中表现优于未精炼的纳什均衡，能将整体策略的脆弱性降低超过50%。

Conclusion: Gadget游戏序列均衡是子博弈求解的优选解决方案，通过精炼方法显著提高了策略的稳健性，适用于不完全信息博弈。

Abstract: Subgame solving is a technique for scaling algorithms to large games by locally refining a precomputed blueprint strategy during gameplay. While straightforward in perfect-information games where search starts from the current state, subgame solving in imperfect-information games must account for hidden states and uncertainty about the opponent's past strategy. Gadget games were developed to ensure that the improved subgame strategy is robust against any possible opponent's strategy in a zero-sum game. Gadget games typically contain infinitely many Nash equilibria. We demonstrate that while these equilibria are equivalent in the gadget game, they yield vastly different performance in the full game, even when facing a rational opponent. We propose gadget game sequential equilibria as the preferred solution concept. We introduce modifications to the sequence-form linear program and counterfactual regret minimization that converge to these refined solutions with only mild additional computational cost. Additionally, we provide several new insights into the surprising superiority of the resolving gadget game over the max-margin gadget game. Our experiments compare different Nash equilibria of gadget games in several standard benchmark games, showing that our refined equilibria consistently outperform unrefined Nash equilibria, and can reduce the exploitability of the overall strategy by more than 50%

</details>


### [6] [Strategic AI in Cournot Markets](https://arxiv.org/abs/2601.17263)
*Sanyukta Deshpande,Sheldon H. Jacobson*

Main category: cs.GT

TL;DR: 研究表明，大型语言模型（LLMs）在寡头古诺市场中不仅能理解复杂的市场动态，还会持续默示共谋，导致价格比纳什均衡水平高出200%。研究还发现，通过强制最佳响应策略监管主导代理可以打破共谋。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在竞争市场中自动决策的普及，理解其动态并确保公平市场机制变得至关重要。本文旨在探究LLMs在寡头市场中的多维决策行为及其对市场竞争的影响。

Method: 研究通过分析LLMs在三个维度（决策类型、对手策略和市场构成）的行为，揭示其对市场竞争的影响，并采用强制最佳响应策略来监管主导代理。

Result: LLMs不仅展示了作为经济规划代理的潜力，还表现出默示共谋行为，导致价格大幅上涨。监管措施能有效打破共谋，恢复竞争性定价。

Conclusion: 研究揭示了AI在竞争市场中集成的潜在问题，并提出了自动化时代的监管政策建议。

Abstract: As artificial intelligence increasingly automates decision-making in competitive markets, understanding the resulting dynamics and ensuring fair market mechanisms is essential. We investigate the multi-faceted decision-making of large language models (LLMs) in oligopolistic Cournot markets, showing that LLMs not only grasp complex market dynamics--demonstrating their potential as effective economic planning agents--but also engage in sustained tacit collusion, driving prices up to 200% above Nash equilibrium levels. Our analysis examines LLM behavior across three dimensions-(1) decision type, (2) opponent strategies, and (3) market composition--revealing how these factors may shape the competitiveness of LLM-based decision-makers. Furthermore, we show that regulating a few dominant agents by enforcing best-response strategies effectively disrupts collusion and helps restore competitive pricing. Our findings identify potential concerns associated with AI integration in competitive market environments and provide regulatory policy recommendations for the era of automation.

</details>


### [7] [Truth-Revealing Participatory Budgeting](https://arxiv.org/abs/2601.17538)
*Qishen Han,Artem Ivaniuk,Edith Elkind,Lirong Xia*

Main category: cs.GT

TL;DR: 本文从认知角度研究参与式预算（PB），假设项目具有隐藏质量水平，代理通过噪声信息投票选举高质量项目。研究发现，常见PB规则在某些条件下可近似最优解，但战略性代理诚实投票的条件极为受限。


<details>
  <summary>Details</summary>
Motivation: 传统PB研究主要基于公理化视角，而本文从认知视角出发，探讨项目隐藏质量对决策的影响。

Method: 通过理论分析和数值实验，评估常见PB规则在信息聚合中的表现，特别关注项目成本范围对结果的影响。

Result: 研究发现，项目成本范围缩小时，规则近似最优解的能力提升；单位成本下规则能以高概率选出最佳项目集。战略性代理诚实投票的条件极为受限。

Conclusion: 本研究揭示了PB规则在隐藏质量条件下的性能边界，为实际应用提供了理论支持。

Abstract: Participatory Budgeting (PB) is commonly studied from an axiomatic perspective, where the aim is to design procedurally fair and economically efficient rules for voters with full information regarding their preferences. In contrast, we take an epistemic perspective and consider a framework where PB projects have different levels of underlying quality, indicating how well the project will take effect, which cannot be directly observed before implementation. Agents with noisy information cast votes to aggregate their information, and aim to elect a high-quality set of projects. We evaluate the performance of common PB rules by measuring the expected utility of their outcomes, compared to the optimal set of projects. We find that the quality of approximation improves as the range of project costs shrinks. When projects have unit cost, these common rules can identify the ``best'' set with probability converging to 1. We also study whether strategic agents have incentives to honestly convey their information in the vote. We find that it happens only under very restrictive conditions. We also run numerical experiments to examine the performance of different rules empirically and support our theoretical findings.

</details>


### [8] [Distances Between Top-Truncated Elections of Different Sizes](https://arxiv.org/abs/2601.17931)
*Piotr Faliszewski,Jitka Mertlová,Pierre Nunn,Stanisław Szufa,Tomasz Wąs*

Main category: cs.GT

TL;DR: 该论文扩展了选举地图框架，使其能够处理候选人和选民数量不同的选举，并支持顶部截断的投票。


<details>
  <summary>Details</summary>
Motivation: 现有的选举地图框架仅适用于候选人和选民数量相同且所有投票为全序的情况，无法处理更复杂的现实选举数据。

Method: 将选举地图框架扩展到支持不同规模的选举，并允许投票为顶部截断的形式。

Result: 成功地可视化了一个大型PrefLib数据库片段，展示了扩展框架的有效性。

Conclusion: 扩展后的框架能够更灵活地处理复杂的选举数据集，为选举分析和可视化提供了更广泛的适用性。

Abstract: The map of elections framework is a methodology for visualizing and analyzing election datasets. So far, the framework was restricted to elections that have equal numbers of candidates, equal numbers of voters, and where all the (ordinal) votes rank all the candidates. We extend it to the case of elections of different sizes, where the votes can be top-truncated. We use our results to present a visualization of a large fragment of the Preflib database.

</details>


### [9] [Credit Fairness: Online Fairness In Shared Resource Pools](https://arxiv.org/abs/2601.17944)
*Seyed Majid Zahedi,Rupert Freeman*

Main category: cs.GT

TL;DR: 本文提出了一种称为“信用公平”的资源分配机制，旨在解决现有最大最小机制导致资源分配不均的问题，同时满足帕累托效率或策略证明性中的一项。


<details>
  <summary>Details</summary>
Motivation: 现有最大最小机制虽然在单轮中满足共享激励、策略证明性和帕累托效率，但会导致总资源分配的严重不均，即使代理的平均需求相同。

Method: 引入“信用公平”概念，设计了一种新机制，确保早期借出资源的代理在后期能够收回资源，并与帕累托效率或策略证明性中的一项结合实现。

Result: 提出的信用公平机制在计算资源共享场景中表现出色，能够在满足信用公平的同时实现帕累托效率。

Conclusion: 信用公平机制弥补了现有机制的不足，尽管无法同时满足帕累托效率和策略证明性，但在特定场景下提供了更公平的资源分配方案。

Abstract: We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.

</details>


### [10] [Decentralized Multi-product Pricing: Diagonal Dominance, Nash Equilibrium, and Price of Anarchy](https://arxiv.org/abs/2601.18117)
*Boxiao Chen,Jiashuo Jiang,Stefanus Jasin*

Main category: cs.GT

TL;DR: 该论文通过分析价格博弈中的无政府状态价格（Price of Anarchy），量化了多产品企业中分散决策导致的效率损失，并推导出分散化收入与集中化收入比率的下界。


<details>
  <summary>Details</summary>
Motivation: 研究多产品企业中分散决策导致的效率损失，尤其是在决策者未能内化跨产品需求互动的情况下。

Method: 使用线性需求系统建模跨产品的替代与互补效应，建立纯策略纳什均衡的存在性与唯一性，并推导出效率损失的紧下界。

Result: 证明了收入比率的下界为$4(1-\mu)/(2-\mu)^2$，并通过构建对称市场拓扑验证了该下界的紧性。

Conclusion: 研究结果为评估多产品企业中集中定价与分散自治的权衡提供了定量框架。

Abstract: Decentralized decision making in multi--product firms can lead to efficiency losses when autonomous decision makers fail to internalize cross--product demand interactions. This paper quantifies the magnitude of such losses by analyzing the Price of Anarchy in a pricing game in which each decision maker independently sets prices to maximize its own product--level revenue. We model demand using a linear system that captures both substitution and complementarity effects across products. We first establish existence and uniqueness of a pure--strategy Nash equilibrium under economically standard diagonal dominance conditions. Our main contribution is the derivation of a tight worst--case lower bound on the ratio between decentralized revenue and the optimal centralized revenue. We show that this efficiency loss is governed by a single scalar parameter, denoted by $μ$, which measures the aggregate strength of cross--price effects relative to own--price sensitivities. In particular, we prove that the revenue ratio is bounded below by $4(1-μ)/(2-μ)^2$, and we demonstrate the tightness of this bound by constructing a symmetric market topology in which the bound is exactly attained. We further refine the analysis by providing an instance--exact characterization of efficiency loss based on the spectral properties of the demand interaction matrix. Together, these results offer a quantitative framework for assessing the trade--off between centralized pricing and decentralized autonomy in multi--product firms.

</details>


### [11] [Dicey Games: Shared Sources of Randomness in Distributed Systems](https://arxiv.org/abs/2601.18303)
*Léonard Brice,Thomas A. Henzinger,K. S. Thejaswini*

Main category: cs.GT

TL;DR: 本文研究了四人对战的硬币匹配游戏，探讨团队如何在共享随机源的情况下提高胜率，并引入了Dicey Games框架来研究分布式系统中的共享随机源问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索团队如何在共享随机源的情况下优化策略，以提高胜利概率，并扩展到分布式系统中共享随机源的优化分配问题。

Method: 引入Dicey Games框架，分析团队在共享随机源时的最优策略存在性、表示方法及计算复杂度，同时研究随机源在团队内的最优分配问题。

Result: 研究发现，团队在共享随机源的情况下可以超过概率1/4的胜率，并提供了对最优策略的系统性分析。

Conclusion: 通过Dicey Games框架，本文揭示了共享随机源对团队策略优化的影响，为分布式系统中的相关问题提供了理论基础和解决方向。

Abstract: Consider a 4-player version of Matching Pennies where a team of three players competes against the Devil. Each player simultaneously says "Heads" or "Tails". The team wins if all four choices match; otherwise the Devil wins. If all team players randomise independently, they win with probability 1/8; if all players share a common source of randomness, they win with probability 1/2. What happens when each pair of team players shares a source of randomness? Can the team do better than win with probability 1/4? The surprising (and nontrivial) answer is yes! We introduce Dicey Games, a formal framework motivated by the study of distributed systems with shared sources of randomness (of which the above example is a specific instance). We characterise the existence, representation and computational complexity of optimal strategies in Dicey Games, and we study the problem of allocating limited sources of randomness optimally within a team.

</details>


### [12] [Maps of Tournaments: Distances, Experiments, and Data](https://arxiv.org/abs/2601.18348)
*Filip Nikolow,Piotr Faliszewski,Stanisław Szufa*

Main category: cs.GT

TL;DR: 该论文提出了一种通过构建“锦标赛地图”来可视化锦标赛的方法，该方法基于二维平面上的点表示锦标赛，并通过欧氏距离反映不同锦标赛之间的相似性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是借鉴选举框架中的地图方法，将其应用于锦标赛的可视化，从而更直观地比较和分析锦标赛的属性和实验结果。

Method: 方法包括定义锦标赛的结构（完全有向图），设计距离度量标准，随机生成锦标赛并与真实锦标赛进行比较，以及构建基于欧氏距离的二维地图。

Result: 研究结果表明，该方法有效帮助可视化实验结果，特别是对于淘汰赛等复杂锦标赛结构。

Conclusion: 结论表明，锦标赛地图是一种实用的可视化工具，能够清晰展示锦标赛之间的关系，并为实验结果的解释提供了新的视角。

Abstract: We form a "map of tournaments" by adapting the map framework from the world of elections. By a tournament we mean a complete directed graph where the nodes are the players and an edge points from a winner of a game to the loser (with no ties allowed). A map is a set of tournaments represented as points on a 2D plane, so that their Euclidean distances resemble the distances computed according to a given measure. We identify useful distance measures, discuss ways of generating random tournaments (and compare them to several real-life ones), and show how the maps are helpful in visualizing experimental results (also for knockout tournaments).

</details>


### [13] [Stable Matching with Deviators and Conformists](https://arxiv.org/abs/2601.18573)
*Frederik Glitzner,David Manlove*

Main category: cs.GT

TL;DR: 这篇论文研究了稳定婚姻和室友问题中减小匹配不稳定的可能性，通过识别"偏离者"和"顺从者"，探索在部分代理人可能引发偏差的情况下，是否能高效找到无偏离者阻塞的匹配。


<details>
  <summary>Details</summary>
Motivation: 在传统的稳定婚姻和室友问题中，存在匹配大小和稳定性之间的权衡。尽管某些情况下稳定性可以高效解决，但在实际应用中，并非所有代理人都可能引发不稳定性。因此，研究如何识别和处理可能引发偏差的代理人（偏离者）和顺从者具有实际意义。

Method: 论文提出了一个新的框架，区分了偏离者和顺从者，并在此基础上研究了匹配的计算复杂性。通过理论分析，探讨了在二分和非二分偏好设置下，是否存在高效算法来确定或找到无偏离者阻塞的匹配。

Result: 研究发现，与经典情况不同，确定是否存在无偏离者阻塞的匹配是一个NP完全问题。尽管如此，论文也识别了一些多项式时间和固定参数可处理的情况，为多智能体系统中无法完全保证稳定性的场景提供了新的算法。

Conclusion: 论文表明，识别和处理偏离者是解决稳定性问题的关键，尽管这一问题在理论上具有较高的计算复杂性，但在某些情况下仍可通过高效算法解决。这一研究为实际应用中的匹配问题提供了新的视角和工具。

Abstract: In the fundamental Stable Marriage and Stable Roommates problems, there are inherent trade-offs between the size and stability of solutions. While in the former problem, a stable matching always exists and can be found efficiently using the celebrated Gale-Shapley algorithm, the existence of a stable matching is not guaranteed in the latter problem, but can be determined efficiently using Irving's algorithm. However, the computation of matchings that minimise the instability, either due to the presence of additional constraints on the size of the matching or due to restrictive preference cycles, gives rise to a collection of infamously intractable almost-stable matching problems. In practice, however, not every agent is able or likely to initiate deviations caused by blocking pairs. Suppose we knew, for example, due to a set of requirements or estimates based on historical data, which agents are likely to initiate deviations - the deviators - and which are likely to comply with whatever matching they are presented with - the conformists. Can we decide efficiently whether a matching exists in which no deviator is blocking, i.e., in which no deviator has an incentive to initiate a deviation? Furthermore, can we find matchings in which only a few deviators are blocking? We characterise the computational complexity of this question in bipartite and non-bipartite preference settings. Surprisingly, these problems prove computationally intractable in strong ways: for example, unlike in the classical setting, where every agent is considered a deviator, in this extension, we prove that it is NP-complete to decide whether a matching exists where no deviator is blocking. On the positive side, we identify polynomial-time and fixed-parameter tractable cases, providing novel algorithmics for multi-agent systems where stability cannot be fully guaranteed.

</details>


### [14] [Learning Real-Life Approval Elections](https://arxiv.org/abs/2601.18651)
*Piotr Faliszewski,Łukasz Janeczko,Andrzej Kaczmarczyk,Marcin Kurdziel,Grzegorz Pierczyński,Stanisław Szufa*

Main category: cs.GT

TL;DR: 论文研究了独立批准模型（IAM）及其混合模型，用于选举中的批准概率学习，并通过最大似然估计和贝叶斯学习算法在Pabulib数据库中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展选举中的批准概率模型，以更灵活地描述复杂的现实选举数据。

Method: 方法包括提出独立批准模型（IAM）及其混合模型的学习算法，如最大似然估计和贝叶斯学习。

Result: 结果表明，单一独立批准模型难以捕捉现实数据的复杂性，但其混合模型表现良好。

Conclusion: 结论指出，混合独立批准模型在描述真实选举数据时具有更好的表现和适应性。

Abstract: We study the independent approval model (IAM) for approval elections, where each candidate has its own approval probability and is approved independently of the other ones. This model generalizes, e.g., the impartial culture, the Hamming noise model, and the resampling model. We propose algorithms for learning IAMs and their mixtures from data, using either maximum likelihood estimation or Bayesian learning. We then apply these algorithms to a large set of elections from the Pabulib database. In particular, we find that single-component models are rarely sufficient to capture the complexity of real-life data, whereas their mixtures perform well.

</details>
