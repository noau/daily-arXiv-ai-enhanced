{"id": "2508.16696", "categories": ["cs.GR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.16696", "abs": "https://arxiv.org/abs/2508.16696", "authors": ["Reema Alshehri", "Rawan Alotaibi", "Leen Almasri", "Rawan Altaweel"], "title": "DecoMind: A Generative AI System for Personalized Interior Design Layouts", "comment": "~7 pages; ~32 figures; compiled with pdfLaTeX. Primary category:\n  cs.CV. (Secondary: cs.AI)", "summary": "This paper introduces a system for generating interior design layouts based\non user inputs, such as room type, style, and furniture preferences. CLIP\nextracts relevant furniture from a dataset, and a layout that contains\nfurniture and a prompt are fed to Stable Diffusion with ControlNet to generate\na design that incorporates the selected furniture. The design is then evaluated\nby classifiers to ensure alignment with the user's inputs, offering an\nautomated solution for realistic interior design.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u8f93\u5165\u7684\u5ba4\u5185\u8bbe\u8ba1\u5e03\u5c40\u751f\u6210\u7cfb\u7edf\uff0c\u5229\u7528CLIP\u63d0\u53d6\u76f8\u5173\u5bb6\u5177\uff0c\u7ed3\u5408Stable Diffusion\u4e0eControlNet\u751f\u6210\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u5206\u7c7b\u5668\u8bc4\u4f30\u8bbe\u8ba1\u4e00\u81f4\u6027\u3002", "motivation": "\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u6839\u636e\u7528\u6237\u7684\u623f\u95f4\u7c7b\u578b\u3001\u98ce\u683c\u548c\u5bb6\u5177\u504f\u597d\u751f\u6210\u7b26\u5408\u9700\u6c42\u7684\u5ba4\u5185\u8bbe\u8ba1\u5e03\u5c40\u3002", "method": "\u4f7f\u7528CLIP\u4ece\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u76f8\u5173\u5bb6\u5177\uff0c\u7ed3\u5408Stable Diffusion\u4e0eControlNet\u751f\u6210\u8bbe\u8ba1\u5e03\u5c40\uff0c\u5e76\u901a\u8fc7\u5206\u7c7b\u5668\u8bc4\u4f30\u8bbe\u8ba1\u7684\u7b26\u5408\u5ea6\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u7b26\u5408\u7528\u6237\u8f93\u5165\u9700\u6c42\u7684\u5ba4\u5185\u8bbe\u8ba1\u5e03\u5c40\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u8bc4\u4f30\u786e\u4fdd\u8bbe\u8ba1\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u81ea\u52a8\u5316\u7684\u5ba4\u5185\u8bbe\u8ba1\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u6ee1\u8db3\u7528\u6237\u7684\u591a\u6837\u5316\u9700\u6c42\u3002"}}
{"id": "2508.16911", "categories": ["cs.GR", "cs.CV", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2508.16911", "abs": "https://arxiv.org/abs/2508.16911", "authors": ["Prerit Gupta", "Jason Alexander Fotso-Puepi", "Zhengyuan Li", "Jay Mehta", "Aniket Bera"], "title": "MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation", "comment": "Accepted at ICCV 2025. Project page:\n  https://gprerit96.github.io/mdd-page", "summary": "We introduce Multimodal DuetDance (MDD), a diverse multimodal benchmark\ndataset designed for text-controlled and music-conditioned 3D duet dance motion\ngeneration. Our dataset comprises 620 minutes of high-quality motion capture\ndata performed by professional dancers, synchronized with music, and detailed\nwith over 10K fine-grained natural language descriptions. The annotations\ncapture a rich movement vocabulary, detailing spatial relationships, body\nmovements, and rhythm, making MDD the first dataset to seamlessly integrate\nhuman motions, music, and text for duet dance generation. We introduce two\nnovel tasks supported by our dataset: (1) Text-to-Duet, where given music and a\ntextual prompt, both the leader and follower dance motion are generated (2)\nText-to-Dance Accompaniment, where given music, textual prompt, and the\nleader's motion, the follower's motion is generated in a cohesive, text-aligned\nmanner. We include baseline evaluations on both tasks to support future\nresearch.", "AI": {"tldr": "MDD\u662f\u4e00\u4e2a\u591a\u5143\u5316\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6587\u672c\u63a7\u5236\u548c\u97f3\u4e50\u6761\u4ef6\u4e0b\u76843D\u53cc\u4eba\u821e\u52a8\u4f5c\u751f\u6210\uff0c\u5305\u542b620\u5206\u949f\u7684\u52a8\u6355\u6570\u636e\u3001\u97f3\u4e50\u540c\u6b65\u548c10K+\u7ec6\u7c92\u5ea6\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3002", "motivation": "\u4e3a\u4fc3\u8fdb\u6587\u672c\u63a7\u5236\u548c\u97f3\u4e50\u6761\u4ef6\u4e0b\u7684\u53cc\u4eba\u821e\u52a8\u4f5c\u751f\u6210\u7814\u7a76\uff0c\u586b\u8865\u73b0\u6709\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u9ad8\u8d28\u91cf\u52a8\u6355\u6570\u636e\u3001\u97f3\u4e50\u540c\u6b65\u548c\u8be6\u7ec6\u6587\u672c\u63cf\u8ff0\u7684MDD\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u65b0\u4efb\u52a1\uff1a\u6587\u672c\u5230\u53cc\u4eba\u821e\u548c\u6587\u672c\u5230\u821e\u8e48\u4f34\u594f\u3002", "result": "\u63d0\u4f9b\u4e86\u5305\u542b\u4e30\u5bcc\u52a8\u4f5c\u8bcd\u6c47\u548c\u8be6\u7ec6\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5728\u4e24\u4e2a\u65b0\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u57fa\u7ebf\u8bc4\u4f30\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "MDD\u6570\u636e\u96c6\u9996\u6b21\u5c06\u4eba\u4f53\u52a8\u4f5c\u3001\u97f3\u4e50\u548c\u6587\u672c\u65e0\u7f1d\u6574\u5408\uff0c\u4e3a\u53cc\u4eba\u821e\u751f\u6210\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8d44\u6e90\u548c\u65b9\u5411\u3002"}}
{"id": "2508.17011", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.17011", "abs": "https://arxiv.org/abs/2508.17011", "authors": ["Jinxi Wang", "Ben Fei", "Dasith de Silva Edirimuni", "Zheng Liu", "Ying He", "Xuequan Lu"], "title": "A Survey of Deep Learning-based Point Cloud Denoising", "comment": null, "summary": "Accurate 3D geometry acquisition is essential for a wide range of\napplications, such as computer graphics, autonomous driving, robotics, and\naugmented reality. However, raw point clouds acquired in real-world\nenvironments are often corrupted with noise due to various factors such as\nsensor, lighting, material, environment etc, which reduces geometric fidelity\nand degrades downstream performance. Point cloud denoising is a fundamental\nproblem, aiming to recover clean point sets while preserving underlying\nstructures. Classical optimization-based methods, guided by hand-crafted\nfilters or geometric priors, have been extensively studied but struggle to\nhandle diverse and complex noise patterns. Recent deep learning approaches\nleverage neural network architectures to learn distinctive representations and\ndemonstrate strong outcomes, particularly on complex and large-scale point\nclouds. Provided these significant advances, this survey provides a\ncomprehensive and up-to-date review of deep learning-based point cloud\ndenoising methods up to August 2025. We organize the literature from two\nperspectives: (1) supervision level (supervised vs. unsupervised), and (2)\nmodeling perspective, proposing a functional taxonomy that unifies diverse\napproaches by their denoising principles. We further analyze architectural\ntrends both structurally and chronologically, establish a unified benchmark\nwith consistent training settings, and evaluate methods in terms of denoising\nquality, surface fidelity, point distribution, and computational efficiency.\nFinally, we discuss open challenges and outline directions for future research\nin this rapidly evolving field.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u622a\u81f32025\u5e748\u6708\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u70b9\u4e91\u53bb\u566a\u65b9\u6cd5\uff0c\u4ece\u76d1\u7763\u6c34\u5e73\u548c\u5efa\u6a21\u89c6\u89d2\u5206\u7c7b\uff0c\u5e76\u5206\u6790\u67b6\u6784\u8d8b\u52bf\u3001\u5efa\u7acb\u7edf\u4e00\u57fa\u51c6\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u70b9\u4e91\u6570\u636e\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u5e38\u53d7\u566a\u58f0\u6c61\u67d3\uff0c\u5f71\u54cd\u51e0\u4f55\u7cbe\u5ea6\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u566a\u58f0\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u663e\u793a\u51fa\u4f18\u52bf\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5bf9\u5176\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u3002", "method": "\u4ece\u76d1\u7763\u6c34\u5e73\uff08\u6709\u76d1\u7763\u4e0e\u65e0\u76d1\u7763\uff09\u548c\u5efa\u6a21\u89c6\u89d2\u5bf9\u6587\u732e\u8fdb\u884c\u5206\u7c7b\uff0c\u63d0\u51fa\u529f\u80fd\u6027\u5206\u7c7b\u6cd5\uff0c\u5e76\u5728\u7edf\u4e00\u57fa\u51c6\u4e0b\u8bc4\u4f30\u65b9\u6cd5\u7684\u53bb\u566a\u8d28\u91cf\u3001\u8868\u9762\u4fdd\u771f\u5ea6\u3001\u70b9\u5206\u5e03\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u5728\u70b9\u4e91\u53bb\u566a\u9886\u57df\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u548c\u5927\u89c4\u6a21\u70b9\u4e91\u4e0a\u8868\u73b0\u4f18\u5f02\u3002\u901a\u8fc7\u7edf\u4e00\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "\u70b9\u4e91\u53bb\u566a\u9886\u57df\u4ecd\u6709\u6311\u6218\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u65b9\u6cd5\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u566a\u58f0\u591a\u6837\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u3002"}}
{"id": "2508.17342", "categories": ["cs.GR", "cs.CV", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2508.17342", "abs": "https://arxiv.org/abs/2508.17342", "authors": ["Hengyuan Zhang", "Zhe Li", "Xingqun Qi", "Mengze Li", "Muyi Sun", "Man Zhang", "Sirui Han"], "title": "DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions", "comment": null, "summary": "Generating coherent and diverse human dances from music signals has gained\ntremendous progress in animating virtual avatars. While existing methods\nsupport direct dance synthesis, they fail to recognize that enabling users to\nedit dance movements is far more practical in real-world choreography\nscenarios. Moreover, the lack of high-quality dance datasets incorporating\niterative editing also limits addressing this challenge. To achieve this goal,\nwe first construct DanceRemix, a large-scale multi-turn editable dance dataset\ncomprising the prompt featuring over 25.3M dance frames and 84.5K pairs. In\naddition, we propose a novel framework for iterative and editable dance\ngeneration coherently aligned with given music signals, namely DanceEditor.\nConsidering the dance motion should be both musical rhythmic and enable\niterative editing by user descriptions, our framework is built upon a\nprediction-then-editing paradigm unifying multi-modal conditions. At the\ninitial prediction stage, our framework improves the authority of generated\nresults by directly modeling dance movements from tailored, aligned music.\nMoreover, at the subsequent iterative editing stages, we incorporate text\ndescriptions as conditioning information to draw the editable results through a\nspecifically designed Cross-modality Editing Module (CEM). Specifically, CEM\nadaptively integrates the initial prediction with music and text prompts as\ntemporal motion cues to guide the synthesized sequences. Thereby, the results\ndisplay music harmonics while preserving fine-grained semantic alignment with\ntext descriptions. Extensive experiments demonstrate that our method\noutperforms the state-of-the-art models on our newly collected DanceRemix\ndataset. Code is available at https://lzvsdy.github.io/DanceEditor/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDanceEditor\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u97f3\u4e50\u4fe1\u53f7\u4e2d\u751f\u6210\u53ef\u8fed\u4ee3\u7f16\u8f91\u7684\u8fde\u8d2f\u4e14\u591a\u6837\u5316\u7684\u821e\u8e48\u52a8\u4f5c\uff0c\u5e76\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u53ef\u7f16\u8f91\u821e\u8e48\u6570\u636e\u96c6DanceRemix\u3002", "motivation": "\u73b0\u6709\u7684\u821e\u8e48\u5408\u6210\u65b9\u6cd5\u867d\u7136\u652f\u6301\u76f4\u63a5\u751f\u6210\u821e\u8e48\u52a8\u4f5c\uff0c\u4f46\u672a\u80fd\u6ee1\u8db3\u5b9e\u9645\u7f16\u821e\u573a\u666f\u4e2d\u7528\u6237\u5bf9\u821e\u8e48\u52a8\u4f5c\u7f16\u8f91\u7684\u9700\u6c42\uff0c\u540c\u65f6\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u53ef\u7f16\u8f91\u821e\u8e48\u6570\u636e\u96c6\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9884\u6d4b-\u7f16\u8f91\u8303\u5f0f\u6846\u67b6DanceEditor\uff0c\u901a\u8fc7\u76f4\u63a5\u5efa\u6a21\u821e\u8e48\u52a8\u4f5c\u548c\u97f3\u4e50\u4fe1\u53f7\u7684\u5173\u8054\uff0c\u5e76\u5728\u540e\u7eed\u7f16\u8f91\u9636\u6bb5\u5f15\u5165\u6587\u672c\u63cf\u8ff0\u4f5c\u4e3a\u6761\u4ef6\u4fe1\u606f\uff0c\u5229\u7528\u8de8\u6a21\u6001\u7f16\u8f91\u6a21\u5757\uff08CEM\uff09\u751f\u6210\u53ef\u7f16\u8f91\u7684\u821e\u8e48\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDanceEditor\u5728\u65b0\u6784\u5efa\u7684DanceRemix\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u65e2\u7b26\u5408\u97f3\u4e50\u8282\u594f\u53c8\u6ee1\u8db3\u6587\u672c\u8bed\u4e49\u7684\u821e\u8e48\u52a8\u4f5c\u3002", "conclusion": "DanceEditor\u6846\u67b6\u901a\u8fc7\u5728\u9884\u6d4b\u9636\u6bb5\u751f\u6210\u9ad8\u8d28\u91cf\u821e\u8e48\u52a8\u4f5c\u548c\u5728\u7f16\u8f91\u9636\u6bb5\u5f15\u5165\u591a\u6a21\u6001\u6761\u4ef6\uff0c\u5b9e\u73b0\u4e86\u53ef\u8fed\u4ee3\u7f16\u8f91\u7684\u821e\u8e48\u5408\u6210\uff0c\u4e3a\u5b9e\u9645\u7f16\u821e\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2508.16823", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.16823", "abs": "https://arxiv.org/abs/2508.16823", "authors": ["Christopher Liaw", "Wennan Zhu"], "title": "Risk-Averse and Optimistic Advertiser Incentive Compatibility in Auto-bidding", "comment": null, "summary": "The rise of auto-bidding has created challenges for ensuring advertiser\nincentive compatibility, particularly when advertisers delegate bidding to\nagents with high-level constraints. One challenge in defining incentive\ncompatibility is the multiplicity of equilibria. After advertisers submit\nreports, it is unclear what the result will be and one only has knowledge of a\nrange of possible results. Nevertheless, Alimohammadi et al. proposed a notion\nof Auto-bidding Incentive Compatibility (AIC) which serves to highlight that\nauctions may not incentivize truthful reporting of constraints. However, their\ndefinition of AIC is very stringent as it requires that the worst-case outcome\nof an advertiser's truthful report is at least as good as the best-case outcome\nof any of the advertiser's possible deviations. Indeed, they show both\nFirst-Price Auction and Second-Price Auction are not AIC. Moreover, the AIC\ndefinition precludes having ordinal preferences on the possible constraints\nthat the advertiser can report.\n  In this paper, we introduce two refined and relaxed concepts: Risk-Averse\nAuto-bidding Incentive Compatibility (RAIC) and Optimistic Auto-bidding\nIncentive Compatibility (OAIC). RAIC (OAIC) stipulates that truthful reporting\nis preferred if its least (most) favorable equilibrium outcome is no worse than\nthe least (most) favorable equilibrium outcome from any misreport. This\ndistinction allows for a clearer modeling of ordinal preferences for\nadvertisers with differing attitudes towards equilibrium uncertainty. We\ndemonstrate that SPA satisfies both RAIC and OAIC. Furthermore, we show that\nSPA also meets these conditions for two advertisers when they are assumed to\nemploy uniform bidding. These findings provide new insights into the incentive\nproperties of SPA in auto-bidding environments, particularly when considering\nadvertisers' perspectives on equilibrium selection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u6539\u8fdb\u7684\u81ea\u52a8\u7ade\u4ef7\u6fc0\u52b1\u517c\u5bb9\u6027\u6982\u5ff5\u2014\u2014\u98ce\u9669\u538c\u6076\u578b\uff08RAIC\uff09\u548c\u4e50\u89c2\u578b\uff08OAIC\uff09\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\uff08SPA\uff09\u7684\u6fc0\u52b1\u7279\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u81ea\u52a8\u7ade\u4ef7\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u3002", "motivation": "\u81ea\u52a8\u7ade\u4ef7\u7684\u5174\u8d77\u4e3a\u5e7f\u544a\u5546\u7684\u6fc0\u52b1\u517c\u5bb9\u6027\u5e26\u6765\u4e86\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5e7f\u544a\u5546\u5c06\u7ade\u4ef7\u59d4\u6258\u7ed9\u5177\u6709\u9ad8\u5c42\u7ea6\u675f\u7684\u4ee3\u7406\u65f6\u3002\u73b0\u6709\u7684\u81ea\u52a8\u7ade\u4ef7\u6fc0\u52b1\u517c\u5bb9\u6027\uff08AIC\uff09\u5b9a\u4e49\u8fc7\u4e8e\u4e25\u683c\uff0c\u4e14\u5ffd\u7565\u4e86\u5e7f\u544a\u5546\u5bf9\u7ea6\u675f\u7684\u591a\u91cd\u504f\u597d\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u4e24\u79cd\u6539\u8fdb\u7684\u6fc0\u52b1\u517c\u5bb9\u6027\u6982\u5ff5\uff1a\u98ce\u9669\u538c\u6076\u578b\u81ea\u52a8\u7ade\u4ef7\u6fc0\u52b1\u517c\u5bb9\u6027\uff08RAIC\uff09\u548c\u4e50\u89c2\u578b\u81ea\u52a8\u7ade\u4ef7\u6fc0\u52b1\u517c\u5bb9\u6027\uff08OAIC\uff09\u3002\u8fd9\u4e9b\u6982\u5ff5\u901a\u8fc7\u6bd4\u8f83\u771f\u5b9e\u62a5\u544a\u548c\u8bef\u62a5\u7684\u6700\u4f18\u6216\u6700\u5dee\u5747\u8861\u7ed3\u679c\u6765\u5b9a\u4e49\u6fc0\u52b1\u517c\u5bb9\u6027\u3002", "result": "\u8bba\u6587\u8bc1\u660e\u4e86\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\uff08SPA\uff09\u6ee1\u8db3RAIC\u548cOAIC\u6761\u4ef6\uff0c\u5e76\u4e14\u5728\u5047\u8bbe\u4e24\u4e2a\u5e7f\u544a\u5546\u91c7\u7528\u7edf\u4e00\u7ade\u4ef7\u65f6\uff0cSPA\u4ecd\u7136\u6ee1\u8db3\u8fd9\u4e9b\u6761\u4ef6\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u81ea\u52a8\u7ade\u4ef7\u73af\u5883\u4e2dSPA\u7684\u6fc0\u52b1\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5c24\u5176\u662f\u5728\u8003\u8651\u5e7f\u544a\u5546\u5bf9\u5747\u8861\u9009\u62e9\u7684\u4e0d\u540c\u6001\u5ea6\u65f6\u3002"}}
{"id": "2508.16746", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.16746", "abs": "https://arxiv.org/abs/2508.16746", "authors": ["Karuna Grewal", "P. Brighten Godfrey", "Justin Hsu"], "title": "SafeTree: Expressive Tree Policies for Microservices", "comment": null, "summary": "A microservice-based application is composed of multiple self-contained\ncomponents called microservices, and controlling inter-service communication is\nimportant for enforcing safety properties. Presently, inter-service\ncommunication is configured using microservice deployment tools. However, such\ntools only support a limited class of single-hop policies, which can be overly\npermissive because they ignore the rich service tree structure of microservice\ncalls. Policies that can express the service tree structure can offer\ndevelopment and security teams more fine-grained control over communication\npatterns.\n  To this end, we design an expressive policy language to specify service tree\nstructures, and we develop a visibly pushdown automata-based dynamic\nenforcement mechanism to enforce service tree policies. Our technique is\nnon-invasive: it does not require any changes to service implementations, and\ndoes not require access to microservice code. To realize our method, we build a\nruntime monitor on top of a service mesh, an emerging network infrastructure\nlayer that can control inter-service communication during deployment. In\nparticular, we employ the programmable network traffic filtering capabilities\nof Istio, a popular service mesh implementation, to implement an online and\ndistributed monitor. Our experiments show that our monitor can enforce rich\nsafety properties while adding minimal latency overhead on the order of\nmilliseconds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u670d\u52a1\u6811\u7ed3\u6784\u7684\u7b56\u7565\u8bed\u8a00\u548c\u6267\u884c\u673a\u5236\uff0c\u901a\u8fc7\u975e\u4fb5\u5165\u5f0f\u8fd0\u884c\u65f6\u76d1\u63a7\u5728\u670d\u52a1\u7f51\u683c\u4e2d\u5b9e\u73b0\u7cbe\u7ec6\u5316\u7684\u901a\u4fe1\u63a7\u5236\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u4e0b\u6709\u6548\u6267\u884c\u5b89\u5168\u6027\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u5fae\u670d\u52a1\u90e8\u7f72\u5de5\u5177\u4ec5\u652f\u6301\u7b80\u5355\u7684\u5355\u8df3\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u5fae\u670d\u52a1\u8c03\u7528\u4e2d\u7684\u6811\u5f62\u7ed3\u6784\uff0c\u5bfc\u81f4\u7b56\u7565\u53ef\u80fd\u8fc7\u4e8e\u5bbd\u677e\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u5316\u7684\u7b56\u7565\u8bed\u8a00\u548c\u6267\u884c\u673a\u5236\u6765\u63a7\u5236\u901a\u4fe1\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8868\u8fbe\u6027\u5f3a\u7684\u7b56\u7565\u8bed\u8a00\u63cf\u8ff0\u670d\u52a1\u6811\u7ed3\u6784\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u663e\u5f0f\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u52a8\u6001\u6267\u884c\u673a\u5236\u3002\u5728\u670d\u52a1\u7f51\u683c\u4e0a\u6784\u5efa\u8fd0\u884c\u65f6\u76d1\u63a7\uff0c\u5229\u7528Istio\u7684\u53ef\u7f16\u7a0b\u7f51\u7edc\u6d41\u91cf\u8fc7\u6ee4\u529f\u80fd\u5b9e\u73b0\u5206\u5e03\u5f0f\u76d1\u63a7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u5f00\u9500\u4e0b\u5f3a\u5236\u6267\u884c\u4e30\u5bcc\u7684\u5b89\u5168\u7b56\u7565\uff0c\u4e14\u65e0\u9700\u4fee\u6539\u670d\u52a1\u5b9e\u73b0\u6216\u8bbf\u95ee\u5fae\u670d\u52a1\u4ee3\u7801\u3002", "conclusion": "\u63d0\u51fa\u7684\u975e\u4fb5\u5165\u5f0f\u76d1\u63a7\u65b9\u6cd5\u4e3a\u5f00\u53d1\u548c\u5b89\u5168\u7ba1\u7406\u56e2\u961f\u63d0\u4f9b\u4e86\u5bf9\u5fae\u670d\u52a1\u901a\u4fe1\u6a21\u5f0f\u7684\u7cbe\u7ec6\u5316\u63a7\u5236\uff0c\u6709\u6548\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.17480", "categories": ["cs.GR", "cs.AR", "eess.IV", "eess.SP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2508.17480", "abs": "https://arxiv.org/abs/2508.17480", "authors": ["Brian Chao", "Jacqueline Yang", "Suyeon Choi", "Manu Gopakumar", "Ryota Koiso", "Gordon Wetzstein"], "title": "Random-phase Gaussian Wave Splatting for Computer-generated Holography", "comment": null, "summary": "Holographic near-eye displays offer ultra-compact form factors for virtual\nand augmented reality systems, but rely on advanced computer-generated\nholography (CGH) algorithms to convert 3D scenes into interference patterns\nthat can be displayed on spatial light modulators (SLMs). Gaussian Wave\nSplatting (GWS) has recently emerged as a powerful CGH paradigm that allows for\nthe conversion of Gaussians, a state-of-the-art neural 3D representation, into\nholograms. However, GWS assumes smooth-phase distributions over the Gaussian\nprimitives, limiting their ability to model view-dependent effects and\nreconstruct accurate defocus blur, and severely under-utilizing the\nspace-bandwidth product of the SLM. In this work, we propose random-phase GWS\n(GWS-RP) to improve bandwidth utilization, which has the effect of increasing\neyebox size, reconstructing accurate defocus blur and parallax, and supporting\ntime-multiplexed rendering to suppress speckle artifacts.\n  At the core of GWS-RP are (1) a fundamentally new wavefront compositing\nprocedure and (2) an alpha-blending scheme specifically designed for\nrandom-phase Gaussian primitives, ensuring physically correct color\nreconstruction and robust occlusion handling. Additionally, we present the\nfirst formally derived algorithm for applying random phase to Gaussian\nprimitives, grounded in rigorous statistical optics analysis and validated\nthrough practical near-eye display applications. Through extensive simulations\nand experimental validations, we demonstrate that these advancements,\ncollectively with time-multiplexing, uniquely enables full-bandwith light field\nCGH that supports accurate accurate parallax and defocus, yielding\nstate-of-the-art image quality and perceptually faithful 3D holograms for\nnext-generation near-eye displays.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGWS-RP\u7684\u968f\u673a\u76f8\u4f4d\u9ad8\u65af\u6ce2\u6e85\u5c04\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u5e26\u5bbd\u5229\u7528\uff0c\u63d0\u5347\u5168\u606f\u8fd1\u773c\u663e\u793a\u7684\u56fe\u50cf\u8d28\u91cf\u548c3D\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u65af\u6ce2\u6e85\u5c04\uff08GWS\uff09\u65b9\u6cd5\u5047\u8bbe\u9ad8\u65af\u539f\u8bed\u5177\u6709\u5e73\u6ed1\u76f8\u4f4d\u5206\u5e03\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u89c6\u56fe\u4f9d\u8d56\u6548\u5e94\u548c\u6563\u7126\u6a21\u7cca\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u7a7a\u95f4\u5149\u8c03\u5236\u5668\u7684\u5e26\u5bbd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u76f8\u4f4d\u9ad8\u65af\u6ce2\u6e85\u5c04\uff08GWS-RP\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u65b0\u7684\u6ce2\u524d\u5408\u6210\u6d41\u7a0b\u548c\u9488\u5bf9\u968f\u673a\u76f8\u4f4d\u9ad8\u65af\u539f\u8bed\u7684Alpha\u6df7\u5408\u65b9\u6848\uff0c\u5e76\u9996\u6b21\u63a8\u5bfc\u4e86\u5c06\u968f\u673a\u76f8\u4f4d\u5e94\u7528\u4e8e\u9ad8\u65af\u539f\u8bed\u7684\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0cGWS-RP\u5728\u63d0\u5347\u5e26\u5bbd\u5229\u7528\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u5927\u7684\u89c6\u7a97\u3001\u51c6\u786e\u7684\u6563\u7126\u6a21\u7cca\u548c\u89c6\u5dee\u6548\u679c\uff0c\u5e76\u652f\u6301\u65f6\u95f4\u590d\u7528\u6e32\u67d3\u4ee5\u51cf\u5c11\u6563\u6591\u566a\u58f0\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u76843D\u5168\u606f\u56fe\u50cf\u3002", "conclusion": "GWS-RP\u4e3a\u65b0\u4e00\u4ee3\u5168\u606f\u8fd1\u773c\u663e\u793a\u63d0\u4f9b\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u56fe\u50cf\u548c\u66f4\u771f\u5b9e\u76843D\u6548\u679c\uff0c\u662f\u8ba1\u7b97\u673a\u751f\u6210\u5168\u606f\u672f\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2508.17111", "categories": ["cs.GT", "cs.SI"], "pdf": "https://arxiv.org/pdf/2508.17111", "abs": "https://arxiv.org/abs/2508.17111", "authors": ["Qinqi Lin", "Lingjie Duan", "Jianwei Huang"], "title": "Personalized Pricing Through Strategic User Profiling in Social Networks", "comment": "Published in IEEE/ACM Transactions on Networking (complete version\n  with supplmentary materials included)", "summary": "Traditional user profiling techniques rely on browsing history or purchase\nrecords to identify users' willingness to pay. This enables sellers to offer\npersonalized prices to profiled users while charging only a uniform price to\nnon-profiled users. However, the emergence of privacy-enhancing technologies\nhas caused users to actively avoid on-site data tracking. Today, major online\nsellers have turned to public platforms such as online social networks to\nbetter track users' profiles from their product-related discussions. This paper\npresents the first analytical study on how users should best manage their\nsocial activities against potential personalized pricing, and how a seller\nshould strategically adjust her pricing scheme to facilitate user profiling in\nsocial networks. We formulate a dynamic Bayesian game played between the seller\nand users under asymmetric information. The key challenge of analyzing this\ngame comes from the double couplings between the seller and the users as well\nas among the users. Furthermore, the equilibrium analysis needs to ensure\nconsistency between users' revealed information and the seller's belief under\nrandom user profiling. We address these challenges by alternately applying\nbackward and forward induction, and successfully characterize the unique\nperfect Bayesian equilibrium (PBE) in closed form. Our analysis reveals that as\nthe accuracy of profiling technology improves, the seller tends to raise the\nequilibrium uniform price to motivate users' increased social activities and\nfacilitate user profiling. However, this results in most users being worse off\nafter the informed consent policy is imposed to ensure users' awareness of data\naccess and profiling practices by potential sellers. This finding suggests that\nrecent regulatory evolution towards enhancing users' privacy awareness may have\nunintended consequences of reducing users' payoffs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5206\u6790\u4e86\u7528\u6237\u5982\u4f55\u5728\u793e\u4ea4\u5a92\u4f53\u6d3b\u52a8\u4e2d\u6700\u4f73\u7ba1\u7406\u4ee5\u5e94\u5bf9\u6f5c\u5728\u7684\u4e2a\u6027\u5316\u5b9a\u4ef7\uff0c\u4ee5\u53ca\u5356\u5bb6\u5982\u4f55\u7b56\u7565\u6027\u5730\u8c03\u6574\u5b9a\u4ef7\u65b9\u6848\u4ee5\u4fc3\u8fdb\u7528\u6237\u753b\u50cf\u3002\u901a\u8fc7\u52a8\u6001\u8d1d\u53f6\u65af\u535a\u5f08\u6a21\u578b\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u968f\u7740\u753b\u50cf\u6280\u672f\u51c6\u786e\u6027\u7684\u63d0\u9ad8\uff0c\u5356\u5bb6\u503e\u5411\u4e8e\u63d0\u9ad8\u5747\u8861\u7edf\u4e00\u4ef7\u683c\u4ee5\u6fc0\u52b1\u7528\u6237\u589e\u52a0\u793e\u4ea4\u6d3b\u52a8\uff0c\u4f46\u5bfc\u81f4\u5927\u591a\u6570\u7528\u6237\u5728\u77e5\u60c5\u540c\u610f\u653f\u7b56\u4e0b\u53d8\u5f97\u66f4\u7cdf\u3002", "motivation": "\u968f\u7740\u9690\u79c1\u589e\u5f3a\u6280\u672f\u7684\u5174\u8d77\uff0c\u7528\u6237\u5f00\u59cb\u907f\u514d\u6570\u636e\u8ddf\u8e2a\uff0c\u5356\u5bb6\u8f6c\u5411\u793e\u4ea4\u7f51\u7edc\u8fdb\u884c\u7528\u6237\u753b\u50cf\u3002\u7814\u7a76\u65e8\u5728\u5206\u6790\u7528\u6237\u5982\u4f55\u7ba1\u7406\u4e0e\u5356\u5bb6\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u4ee5\u5e94\u5bf9\u4e2a\u6027\u5316\u5b9a\u4ef7\uff0c\u4ee5\u53ca\u5356\u5bb6\u5982\u4f55\u7b56\u7565\u8c03\u6574\u5b9a\u4ef7\u65b9\u6848\u3002", "method": "\u7814\u7a76\u91c7\u7528\u52a8\u6001\u8d1d\u53f6\u65af\u535a\u5f08\u6a21\u578b\uff0c\u5206\u6790\u5356\u5bb6\u548c\u7528\u6237\u5728\u4e0d\u5bf9\u79f0\u4fe1\u606f\u4e0b\u7684\u4e92\u52a8\u3002\u901a\u8fc7\u4ea4\u66ff\u5e94\u7528\u524d\u540e\u5411\u5f52\u7eb3\u6cd5\uff0c\u6210\u529f\u523b\u753b\u4e86\u552f\u4e00\u7684\u5b8c\u7f8e\u8d1d\u53f6\u65af\u5747\u8861\uff08PBE\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u968f\u7740\u753b\u50cf\u6280\u672f\u51c6\u786e\u6027\u7684\u63d0\u9ad8\uff0c\u5356\u5bb6\u63d0\u9ad8\u5747\u8861\u7edf\u4e00\u4ef7\u683c\u4ee5\u6fc0\u52b1\u7528\u6237\u793e\u4ea4\u6d3b\u52a8\uff0c\u4f46\u5bfc\u81f4\u5927\u591a\u6570\u7528\u6237\u5728\u77e5\u60c5\u540c\u610f\u653f\u7b56\u4e0b\u53d8\u5f97\u66f4\u7cdf\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\uff0c\u589e\u5f3a\u7528\u6237\u9690\u79c1\u610f\u8bc6\u7684\u76d1\u7ba1\u6539\u9769\u53ef\u80fd\u4f1a\u610f\u5916\u51cf\u5c11\u7528\u6237\u7684\u6536\u76ca\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u9690\u79c1\u4fdd\u62a4\u653f\u7b56\u53ef\u80fd\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2508.16848", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.16848", "abs": "https://arxiv.org/abs/2508.16848", "authors": ["David Moon", "Andrew Blinn", "Thomas J. Porter", "Cyrus Omar"], "title": "Syntactic Completions with Material Obligations", "comment": null, "summary": "Code editors provide essential services that help developers understand,\nnavigate, and modify programs. However, these services often fail in the\npresence of syntax errors. Existing syntax error recovery techniques, like\npanic mode and multi-option repairs, are either too coarse, e.g. in deleting\nlarge swathes of code, or lead to a proliferation of possible completions. This\npaper introduces $\\texttt{tylr}$, a parser and editor generator that completes\narbitrarily malformed code by inserting obligations, which generalize holes to\ncover missing operands, operators, mixfix keywords, and sort transitions.\n$\\texttt{tylr}$ is backed by a novel theory of tile-based parsing, which\nextends operator-precedence parsing in two ways. First, traditional token\nprecedence comparisons are replaced by a notion of grammar walks, which form\nthe basis for generating obligations. Second, a distinct \"molding\" system based\non grammar zippers expand grammar expressivity by allowing the system to\ndisambiguate between possible parses and completions based on an obligation\nminimization criterion. In addition to serving as a novel approach to error\ncorrection, $\\texttt{tylr}$'s design enables the development of an editor that\nvisually materializes obligations to the human user, serving as a novel hybrid\nbetween a text editor and a structure editor. We introduce $\\texttt{tylr}$ by\nexample, then formalize its key ideas. Finally, we conduct a human subjects\nstudy to evaluate the extent to which an editor like $\\texttt{tylr}$ that\nmaterializes syntactic obligations might be usable and useful, finding both\npoints of positivity and interesting new avenues for future work.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a$\\texttt{tylr}$\u7684\u89e3\u6790\u5668\u548c\u7f16\u8f91\u5668\u751f\u6210\u5de5\u5177\uff0c\u901a\u8fc7\u63d2\u5165\u201c\u4e49\u52a1\u201d\u6765\u8865\u5168\u4ee3\u7801\u4e2d\u7684\u8bed\u6cd5\u9519\u8bef\uff0c\u5e76\u652f\u6301\u89c6\u89c9\u5316\u5c55\u793a\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u4ecb\u4e8e\u6587\u672c\u7f16\u8f91\u5668\u548c\u7ed3\u6784\u7f16\u8f91\u5668\u4e4b\u95f4\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u6cd5\u9519\u8bef\u6062\u590d\u6280\u672f\uff08\u5982\u6050\u614c\u6a21\u5f0f\u548c\u591a\u9009\u9879\u4fee\u590d\uff09\u8981\u4e48\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u8981\u4e48\u5bfc\u81f4\u8865\u5168\u9009\u9879\u8fc7\u591a\u3002$\\texttt{tylr}$\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u548c\u7075\u6d3b\u7684\u8bed\u6cd5\u9519\u8bef\u8865\u5168\u65b9\u6cd5\u3002", "method": "$\\texttt{tylr}$\u57fa\u4e8e\u6539\u8fdb\u7684\u57fa\u4e8e\u74e6\u7247\u7684\u89e3\u6790\u7406\u8bba\uff0c\u901a\u8fc7\u8bed\u6cd5\u884c\u8d70\u751f\u6210\u4e49\u52a1\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u8bed\u6cd5\u62c9\u94fe\u7684\u201c\u6210\u578b\u201d\u7cfb\u7edf\u6269\u5c55\u8bed\u6cd5\u8868\u8fbe\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u89c6\u89c9\u5316\u5c55\u793a\u529f\u80fd\u3002", "result": "\u901a\u8fc7\u793a\u4f8b\u548c\u5f62\u5f0f\u5316\u5206\u6790\uff0c\u8bba\u6587\u5c55\u793a\u4e86$\\texttt{tylr}$\u7684\u6709\u6548\u6027\u3002\u4eba\u7c7b\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u53ef\u89c6\u5316\u7684\u8bed\u6cd5\u4e49\u52a1\u7f16\u8f91\u5668\u5177\u6709\u5b9e\u7528\u6027\u548c\u6f5c\u529b\u3002", "conclusion": "$\\texttt{tylr}$\u4e3a\u8bed\u6cd5\u9519\u8bef\u8865\u5168\u548c\u4ee3\u7801\u7f16\u8f91\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u672a\u6765\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2508.17620", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.17620", "abs": "https://arxiv.org/abs/2508.17620", "authors": ["Dingkun Yan", "Xinrui Wang", "Zhuoru Li", "Suguru Saito", "Yusuke Iwasawa", "Yutaka Matsuo", "Jiaxian Guo"], "title": "Enhancing Reference-based Sketch Colorization via Separating Reference Representations", "comment": null, "summary": "Reference-based sketch colorization methods have garnered significant\nattention for the potential application in animation and digital illustration\nproduction. However, most existing methods are trained with image triplets of\nsketch, reference, and ground truth that are semantically and spatially\nsimilar, while real-world references and sketches often exhibit substantial\nmisalignment. This mismatch in data distribution between training and inference\nleads to overfitting, consequently resulting in artifacts and signif- icant\nquality degradation in colorization results. To address this issue, we conduct\nan in-depth analysis of the reference representations, defined as the\nintermedium to transfer information from reference to sketch. Building on this\nanalysis, we introduce a novel framework that leverages distinct reference\nrepresentations to optimize different aspects of the colorization process. Our\napproach decomposes colorization into modular stages, al- lowing\nregion-specific reference injection to enhance visual quality and reference\nsimilarity while mitigating spatial artifacts. Specifically, we first train a\nbackbone network guided by high-level semantic embeddings. We then introduce a\nbackground encoder and a style encoder, trained in separate stages, to enhance\nlow-level feature transfer and improve reference similar- ity. This design also\nenables flexible inference modes suited for a variety of use cases. Extensive\nqualitative and quantitative evaluations, together with a user study,\ndemonstrate the superior performance of our proposed method compared to\nexisting approaches. Code and pre-trained weight will be made publicly\navailable upon paper acceptance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53c2\u8003\u7684\u8349\u56fe\u7740\u8272\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7740\u8272\u8fc7\u7a0b\u4e3a\u6a21\u5757\u5316\u9636\u6bb5\uff0c\u4f18\u5316\u4e86\u89c6\u89c9\u8d28\u91cf\u548c\u53c2\u8003\u76f8\u4f3c\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u7a7a\u95f4\u4f2a\u5f71\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u8003\u7740\u8272\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u6570\u636e\u548c\u63a8\u7406\u6570\u636e\u7684\u5206\u5e03\u4e00\u81f4\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u8349\u56fe\u548c\u53c2\u8003\u56fe\u50cf\u5f80\u5f80\u5b58\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\uff0c\u5bfc\u81f4\u989c\u8272\u5316\u7ed3\u679c\u51fa\u73b0\u4f2a\u5f71\u548c\u8d28\u91cf\u4e0b\u964d\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7740\u8272\u8fc7\u7a0b\u4e3a\u6a21\u5757\u5316\u9636\u6bb5\uff0c\u5e76\u5f15\u5165\u80cc\u666f\u7f16\u7801\u5668\u548c\u98ce\u683c\u7f16\u7801\u5668\uff0c\u5206\u522b\u5728\u4e0d\u540c\u9636\u6bb5\u8bad\u7ec3\uff0c\u4ee5\u4f18\u5316\u4f4e\u5c42\u7ea7\u7279\u5f81\u7684\u8f6c\u79fb\u548c\u53c2\u8003\u76f8\u4f3c\u5ea6\u3002", "result": "\u5b9e\u9a8c\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u4ee5\u53ca\u7528\u6237\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u53c2\u8003\u76f8\u4f3c\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u6846\u67b6\u663e\u8457\u6539\u8fdb\u4e86\u8349\u56fe\u7740\u8272\u6548\u679c\uff0c\u5e76\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2508.17177", "categories": ["cs.GT", "91B12, 91B14, 68Q25, 68T01", "F.2; I.2; J.4"], "pdf": "https://arxiv.org/pdf/2508.17177", "abs": "https://arxiv.org/abs/2508.17177", "authors": ["Ratip Emin Berker", "Ben Armstrong", "Vincent Conitzer", "Nihar B. Shah"], "title": "Designing Rules to Pick a Rule: Aggregation by Consistency", "comment": "42 pages, 7 figures", "summary": "Given a set of items and a set of evaluators who all individually rank them,\nhow do we aggregate these evaluations into a single societal ranking? Work in\nsocial choice and statistics has produced many aggregation methods for this\nproblem, each with its desirable properties, but also with its limitations.\nFurther, existing impossibility results rule out designing a single method that\nachieves every property of interest. Faced with this trade-off between\nincompatible desiderata, how do we decide which aggregation rule to use, i.e.,\nwhat is a good rule picking rule?\n  In this paper, we formally address this question by introducing a novel\nframework for rule picking rules (RPRs). We then design a data-driven RPR that\nidentifies the best aggregation method for each specific setting, without\nassuming any generative model. The principle behind our RPR is to pick the rule\nwhich maximizes the consistency of the output ranking if the data collection\nprocess were repeated. We introduce several consistency-related axioms for RPRs\nand show that our method satisfies them, including those failed by a wide class\nof natural RPRs. While we prove that the algorithmic problem of maximizing\nconsistency is computationally hard, we provide a sampling-based implementation\nof our RPR that is efficient in practice. We run this implementation on known\nstatistical models and find that, when possible, our method selects the maximum\nlikelihood estimator of the data. Finally, we show that our RPR can be used in\nmany real-world settings to gain insights about how the rule currently being\nused can be modified or replaced to substantially improve the consistency of\nthe process.\n  Taken together, our work bridges an important gap between the axiomatic and\nstatistical approaches to rank aggregation, laying a robust theoretical and\ncomputational foundation for principled rule picking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89c4\u5219\u9009\u62e9\u89c4\u5219\uff08RPR\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u7ed3\u679c\u7684\u91cd\u590d\u4e00\u81f4\u6027\u6765\u9009\u62e9\u6700\u4f18\u6392\u540d\u805a\u5408\u65b9\u6cd5\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u6392\u540d\u805a\u5408\u95ee\u9898\u4e2d\uff0c\u73b0\u6709\u65b9\u6cd5\u5404\u6709\u4f18\u7f3a\u70b9\u4e14\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u7406\u60f3\u5c5e\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u9002\u5408\u5177\u4f53\u573a\u666f\u7684\u805a\u5408\u89c4\u5219\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u89c4\u5219\u9009\u62e9\u89c4\u5219\uff08RPR\uff09\uff0c\u901a\u8fc7\u6700\u5927\u5316\u91cd\u590d\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u7684\u4e00\u81f4\u6027\u6765\u9009\u53d6\u6700\u4f73\u805a\u5408\u65b9\u6cd5\uff0c\u65e0\u9700\u5047\u8bbe\u751f\u6210\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u7684RPR\u6ee1\u8db3\u591a\u9879\u4e00\u81f4\u6027\u516c\u7406\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u6210\u529f\u9009\u62e9\u4e86\u6570\u636e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u6392\u540d\u805a\u5408\u95ee\u9898\u4e2d\u7684\u89c4\u5219\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5c06\u516c\u7406\u5316\u548c\u7edf\u8ba1\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u89c4\u5219\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.17645", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.17645", "abs": "https://arxiv.org/abs/2508.17645", "authors": ["Xiaoyang Huang", "Bingbing Ni", "Wenjun Zhang"], "title": "Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph", "comment": null, "summary": "The emergence of 3D artificial intelligence-generated content (3D-AIGC) has\nenabled rapid synthesis of intricate geometries. However, a fundamental\ndisconnect persists between AI-generated content and human-centric design\nparadigms, rooted in representational incompatibilities: conventional AI\nframeworks predominantly manipulate meshes or neural representations\n(\\emph{e.g.}, NeRF, Gaussian Splatting), while designers operate within\nparametric modeling tools. This disconnection diminishes the practical value of\nAI for 3D industry, undermining the efficiency of human-AI collaboration. To\nresolve this disparity, we focus on generating design operation sequences,\nwhich are structured modeling histories that comprehensively capture the\nstep-by-step construction process of 3D assets and align with designers'\ntypical workflows in modern 3D software. We first reformulate fundamental\nmodeling operations (\\emph{e.g.}, \\emph{Extrude}, \\emph{Boolean}) into\ndifferentiable units, enabling joint optimization of continuous (\\emph{e.g.},\n\\emph{Extrude} height) and discrete (\\emph{e.g.}, \\emph{Boolean} type)\nparameters via gradient-based learning. Based on these differentiable\noperations, a hierarchical graph with gating mechanism is constructed and\noptimized end-to-end by minimizing Chamfer Distance to target geometries.\nMulti-stage sequence length constraint and domain rule penalties enable\nunsupervised learning of compact design sequences without ground-truth sequence\nsupervision. Extensive validation demonstrates that the generated operation\nsequences achieve high geometric fidelity, smooth mesh wiring, rational step\ncomposition and flexible editing capacity, with full compatibility within\ndesign industry.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06AI\u751f\u6210\u76843D\u5185\u5bb9\u4e0e\u8bbe\u8ba1\u5e08\u5de5\u4f5c\u6d41\u7a0b\u5bf9\u63a5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u64cd\u4f5c\u5e8f\u5217\u5b9e\u73b0\u9ad8\u6548\u51e0\u4f55\u5efa\u6a21\uff0c\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002", "motivation": "\u5f53\u524dAI\u751f\u6210\u76843D\u5185\u5bb9\uff08\u5982\u7f51\u683c\u6216\u795e\u7ecf\u8868\u793a\uff09\u4e0e\u8bbe\u8ba1\u5e08\u4f7f\u7528\u7684\u53c2\u6570\u5316\u5efa\u6a21\u5de5\u5177\u4e4b\u95f4\u5b58\u5728\u8131\u8282\uff0c\u9650\u5236\u4e86AI\u57283D\u8bbe\u8ba1\u884c\u4e1a\u7684\u5b9e\u7528\u4ef7\u503c\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u9e3f\u6c9f\uff0c\u4f7fAI\u751f\u6210\u7684\u5185\u5bb9\u66f4\u8d34\u5408\u8bbe\u8ba1\u5e08\u7684\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u8bba\u6587\u5c06\u57fa\u672c\u5efa\u6a21\u64cd\u4f5c\uff08\u5982\u6324\u51fa\u3001\u5e03\u5c14\u8fd0\u7b97\uff09\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u5355\u5143\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u5b66\u4e60\u4f18\u5316\u8fde\u7eed\u548c\u79bb\u6563\u53c2\u6570\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u5e26\u6709\u95e8\u63a7\u673a\u5236\u7684\u5206\u5c42\u56fe\uff0c\u901a\u8fc7\u6700\u5c0f\u5316Chamfer\u8ddd\u79bb\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\u3002\u591a\u9636\u6bb5\u5e8f\u5217\u957f\u5ea6\u7ea6\u675f\u548c\u9886\u57df\u89c4\u5219\u60e9\u7f5a\u5b9e\u73b0\u4e86\u65e0\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u751f\u6210\u76843D\u8bbe\u8ba1\u64cd\u4f5c\u5e8f\u5217\u5728\u51e0\u4f55\u4fdd\u771f\u5ea6\u3001\u7f51\u683c\u5e73\u6ed1\u6027\u3001\u6b65\u9aa4\u5408\u7406\u6027\u4ee5\u53ca\u7f16\u8f91\u7075\u6d3b\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5b8c\u5168\u517c\u5bb9\u8bbe\u8ba1\u884c\u4e1a\u6807\u51c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06AI\u751f\u6210\u76843D\u5185\u5bb9\u4e0e\u8bbe\u8ba1\u5e08\u7684\u5de5\u4f5c\u6d41\u7a0b\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u7387\uff0c\u5e76\u5c55\u793a\u4e86\u57283D\u8bbe\u8ba1\u884c\u4e1a\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2508.17206", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.17206", "abs": "https://arxiv.org/abs/2508.17206", "authors": ["Chenlan Wang", "Mingyan Liu"], "title": "Decision-Making on Timing and Route Selection: A Game-Theoretic Approach", "comment": "This work has been accepted for publication in the proceedings of the\n  2025 64th IEEE Conference on Decision and Control (CDC)", "summary": "We present a Stackelberg game model to investigate how individuals make their\ndecisions on timing and route selection. Group formation can naturally result\nfrom these decisions, but only when individuals arrive at the same time and\nchoose the same route. Although motivated by bird migration, our model applies\nto scenarios such as traffic planning, disaster evacuation, and other animal\nmovements. Early arrivals secure better territories, while traveling together\nenhances navigation accuracy, foraging efficiency, and energy efficiency.\nLonger or more difficult migration routes reduce predation risks but increase\ntravel costs, such as higher elevations and scarce food resources. Our analysis\nreveals a richer set of subgame perfect equilibria (SPEs) and heightened\ncompetition, compared to earlier models focused only on timing. By\nincorporating individual differences in travel costs, our model introduces a\n\"neutrality\" state in addition to \"cooperation\" and \"competition.\"", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2aStackelberg\u535a\u5f08\u6a21\u578b\uff0c\u7814\u7a76\u4e2a\u4f53\u5728\u65f6\u95f4\u548c\u8def\u7ebf\u9009\u62e9\u4e0a\u7684\u51b3\u7b56\uff0c\u9002\u7528\u4e8e\u9e1f\u7c7b\u8fc1\u5f99\u3001\u4ea4\u901a\u89c4\u5212\u7b49\u591a\u79cd\u573a\u666f\u3002", "motivation": "\u7814\u7a76\u4e2a\u4f53\u5728\u65f6\u95f4\u548c\u8def\u7ebf\u9009\u62e9\u4e0a\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u5e76\u63a2\u8ba8\u8fd9\u4e9b\u884c\u4e3a\u5982\u4f55\u81ea\u7136\u5f62\u6210\u7fa4\u4f53\uff0c\u7279\u522b\u662f\u5728\u9e1f\u7c7b\u8fc1\u5f99\u3001\u4ea4\u901a\u89c4\u5212\u7b49\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528Stackelberg\u535a\u5f08\u6a21\u578b\uff0c\u7ed3\u5408\u4e2a\u4f53\u7684\u65c5\u884c\u6210\u672c\u5dee\u5f02\uff0c\u5206\u6790\u65f6\u95f4\u548c\u8def\u7ebf\u9009\u62e9\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u6a21\u578b\u63ed\u793a\u4e86\u6bd4\u4ee5\u5f80\u4ec5\u5173\u6ce8\u65f6\u95f4\u7684\u6a21\u578b\u66f4\u4e30\u5bcc\u7684\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\uff08SPEs\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u4e2d\u6027\u72b6\u6001\uff0c\u6269\u5c55\u4e86\u201c\u5408\u4f5c\u201d\u4e0e\u201c\u7ade\u4e89\u201d\u4e4b\u5916\u7684\u9009\u9879\u3002", "conclusion": "\u6a21\u578b\u4e0d\u4ec5\u9002\u7528\u4e8e\u9e1f\u7c7b\u8fc1\u5f99\uff0c\u8fd8\u4e3a\u4ea4\u901a\u89c4\u5212\u548c\u707e\u5bb3\u758f\u6563\u7b49\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u65f6\u95f4\u548c\u8def\u7ebf\u9009\u62e9\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2508.17811", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.17811", "abs": "https://arxiv.org/abs/2508.17811", "authors": ["Hanzhi Chang", "Ruijie Zhu", "Wenjie Chang", "Mulin Yu", "Yanzhe Liang", "Jiahao Lu", "Zhuoyuan Li", "Tianzhu Zhang"], "title": "MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting", "comment": "17 pages, 15 figures, 5 tables", "summary": "Surface reconstruction has been widely studied in computer vision and\ngraphics. However, existing surface reconstruction works struggle to recover\naccurate scene geometry when the input views are extremely sparse. To address\nthis issue, we propose MeshSplat, a generalizable sparse-view surface\nreconstruction framework via Gaussian Splatting. Our key idea is to leverage\n2DGS as a bridge, which connects novel view synthesis to learned geometric\npriors and then transfers these priors to achieve surface reconstruction.\nSpecifically, we incorporate a feed-forward network to predict per-view\npixel-aligned 2DGS, which enables the network to synthesize novel view images\nand thus eliminates the need for direct 3D ground-truth supervision. To improve\nthe accuracy of 2DGS position and orientation prediction, we propose a Weighted\nChamfer Distance Loss to regularize the depth maps, especially in overlapping\nareas of input views, and also a normal prediction network to align the\norientation of 2DGS with normal vectors predicted by a monocular normal\nestimator. Extensive experiments validate the effectiveness of our proposed\nimprovement, demonstrating that our method achieves state-of-the-art\nperformance in generalizable sparse-view mesh reconstruction tasks. Project\nPage: https://hanzhichang.github.io/meshsplat_web", "AI": {"tldr": "MeshSplat\u662f\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6e85\u5c04\u7684\u901a\u7528\u7a00\u758f\u89c6\u56fe\u8868\u9762\u91cd\u5efa\u6846\u67b6\uff0c\u901a\u8fc72DGS\u8fde\u63a5\u65b0\u89c6\u56fe\u5408\u6210\u4e0e\u5b66\u4e60\u51e0\u4f55\u5148\u9a8c\uff0c\u4ece\u800c\u5728\u7a00\u758f\u8f93\u5165\u89c6\u56fe\u4e0b\u5b9e\u73b0\u7cbe\u786e\u7684\u51e0\u4f55\u6062\u590d\u3002", "motivation": "\u73b0\u6709\u8868\u9762\u91cd\u5efa\u65b9\u6cd5\u5728\u8f93\u5165\u89c6\u56fe\u6781\u4e3a\u7a00\u758f\u65f6\u96be\u4ee5\u6062\u590d\u51c6\u786e\u7684\u573a\u666f\u51e0\u4f55\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u7a00\u758f\u89c6\u56fe\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u91cd\u5efa\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u524d\u9988\u7f51\u7edc\u9884\u6d4b\u9010\u89c6\u56fe\u50cf\u7d20\u5bf9\u9f50\u76842DGS\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u52a0\u6743Chamfer\u8ddd\u79bb\u635f\u5931\u548c\u6cd5\u7ebf\u9884\u6d4b\u7f51\u7edc\u4ee5\u4f18\u53162DGS\u7684\u4f4d\u7f6e\u4e0e\u65b9\u5411\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u5728\u901a\u7528\u7a00\u758f\u89c6\u56fe\u7f51\u683c\u91cd\u5efa\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "MeshSplat\u901a\u8fc72DGS\u548c\u51e0\u4f55\u5148\u9a8c\u7684\u8f6c\u6362\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7a00\u758f\u89c6\u56fe\u4e0b\u8868\u9762\u91cd\u5efa\u7684\u6311\u6218\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7a00\u758f\u8f93\u5165\u60c5\u51b5\u4e0b\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.17489", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.17489", "abs": "https://arxiv.org/abs/2508.17489", "authors": ["Avital Finanser", "Nimrod Talmon"], "title": "A Dynamic Approach to Collaborative Document Writing", "comment": "Accepted at the 27th European Conference on Artificial Intelligence\n  (ECAI 2025). This arXiv version presents the complete work with supplementary\n  materials and additional experimental details not included in the conference\n  proceedings", "summary": "We introduce a model for collaborative text aggregation in which an agent\ncommunity coauthors a document, modeled as an unordered collection of\nparagraphs, using a dynamic mechanism: agents propose paragraphs and vote on\nthose suggested by others. We formalize the setting and explore its\nrealizations, concentrating on voting mechanisms that aggregate votes into a\nsingle, dynamic document. We focus on two desiderata: the eventual stability of\nthe process and its expected social welfare. Following an impossibility result,\nwe describe several aggregation methods and report on agent-based simulations\nthat utilize natural language processing (NLP) and large-language models (LLMs)\nto model agents and their contexts. Using these simulations, we demonstrate\npromising results regarding the possibility of rapid convergence to a high\nsocial welfare collaborative text.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u534f\u4f5c\u6587\u672c\u805a\u5408\u6a21\u578b\uff0c\u793e\u533a\u4ee3\u7406\u901a\u8fc7\u6295\u7968\u673a\u5236\u5171\u540c\u7f16\u5199\u6587\u6863\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5feb\u901f\u6536\u655b\u81f3\u9ad8\u793e\u4f1a\u4ef7\u503c\u6587\u6863\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u52a8\u6001\u6295\u7968\u673a\u5236\u5b9e\u73b0\u793e\u533a\u4ee3\u7406\u534f\u4f5c\u64b0\u5199\u6587\u6863\uff0c\u540c\u65f6\u5173\u6ce8\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u793e\u4f1a\u4ef7\u503c\u7684\u6700\u5927\u5316\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5f62\u5f0f\u5316\u534f\u4f5c\u6587\u672c\u805a\u5408\u573a\u666f\uff0c\u8bbe\u8ba1\u6295\u7968\u673a\u5236\u5c06\u4ee3\u7406\u63d0\u8bae\u7684\u6bb5\u843d\u6574\u5408\u4e3a\u52a8\u6001\u6587\u6863\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408NLP\u548cLLM\u7684\u4ee3\u7406\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u6295\u7968\u673a\u5236\uff0c\u534f\u4f5c\u6587\u672c\u80fd\u591f\u5feb\u901f\u6536\u655b\u81f3\u9ad8\u8d28\u91cf\u4e14\u5177\u6709\u9ad8\u793e\u4f1a\u4ef7\u503c\u7684\u6587\u6863\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u52a8\u6001\u6295\u7968\u673a\u5236\u53ef\u4ee5\u6709\u6548\u4fc3\u8fdb\u534f\u4f5c\u6587\u672c\u7684\u7a33\u5b9a\u6027\u548c\u793e\u4f1a\u4ef7\u503c\uff0c\u4e3a\u793e\u533a\u4ee3\u7406\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.17557", "categories": ["cs.GT", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2508.17557", "abs": "https://arxiv.org/abs/2508.17557", "authors": ["Yunzhe Bai", "Alec Sun"], "title": "Price of Uncertainty for Consensus Games", "comment": "14 pages", "summary": "Many game-theoretic models assume that players have access to accurate\ninformation, but uncertainty in observed data is frequently present in\nreal-world settings. In this paper, we consider a model of uncertainty where\nadversarial perturbations of relative magnitude $1+\\varepsilon$ are introduced\nto players' observed costs. The effect of uncertainty on social cost is denoted\nas the price of uncertainty. We prove a tight bound on the price of uncertainty\nfor consensus games of $\\Theta(\\varepsilon^2 n^2)$ for all $\\varepsilon =\n\\Omega\\mathopen{}\\left(n^{-1/4}\\right)$. This improves a previous lower bound\nof $\\Omega(\\varepsilon^3 n^2)$ as well as a previous upper bound of\n$O(\\varepsilon n^2)$.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u535a\u5f08\u6a21\u578b\u4e2d\u4e0d\u786e\u5b9a\u6027\u5bf9\u793e\u4ea4\u6210\u672c\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u4e86\u5171\u8bc6\u6e38\u620f\u4e2d\u4e0d\u786e\u5b9a\u6027\u4ef7\u683c\u7684\u7d27\u754c\u4e3a\u0398(\u03b5\u00b2n\u00b2)\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u535a\u5f08\u6a21\u578b\u4e2d\u7684\u73a9\u5bb6\u901a\u5e38\u9762\u4e34\u4fe1\u606f\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u73b0\u6709\u6a21\u578b\u5e38\u5047\u8bbe\u4fe1\u606f\u51c6\u786e\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u7f3a\uff0c\u63a2\u7d22\u4e0d\u786e\u5b9a\u6027\u5bf9\u535a\u5f08\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u5bf9\u73a9\u5bb6\u7684\u89c2\u5bdf\u6210\u672c\u65bd\u52a0\u76f8\u5bf9\u5e45\u5ea61+\u03b5\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5206\u6790\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u5bf9\u793e\u4ea4\u6210\u672c\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5171\u8bc6\u6e38\u620f\u4e2d\uff0c\u4e0d\u786e\u5b9a\u6027\u4ef7\u683c\u7684\u7d27\u754c\u4e3a\u0398(\u03b5\u00b2n\u00b2)\uff0c\u6539\u8fdb\u4e86\u6b64\u524d\u03a9(\u03b5\u00b3n\u00b2)\u7684\u4e0b\u754c\u548cO(\u03b5n\u00b2)\u7684\u4e0a\u754c\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u535a\u5f08\u8bba\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u7406\u8bba\u5de5\u5177\uff0c\u5e76\u5c55\u793a\u4e86\u5bf9\u6297\u6027\u6270\u52a8\u5bf9\u793e\u4ea4\u6210\u672c\u7684\u6df1\u523b\u5f71\u54cd\u3002"}}
{"id": "2508.17671", "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.TH"], "pdf": "https://arxiv.org/pdf/2508.17671", "abs": "https://arxiv.org/abs/2508.17671", "authors": ["Sam Ganzfried"], "title": "Consistent Opponent Modeling of Static Opponents in Imperfect-Information Games", "comment": null, "summary": "The goal of agents in multi-agent environments is to maximize total reward\nagainst the opposing agents that are encountered. Following a game-theoretic\nsolution concept, such as Nash equilibrium, may obtain a strong performance in\nsome settings; however, such approaches fail to capitalize on historical and\nobserved data from repeated interactions against our opponents. Opponent\nmodeling algorithms integrate machine learning techniques to exploit suboptimal\nopponents utilizing available data; however, the effectiveness of such\napproaches in imperfect-information games to date is quite limited. We show\nthat existing opponent modeling approaches fail to satisfy a simple desirable\nproperty even against static opponents drawn from a known prior distribution;\nnamely, they do not guarantee that the model approaches the opponent's true\nstrategy even in the limit as the number of game iterations approaches\ninfinity. We develop a new algorithm that is able to achieve this property and\nruns efficiently by solving a convex minimization problem based on the\nsequence-form game representation using projected gradient descent. The\nalgorithm is guaranteed to efficiently converge to the opponent's true strategy\ngiven observations from gameplay and possibly additional historical data if it\nis available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u89e3\u51b3\u57fa\u4e8e\u5e8f\u5217\u5f62\u5f0f\u535a\u5f08\u8868\u793a\u7684\u51f8\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u6709\u6548\u5efa\u6a21\u5bf9\u624b\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u624b\u5efa\u6a21\u65b9\u6cd5\u5728\u9759\u6001\u5bf9\u624b\u73af\u5883\u4e2d\u65e0\u6cd5\u4fdd\u8bc1\u6536\u655b\u7684\u7f3a\u9677\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u73b0\u6709\u5bf9\u624b\u5efa\u6a21\u65b9\u6cd5\u65e0\u6cd5\u5229\u7528\u5386\u53f2\u6570\u636e\u6709\u6548\u5efa\u6a21\u5bf9\u624b\u7b56\u7565\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u6548\u679c\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u5229\u7528\u5e8f\u5217\u5f62\u5f0f\u535a\u5f08\u8868\u793a\uff0c\u901a\u8fc7\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u89e3\u51b3\u51f8\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u5bf9\u5bf9\u624b\u7b56\u7565\u7684\u9ad8\u6548\u5efa\u6a21\u3002", "result": "\u8be5\u7b97\u6cd5\u80fd\u4fdd\u8bc1\u5728\u6e38\u620f\u8fed\u4ee3\u6b21\u6570\u8d8b\u8fd1\u4e8e\u65e0\u7a77\u65f6\uff0c\u6a21\u578b\u80fd\u6536\u655b\u5230\u5bf9\u624b\u7684\u771f\u5b9e\u7b56\u7565\uff0c\u4e14\u5728\u5386\u53f2\u548c\u5b9e\u65f6\u6570\u636e\u53ef\u7528\u65f6\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u624b\u5efa\u6a21\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u5de8\u5927\u3002"}}
{"id": "2508.17907", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.17907", "abs": "https://arxiv.org/abs/2508.17907", "authors": ["Siddarth Srinivasan", "Tao Lin", "Connacher Murphy", "Anish Thilagar", "Yiling Chen", "Ezra Karger"], "title": "WOMAC: A Mechanism For Prediction Competitions", "comment": null, "summary": "Competitions are widely used to identify top performers in judgmental\nforecasting and machine learning, and the standard competition design ranks\ncompetitors based on their cumulative scores against a set of realized outcomes\nor held-out labels. However, this standard design is neither\nincentive-compatible nor very statistically efficient. The main culprit is\nnoise in outcomes/labels that experts are scored against; it allows weaker\ncompetitors to often win by chance, and the winner-take-all nature incentivizes\nmisreporting that improves win probability even if it decreases expected score.\nAttempts to achieve incentive-compatibility rely on randomized mechanisms that\nadd even more noise in winner selection, but come at the cost of determinism\nand practical adoption. To tackle these issues, we introduce a novel\ndeterministic mechanism: WOMAC (Wisdom of the Most Accurate Crowd). Instead of\nscoring experts against noisy outcomes, as is standard, WOMAC scores experts\nagainst the best ex-post aggregate of peer experts' predictions given the noisy\noutcomes. WOMAC is also more efficient than the standard competition design in\ntypical settings. While the increased complexity of WOMAC makes it challenging\nto analyze incentives directly, we provide a clear theoretical foundation to\njustify the mechanism. We also provide an efficient vectorized implementation\nand demonstrate empirically on real-world forecasting datasets that WOMAC is a\nmore reliable predictor of experts' out-of-sample performance relative to the\nstandard mechanism. WOMAC is useful in any competition where there is\nsubstantial noise in the outcomes/labels.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWOMAC\u7684\u65b0\u578b\u786e\u5b9a\u6027\u673a\u5236\uff0c\u7528\u4e8e\u89e3\u51b3\u6807\u51c6\u6bd4\u8d5b\u8bbe\u8ba1\u4e2d\u56e0\u7ed3\u679c/\u6807\u7b7e\u566a\u58f0\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u6807\u51c6\u6bd4\u8d5b\u8bbe\u8ba1\u5728\u5224\u65ad\u6027\u9884\u6d4b\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7531\u4e8e\u7ed3\u679c/\u6807\u7b7e\u7684\u566a\u58f0\uff0c\u65e2\u4e0d\u6fc0\u52b1\u517c\u5bb9\uff0c\u7edf\u8ba1\u6548\u7387\u4e5f\u4e0d\u9ad8\u3002\u8fd9\u5bfc\u81f4\u8f83\u5f31\u7684\u7ade\u4e89\u8005\u53ef\u80fd\u51ed\u8fd0\u6c14\u83b7\u80dc\uff0c\u5e76\u6fc0\u52b1\u53c2\u8d5b\u8005\u901a\u8fc7\u865a\u5047\u62a5\u544a\u63d0\u9ad8\u83b7\u80dc\u6982\u7387\u3002", "method": "\u5f15\u5165\u4e86WOMAC\uff08Wisdom of the Most Accurate Crowd\uff09\u673a\u5236\uff0c\u901a\u8fc7\u5c06\u4e13\u5bb6\u7684\u8bc4\u5206\u57fa\u4e8e\u6700\u4f18\u7684\u540e\u9a8c\u540c\u884c\u9884\u6d4b\u805a\u5408\uff0c\u800c\u975e\u76f4\u63a5\u8bc4\u5206\u4e8e\u566a\u58f0\u7ed3\u679c\uff0c\u4ece\u800c\u51cf\u5c11\u566a\u58f0\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cWOMAC\u5728\u5178\u578b\u8bbe\u7f6e\u4e2d\u6bd4\u6807\u51c6\u8bbe\u8ba1\u66f4\u9ad8\u6548\uff0c\u5e76\u80fd\u591f\u66f4\u53ef\u9760\u5730\u9884\u6d4b\u4e13\u5bb6\u7684\u6837\u672c\u5916\u8868\u73b0\u3002", "conclusion": "WOMAC\u662f\u4e00\u79cd\u9002\u7528\u4e8e\u7ed3\u679c/\u6807\u7b7e\u566a\u58f0\u8f83\u5927\u7684\u7ade\u4e89\u7684\u65b0\u578b\u673a\u5236\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u548c\u7edf\u8ba1\u6548\u7387\u3002"}}
{"id": "2508.17945", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.17945", "abs": "https://arxiv.org/abs/2508.17945", "authors": ["Mandar Datar", "Yann Dujardin"], "title": "Adaptive Learning for Moving Target defence: Enhancing Cybersecurity Strategies", "comment": null, "summary": "In this work, we model Moving Target Defence (MTD) as a partially observable\nstochastic game between an attacker and a defender. The attacker tries to\ncompromise the system through probing actions, while the defender minimizes the\nrisk by reimaging the system, balancing between performance cost and security\nlevel. We demonstrate that the optimal strategies for both players follow a\nthreshold structure. Based on this insight, we propose a structure-aware policy\ngradient reinforcement learning algorithm that helps both players converge to\nthe Nash equilibrium. This approach enhances the defender's ability to adapt\nand effectively counter evolving threats, improving the overall security of the\nsystem. Finally, we validate the proposed method through numerical simulations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u79fb\u52a8\u76ee\u6807\u9632\u5fa1\u5efa\u6a21\u4e3a\u4e00\u4e2a\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\u968f\u673a\u535a\u5f08\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9608\u503c\u7684\u7b56\u7565\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e2e\u52a9\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u4ece\u800c\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u9632\u5fa1\u7b56\u7565\u6765\u5e73\u8861\u6027\u80fd\u6210\u672c\u548c\u5b89\u5168\u6027\uff0c\u540c\u65f6\u5bf9\u6297\u4e0d\u65ad\u6f14\u53d8\u7684\u653b\u51fb\u5a01\u80c1\u3002", "method": "\u5c06\u79fb\u52a8\u76ee\u6807\u9632\u5fa1\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\u968f\u673a\u535a\u5f08\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9608\u503c\u7ed3\u6784\u7684\u7b56\u7565\u68af\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u6700\u4f18\u7b56\u7565\u8868\u73b0\u51fa\u9608\u503c\u7ed3\u6784\uff0c\u7b97\u6cd5\u5e2e\u52a9\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u589e\u5f3a\u9632\u5fa1\u8005\u7684\u9002\u5e94\u6027\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6574\u4f53\u5b89\u5168\u6027\u3002"}}
