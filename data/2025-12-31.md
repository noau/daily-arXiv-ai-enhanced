<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 8]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [OpenPBR: Novel Features and Implementation Details](https://arxiv.org/abs/2512.23696)
*Jamie Portsmouth,Peter Kutz,Stephen Hill*

Main category: cs.GR

TL;DR: OpenPBR是一个基于物理的标准化超级着色器，旨在实现跨视觉效果、动画和设计可视化工作流的互操作材质创作和渲染。


<details>
  <summary>Details</summary>
Motivation: OpenPBR的开发是为了提供一个统一的模型，支持复杂的材质表现和跨工作流的互操作性，满足视觉效果、动画和设计可视化的需求。

Method: 论文详细介绍了OpenPBR的理论基础和实现方法，包括基于板层的分层、统计混合、微表面理论，以及金属、电介质、次表面和光泽漫反射基底材质的表现。此外，还讨论了薄壁物体的特殊渲染模式和技术细节。

Result: OpenPBR提供了一个全面的材质模型，支持多种物理组件和技术细节，如薄膜虹彩、涂层和绒毛层，以及次表面散射的参数化选择和涂层暗化的物理细节。

Conclusion: OpenPBR是一个功能强大且通用的着色器模型，未来将继续扩展，支持更多高级效果如模糊镜面反射和逆向反射。

Abstract: OpenPBR is a physically based, standardized uber-shader developed for interoperable material authoring and rendering across VFX, animation, and design visualization workflows. This document serves as a companion to the official specification, offering deeper insight into the model's development and more detailed implementation guidance, including code examples and mathematical derivations.
  We begin with a description of the model's formal structure and theoretical foundations - covering slab-based layering, statistical mixing, and microfacet theory - before turning to its physical components. These include metallic, dielectric, subsurface, and glossy-diffuse base substrates, followed by thin-film iridescence, coat, and fuzz layers. A special-case mode for rendering thin-walled objects is also described.
  Additional sections explore technical topics in greater depth, such as the decoupling of specular reflectivity from transmission, the choice of parameterization for subsurface scattering, and the detailed physics of coat darkening and thin-film interference. We also discuss planned extensions, including hazy specular reflection and retroreflection.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Symbolic Specification and Reasoning for Quantum Data and Operations](https://arxiv.org/abs/2512.22383)
*Mingsheng Ying*

Main category: cs.PL

TL;DR: 提出了一种称为符号算子逻辑（SOL）的一般逻辑框架，用于量子数据和操作的符号规范与推理，将经典一阶逻辑嵌入形式算子语言中。


<details>
  <summary>Details</summary>
Motivation: 量子信息研究中缺乏符号规范和推理的形式理论，限制了量子计算中自动化验证技术的实际应用。

Method: 通过将经典一阶逻辑嵌入形式算子语言中，构建SOL框架，支持量子数据和操作的符号规范与递归定义。

Result: SOL框架为量子计算的形式验证和自动化定理证明提供了概念基础，可利用现有经典计算验证工具。

Conclusion: SOL框架填补了量子数据符号推理的理论空白，有望在Lean、Coq等证明助手中广泛应用。

Abstract: In quantum information and computation research, symbolic methods have been widely used for human specification and reasoning about quantum states and operations. At the same time, they are essential for ensuring the scalability and efficiency of automated reasoning and verification tools for quantum algorithms and programs. However, a formal theory for symbolic specification and reasoning about quantum data and operations is still lacking, which significantly limits the practical applicability of automated verification techniques in quantum computing.
  In this paper, we present a general logical framework, called Symbolic Operator Logic $\mathbf{SOL}$, which enables symbolic specification and reasoning about quantum data and operations. Within this framework, a classical first-order logical language is embedded into a language of formal operators used to specify quantum data and operations, including their recursive definitions. This embedding allows reasoning about their properties modulo a chosen theory of the underlying classical data (e.g., Boolean algebra or group theory), thereby leveraging existing automated verification tools developed for classical computing. It should be emphasised that this embedding of classical first-order logic into $\mathbf{SOL}$ is precisely what makes the symbolic method possible.
  We envision that this framework can provide a conceptual foundation for the formal verification and automated theorem proving of quantum computation and information in proof assistants such as Lean, Coq, and related systems.

</details>


### [3] [Eliminate Branches by Melding IR Instructions](https://arxiv.org/abs/2512.22390)
*Yuze Li,Srinivasan Ramachandra Sharma,Charitha Saumya,Ali R. Butt,Kirshanthan Sundararajah*

Main category: cs.PL

TL;DR: MERIT是一种编译器转换技术，通过对齐和融合不同路径中的相似操作来消除分支，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代处理器中分支预测失败会导致严重的性能损失，而现有的硬件预测器和配置文件引导技术难以处理具有不规则模式的数据依赖性分支，传统的if-conversion在x86等架构上也有局限性。

Method: MERIT通过观察不同路径中执行结构相似操作的特点，采用序列对齐技术发现合并机会，并在IR指令级别进行安全操作数级保护以确保语义正确性，无需硬件预测。

Result: 在LLVM中实现并评估了102个程序后，MERIT实现了10.9%的几何平均加速，峰值性能提升达32倍，同时减少了静态指令开销。

Conclusion: MERIT通过编译器技术有效消除分支，显著提升了性能，展示了其在减少静态指令开销和提高性能方面的潜力。

Abstract: Branch mispredictions cause catastrophic performance penalties in modern processors, leading to performance loss. While hardware predictors and profile-guided techniques exist, data-dependent branches with irregular patterns remain challenging. Traditional if-conversion eliminates branches via software predication but faces limitations on architectures like x86. It often fails on paths containing memory instructions or incurs excessive instruction overhead by fully speculating large branch bodies.
  This paper presents Melding IR Instructions (MERIT), a compiler transformation that eliminates branches by aligning and melding similar operations from divergent paths at the IR instruction level. By observing that divergent paths often perform structurally similar operations with different operands, MERIT adapts sequence alignment to discover merging opportunities and employs safe operand-level guarding to ensure semantic correctness without hardware predication. Implemented as an LLVM pass and evaluated on 102 programs from four benchmark suites, MERIT achieves a geometric mean speedup of 10.9% with peak improvements of 32x compared to hardware branch predictor, demonstrating the effectiveness with reduced static instruction overhead.

</details>


### [4] [A Bounded Game Semantics Checker for Precise Smart Contract Analysis](https://arxiv.org/abs/2512.22417)
*Vasileios Koutavas,Yu-Yang Lin,Nikos Tzevelekos*

Main category: cs.PL

TL;DR: 提出了一种基于游戏语义的智能合约漏洞检测方法YulToolkit，该方法精确无假阳性，并通过可行性交互探索实现有限完备性。


<details>
  <summary>Details</summary>
Motivation: 智能合约漏洞检测需要一种既能避免假阳性又能扩展到实际合约的方法。

Method: 基于游戏语义建模合约与环境之间的交互，避免过度近似，支持Solidity编写的工具扩展，并在Yul中间语言上实现为YulToolkit工具。

Result: YulToolkit在DAO、PredyPool和Lendf.M等实际案例中成功检测到已知漏洞，修复后未再报出违规。

Conclusion: 有限游戏语义探索是一种高效且精确的智能合约漏洞检测方法，尤其适用于重入等难以精确检测的漏洞。

Abstract: We present a new approach to finding smart contract vulnerabilities that is precise (no false positives up to our EVM-Yul interpreter), bounded-complete, and, when instrumented with domain knowledge, scales to real-world contracts. Our method is based on game semantics, modelling computation as an interaction between a contract and its environment, reducing reasoning about unknown or malicious external contracts to trace enumeration. We implement this in a tool we refer to as YulToolkit, a bounded game-semantics checker for Yul, the intermediate language of Solidity. By exploring only feasible interactions, YulToolkit avoids over-approximation, and by relying on the theory of game semantics it achieves bounded completeness. To make exploration tractable, YulToolkit supports instrumentation written in Solidity and propagated to Yul, comparable in effort to creating a test harness. Unlike tests, however, our technique explores all admissible traces within the chosen parameters and bounds. We evaluate YulToolkit on three real-world incidents: The DAO, PredyPool, and Lendf.Me, as well as benchmark contracts. In all cases, YulToolkit detects the known vulnerabilities (producing a violation-triggering trace), and after applying fixes, reports no further violations within bounds. These results show that bounded game semantics exploration is an effective and precise addition to the smart contract analysis toolbox, particularly for vulnerabilities such as reentrancy that are hard to detect precisely in real code.

</details>


### [5] [Compiling Gradual Types with Evidence](https://arxiv.org/abs/2512.22684)
*José Luis Romero,Cristóbal Isla,Matías Toro,Éric Tanter*

Main category: cs.PL

TL;DR: Grift编译器是目前唯一支持结构性类型语言中渐进式类型化的实现，利用强制转换进行运行时检查。本文设计并实现了基于证据的编译器GrEv，发现其在性能上可与强制转换编译器竞争甚至更快。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索基于证据的语义是否能够高效实现渐进式类型化，填补了理论与实现之间的鸿沟。

Method: 设计并实现了基于证据的编译器GrEv，通过抽象解释和演化证据的理论基础，将其转化为实际编译器实现。

Result: GrEv在Grift基准测试中表现优异，性能与强制转换编译器相当甚至更快，且在静态到动态的频谱上表现更稳定。

Conclusion: GrEv的成功不仅丰富了渐进式类型化编译器的多样性，还为基于AGT理论的其他高级渐进式类型化实现提供了直接可能性。

Abstract: Efficiently supporting sound gradual typing in a language with structural types is challenging. To date, the Grift compiler is the only close-to-the-metal implementation of gradual typing in this setting, exploiting coercions for runtime checks, and further extended with monotonic references for efficient access to statically-typed data structures. On the language design and semantics side, the Abstracting Gradual Typing (AGT) methodology has proven fruitful to elucidate existing designs and to innovate by deriving gradualizations of a wide variety of typing disciplines and language features. Grounded in abstract interpretation, the Curry-Howard inspired runtime semantics of AGT is based on the notion of evidence for consistent judgments that evolve during reduction, monitoring the plausibility of well-typedness. While expressive and versatile, it is unclear whether such evidence-based semantics are a viable route to realize an efficient implementation of gradual typing.
  In this work, we explore this question by designing, implementing, and evaluating an evidence-based compiler, called GrEv. We explain how to bridge the gap between the formal semantics and the GrEv compiler implementation, and identify novel monotonic semantics. We empirically evaluate the performance of GrEv on the Grift benchmark suite. The results show that an evidence-based compiler can be competitive with, and even faster than, a coercion-based compiler, exhibiting more stability across configurations on the static-to-dynamic spectrum. In addition to enriching the space of gradual typing compilers, this work opens a direct door to exploring efficient implementations of the many advanced gradual typing disciplines formally derived with AGT in the literature.

</details>


### [6] [Fancy Some Chips for Your TeaStore? Modeling the Control of an Adaptable Discrete System](https://arxiv.org/abs/2512.23496)
*Anna Gallone,Simon Bliudze,Sophie Cerf,Olga Kouchnarenko*

Main category: cs.PL

TL;DR: 提出了一个名为Chips的语言，用于简化由多种相互交织组件组成的模型设计，并支持以功能块形式描述应用。


<details>
  <summary>Details</summary>
Motivation: 开发者在设计新Web应用时需要应对多种资源约束，希望系统能确保稳健性以提供良好的服务质量。

Method: 结合控制理论和通用编程语言的概念，开发了Chips语言，用于生成稳健的基于组件的模型。

Result: 通过Adaptable TeaStore应用的变体示例，展示了如何使用Chips系统化地设计、建模和分析复杂系统项目。

Conclusion: Chips语言为复杂系统的设计和分析提供了一种系统化且高效的方法。

Abstract: When designing new web applications, developers must cope with different kinds of constraints relative to the resources they rely on: software, hardware, network, online micro-services, or any combination of the mentioned entities. Together, these entities form a complex system of communicating interdependent processes, physical or logical. It is very desirable that such system ensures its robustness to provide a good quality of service. In this paper we introduce Chips, a language that aims at facilitating the design of models made of various entwined components. It allows the description of applications in the form of functional blocks. Chips mixes notions  from control theory and general purpose programming languages to generate robust component-based models. This paper presents how to use Chips to systematically design, model and analyse a complex system project, using a variation of the Adaptable TeaStore application as running example.

</details>


### [7] [Adaptable TeaStore: A Choreographic Approach](https://arxiv.org/abs/2512.23497)
*Giuseppe De Palma,Saverio Giallorenzo,Ivan Lanese,Gianluigi Zavattaro*

Main category: cs.PL

TL;DR: 本文介绍了基于AIOCJ（一种编排语言）的Adaptable TeaStore实现，展示了该方法的优势和局限性，并提出了改进方向的建议。


<details>
  <summary>Details</summary>
Motivation: Adaptable TeaStore作为一种可适应微服务架构的参考模型，需要一种能够在运行时动态适应的编程语言来实现其配置切换场景。

Method: 使用AIOCJ编排语言实现Adaptable TeaStore，确保通信的正确性（如无死锁）并在运行时动态适应不同条件。

Result: 研究表明，AIOCJ能够有效支持动态适应，但存在一些局限性，需要进一步优化以适应实际云架构。

Conclusion: 本文展示了AIOCJ在可适应微服务架构中的潜力，并提出了未来改进方向，特别是对AIOCJ语言的优化建议。

Abstract: The Adaptable TeaStore has recently been proposed as a reference model for adaptable microservice architectures. It includes different configurations, as well as scenarios requiring to transition between them. We describe an implementation of the Adaptable TeaStore based on AIOCJ, a choreographic language that allows one to program multiparty systems that can adapt at runtime to different conditions. Following the choreographic tradition, AIOCJ ensures by-construction correctness of communications (e.g., no deadlocks) before, during, and after adaptation. Adaptation is dynamic, and the adaptation scenarios need to be fully specified only at runtime. Using AIOCJ to model the Adaptable TeaStore, we showcase the strengths of the approach and its current limitations, providing suggestions for future directions for refining the paradigm (and the AIOCJ language, in particular), to better align it with real-world Cloud architectures.

</details>


### [8] [Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction](https://arxiv.org/abs/2512.23552)
*Martin Sulzmann*

Main category: cs.PL

TL;DR: 该论文提出了一种改进的锁集构造方法，通过放宽临界区的限制以涵盖多线程事件，解决了传统锁集构造中的假阳性和假阴性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的锁集构造仅考虑同一线程内的锁获取，而忽略了其他线程的锁事件，导致假阳性和假阴性问题。

Method: 论文通过基于轨迹的临界区定义，放宽了临界区必须限制在单线程内的限制，并结合偏序关系对其进行近似。

Result: 改进后的锁集构造方法消除了DIRK死锁预测器的假阳性，并扩展了SPDOffline以减少假阴性，同时保持了原有性能。

Conclusion: 改进的锁集构造方法在保持高效计算的同时，提高了准确性，显著减少了假阳性和假阴性问题。

Abstract: Lock sets are commonly used for dynamic analysis of deadlocks. The standard per-thread lock set construction only considers locks acquired in the same thread, but is unaware of locks acquired in another thread. This leads to false positives and false negatives. The underlying issue is that the commonly used notion of a critical section on which the lock set construction relies ignores events from other threads. We give a trace-based characterization of critical sections that drops this restriction. Critical sections are no longer restricted to a single thread and can cover multiple threads. Such forms of critical sections exist, are natural, and correct the standard formulation.
  We show how to soundly approximate the trace-based characterization via partial order relations. Thus, we obtain an improved lock set construction that can still be efficiently computed and allows us to remove false positives reported by the DIRK deadlock predictor and remove false negatives by extending the SPDOffline deadlock predictor. We integrate various lock set constructions with increased precision in an extension of SPDOffline. Our extensions remain sound (no false positives) but are more complete (fewer false negatives) w.r.t. SPDOffline. For an extensive standard benchmark suite we can also show that the performance is not affected.

</details>


### [9] [Automating the Analysis of Parsing Algorithms (and other Dynamic Programs)](https://arxiv.org/abs/2512.23665)
*Tim Vieira,Ryan Cotterell,Jason Eisner*

Main category: cs.PL

TL;DR: 本文提出了一个帮助程序员分析NLP算法的系统，成功推断出类型、冗余代码及复杂度边界。


<details>
  <summary>Details</summary>
Motivation: NLP领域的研究常涉及高效操作复杂形式结构，算法设计者需要为其算法提供运行时间或空间复杂度的保证，并验证类型错误。本文旨在帮助程序员进行此类分析。

Method: 开发了一个分析系统，应用于多个NLP算法。

Result: 系统成功推断出类型、死代码和冗余代码，并计算出参数化的运行时和空间复杂度边界。

Conclusion: 提出的系统能够有效辅助程序员完成NLP算法的分析和验证任务。

Abstract: Much algorithmic research in NLP aims to efficiently manipulate rich formal structures. An algorithm designer typically seeks to provide guarantees about their proposed algorithm -- for example, that its running time or space complexity is upper-bounded as a certain function of its input size. They may also wish to determine the necessary properties of the quantities derived by the algorithm to synthesize efficient data structures and verify type errors. In this paper, we develop a system for helping programmers to perform these types of analyses. We apply our system to a number of NLP algorithms and find that it successfully infers types, dead and redundant code, and parametric runtime and space complexity bounds.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [10] [Analyzing Skill Element in Online Fantasy Cricket](https://arxiv.org/abs/2512.22254)
*Sarthak Sarkar,Supratim Das,Purushottam Saha,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.GT

TL;DR: 该论文提出了一种统计框架，用于评估在线梦幻板球比赛中技能与运气的作用，并通过多种策略分析和动态模型实验证明了技能在这一平台上的重要性。


<details>
  <summary>Details</summary>
Motivation: 在线梦幻板球作为一种大规模竞技系统，其结果是由技能还是运气主导尚不明确，因此需要一种方法来量化技能的作用。

Method: 研究构建了基于近期表现、历史数据、统计优化和多准则决策的确定性及随机性团队选择策略，并通过软最大重加权机制引入了动态锦标赛模型。

Result: 实验结果通过IPL 2024数据集验证，证明了在线梦幻板球中技能的作用，并找到了最优策略集。

Conclusion: 研究定量证明了在线梦幻板球平台的技能因素，为参与者提供了优化策略的科学依据。

Abstract: Online fantasy cricket has emerged as large-scale competitive systems in which participants construct virtual teams and compete based on real-world player performances. This massive growth has been accompanied by important questions about whether outcomes are primarily driven by skill or chance. We develop a statistical framework to assess the role of skill in determining success on these platforms. We construct and analyze a range of deterministic and stochastic team selection strategies, based on recent form, historical statistics, statistical optimization, and multi-criteria decision making. Strategy performance is evaluated based on points, ranks, and payoff under two contest structures Mega and 4x or Nothing. An extensive comparison between different strategies is made to find an optimal set of strategies. To capture adaptive behavior, we further introduce a dynamic tournament model in which agent populations evolve through a softmax reweighting mechanism proportional to positive payoff realizations. We demonstrate our work by running extensive numerical experiments on the IPL 2024 dataset. The results provide quantitative evidence in favor of the skill element present in online fantasy cricket platforms.

</details>


### [11] [Computing Pure-Strategy Nash Equilibria in a Two-Party Policy Competition: Existence and Algorithmic Approaches](https://arxiv.org/abs/2512.22552)
*Chuang-Chieh Lin,Chi-Jen Lu,Po-An Chen,Chih-Chieh Hung*

Main category: cs.GT

TL;DR: 本文将两党政策竞争建模为一个非合作博弈，验证了等渗函数的假设，证明了纯策略纳什均衡的存在性，并通过实验展示了算法的快速收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究两党在政策竞争中的博弈行为，扩展了Lin等人的工作（2021），以更好地理解政策选择和选民偏好的相互作用。

Method: 通过模拟验证等渗性假设，证明纯策略纳什均衡的存在性，并设计梯度算法和网格搜索算法寻找近似均衡。

Result: 验证了等渗假设，证明了多维度情况下均衡的存在性，展示了算法的快速收敛性，并提出了多项式时间算法。

Conclusion: 研究提供了政策竞争博弈的理论基础和实践工具，为理解政策选择和选民行为提供了新的视角。

Abstract: We formulate two-party policy competition as a two-player non-cooperative game, generalizing Lin et al.'s work (2021). Each party selects a real-valued policy vector as its strategy from a compact subset of Euclidean space, and a voter's utility for a policy is given by the inner product with their preference vector. To capture the uncertainty in the competition, we assume that a policy's winning probability increases monotonically with its total utility across all voters, and we formalize this via an affine isotonic function. A player's payoff is defined as the expected utility received by its supporters. In this work, we first test and validate the isotonicity hypothesis through voting simulations. Next, we prove the existence of a pure-strategy Nash equilibrium (PSNE) in both one- and multi-dimensional settings. Although we construct a counterexample demonstrating the game's non-monotonicity, our experiments show that a decentralized gradient-based algorithm typically converges rapidly to an approximate PSNE. Finally, we present a grid-based search algorithm that finds an $ε$-approximate PSNE of the game in time polynomial in the input size and $1/ε$.

</details>


### [12] [Facility Location Games for Multi-Location Agents with Satisfaction](https://arxiv.org/abs/2512.22873)
*Huanjun Wang,Qizhi Fang,Wenjing Liu*

Main category: cs.GT

TL;DR: 本文研究了单设施位置博弈中的机制设计，考虑了代理人满意度函数的不同变体，提出了两种类型的目标：总和变体满意度和最大值变体满意度。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为单设施位置博弈设计机制，以最大化代理人满意度总和或最小值，同时激励代理人真实报告位置。

Method: 主要方法包括提出两种群体策略证明机制，分别在总和变体满意度和最大值变体满意度下实现近似比为2和5/4的优化。针对厌恶设施位置博弈，提出最优机制，并设计随机机制。

Result: 结果显示，提出的机制在总和变体满意度和最大值变体满意度下分别实现了最优近似比2和5/4。随机机制降低了近似比至4/3，并给出了下界。

Conclusion: 本文为单设施位置博弈提供了有效的机制设计，实现了代理人的满意度优化，并激励了真实报告行为。

Abstract: In this paper, we study mechanism design for single-facility location games where each agent has multiple private locations in [0, 1]. The individual objective is a satisfaction function that measures the discrepancy between the optimal facility location for an agent and the location provided by the mechanism. Based on different distance functions from agents to the facility, we consider two types of individual objectives: the sum-variant satisfaction and the max-variant satisfaction. Our goal is to design mechanisms that locate one facility to maximize the sum (or the minimum) of all agents' satisfactions, while incentivizing agents to truthfully report their locations. In this paper, we mainly focus on desirable and obnoxious facility location games. For desirable facility location games, we propose two group strategy-proof mechanisms with approximation ratios of 2 and 5/4 for maximizing the sum of the sum-variant and max-variant satisfaction, respectively. Moreover, another mechanism achieves an approximation ratio of 2 for simultaneously maximizing the minimum of the sum-variant satisfaction and the minimum of the max-variant satisfaction. For obnoxious facility location games, we establish that two group strategy-proof mechanisms are the best possible, providing an approximation ratio of 2 for maximizing the sum of the sum-variant satisfaction and the sum of the max-variant satisfaction, respectively. Additionally, we devise two 4/3-approximation randomized group strategy-proof mechanisms, and provide two lower bounds of 1.0625 and 1.0448 of randomized strategy-proof mechanisms for maximizing the sum of the sum-variant satisfaction and the sum of the max-variant satisfaction, respectively.

</details>


### [13] [Impact of Volatility on Time-Based Transaction Ordering Policies](https://arxiv.org/abs/2512.23386)
*Sunghun Ko,Jinsuk Park*

Main category: cs.GT

TL;DR: Arbitrum的提前拍卖（ELA）通过第二价格拍卖赋予获胜者一分钟的独占延迟优势。研究发现，由于短期波动性和竞标者风险厌恶的影响，优先访问的价值相对于风险中性估值有所折扣。


<details>
  <summary>Details</summary>
Motivation: 研究ELA拍卖的目的是探讨在风险厌恶竞标者的单轮模型中，优先访问的价值是否会因为短期波动性和风险厌恶而被低估。

Method: 研究基于单轮模型，分析了风险厌恶竞标者的行为，并通过匹配ELA投标记录与高频ETH价格数据来验证假设。

Result: 研究发现，ELA拍卖的结果与模型预测一致，即优先访问的价值相对于风险中性估值有所折扣。

Conclusion: 结论表明，风险厌恶和短期波动性对优先访问的估值有显著影响，ELA拍卖的结果支持了这一假设。

Abstract: We study Arbitrum's Express Lane Auction (ELA), an ahead-of-time second-price auction that grants the winner an exclusive latency advantage for one minute. Building on a single-round model with risk-averse bidders, we propose a hypothesis that the value of priority access is discounted relative to risk-neutral valuation due to the difficulty of forecasting short-horizon volatility and bidders' risk aversion. We test these predictions using ELA bid records matched to high-frequency ETH prices and find that the result is consistent with the model.

</details>


### [14] [Verifiable Off-Chain Governance](https://arxiv.org/abs/2512.23618)
*Jake Hartnell,Eugenio Battaglia*

Main category: cs.GT

TL;DR: 本文提出了一种通过可验证的链下计算框架，提升DAO治理多样性和效率的方法。


<details>
  <summary>Details</summary>
Motivation: 当前的DAO治理实践受限于链上计算能力，只能使用代币权重投票，限制了组织的表达力和复杂决策能力。

Method: 利用可验证服务（Verifiable Services）、可信执行环境（TEEs）和零知识证明（ZK proofs），提出了三种新型治理机制：(1)基于证明的多维利益相关者合法性计算，(2)通过可验证偏好处理的集体智能，(3)基于策略即代码（Policy-as-Code）的自主策略执行。

Result: 该框架提供了架构规范、安全模型和实施考虑，验证了其实用性。

Conclusion: 通过可验证链下计算，DAO可以实现更高的表达力和操作效率，同时保持密码经济安全性。

Abstract: Current DAO governance praxis limits organizational expressivity and reduces complex organizational decisions to token-weighted voting due to on-chain computational limits. This paper proposes verifiable off-chain computation (leveraging Verifiable Services, TEEs, and ZK proofs) as a framework to transcend these constraints while maintaining cryptoeconomic security. This paper explores three novel governance mechanisms: (1) attestation-based systems that compute multi-dimensional stakeholder legitimacy, (2) collective intelligence through verifiable preference processing, and (3) autonomous policy execution via Policy-as-Code. The framework provides architectural specifications, security models, and implementation considerations for DAOs seeking higher-resolution expressivity and increased operational efficiency, with validation from pioneering implementations demonstrating practical viability.

</details>
