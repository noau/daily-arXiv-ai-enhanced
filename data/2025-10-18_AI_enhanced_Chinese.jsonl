{"id": "2510.14450", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.14450", "abs": "https://arxiv.org/abs/2510.14450", "authors": ["Fran\u00e7ois Durand"], "title": "Why Instant-Runoff Voting Is So Resilient to Coalitional Manipulation: Phase Transitions in the Perturbed Culture", "comment": null, "summary": "Previous studies have shown that Instant-Runoff Voting (IRV) is highly\nresistant to coalitional manipulation (CM), though the theoretical reasons for\nthis remain unclear. To address this gap, we analyze the susceptibility to CM\nof three major voting rules-Plurality, Two-Round System, and IRV-within the\nPerturbed Culture model. Our findings reveal that each rule undergoes a phase\ntransition at a critical value theta\\_c of the concentration of preferences:\nthe probability of CM for large electorates converges exponentially fast to 1\nbelow theta\\_c and to 0 above theta\\_c. We introduce the Super Condorcet Winner\n(SCW), showing that its presence is a key factor of IRV's resistance to\ncoalitional manipulation, both theoretically and empirically. Notably, we use\nthis notion to prove that for IRV, theta\\_c = 0, making it resistant to CM with\neven minimal preference concentration.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\u5373\u65f6\u51b3\u9009\u6295\u7968\uff08IRV\uff09\u5bf9\u8054\u76df\u64cd\u7eb5\uff08CM\uff09\u9ad8\u5ea6\u62b5\u6297\uff0c\u5e76\u5728Perturbed Culture\u6a21\u578b\u4e2d\u5206\u6790\u4e86\u4e09\u79cd\u6295\u7968\u89c4\u5219\u7684CM\u6613\u611f\u6027\u3002", "motivation": "\u5f25\u8865\u5173\u4e8eIRV\u4e3a\u4f55\u5bf9\u8054\u76df\u64cd\u7eb5\u5177\u6709\u9ad8\u5ea6\u62b5\u6297\u529b\u7684\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u5728Perturbed Culture\u6a21\u578b\u4e2d\u5206\u6790\u591a\u6570\u6295\u7968\u3001\u4e24\u8f6e\u5236\u548cIRV\u5bf9CM\u7684\u6613\u611f\u6027\uff0c\u5e76\u5f15\u5165\u8d85\u7ea7\u5b54\u591a\u585e\u8d62\u5bb6\uff08SCW\uff09\u7684\u6982\u5ff5\u3002", "result": "\u6bcf\u79cd\u89c4\u5219\u5728\u504f\u597d\u96c6\u4e2d\u5ea6\u7684\u4e34\u754c\u503c\u03b8_c\u5904\u7ecf\u5386\u76f8\u53d8\uff0c\u4e14IRV\u7684\u03b8_c\u4e3a0\uff0c\u4f7f\u5176\u5373\u4f7f\u5728\u6700\u5c0f\u504f\u597d\u96c6\u4e2d\u5ea6\u4e0b\u4e5f\u80fd\u62b5\u6297CM\u3002", "conclusion": "SCW\u7684\u5b58\u5728\u662fIRV\u62b5\u6297\u8054\u76df\u64cd\u7eb5\u7684\u5173\u952e\uff0c\u8fd9\u4e00\u53d1\u73b0\u4e3aIRV\u7684\u9ad8\u62b5\u6297\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2510.14555", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.14555", "abs": "https://arxiv.org/abs/2510.14555", "authors": ["Amal Sakr", "Andrea Araldo", "Tijani Chahed", "Daniel Kofman"], "title": "Co-Investment under Revenue Uncertainty Based on Stochastic Coalitional Game Theory", "comment": null, "summary": "The introduction of new services, such as Mobile Edge Computing (MEC),\nrequires a massive investment that cannot be assumed by a single stakeholder,\nfor instance the Infrastructure Provider (InP). Service Providers (SPs) however\nalso have an interest in the deployment of such services. We hence propose a\nco-investment scheme in which all stakeholders, i.e., the InP and the SPs, form\nthe so-called grand coalition composed of all the stakeholders with the aim of\nsharing costs and revenues and maximizing their payoffs. The challenge comes\nfrom the fact that future revenues are uncertain. We devise in this case a\nnovel stochastic coalitional game formulation which builds upon robust game\ntheory and derive a lower bound on the probability of the stability of the\ngrand coalition, wherein no player can be better off outside of it. In the\npresence of some correlated fluctuations of revenues however, stability can be\ntoo conservative. In this case, we make use also of profitability, in which\npayoffs of players are non-negative, as a necessary condition for\nco-investment. The proposed framework is showcased for MEC deployment, where\ncomputational resources need to be deployed in nodes at the edge of a\ntelecommunication network. Numerical results show high lower bound on the\nprobability of stability when the SPs' revenues are of similar magnitude and\nthe investment period is sufficiently long, even with high levels of\nuncertainty. In the case where revenues are highly variable however, the lower\nbound on stability can be trivially low whereas co-investment is still\nprofitable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u8054\u76df\u6e38\u620f\u7684\u5171\u6295\u8d44\u65b9\u6848\uff0c\u65e8\u5728\u89e3\u51b3\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u90e8\u7f72\u4e2d\u6210\u672c\u548c\u6536\u76ca\u5171\u4eab\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7a33\u5065\u535a\u5f08\u7406\u8bba\u63a8\u5bfc\u51fa\u5927\u8054\u76df\u7a33\u5b9a\u6027\u7684\u6982\u7387\u4e0b\u9650\u3002", "motivation": "\u7531\u4e8e\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u7b49\u670d\u52a1\u9700\u8981\u5927\u91cf\u6295\u8d44\uff0c\u5355\u4e00\u5229\u76ca\u76f8\u5173\u8005\uff08\u5982\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u5546\uff09\u65e0\u6cd5\u72ec\u7acb\u627f\u62c5\u3002\u56e0\u6b64\uff0c\u9700\u8981\u670d\u52a1\u63d0\u4f9b\u5546\u7b49\u5229\u76ca\u76f8\u5173\u8005\u5171\u540c\u6295\u8d44\uff0c\u4f46\u672a\u6765\u6536\u76ca\u7684\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a33\u5065\u535a\u5f08\u7406\u8bba\u7684\u968f\u673a\u8054\u76df\u6e38\u620f\u6a21\u578b\uff0c\u65e8\u5728\u5206\u6790\u5171\u6295\u8d44\u65b9\u6848\u7684\u7a33\u5b9a\u6027\u548c\u76c8\u5229\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6536\u76ca\u6ce2\u52a8\u7684\u60c5\u51b5\u4e0b\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u6536\u76ca\u76f8\u4f3c\u4e14\u6295\u8d44\u5468\u671f\u8db3\u591f\u957f\u65f6\uff0c\u5927\u8054\u76df\u7684\u7a33\u5b9a\u6027\u6982\u7387\u4e0b\u9650\u8f83\u9ad8\uff1b\u800c\u5728\u6536\u76ca\u6ce2\u52a8\u8f83\u5927\u65f6\uff0c\u5c3d\u7ba1\u7a33\u5b9a\u6027\u4e0b\u9650\u8f83\u4f4e\uff0c\u5171\u6295\u8d44\u4ecd\u7136\u5177\u6709\u76c8\u5229\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7b49\u670d\u52a1\u7684\u5171\u6295\u8d44\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u6536\u76ca\u76f8\u4f3c\u4e14\u6295\u8d44\u5468\u671f\u957f\u7684\u6761\u4ef6\u4e0b\uff0c\u5171\u6295\u8d44\u65b9\u6848\u5177\u6709\u8f83\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u5728\u6536\u76ca\u6ce2\u52a8\u65f6\u4ecd\u80fd\u4fdd\u6301\u76c8\u5229\u80fd\u529b\u3002"}}
{"id": "2510.14642", "categories": ["cs.GT", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.14642", "abs": "https://arxiv.org/abs/2510.14642", "authors": ["Andrei Seoev", "Leonid Gremyachikh", "Anastasiia Smirnova", "Yash Madhwal", "Alisa Kalacheva", "Dmitry Belousov", "Ilia Zubov", "Aleksei Smirnov", "Denis Fedyanin", "Vladimir Gorgadze", "Yury Yanovich"], "title": "The Bidding Games: Reinforcement Learning for MEV Extraction on Polygon Blockchain", "comment": null, "summary": "In blockchain networks, the strategic ordering of transactions within blocks\nhas emerged as a significant source of profit extraction, known as Maximal\nExtractable Value (MEV). The transition from spam-based Priority Gas Auctions\nto structured auction mechanisms like Polygon Atlas has transformed MEV\nextraction from public bidding wars into sealed-bid competitions under extreme\ntime constraints. While this shift reduces network congestion, it introduces\ncomplex strategic challenges where searchers must make optimal bidding\ndecisions within a sub-second window without knowledge of competitor behavior\nor presence. Traditional game-theoretic approaches struggle in this\nhigh-frequency, partially observable environment due to their reliance on\ncomplete information and static equilibrium assumptions. We present a\nreinforcement learning framework for MEV extraction on Polygon Atlas and make\nthree contributions: (1) A novel simulation environment that accurately models\nthe stochastic arrival of arbitrage opportunities and probabilistic competition\nin Atlas auctions; (2) A PPO-based bidding agent optimized for real-time\nconstraints, capable of adaptive strategy formulation in continuous action\nspaces while maintaining production-ready inference speeds; (3) Empirical\nvalidation demonstrating our history-conditioned agent captures 49\\% of\navailable profits when deployed alongside existing searchers and 81\\% when\nreplacing the market leader, significantly outperforming static bidding\nstrategies. Our work establishes that reinforcement learning provides a\ncritical advantage in high-frequency MEV environments where traditional\noptimization methods fail, offering immediate value for industrial participants\nand protocol designers alike.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u533a\u5757\u94fe\u7f51\u7edc\u4e2dMEV\uff08\u6700\u5927\u53ef\u63d0\u53d6\u4ef7\u503c\uff09\u63d0\u53d6\u7684\u9ad8\u9891\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u6218\u7565\u6311\u6218\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u533a\u5757\u94fe\u7f51\u7edc\u4e2dMEV\u63d0\u53d6\u7684\u673a\u5236\u4ece\u516c\u5f00\u7ade\u4ef7\u8f6c\u53d8\u4e3a\u5bc6\u5c01\u7ade\u4ef7\uff0c\u5bfc\u81f4\u4f20\u7edf\u7684\u535a\u5f08\u8bba\u65b9\u6cd5\u5728\u9ad8\u9891\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u5931\u6548\uff0c\u4e9f\u9700\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09\u6a21\u62dfPolygon Atlas\u62cd\u5356\u4e2d\u5957\u5229\u673a\u4f1a\u548c\u7ade\u4e89\u7684\u968f\u673a\u73af\u5883\uff1b2\uff09\u57fa\u4e8ePPO\u7684\u5b9e\u65f6\u7ade\u4ef7\u4ee3\u7406\uff1b3\uff09\u5386\u53f2\u6761\u4ef6\u5316\u7684\u81ea\u9002\u5e94\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u4ee3\u7406\u5728\u73b0\u6709\u641c\u7d22\u8005\u4e2d\u6355\u83b749%\u7684\u5229\u6da6\uff0c\u66ff\u6362\u5e02\u573a\u9886\u5bfc\u8005\u540e\u53ef\u8fbe81%\uff0c\u663e\u8457\u4f18\u4e8e\u9759\u6001\u7ade\u4ef7\u7b56\u7565\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u9891MEV\u73af\u5883\u4e2d\u5177\u6709\u5173\u952e\u4f18\u52bf\uff0c\u4e3a\u5de5\u4e1a\u53c2\u4e0e\u8005\u548c\u534f\u8bae\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u76f4\u63a5\u4ef7\u503c\u3002"}}
{"id": "2510.14752", "categories": ["cs.GT", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.14752", "abs": "https://arxiv.org/abs/2510.14752", "authors": ["Javier Cembrano", "Jose Correa", "Svenja M. Griesbach", "Victor Verdugo"], "title": "Online Proportional Apportionment", "comment": null, "summary": "Traditionally, the problem of apportioning the seats of a legislative body\nhas been viewed as a one-shot process with no dynamic considerations. While\nthis approach is reasonable for some settings, dynamic aspects play an\nimportant role in many others. We initiate the study of apportionment problems\nin an online setting. Specifically, we introduce a framework for proportional\napportionment with no information about the future. In this model, time is\ndiscrete and there are $n$ parties that receive a certain share of the votes at\neach time step. An online algorithm needs to irrevocably assign a prescribed\nnumber of seats at each time, ensuring that each party receives its fractional\nshare rounded up or down, and that the cumulative number of seats allocated to\neach party remains close to its cumulative share up to that time.\n  We study deterministic and randomized online apportionment methods. For\ndeterministic methods, we construct a family of adversarial instances that\nyield a lower bound, linear in $n$, on the worst-case deviation between the\nseats allocated to a party and its cumulative share. We show that this bound is\nbest possible and is matched by a natural greedy method. As a consequence, a\nmethod guaranteeing that the cumulative number of seats assigned to each party\nup to any step equals its cumulative share rounded up or down (global quota)\nexists if and only if $n\\leq 3$. Then, we turn to randomized allocations and\nshow that, for $n\\leq 3$, we can randomize over methods satisfying global quota\nwith the additional guarantee that each party receives, in expectation, its\nproportional share in every step. Our proof is constructive: Any method\nsatisfying these properties can be obtained from a flow on a recursively\nconstructed network. We showcase the applicability of our results to obtain\napproximate solutions in the context of online dependent rounding procedures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u73af\u5883\u4e0b\u7684\u6bd4\u4f8b\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u6846\u67b6\uff0c\u5e76\u5206\u6790\u4e86\u786e\u5b9a\u6027\u548c\u968f\u673a\u6027\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u7acb\u6cd5\u5e2d\u4f4d\u5206\u914d\u88ab\u89c6\u4e3a\u4e00\u6b21\u6027\u8fc7\u7a0b\uff0c\u5ffd\u7565\u4e86\u52a8\u6001\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002\u8bba\u6587\u65e8\u5728\u7814\u7a76\u5728\u7ebf\u73af\u5883\u4e0b\u7684\u6bd4\u4f8b\u5206\u914d\u95ee\u9898\uff0c\u4ee5\u9002\u5e94\u66f4\u590d\u6742\u7684\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u6846\u67b6\uff0c\u5176\u4e2d\u65f6\u95f4\u79bb\u6563\u4e14\u6bcf\u6b21\u6295\u7968\u540e\u9700\u7acb\u5373\u5206\u914d\u5e2d\u4f4d\u3002\u7814\u7a76\u4e86\u786e\u5b9a\u6027\u548c\u968f\u673a\u6027\u5728\u7ebf\u5206\u914d\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u7684\u6027\u80fd\u548c\u5c40\u9650\u6027\u3002", "result": "\u786e\u5b9a\u6027\u65b9\u6cd5\u7684\u504f\u5dee\u4e0b\u9650\u662f\u7ebf\u6027\u7684\uff0c\u4e14\u8d2a\u5a6a\u65b9\u6cd5\u53ef\u8fbe\u6700\u4f73\u6027\u80fd\u3002\u968f\u673a\u6027\u65b9\u6cd5\u5728$n\\leq3$\u65f6\u53ef\u6ee1\u8db3\u5168\u5c40\u914d\u989d\u548c\u671f\u671b\u6bd4\u4f8b\u5206\u914d\u7684\u4fdd\u8bc1\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u5728\u7ebf\u6bd4\u4f8b\u5206\u914d\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u7b97\u6cd5\u4e0a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5728\u7ebf\u4f9d\u8d56\u820d\u5165\u7684\u8fd1\u4f3c\u89e3\u3002"}}
{"id": "2510.14558", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.14558", "abs": "https://arxiv.org/abs/2510.14558", "authors": ["Amir Mohammad Fadaei Ayyam", "Michael Sammler"], "title": "HITrees: Higher-Order Interaction Trees", "comment": null, "summary": "Recent years have witnessed the rise of compositional semantics as a\nfoundation for formal verification of complex systems. In particular,\ninteraction trees have emerged as a popular denotational semantics. Interaction\ntrees achieve compositionality by providing a reusable library of effects.\nHowever, their notion of effects does not support higher-order effects, i.e.,\neffects that take or return monadic computations. Such effects are essential to\nmodel complex semantic features like parallel composition and call/cc.\n  We introduce Higher-Order Interaction Trees (HITrees), the first variant of\ninteraction trees to support higher-order effects in a non-guarded type theory.\nHITrees accomplish this through two key techniques: first, by designing the\nnotion of effects such that the fixpoints of effects with higher-order input\ncan be expressed as inductive types inside the type theory; and second, using\ndefunctionalization to encode higher-order outputs into a first-order\nrepresentation. We implement HITrees in the Lean proof assistant, accompanied\nby a comprehensive library of effects including concurrency, recursion, and\ncall/cc. Furthermore, we provide two interpretations of HITrees, as state\ntransition systems and as monadic programs. To demonstrate the expressiveness\nof HITrees, we apply them to define the semantics of a language with parallel\ncomposition and call/cc.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u9ad8\u9636\u6548\u5e94\u7684\u4ea4\u4e92\u6811\u53d8\u4f53\uff08HITrees\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4ea4\u4e92\u6811\u65e0\u6cd5\u5904\u7406\u9ad8\u9636\u6548\u5e94\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7Lean\u8bc1\u660e\u52a9\u624b\u5b9e\u73b0\u4e86\u4e00\u5957\u5168\u9762\u7684\u6548\u5e94\u5e93\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u7ec4\u5408\u8bed\u4e49\u5b66\u5728\u590d\u6742\u7cfb\u7edf\u7684\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u53d8\u5f97\u91cd\u8981\u3002\u4ea4\u4e92\u6811\u4f5c\u4e3a\u4e00\u79cd\u6d41\u884c\u7684\u6307\u79f0\u8bed\u4e49\uff0c\u867d\u7136\u5b9e\u73b0\u4e86\u7ec4\u5408\u6027\uff0c\u4f46\u5176\u6548\u5e94\u6982\u5ff5\u65e0\u6cd5\u652f\u6301\u9ad8\u9636\u6548\u5e94\uff0c\u800c\u8fd9\u4e9b\u6548\u5e94\u5bf9\u4e8e\u5efa\u6a21\u5e76\u884c\u7ec4\u5408\u548ccall/cc\u7b49\u590d\u6742\u8bed\u4e49\u7279\u5f81\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u652f\u6301\u9ad8\u9636\u6548\u5e94\u3002", "method": "\u672c\u6587\u63d0\u51faHigher-Order Interaction Trees\uff08HITrees\uff09\uff0c\u901a\u8fc7\u4e24\u79cd\u5173\u952e\u6280\u672f\u5b9e\u73b0\u9ad8\u9636\u6548\u5e94\u652f\u6301\uff1a1\uff09\u8bbe\u8ba1\u6548\u5e94\u6982\u5ff5\u4ee5\u8868\u8fbe\u9ad8\u9636\u8f93\u5165\u7684\u5b9a\u70b9\u4e3a\u5f52\u7eb3\u7c7b\u578b\uff1b2\uff09\u4f7f\u7528\u8131\u51fd\u6570\u5316\u5c06\u9ad8\u9636\u8f93\u51fa\u7f16\u7801\u4e3a\u4e00\u9636\u8868\u793a\u3002", "result": "HITrees\u5728Lean\u8bc1\u660e\u52a9\u624b\u4e2d\u5b9e\u73b0\uff0c\u5e76\u914d\u5907\u4e86\u5305\u62ec\u5e76\u53d1\u3001\u9012\u5f52\u548ccall/cc\u5728\u5185\u7684\u6548\u5e94\u5e93\u3002\u6b64\u5916\uff0c\u63d0\u4f9b\u4e86HITrees\u7684\u4e24\u79cd\u89e3\u91ca\uff1a\u72b6\u6001\u8f6c\u6362\u7cfb\u7edf\u548c\u5355\u5b50\u7a0b\u5e8f\u3002\u5e94\u7528HITrees\u6210\u529f\u5b9a\u4e49\u4e86\u4e00\u4e2a\u652f\u6301\u5e76\u884c\u7ec4\u5408\u548ccall/cc\u7684\u8bed\u8a00\u8bed\u4e49\u3002", "conclusion": "HITrees\u662f\u7b2c\u4e00\u79cd\u5728\u975e\u4fdd\u62a4\u7c7b\u578b\u7406\u8bba\u4e2d\u652f\u6301\u9ad8\u9636\u6548\u5e94\u7684\u4ea4\u4e92\u6811\u53d8\u4f53\uff0c\u4e3a\u89e3\u51b3\u9ad8\u9636\u6548\u5e94\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2510.14146", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14146", "abs": "https://arxiv.org/abs/2510.14146", "authors": ["Arman Maesumi", "Tanish Makadia", "Thibault Groueix", "Vladimir G. Kim", "Daniel Ritchie", "Noam Aigerman"], "title": "PoissonNet: A Local-Global Approach for Learning on Surfaces", "comment": "In ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia) 2025,\n  16 pages", "summary": "Many network architectures exist for learning on meshes, yet their\nconstructions entail delicate trade-offs between difficulty learning\nhigh-frequency features, insufficient receptive field, sensitivity to\ndiscretization, and inefficient computational overhead. Drawing from classic\nlocal-global approaches in mesh processing, we introduce PoissonNet, a novel\nneural architecture that overcomes all of these deficiencies by formulating a\nlocal-global learning scheme, which uses Poisson's equation as the primary\nmechanism for feature propagation. Our core network block is simple; we apply\nlearned local feature transformations in the gradient domain of the mesh, then\nsolve a Poisson system to propagate scalar feature updates across the surface\nglobally. Our local-global learning framework preserves the features's full\nfrequency spectrum and provides a truly global receptive field, while remaining\nagnostic to mesh triangulation. Our construction is efficient, requiring far\nless compute overhead than comparable methods, which enables scalability --\nboth in the size of our datasets, and the size of individual training samples.\nThese qualities are validated on various experiments where, compared to\nprevious intrinsic architectures, we attain state-of-the-art performance on\nsemantic segmentation and parameterizing highly-detailed animated surfaces.\nFinally, as a central application of PoissonNet, we show its ability to learn\ndeformations, significantly outperforming state-of-the-art architectures that\nlearn on surfaces.", "AI": {"tldr": "PoissonNet\u662f\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5c40\u90e8-\u5168\u5c40\u5b66\u4e60\u65b9\u6848\u89e3\u51b3\u7f51\u683c\u5b66\u4e60\u4e2d\u9ad8\u9891\u7279\u5f81\u5b66\u4e60\u3001\u611f\u53d7\u91ce\u4e0d\u8db3\u3001\u79bb\u6563\u5316\u654f\u611f\u548c\u8ba1\u7b97\u5f00\u9500\u4f4e\u6548\u7b49\u95ee\u9898\uff0c\u5229\u7528\u6cca\u677e\u65b9\u7a0b\u5b9e\u73b0\u7279\u5f81\u4f20\u64ad\uff0c\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7f51\u683c\u5b66\u4e60\u67b6\u6784\u5728\u5b66\u4e60\u9ad8\u9891\u7279\u5f81\u3001\u611f\u53d7\u91ce\u3001\u79bb\u6563\u5316\u654f\u611f\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u590d\u6742\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165PoissonNet\uff0c\u91c7\u7528\u5c40\u90e8-\u5168\u5c40\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u7f51\u683c\u68af\u5ea6\u57df\u8fdb\u884c\u5c40\u90e8\u7279\u5f81\u53d8\u6362\uff0c\u5e76\u901a\u8fc7\u6c42\u89e3\u6cca\u677e\u7cfb\u7edf\u5168\u5c40\u4f20\u64ad\u7279\u5f81\u66f4\u65b0\u3002", "result": "PoissonNet\u5728\u9ad8\u9891\u7279\u5f81\u4fdd\u7559\u3001\u5168\u5c40\u611f\u53d7\u91ce\u3001\u8ba1\u7b97\u6548\u7387\u548c\u7f51\u683c\u65e0\u5173\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u8bed\u4e49\u5206\u5272\u548c\u52a8\u753b\u8868\u9762\u53c2\u6570\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "PoissonNet\u901a\u8fc7\u5b66\u4e60\u53d8\u5f62\u7b49\u4efb\u52a1\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8868\u9762\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7f51\u683c\u5904\u7406\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.14907", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.14907", "abs": "https://arxiv.org/abs/2510.14907", "authors": ["Geelon So", "Yi-An Ma"], "title": "Learnable Mixed Nash Equilibria are Collectively Rational", "comment": null, "summary": "We extend the study of learning in games to dynamics that exhibit\nnon-asymptotic stability. We do so through the notion of uniform stability,\nwhich is concerned with equilibria of individually utility-seeking dynamics.\nPerhaps surprisingly, it turns out to be closely connected to economic\nproperties of collective rationality. Under mild non-degeneracy conditions and\nup to strategic equivalence, if a mixed equilibrium is not uniformly stable,\nthen it is not weakly Pareto optimal: there is a way for all players to improve\nby jointly deviating from the equilibrium. On the other hand, if it is locally\nuniformly stable, then the equilibrium must be weakly Pareto optimal. Moreover,\nwe show that uniform stability determines the last-iterate convergence behavior\nfor the family of incremental smoothed best-response dynamics, used to model\nindividual and corporate behaviors in the markets. Unlike dynamics around\nstrict equilibria, which can stabilize to socially-inefficient solutions,\nindividually utility-seeking behaviors near mixed Nash equilibria lead to\ncollective rationality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u975e\u6e10\u8fdb\u7a33\u5b9a\u6027\u52a8\u6001\u4e0b\u7684\u535a\u5f08\u5b66\u4e60\uff0c\u63d0\u51fa\u4e86\u5747\u5300\u7a33\u5b9a\u6027\u7684\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u96c6\u4f53\u7406\u6027\u7ecf\u6d4e\u7279\u6027\u7684\u7d27\u5bc6\u8054\u7cfb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6269\u5c55\u535a\u5f08\u5b66\u4e60\u7684\u7814\u7a76\u8303\u56f4\uff0c\u63a2\u7d22\u975e\u6e10\u8fdb\u7a33\u5b9a\u6027\u52a8\u6001\u4e0b\u7684\u5747\u8861\u884c\u4e3a\u53ca\u5176\u4e0e\u96c6\u4f53\u7406\u6027\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5747\u5300\u7a33\u5b9a\u6027\u7684\u6982\u5ff5\u5206\u6790\u6df7\u5408\u5747\u8861\u7684\u6027\u8d28\uff0c\u5e76\u7ed3\u5408\u589e\u91cf\u5e73\u6ed1\u6700\u4f73\u54cd\u5e94\u52a8\u6001\u5bb6\u65cf\u7684\u8fed\u4ee3\u6536\u655b\u884c\u4e3a\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u975e\u9000\u5316\u6761\u4ef6\u4e0b\uff0c\u82e5\u6df7\u5408\u5747\u8861\u4e0d\u5177\u5747\u5300\u7a33\u5b9a\u6027\uff0c\u5219\u4e0d\u5177\u5907\u5f31\u5e15\u7d2f\u6258\u6700\u4f18\u6027\uff1b\u53cd\u4e4b\uff0c\u5c40\u90e8\u5747\u5300\u7a33\u5b9a\u7684\u5747\u8861\u5219\u5177\u6709\u5f31\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u6307\u51fa\uff0c\u4e2a\u4f53\u6548\u7528\u8ffd\u6c42\u884c\u4e3a\u5728\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u9644\u8fd1\u80fd\u591f\u5b9e\u73b0\u96c6\u4f53\u7406\u6027\uff0c\u8fd9\u4e0e\u4e25\u683c\u5747\u8861\u9644\u8fd1\u7684\u884c\u4e3a\u53ef\u80fd\u5bfc\u81f4\u793e\u4f1a\u4f4e\u6548\u89e3\u4e0d\u540c\u3002"}}
