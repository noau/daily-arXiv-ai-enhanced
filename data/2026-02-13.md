<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 13]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Filmsticking++: Rapid Film Sticking for Explicit Surface Reconstruction](https://arxiv.org/abs/2602.11433)
*Pengfei Wang,Jian Liu,Qiujie Dong,Shiqing Xin,Yuanfeng Zhou,Changhe Tu,Caiming Zhang,Wenping Wang*

Main category: cs.GR

TL;DR: 论文提出了一种名为Filmsticking++的方法，通过引入加权距离的限制功率图（RPD）和虚拟站点，解决了现有RVD-based filmsticking在深内部空腔情况下无法插值所有点的问题，提升了计算效率、鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于受限Voronoi图（RVD）的filmsticking技术在处理低质量点云时，尤其是在深内部空腔情况下，无法插值所有点，导致错误的拓扑结构。这是由于欧几里得距离度量的固有局限性。

Method: Filmsticking++采用了基于加权距离的限制功率图（RPD），确保所有点都能被插值。此外，通过观察发现外部中轴在引导表面接近目标形状时会逐渐被排出，因此在引导表面内部放置虚拟站点以加速这一过程。

Result: Filmsticking++显著优于现有的RVD-based filmsticking方法，实现了对所有点的插值，同时降低了计算成本，提升了方法的鲁棒性和可扩展性。

Conclusion: Filmsticking++通过创新的加权距离和虚拟站点技术，克服了欧几里得距离的传统限制，成为显式表面重建领域的新标杆方法。

Abstract: Explicit surface reconstruction aims to generate a surface mesh that exactly interpolates a given point cloud. This requirement is crucial when the point cloud must lie non-negotiably on the final surface to preserve sharp features and fine geometric details. However, the task becomes substantially challenging with low-quality point clouds, due to inherent reconstruction ambiguities compounded by combinatorial complexity. A previous method using filmsticking technique by iteratively compute restricted Voronoi diagram to address these issues, ensures to produce a watertight manifold, setting a new benchmark as the state-of-the-art (SOTA) technique. Unfortunately, RVD-based filmsticking is inability to interpolate all points in the case of deep internal cavities, resulting in very likely is the generation of faulty topology. The cause of this issue is that RVD-based filmsticking has inherent limitations due to Euclidean distance metrics. In this paper, we extend the filmsticking technique, named Filmsticking++. Filmsticking++ reconstructing an explicit surface from points without normals. On one hand, Filmsticking++ break through the inherent limitations of Euclidean distance by employing a weighted-distance-based Restricted Power Diagram, which guarantees that all points are interpolated. On the other hand, we observe that as the guiding surface increasingly approximates the target shape, the external medial axis is gradually expelled outside the guiding surface. Building on this observation, we propose placing virtual sites inside the guiding surface to accelerate the expulsion of the external medial axis from its interior. To summarize, contrary to the SOTA method, Filmsticking++ demonstrates multiple benefits, including decreases computational cost, improved robustness and scalability.

</details>


### [2] [LeafFit: Plant Assets Creation from 3D Gaussian Splatting](https://arxiv.org/abs/2602.11577)
*Chang Luo,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: LeafFit是一種將3D高斯灑點（3DGS）的單株植物轉換為可編輯、實例化的網格資產的管道，解決了3DGS在遊戲製作中記憶體占用高和缺乏網格拓撲的問題。


<details>
  <summary>Details</summary>
Motivation: 傳統3DGS雖能準確捕捉複雜的葉片結構，但因高記憶體需求和缺乏網格拓撲，難以應用於遊戲生產流程。LeafFit旨在解決這些限制。

Method: LeafFit通過分段葉片、選擇代表性葉片群組並轉換為模板，再使用可微分的Moving Least Squares（MLS）變形將其擬合到其他葉片上，最後在運行時通過頂點著色器高效計算變形。

Result: 實驗顯示，LeafFit在分割質量和變形精度上優於近期基準方法，同時大幅減少了數據大小並支持參數級編輯。

Conclusion: LeafFit成功將3DGS轉換為適合遊戲生產的可編輯網格資產，兼具高效性和準確性。

Abstract: We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing.

</details>


### [3] [Variation-aware Flexible 3D Gaussian Editing](https://arxiv.org/abs/2602.11638)
*Hao Qin,Yukai Sun,Meng Wang,Ming Kong,Mengxu Lu,Qiang Zhu*

Main category: cs.GR

TL;DR: VF-Editor是一种直接编辑3D高斯抛体（3DGS）的原生方法，通过预测属性变化避免了间接编辑中的跨视图不一致性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有的间接编辑方法在3D高斯抛体（3DGS）中存在跨视图不一致性和编辑灵活性不足的问题，VF-Editor旨在解决这些问题。

Method: VF-Editor通过设计一个新颖的变化预测器，从2D编辑知识中提取信息，生成变化场并迭代推断每个3D高斯的属性变化。

Result: 在公开和私有数据集上的实验证明了间接编辑管线的局限性，并验证了VF-Editor的有效性和灵活性。

Conclusion: VF-Editor通过原生编辑和知识转移，提供了一种灵活且高效的3D编辑解决方案。

Abstract: Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.

</details>


### [4] [OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars](https://arxiv.org/abs/2602.11693)
*Zehao Xia,Yiqun Wang,Zhengda Lu,Kai Liu,Jun Xiao,Peter Wonka*

Main category: cs.GR

TL;DR: OMEGA-Avatar 是一种前馈框架，首次从单张图像同时生成可泛化、360°完整且可动画的3D高斯头像，解决了当前方法无法同时满足三个关键属性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的方法无法同时满足前馈、360°完整和可动画化的三个关键属性。为了解决这一限制，提出了 OMEGA-Avatar，旨在生成高质量的可动画3D头像。

Method: OMEGA-Avatar 结合了两种新颖组件：1) 语义感知的网格变形模块，通过多视角法线优化FLAME头部并保留其拓扑结构；2) 多视角特征投射模块，通过可微分双线性投射和可见性感知融合实现全头部特征的高效前馈解码。

Result: 实验表明，OMEGA-Avatar 在360°全头部完整性上显著优于现有基线，同时在多视角下保持身份的一致性。

Conclusion: OMEGA-Avatar 是首个同时满足前馈、360°完整和可动画化的框架，为高质量3D头像生成提供了新方法。

Abstract: Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.

</details>


### [5] [Iskra: A System for Inverse Geometry Processing](https://arxiv.org/abs/2602.12105)
*Ana Dodik,Ahmed H. Mahmoud,Justin Solomon*

Main category: cs.GR

TL;DR: 论文提出了一种通过几何处理问题解决方案进行微分的系统，适用于多种几何算法，并利用机器学习框架，实现低实现成本、快速运行和低内存需求。


<details>
  <summary>Details</summary>
Motivation: 几何处理算法在机器学习和优化中的应用需求日益增长，但现有方法往往需要重新设计算法或计算代价高昂。本研究旨在提供一种无需重构现有算法即可实现高效微分的解决方案。

Method: 系统结合了散射-聚集方法和基于张量的工作流程，利用伴随方法自动生成高效的反向传播过程，兼容本地-全局和ADMM求解器等几何处理技术。

Result: 在平均曲率流、谱共形参数化、测地距离计算和尽可能刚性变形等应用中，系统表现出较高的可用性和性能，运行速度快且内存需求低。

Conclusion: 该系统为几何处理算法的微分提供了高效且易用的工具，为逆几何处理应用开辟了新的可能性。

Abstract: We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris](https://arxiv.org/abs/2602.11481)
*Minda Li,Bhaskar Krishnamachari*

Main category: cs.PL

TL;DR: GPT-5在Python、C++和Java等常用编程语言中表现优异，但在低资源语言如Idris中的表现尚未充分探索。通过反馈驱动的迭代提示，尤其是利用本地编译错误，GPT-5在Idris练习中的表现从22/56提升到54/56。


<details>
  <summary>Details</summary>
Motivation: 探索GPT-5在低资源或非常用编程语言（如Idris）中的学习能力，验证其是否可以通过反馈驱动的提示提升表现。

Method: 通过零次提示建立基准，并评估多种改进策略，包括基于平台反馈的迭代提示、增强提示文档和错误分类指南，以及利用本地编译错误的迭代提示。

Result: 利用本地编译错误的迭代提示显著提升了GPT-5的表现，解决了54/56的Idris练习问题。

Conclusion: 在低资源环境中，结构化编译器级反馈对解锁大型语言模型的能力至关重要。

Abstract: GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Computing stable limit cycles of learning in games](https://arxiv.org/abs/2602.11315)
*Oliver Biggar,Christos Papadimitriou*

Main category: cs.GT

TL;DR: 本文研究了博弈动态中的周期性行为稳定性问题，重点关注虚构玩法/最佳响应动态和复制动态，提出了多项式时间稳定性测试方法和结构性条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于回答博弈动态中哪些周期性行为是稳定的，填补了Shapley（1964）以来的研究空白。

Method: 方法包括分析周期性序列在虚构玩法和复制动态中的稳定性，并提供多项式时间的光谱稳定性测试。

Result: 结果表明，周期性序列在这两种动态中的稳定性等价，且提出了一个结构性充分条件：任何作为博弈偏好图汇平衡的周期都是稳定的，且是复制动态的吸引子。

Conclusion: 结论是本文结果扩展了Shapley和Jordan的经典定理，同时推进了偏好图与复制动态吸引子关系的研究前沿。

Abstract: Many well-studied learning dynamics, such as fictitious play and the replicator, are known to not converge in general $N$-player games. The simplest mode of non-convergence is cyclical or periodic behavior. Such cycles are fundamental objects, and have inspired a number of significant insights in the field, beginning with the pioneering work of Shapley (1964). However a central question remains unanswered: which cycles are stable under game dynamics? In this paper we give a complete and computational answer to this question for the two best-studied dynamics, fictitious play/best-response dynamics and the replicator dynamic. We show (1) that a periodic sequence of profiles is stable under one of these dynamics if and only it is stable under the other, and (2) we provide a polynomial-time spectral stability test to determine whether a given periodic sequence is stable under either dynamic. Finally, we give an entirely `structural' sufficient condition for stability: every cycle that is a sink equilibrium of the preference graph of the game is stable, and moreover it is an attractor of the replicator dynamic. This result generalizes the famous theorems of Shapley (1964) and Jordan (1993), and extends the frontier of recent work relating the preference graph to the replicator attractors.

</details>


### [8] [Achieving EF1 and Epistemic EFX Guarantees Simultaneously](https://arxiv.org/abs/2602.11732)
*Hannaneh Akrami,Ryoga Mahara,Kurt Mehlhorn,Nidhi Rathi*

Main category: cs.GT

TL;DR: 该论文研究了在不可分割物品分配中如何实现EF1和EEFX的公平性，并提出了一个新的公平性概念‘strong EEFX share’，为解决EFX问题提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 研究不可分割物品公平分配的开放性问题，特别是EFX的存在性问题，以及其放松条件EF1和EEFX的组合实现。

Method: 引入了新的公平性概念‘strong EEFX share’，并证明其与EF1的兼容性，从而实现了EF1和EEFX的同步满足。

Result: 证明了对于加性估值，存在同时满足EF1和EEFX的分配方案，解决了Akrami和Rathi（2025）提出的主要开放性问题。

Conclusion: 通过引入‘strong EEFX share’概念，填补了EFX问题研究中的空白，为最终解决EFX问题迈出了重要一步。

Abstract: We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved.
  In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.

</details>


### [9] [Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition](https://arxiv.org/abs/2602.11835)
*Yutong Chao,Jalal Etesami*

Main category: cs.GT

TL;DR: 本文研究了在一般和博弈中寻找纳什均衡的问题，重点关注基于一阶梯度的算法及其变体（如块坐标下降算法），并提出了一个称为"n-sided PL条件"的条件集，以分析梯度下降算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 动机在于探索和解决标准梯度下降方法在某些情况下无法收敛到纳什均衡的问题，并通过提出的新条件扩展分析工具。

Method: 方法包括引入"n-sided PL条件"及多凸性概念，以及提出改进的梯度下降变体算法，如块坐标下降算法。

Result: 结果表明，所提出的条件适用于多类非凸函数，且改进的梯度下降变体能在标准方法失效的情况下收敛到纳什均衡。

Conclusion: 结论是提出的"n-sided PL条件"和改进算法能有效解决研究问题，且实验验证了其性能。

Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-Łojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.

</details>


### [10] [Scale-Invariant Fast Convergence in Games](https://arxiv.org/abs/2602.11857)
*Taira Tsuchiya,Haipeng Luo,Shinji Ito*

Main category: cs.GT

TL;DR: 该论文提出了在游戏中实现尺度不变性的学习动态方法，无需预先了解效用尺度即可快速收敛。


<details>
  <summary>Details</summary>
Motivation: 当前大多数游戏学习中的快速收敛保证需要预先知道效用尺度，限制了其应用范围。为解决这一问题，论文开发了尺度无关且尺度不变的学习动态方法。

Method: 采用了乐观跟随正则化领导者（optimistic follow-the-regularized-leader）方法，结合自适应学习率和新的停止时间分析技术，还引入了加倍裁剪技术。

Result: 在两人零和游戏中，外部遗憾为$	ilde{O}(A_{\mathrm{diff}})$；在多玩家游戏中，交换遗憾为$O(U_{\mathrm{max}} \log T)$，实现了快速的纳什均衡和关联均衡收敛。

Conclusion: 论文提出的方法不仅尺度无关且尺度不变，还能在各种游戏中实现快速收敛，显著提升了学习动态的实用性。

Abstract: Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\tilde{O}(A_{\mathrm{diff}})$, where $A_{\mathrm{diff}}$ is the payoff range, which implies an $\tilde{O}(A_{\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\mathrm{max}} \log T)$, where $U_{\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\mathrm{max}} \log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.

</details>


### [11] [Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection](https://arxiv.org/abs/2602.11914)
*Hanbing Liu,Ningyuan Li,Weian Li,Qi Qi,Changyuan Yu*

Main category: cs.GT

TL;DR: 本文研究了带有预选和分数线公开的排名竞赛，分析了预选参赛者在不同奖金结构和预选规模下的均衡行为。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探讨如何在预选竞赛中确保公平性，并通过设定分数线筛选参赛者。

Method: 作者对预选竞赛进行了建模，分析了两种目标函数（最高个人表现和总表现）下的最优竞赛形式。

Result: 研究发现，对于最高个人表现，最优预选规模为两人；而对于总表现，预选规模对结果无影响。此外，预选后的最高个人表现比未预选时高出4/3倍。

Conclusion: 预选竞赛在提升最高个人表现方面效果显著，但对于总表现并无影响，最优竞赛形式为赢家通吃。

Abstract: Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.

</details>


### [12] [Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions](https://arxiv.org/abs/2602.11959)
*Moshe Babaioff,Yiding Feng,Zihan Luo*

Main category: cs.GT

TL;DR: 该论文探讨了在多单位拍卖中，通过加强分布假设和改进VCG拍卖机制，显著降低了实现（接近）最优收入所需的额外买家数量。


<details>
  <summary>Details</summary>
Motivation: 经典研究显示，VCG拍卖在正则分布下需要添加m个额外买家才能达到最优收入。然而，这种竞争复杂度在某些情况下过高，因此在更强分布假设和改进机制下探索降低竞争复杂度的方法。

Method: 研究基于MHR分布的平衡市场，发现添加约0.4447n个额外买家即可达到最优收入；同时分析了限制供应量的VCG变体机制，进一步减少所需额外买家数量。

Result: 在MHR分布下，最优收入的竞争复杂度降至0.4447n；供应限制VCG变体机制显著减少额外买家需求，优于标准VCG拍卖。

Conclusion: 通过更强分布假设和机制改进，可以有效降低实现（接近）最优收入所需的额外买家数量，为拍卖设计提供了更高效的解决方案。

Abstract: The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the "competition complexity" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions.
  First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\leq n$, and any target fraction of the optimal revenue.
  Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers.
  Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.

</details>


### [13] [Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare](https://arxiv.org/abs/2602.11967)
*Moshe Babaioff,Sijin Chen,Zhaohua Chen,Yiding Feng*

Main category: cs.GT

TL;DR: 研究了一个贝叶斯单物品拍卖的帕累托前沿，分析了在不同分布假设下帕累托最优机制的特性，并将机制选择问题建模为一个双边谈判博弈，探讨了两种经典解决方案的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨在不同分布假设下拍卖机制的帕累托最优性及其对买卖双方效用的影响，并研究公平与效率之间的权衡问题。

Method: 首先提供了帕累托前沿的结构特性，随后将机制选择问题建模为双边谈判博弈，分析了Kalai-Smorodinsky (KS)解和纳什解的适用范围和性能。

Result: 在独立同分布且满足双重假设的条件下，两种解在大市场中表现优异；而在最坏MHR分布下，KS解保证了一半的最优福利，纳什解可能仅占极小部分。

Conclusion: 结果凸显了公平与效率权衡对分布结构的敏感性，并认为KS解在不对称双边市场中更为稳健。

Abstract: A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve.
  Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.

</details>


### [14] [Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation](https://arxiv.org/abs/2602.12089)
*Kehang Zhu,Lithium Thain,Vivian Tsai,James Wexler,Crystal Qian*

Main category: cs.GT

TL;DR: 研究发现，在多人协商游戏中，尽管参与者更倾向推荐型的AI助手，但委托型的AI助手能带来更高的个人收益和群体效益。


<details>
  <summary>Details</summary>
Motivation: 随着AI在社会环境中的广泛应用，理解AI与用户的互动对于设计提升个人和群体效益的系统至关重要。

Method: 进行了一项在线行为实验，参与者分三组进行多轮协商游戏，每组使用不同的AI辅助模式：主动推荐的"Advisor"、反馈型的"Coach"或自主执行的"Delegate"。

Result: 尽管参与者更偏爱"Advisor"，但"Delegate"模式带来最高的个人收益和群体效益，且未使用AI的用户也能从中受益。

Conclusion: 自主AI助手虽具备超人类策略能力，但其对实际效益的影响受限于用户界面和采用障碍。设计需考虑参与机制和兼容性规则。

Abstract: As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach}, or autonomous execution by a \textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \textit{Advisor} modality, participants achieve the highest mean individual gains with the \textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.

</details>


### [15] [Anonymous Contracts](https://arxiv.org/abs/2602.12118)
*Johannes Brustle,Paul Duetting,Stefano Leonardi,Tomasz Ponitka,Matteo Russo*

Main category: cs.GT

TL;DR: 本研究探讨了多智能体合同问题，引入了匿名合同以确保公平性，分析了其在纯纳什均衡下的表现和效率极限。


<details>
  <summary>Details</summary>
Motivation: 传统歧视性合同虽能提取全部社会福利，但可能被视为不公平。匿名合同通过依赖总成功数实现公平，成为研究的动机。

Method: 研究引入匿名合同，分析其纯纳什均衡特性，并定义统一匿名合同作为子类以确保唯一均衡。同时探讨了有限责任和无限制责任下的效率极限。

Result: 匿名合同在有限责任下存在对数级效率极限，统一合同可匹配此极限。取消有限责任显著提升性能，甚至在某些条件下可提取全部社会福利。

Conclusion: 匿名合同在公平性和效率之间取得平衡，有限责任的结构反转揭示了不同概率分布下的挑战差异。

Abstract: We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents.
  We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees.
  In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.

</details>


### [16] [Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria](https://arxiv.org/abs/2602.12181)
*Anas Barakat,Ioannis Panageas,Antonios Varvitsiotis*

Main category: cs.GT

TL;DR: 该论文研究了广义效用马尔可夫博弈（GUMGs），填补了凸马尔可夫博弈在纳什均衡结构和学习算法保证方面的理论空白。


<details>
  <summary>Details</summary>
Motivation: 凸马尔可夫博弈（cMGs）扩展了多智能体学习问题的建模范围，但其理论基础（如纳什均衡结构和学习算法保证）尚未被充分理解。论文旨在填补这些理论空白。

Method: 论文通过扩展cMGs提出了GUMGs，并证明了纳什均衡与投影伪梯度动力学固定点的一致性。此外，还引入了基于Brouwer不动点定理的简单证明，并提出了一个无模型策略梯度算法。

Result: 研究表明，GUMGs中的纳什均衡可通过代理梯度支配性质实现，证实了马尔可夫完美均衡的存在性，并为潜在GUMGs提供了迭代复杂性和样本复杂性保证。

Conclusion: 论文首次对共同利益的cMGs进行了理论分析，为GUMGs的理论基础和算法设计提供了重要贡献。

Abstract: Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.

</details>


### [17] [Bandit Learning in Matching Markets with Interviews](https://arxiv.org/abs/2602.12224)
*Amirmahdi Mirfakhar,Xuchuang Wang,Mengfan Xu,Hedyeh Beyhaghi,Mohammad Hajiesmaili*

Main category: cs.GT

TL;DR: 本研究探讨了在匹配市场中通过面试作为低成本提示的偏好信息学习方法，引入策略性延期以处理不确定性，并设计了集中式和分散式算法，显著提升了后悔界限。


<details>
  <summary>Details</summary>
Motivation: 匹配市场中，参与者通常无法全面评估偏好，而面试提供的早期噪声信号会影响最终决策。研究旨在解决企业和代理在偏好不确定时的学习问题。

Method: 提出了一种框架，将面试建模为低成本提示，扩展企业的行动空间以支持策略性延期。设计了集中式和分散式算法，分别适用于不同反馈类型。

Result: 所有算法均实现了时间无关的后悔界限，显著优于现有方法。在结构化市场中，分散式算法的性能接近集中式算法。

Conclusion: 通过策略性延期和高效算法，本研究为匹配市场中的学习问题提供了新的解决方案，显著提升了性能并支持分散式学习。

Abstract: Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.

</details>


### [18] [Adjusted Winner: from Splitting to Selling](https://arxiv.org/abs/2602.12231)
*Robert Bredereck,Bin Sun,Eyal Briman,Nimrod Talmon*

Main category: cs.GT

TL;DR: 论文提出了一种扩展的Adjusted Winner方法，允许在预算约束下出售部分资源并重新分配收益，以实现更公平的资源分配。


<details>
  <summary>Details</summary>
Motivation: Adjusted Winner方法在公平分配不可分割资源时依赖分割资源，可能导致实际操作中的问题。本研究旨在通过扩展该方法解决这一问题。

Method: 提出了一种扩展的Adjusted Winner框架，允许资源出售和收益再分配。通过公理化分析研究了公平性和无嫉妒性的变化，并设计了FPTAS以解决计算复杂度问题。

Result: 研究结果表明扩展方法能在预算约束下实现尽可能公平的分配，并通过计算机模拟验证了其有效性。

Conclusion: 该扩展方法为公平分配不可分割资源提供了更实用的解决方案，并通过理论分析和模拟验证了其可行性和效果。

Abstract: The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.

</details>


### [19] [Is Online Linear Optimization Sufficient for Strategic Robustness?](https://arxiv.org/abs/2602.12253)
*Yang Cai,Haipeng Luo,Chen-Yu Wei,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文研究了在重复贝叶斯一级价格拍卖中的投标算法，特别关注其统计效率、计算效率和战略鲁棒性。通过简单的在线线性优化算法，提出了具有子线性线性化遗憾和战略鲁棒性的投标算法。


<details>
  <summary>Details</summary>
Motivation: 研究投标算法在统计效率和计算效率方面的最优性，同时确保其对卖家操纵的战略鲁棒性。现有算法虽能满足部分需求，但在效率或鲁棒性上存在不足。

Method: 使用简单的在线线性优化（OLO）算法，构建黑盒转换方法，将任何OLO算法转换为具有战略鲁棒性的无遗憾投标算法。适用于已知和未知价值分布的情况。

Result: 在已知价值分布情况下，算法实现$O(\sqrt{T \log K})$遗憾和战略鲁棒性；在未知情况下，算法实现高概率$O(\sqrt{T (\log K+\log(T/\delta)})$遗憾和鲁棒性，且无需有界密度假设。

Conclusion: 简单的OLO算法足以实现具有子线性线性化遗憾和战略鲁棒性的投标算法，显著提升了现有方法的效率和适用性。

Abstract: We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.
  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\sqrt{T \log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\sqrt{T (\log K+\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].

</details>
