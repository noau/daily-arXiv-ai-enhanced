{"id": "2512.03052", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.03052", "abs": "https://arxiv.org/abs/2512.03052", "authors": ["Zeqiang Lai", "Yunfei Zhao", "Zibo Zhao", "Haolin Liu", "Qingxiang Lin", "Jingwei Huang", "Chunchao Guo", "Xiangyu Yue"], "title": "LATTICE: Democratize High-Fidelity 3D Generation at Scale", "comment": "Technical Report", "summary": "We present LATTICE, a new framework for high-fidelity 3D asset generation that bridges the quality and scalability gap between 3D and 2D generative models. While 2D image synthesis benefits from fixed spatial grids and well-established transformer architectures, 3D generation remains fundamentally more challenging due to the need to predict both spatial structure and detailed geometric surfaces from scratch. These challenges are exacerbated by the computational complexity of existing 3D representations and the lack of structured and scalable 3D asset encoding schemes. To address this, we propose VoxSet, a semi-structured representation that compresses 3D assets into a compact set of latent vectors anchored to a coarse voxel grid, enabling efficient and position-aware generation. VoxSet retains the simplicity and compression advantages of prior VecSet methods while introducing explicit structure into the latent space, allowing positional embeddings to guide generation and enabling strong token-level test-time scaling. Built upon this representation, LATTICE adopts a two-stage pipeline: first generating a sparse voxelized geometry anchor, then producing detailed geometry using a rectified flow transformer. Our method is simple at its core, but supports arbitrary resolution decoding, low-cost training, and flexible inference schemes, achieving state-of-the-art performance on various aspects, and offering a significant step toward scalable, high-quality 3D asset creation.", "AI": {"tldr": "LATTICE\u662f\u4e00\u4e2a\u65b0\u7684\u9ad8\u4fdd\u771f3D\u8d44\u4ea7\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7VoxSet\u534a\u7ed3\u6784\u5316\u8868\u793a\u89e3\u51b3\u4e863D\u751f\u6210\u7684\u6311\u6218\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\u5b9e\u73b0\u9ad8\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "3D\u751f\u6210\u5728\u9884\u6d4b\u7a7a\u95f4\u7ed3\u6784\u548c\u51e0\u4f55\u8868\u9762\u65b9\u9762\u6bd42D\u66f4\u5177\u6311\u6218\u6027\uff0c\u4e14\u73b0\u67093D\u8868\u793a\u8ba1\u7b97\u590d\u6742\u4e14\u7f3a\u4e4f\u7ed3\u6784\u5316\u7f16\u7801\u65b9\u6848\u3002LATTICE\u65e8\u5728\u7f29\u5c0f3D\u4e0e2D\u751f\u6210\u6a21\u578b\u4e4b\u95f4\u7684\u8d28\u91cf\u4e0e\u53ef\u6269\u5c55\u6027\u5dee\u8ddd\u3002", "method": "\u63d0\u51faVoxSet\u534a\u7ed3\u6784\u5316\u8868\u793a\uff0c\u5c063D\u8d44\u4ea7\u538b\u7f29\u5230\u7c97\u7c92\u5ea6\u4f53\u7d20\u7f51\u683c\u7684\u6f5c\u5411\u91cf\u4e2d\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u5148\u751f\u6210\u7a00\u758f\u4f53\u7d20\u951a\u70b9\uff0c\u518d\u901a\u8fc7\u6574\u6d41\u6d41\u53d8\u6362\u5668\u751f\u6210\u8be6\u7ec6\u51e0\u4f55\u3002", "result": "LATTICE\u652f\u6301\u4efb\u610f\u5206\u8fa8\u7387\u89e3\u7801\u3001\u4f4e\u6210\u672c\u8bad\u7ec3\u548c\u7075\u6d3b\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "LATTICE\u4e3a\u9ad8\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u76843D\u8d44\u4ea7\u751f\u6210\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2512.04076", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.04076", "abs": "https://arxiv.org/abs/2512.04076", "authors": ["Alexander Mai", "Trevor Hedstrom", "George Kopanas", "Janne Kontkanen", "Falko Kuester", "Jonathan T. Barron"], "title": "Radiance Meshes for Volumetric Reconstruction", "comment": "Website: half-potato.gitlab.io/rm", "summary": "We introduce radiance meshes, a technique for representing radiance fields with constant density tetrahedral cells produced with a Delaunay tetrahedralization. Unlike a Voronoi diagram, a Delaunay tetrahedralization yields simple triangles that are natively supported by existing hardware. As such, our model is able to perform exact and fast volume rendering using both rasterization and ray-tracing. We introduce a new rasterization method that achieves faster rendering speeds than all prior radiance field representations (assuming an equivalent number of primitives and resolution) across a variety of platforms. Optimizing the positions of Delaunay vertices introduces topological discontinuities (edge flips). To solve this, we use a Zip-NeRF-style backbone which allows us to express a smoothly varying field even when the topology changes. Our rendering method exactly evaluates the volume rendering equation and enables high quality, real-time view synthesis on standard consumer hardware. Our tetrahedral meshes also lend themselves to a variety of exciting applications including fisheye lens distortion, physics-based simulation, editing, and mesh extraction.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u8f90\u5c04\u7f51\u683c\uff0c\u4e00\u79cd\u5229\u7528Delaunay\u56db\u9762\u4f53\u5316\u751f\u6210\u7684\u6052\u5b9a\u5bc6\u5ea6\u56db\u9762\u4f53\u5355\u5143\u6765\u8868\u793a\u8f90\u5c04\u573a\u7684\u6280\u672f\uff0c\u652f\u6301\u5feb\u901f\u4f53\u79ef\u6e32\u67d3\u548c\u591a\u79cd\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u8f90\u5c04\u573a\u8868\u793a\u5728\u786c\u4ef6\u652f\u6301\u548c\u6e32\u67d3\u901f\u5ea6\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u5229\u7528\u73b0\u6709\u786c\u4ef6\u5e76\u652f\u6301\u591a\u6837\u5e94\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528Delaunay\u56db\u9762\u4f53\u5316\u751f\u6210\u6052\u5b9a\u5bc6\u5ea6\u56db\u9762\u4f53\u5355\u5143\uff0c\u63d0\u51fa\u65b0\u7684\u5149\u6805\u5316\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408Zip-NeRF\u98ce\u683c\u7684\u9aa8\u5e72\u7f51\u7edc\u5904\u7406\u62d3\u6251\u53d8\u5316\u3002", "result": "\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u8f90\u5c04\u573a\u8868\u793a\u66f4\u5feb\u7684\u6e32\u67d3\u901f\u5ea6\uff0c\u652f\u6301\u9ad8\u8d28\u91cf\u3001\u5b9e\u65f6\u7684\u89c6\u89d2\u5408\u6210\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002", "conclusion": "\u8f90\u5c04\u7f51\u683c\u6280\u672f\u4e0d\u4ec5\u63d0\u5347\u4e86\u6e32\u67d3\u6548\u7387\u548c\u8d28\u91cf\uff0c\u8fd8\u4e3a\u591a\u79cd\u5e94\u7528\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u73b0\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.03083", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.03083", "abs": "https://arxiv.org/abs/2512.03083", "authors": ["ZeHao Yu"], "title": "Evaluate the Stack Management in Effect Handlers using the libseff C Library", "comment": null, "summary": "Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u6280\u672f\u4f18\u5316\u5806\u6808\u7ba1\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7libseff C\u5e93\u5b9e\u73b0\u52a8\u6001\u5806\u6808\u8c03\u6574\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\u63d0\u9ad8\u4e86\u5185\u5b58\u5229\u7528\u7387\u5e76\u51cf\u5c11\u4e86\u6d6a\u8d39\u3002", "motivation": "\u73b0\u4ee3\u7f16\u7a0b\u4e2d\u6548\u5e94\u5904\u7406\u5668\u7684\u52a8\u6001\u63a7\u5236\u6d41\u53d8\u5316\u7ed9\u5806\u6808\u7ba1\u7406\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5185\u5b58\u5229\u7528\u548c\u6027\u80fd\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u6280\u672f\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5229\u7528libseff C\u5e93\u7ed3\u5408\u865a\u62df\u5185\u5b58\u673a\u5236\u548c\u4fdd\u62a4\u6027\u61d2\u60f0\u5206\u914d\uff0c\u63d0\u51fa\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u5b9e\u73b0\u52a8\u6001\u5806\u6808\u8c03\u6574\uff0c\u5e76\u5bf9\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5927\u5c0f\u5806\u6808\u3001\u5206\u6bb5\u5806\u6808\u548c\u5185\u6838\u7ea7\u8d85\u989d\u63d0\u4ea4\u7684\u4f18\u52bf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5185\u6838\u7ea7\u8d85\u989d\u63d0\u4ea4\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e0a\u8868\u73b0\u5747\u8861\uff0c\u800c\u7528\u6237\u7ea7\u5b9e\u73b0\u867d\u7075\u6d3b\u4f46\u5b58\u5728\u989d\u5916\u5f00\u9500\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "conclusion": "\u672c\u6587\u8be6\u7ec6\u6bd4\u8f83\u4e86\u591a\u79cd\u5806\u6808\u7ba1\u7406\u7b56\u7565\uff0c\u63d0\u4f9b\u4e86\u9488\u5bf9\u7279\u5b9a\u5e94\u7528\u9700\u6c42\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6539\u8fdb\u7528\u6237\u7ea7\u673a\u5236\u548c\u6269\u5c55\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002"}}
{"id": "2512.03975", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03975", "abs": "https://arxiv.org/abs/2512.03975", "authors": ["Kshipra Bhawalkar", "Alexandros Psomas", "Di Wang"], "title": "Sponsored Questions and How to Auction Them", "comment": null, "summary": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow?\n  This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u7ebf\u5e73\u53f0\u5982\u4f55\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3b\u52a8\u63d0\u4f9b\u6f84\u6e05\u63d0\u793a\u6765\u89e3\u51b3\u7528\u6237\u67e5\u8be2\u7684\u6a21\u7cca\u6027\uff0c\u5e76\u7814\u7a76\u5982\u4f55\u5c06\u8fd9\u4e9b\u63d0\u793a\u4f4d\u5206\u914d\u7ed9\u5e7f\u544a\u5546\uff0c\u4ee5\u53ca\u5982\u4f55\u4e0e\u4f20\u7edf\u5e7f\u544a\u62cd\u5356\u673a\u5236\u4e92\u52a8\u3002", "motivation": "\u7528\u6237\u7684\u641c\u7d22\u67e5\u8be2\u901a\u5e38\u5b58\u5728\u610f\u56fe\u6a21\u7cca\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u88ab\u52a8\u9884\u6d4b\u65b9\u6cd5\u6548\u679c\u6709\u9650\u3002\u672c\u6587\u63a2\u7d22\u5982\u4f55\u5229\u7528LLM\u4e3b\u52a8\u63d0\u4f9b\u6f84\u6e05\u63d0\u793a\uff0c\u5e76\u5c06\u5176\u4e2d\u7684\u90e8\u5206\u63d0\u793a\u4f4d\uff08\"\u8d5e\u52a9\u63d0\u793a\"\uff09\u5206\u914d\u7ed9\u5e7f\u544a\u5546\uff0c\u540c\u65f6\u7814\u7a76\u8fd9\u79cd\u65b0\u673a\u5236\u4e0e\u4f20\u7edf\u5e7f\u544a\u62cd\u5356\u7684\u4e92\u52a8\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u8bbe\u8ba1\u548c\u5206\u6790\u6b64\u7c7b\u4ea4\u4e92\u5f0f\u5e73\u53f0\u3002\u7814\u7a76\u4e86\u4e24\u79cd\u5de5\u7a0b\u9009\u62e9\uff1a\u4e00\u79cd\u662f\u8054\u5408\u4f18\u5316\u7528\u6237\u4ea4\u4e92\u548c\u6700\u7ec8\u5e7f\u544a\u62cd\u5356\u7684\u7aef\u5230\u7aef\u7ba1\u9053\uff1b\u53e6\u4e00\u79cd\u662f\u5c06\u63d0\u793a\u4f4d\u548c\u540e\u7eed\u5e7f\u544a\u4f4d\u673a\u5236\u5206\u5f00\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u53ef\u4ee5\u91c7\u7528VCG\u673a\u5236\u8054\u5408\u4f18\u5316\u8d5e\u52a9\u63d0\u793a\u548c\u540e\u7eed\u5e7f\u544a\uff0c\u867d\u7136\u590d\u6742\u4f46\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u771f\u5b9e\u7684\u5206\u914d\u3002\u800c\u7b80\u5355\u5b9e\u73b0\u7684\u6a21\u5757\u5316\u65b9\u6cd5\u5b58\u5728\u7b56\u7565\u6027\u4f4e\u6548\u95ee\u9898\uff0c\u5176\"\u65e0\u653f\u5e9c\u72b6\u6001\u4ef7\u683c\"\u65e0\u754c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u4e92\u5f0f\u5e73\u53f0\u673a\u5236\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8054\u5408\u4f18\u5316\u673a\u5236\u7684\u4f18\u52bf\uff0c\u5e76\u6307\u51fa\u6a21\u5757\u5316\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002"}}
{"id": "2512.03086", "categories": ["cs.PL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.03086", "abs": "https://arxiv.org/abs/2512.03086", "authors": ["Le Chen", "Nuo Xu", "Winson Chen", "Bin Lei", "Pei-Hung Lin", "Dunzhi Zhou", "Rajeev Thakur", "Caiwen Ding", "Ali Jannesari", "Chunhua Liao"], "title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation", "comment": null, "summary": "Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ccLLM\u95ee\u7b54\u8bbe\u8ba1\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Fortran\u548cCUDA\uff09\u7684\u4ee3\u7801\u7ffb\u8bd1\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u9886\u57df\uff08\u5982Fortran\u548cCUDA\uff09\u6027\u80fd\u4e0b\u964d\uff0c\u539f\u56e0\u662f\u9ad8\u8d28\u91cf\u5e76\u884c\u6570\u636e\u7a00\u7f3a\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u7ba1\u9053\uff0c\u8bbe\u8ba1\u4e86\u53ccLLM\u95ee\u7b54\u673a\u5236\uff08Questioner-Solver\uff09\uff0c\u5e76\u7ed3\u5408\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u53cd\u9988\u7684\u5916\u90e8\u77e5\u8bc6\uff0c\u751f\u6210\u5e26\u6709\u5355\u5143\u6d4b\u8bd5\u548c\u591a\u8f6e\u5bf9\u8bdd\u7684\u6570\u636e\u96c6\u3002", "result": "\u5728Fortran -> C++\u548cC++ -> CUDA\u4efb\u52a1\u4e2d\uff0c\u751f\u6210\u4e863.64k\u548c3.93k\u7684\u5bf9\u8bdd\u6570\u636e\uff0c\u5fae\u8c03\u540e\u529f\u80fd\u6b63\u786e\u6027\u63d0\u5347\u660e\u663e\uff0cC++-to-CUDA\u4efb\u52a1\u5355\u5143\u6d4b\u8bd5\u6210\u529f\u7387\u63d0\u9ad8\u4e8656\\%\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\uff0c\u8fd8\u4f7f7B\u5f00\u6e90\u6a21\u578b\u5728\u5173\u952e\u6307\u6807\uff08\u5982\u7f16\u8bd1\u6210\u529f\u7387\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u66f4\u5927\u7684\u4e13\u6709\u7cfb\u7edf\u3002"}}
{"id": "2512.03972", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.03972", "abs": "https://arxiv.org/abs/2512.03972", "authors": ["Hassan Arafat", "David Bremner", "Kenneth B. Kent", "Julian Wang"], "title": "OOPredictor: Predicting Object-Oriented Accesses using Static Analysis", "comment": null, "summary": "Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7f16\u8bd1\u65f6\u9759\u6001\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u4e2d\u6307\u9488\u8ffd\u8e2a\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4ee5\u51cf\u5c11\u7f13\u5b58\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u7684\u95f4\u63a5\u5bfb\u5740\u5bfc\u81f4\u6307\u9488\u8ffd\u8e2a\u9891\u7e41\uff0c\u5f71\u54cd\u4e86\u7f13\u5b58\u6027\u80fd\u4e14\u73b0\u4ee3\u786c\u4ef6\u9884\u53d6\u5668\u96be\u4ee5\u5904\u7406\u5176\u4e0d\u53ef\u9884\u6d4b\u6027\u3002\u73b0\u6709\u8f6f\u4ef6\u65b9\u6cd5\u591a\u4f9d\u8d56\u8fd0\u884c\u65f6\u5206\u6790\uff0c\u5f00\u9500\u8f83\u5927\u3002", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u9884\u6d4b\u7a0b\u5e8f\u7684\u5e38\u89c1\u8bbf\u95ee\u6a21\u5f0f\uff0c\u5e76\u5728OpenJ9 JVM\u4e2d\u5b9e\u73b0\u539f\u578b\u3002\u8f93\u51fa\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u62df\u7a0b\u5e8f\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u9884\u6d4b\u5668\u51c6\u786e\u6027\u9ad8\uff0c\u53ef\u7528\u4e8e\u6307\u5bfc\u6700\u5c0f\u4fb5\u5165\u6027\u7684\u8d1f\u8f7d\u505c\u987f\u7f13\u89e3\u7b56\u7565\uff0c\u5982\u4f18\u5316\u5783\u573e\u56de\u6536\u7684\u590d\u5236\u987a\u5e8f\u3002", "conclusion": "\u63d0\u51fa\u7684\u9759\u6001\u5206\u6790\u65b9\u6cd5\u80fd\u6709\u6548\u9884\u6d4b\u6307\u9488\u8ffd\u8e2a\u6a21\u5f0f\uff0c\u4e3a\u4f18\u5316\u7f13\u5b58\u6027\u80fd\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u5f00\u9500\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
