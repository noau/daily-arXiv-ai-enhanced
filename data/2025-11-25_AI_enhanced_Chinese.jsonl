{"id": "2511.17733", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17733", "abs": "https://arxiv.org/abs/2511.17733", "authors": ["Tristan Mott", "Caleb Bradshaw", "David Grimsman", "Christopher Archibald"], "title": "The Impacts of Increasingly Complex Matchup Models on Baseball Win Probability", "comment": "Undergraduate Honors Thesis, Brigham Young University", "summary": "Baseball is a game of strategic decisions including bullpen usage, pinch-hitting and intentional walks. Managers must adjust their strategies based on the changing state of the game in order to give their team the best chance of winning. In this thesis, we investigate how matchup models -- tools that predict the probabilities of plate appearance outcomes -- impact in-game strategy and ultimately affect win probability. We develop four progressively complex, hierarchical Bayesian models that predict plate appearance outcomes by combining information from both pitchers and batters, their handedness, and recent data, along with base running probabilities calibrated to a player's base-stealing tendencies.\n  Using each model within a game-theoretic framework, we approximate subgame perfect Nash equilibria for in-game decisions, including substitutions and intentional walks. Simulations of the 2024 MLB postseason show that more accurate matchup models can yield tangible gains in win probability -- as much as one additional victory per 162-game season. Furthermore, employing the most detailed model to generate win predictions for actual playoff games demonstrates alignment with market expectations, underscoring both the power and potential of advanced matchup modeling for on-field strategy and prediction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u68d2\u7403\u6bd4\u8d5b\u4e2d\u57fa\u4e8e\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u7684\u5339\u914d\u5de5\u5177\u5982\u4f55\u901a\u8fc7\u9884\u6d4b\u6295\u6253\u7ed3\u679c\u5f71\u54cd\u6bd4\u8d5b\u7b56\u7565\u548c\u80dc\u7387\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u68d2\u7403\u6bd4\u8d5b\u4e2d\u7684\u6218\u7565\u51b3\u7b56\uff08\u5982\u6295\u624b\u8c03\u5ea6\u3001\u4ee3\u6253\u548c\u6545\u610f\u4fdd\u9001\uff09\u9700\u8981\u6839\u636e\u6bd4\u8d5b\u72b6\u6001\u52a8\u6001\u8c03\u6574\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5148\u8fdb\u7684\u5339\u914d\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u9884\u6d4b\u6295\u6253\u7ed3\u679c\u7684\u6982\u7387\u6765\u4f18\u5316\u7b56\u7565\uff0c\u63d0\u9ad8\u80dc\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u56db\u4e2a\u9010\u6b65\u590d\u6742\u7684\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\uff0c\u7ed3\u5408\u6295\u624b\u548c\u6253\u8005\u7684\u4fe1\u606f\u3001\u60ef\u7528\u624b\u3001\u8fd1\u671f\u6570\u636e\u4ee5\u53ca\u57fa\u4e8e\u5077\u5792\u503e\u5411\u7684\u8dd1\u5792\u6982\u7387\uff0c\u9884\u6d4b\u6295\u6253\u7ed3\u679c\u3002\u968f\u540e\u5728\u535a\u5f08\u8bba\u6846\u67b6\u4e0b\u8fd1\u4f3c\u5b50\u535a\u5f08\u5b8c\u7f8e\u7eb3\u4ec0\u5747\u8861\uff0c\u7528\u4e8e\u6a21\u62df\u6bd4\u8d5b\u4e2d\u7684\u51b3\u7b56\u3002", "result": "\u6a21\u62df2024\u5e74MLB\u5b63\u540e\u8d5b\u8868\u660e\uff0c\u66f4\u51c6\u786e\u7684\u5339\u914d\u6a21\u578b\u80fd\u4e3a\u7403\u961f\u5e26\u6765\u663e\u8457\u7684\u80dc\u7387\u63d0\u5347\uff0c\u76f8\u5f53\u4e8e\u6bcf162\u573a\u6bd4\u8d5b\u591a\u8d62\u4e00\u573a\u3002\u6b64\u5916\uff0c\u6700\u8be6\u7ec6\u6a21\u578b\u751f\u6210\u7684\u80dc\u7387\u9884\u6d4b\u4e0e\u5b9e\u9645\u5b63\u540e\u8d5b\u7684\u5e02\u573a\u9884\u671f\u4e00\u81f4\u3002", "conclusion": "\u9ad8\u7ea7\u5339\u914d\u6a21\u578b\u5728\u68d2\u7403\u6bd4\u8d5b\u7b56\u7565\u548c\u9884\u6d4b\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u80fd\u591f\u901a\u8fc7\u4f18\u5316\u51b3\u7b56\u63d0\u5347\u7403\u961f\u8868\u73b0\u5e76\u4e0e\u5b9e\u9645\u7ed3\u679c\u76f8\u5370\u8bc1\u3002"}}
{"id": "2511.18328", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.18328", "abs": "https://arxiv.org/abs/2511.18328", "authors": ["Akaki Mamageishvili", "Christoph Schlegel", "Ko Sunghun", "Jinsuk Park", "Ali Taslimi"], "title": "TimeBoost: Do Ahead-of-Time Auctions Work?", "comment": null, "summary": "We study the performance of the TimeBoost auction, by comparing cumulative fixed time markout of fast lane trades over the TimeBoost interval to bids for the fast lane. Such comparison allows us to assess how well bids predict future extracted value from the time advantage. The correlation between winning bids and markouts is weak across bidders, suggesting that bids are a noisy predictor of extracted value. The correlation slightly improves when comparing paid bids (the second highest bid) instead of winning bids to markouts, which we attribute to the fact that the auction is more of a common value type. In all settings, the relative order of the most frequent bidder performance remains the same, together with their absolute profits. Bids and markouts aggregated over long time intervals exhibit much higher correlation, indicating that bidders detect trends much better than identify when the high arbitrage value is exactly available. One possible explanation for this is the fact that the correlation between previous minute markouts and current minute bids is significant, suggesting that the previous minute markouts is used to predict the next minute value when bidding.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86TimeBoost\u62cd\u5356\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u6bd4\u8f83\u5feb\u8f66\u9053\u4ea4\u6613\u7684\u7d2f\u8ba1\u56fa\u5b9a\u65f6\u95f4\u6807\u8bb0\u4e0e\u5feb\u8f66\u9053\u7684\u51fa\u4ef7\uff0c\u8bc4\u4f30\u51fa\u4ef7\u5bf9\u672a\u6765\u63d0\u53d6\u4ef7\u503c\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u901a\u8fc7\u5206\u6790TimeBoost\u62cd\u5356\u7684\u51fa\u4ef7\u4e0e\u6807\u8bb0\u503c\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u8bc4\u4f30\u51fa\u4ef7\u662f\u5426\u80fd\u6709\u6548\u9884\u6d4b\u672a\u6765\u63d0\u53d6\u7684\u4ef7\u503c\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u6bd4\u8f83\u5feb\u8f66\u9053\u4ea4\u6613\u7684\u7d2f\u8ba1\u6807\u8bb0\u503c\u4e0e\u51fa\u4ef7\uff0c\u5206\u6790\u4e0d\u540c\u51fa\u4ef7\u7c7b\u578b\uff08\u5982\u6700\u9ad8\u51fa\u4ef7\u548c\u7b2c\u4e8c\u9ad8\u51fa\u4ef7\uff09\u4e0e\u6807\u8bb0\u503c\u7684\u76f8\u5173\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u51fa\u4ef7\u4e0e\u6807\u8bb0\u503c\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u8868\u660e\u51fa\u4ef7\u5bf9\u63d0\u53d6\u4ef7\u503c\u7684\u9884\u6d4b\u8f83\u4e3a\u6a21\u7cca\uff1b\u800c\u5728\u957f\u65f6\u95f4\u533a\u95f4\u5185\u805a\u5408\u7684\u51fa\u4ef7\u548c\u6807\u8bb0\u503c\u76f8\u5173\u6027\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\uff0c\u5c3d\u7ba1\u51fa\u4ef7\u4e0e\u6807\u8bb0\u503c\u7684\u77ed\u671f\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u4f46\u957f\u671f\u76f8\u5173\u6027\u8f83\u5f3a\uff0c\u8868\u660e\u6295\u6807\u8005\u66f4\u64c5\u957f\u68c0\u6d4b\u8d8b\u52bf\u800c\u975e\u7cbe\u786e\u8bc6\u522b\u9ad8\u5957\u5229\u4ef7\u503c\u65f6\u673a\u3002"}}
{"id": "2511.18418", "categories": ["cs.GT", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.18418", "abs": "https://arxiv.org/abs/2511.18418", "authors": ["Georgios C. Chasparis"], "title": "Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part B: Stochastic Stability in Weakly Acyclic Games", "comment": null, "summary": "Reinforcement-based learning dynamics may exhibit several limitations when applied in a distributed setup. In (repeatedly-played) multi-player/action strategic-form games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. Furthermore, strong convergence guarantees (i.e., almost sure convergence or weak convergence) are mostly restricted to two-player games. To address this main limitation of reinforcement-based learning in repeatedly-played strategic-form games, this paper introduces a novel payoff-based learning scheme for distributed optimization in multi-player/action strategic-form games. We present an extension of perturbed learning automata (PLA), namely aspiration-based perturbed learning automata (APLA), in which each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This paper is the second part of this study that analyzes stochastic stability in multi-player/action weakly-acyclic games in the presence of noisy observations. We provide conditions under which convergence is attained (in weak sense) to the set of pure Nash equilibria and payoff-dominant equilibria. To the best of our knowledge, this is the first reinforcement-based learning scheme that addresses convergence in weakly-acyclic games. Lastly, we provide a specialization of the results to the classical Stag-Hunt game, supported by a simulation study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6536\u76ca\u7684\u65b0\u578b\u5b66\u4e60\u65b9\u6848APLA\uff0c\u7528\u4e8e\u89e3\u51b3\u5206\u5e03\u5f0f\u591a\u73a9\u5bb6/\u52a8\u4f5c\u7b56\u7565\u6e38\u620f\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u566a\u58f0\u89c2\u6d4b\u4e0b\u5206\u6790\u4e86\u5176\u968f\u673a\u7a33\u5b9a\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5206\u5e03\u5f0f\u591a\u73a9\u5bb6/\u52a8\u4f5c\u7b56\u7565\u6e38\u620f\u4e2d\u5f3a\u5316\u5b66\u4e60\u65e0\u6cd5\u4fdd\u8bc1\u6536\u655b\u5230\u7eaf\u7eb3\u4ec0\u5747\u8861\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u566a\u58f0\u89c2\u6d4b\u73af\u5883\u4e0b\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u6ee1\u610f\u5ea6\u7684\u6270\u52a8\u5b66\u4e60\u81ea\u52a8\u5316\u5668\uff08APLA\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u91cd\u590d\u9009\u62e9\u548c\u6ee1\u610f\u5ea6\u56e0\u5b50\u6765\u5f3a\u5316\u73a9\u5bb6\u7684\u52a8\u4f5c\u9009\u62e9\u6982\u7387\u5206\u5e03\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cAPLA\u5728\u591a\u73a9\u5bb6\u6b63\u6548\u7528\u6e38\u620f\u548c\u5f31\u975e\u5faa\u73af\u6e38\u620f\u4e2d\uff0c\u80fd\u5728\u566a\u58f0\u89c2\u6d4b\u4e0b\u5f31\u6536\u655b\u5230\u7eaf\u7eb3\u4ec0\u5747\u8861\u548c\u6536\u76ca\u4e3b\u5bfc\u5747\u8861\u3002", "conclusion": "APLA\u662f\u9996\u4e2a\u5728\u5f31\u975e\u5faa\u73af\u6e38\u620f\u4e2d\u5b9e\u73b0\u6536\u655b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u7ecf\u5178Stag-Hunt\u6e38\u620f\u7684\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.17838", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.17838", "abs": "https://arxiv.org/abs/2511.17838", "authors": ["Jai Arora", "Sirui Lu", "Devansh Jain", "Tianfan Xu", "Farzin Houshmand", "Phitchaya Mangpo Phothilimthana", "Mohsen Lesani", "Praveen Narayanan", "Karthik Srinivasa Murthy", "Rastislav Bodik", "Amit Sabne", "Charith Mendis"], "title": "TensorRight: Automated Verification of Tensor Graph Rewrites", "comment": "61 pages, 13 figures, published in POPL 2025", "summary": "Tensor compilers, essential for generating efficient code for deep learning models across various applications, employ tensor graph rewrites as one of the key optimizations. These rewrites optimize tensor computational graphs with the expectation of preserving semantics for tensors of arbitrary rank and size. Despite this expectation, to the best of our knowledge, there does not exist a fully automated verification system to prove the soundness of these rewrites for tensors of arbitrary rank and size. Previous works, while successful in verifying rewrites with tensors of concrete rank, do not provide guarantees in the unbounded setting.\n  To fill this gap, we introduce TensorRight, the first automatic verification system that can verify tensor graph rewrites for input tensors of arbitrary rank and size. We introduce a core language, TensorRight DSL, to represent rewrite rules using a novel axis definition, called aggregated-axis, which allows us to reason about an unbounded number of axes. We achieve unbounded verification by proving that there exists a bound on tensor ranks, under which bounded verification of all instances implies the correctness of the rewrite rule in the unbounded setting. We derive an algorithm to compute this rank using the denotational semantics of TensorRight DSL. TensorRight employs this algorithm to generate a finite number of bounded-verification proof obligations, which are then dispatched to an SMT solver using symbolic execution to automatically verify the correctness of the rewrite rules. We evaluate TensorRight's verification capabilities by implementing rewrite rules present in XLA's algebraic simplifier. The results demonstrate that TensorRight can prove the correctness of 115 out of 175 rules in their full generality, while the closest automatic, bounded-verification system can express only 18 of these rules.", "AI": {"tldr": "TensorRight\u662f\u7b2c\u4e00\u4e2a\u80fd\u591f\u9a8c\u8bc1\u4efb\u610f\u79e9\u548c\u5927\u5c0f\u7684\u8f93\u5165\u5f20\u91cf\u7684\u5f20\u91cf\u56fe\u91cd\u5199\u7684\u81ea\u52a8\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u5b8c\u5168\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7684\u5f20\u91cf\u7f16\u8bd1\u5668\u7f3a\u4e4f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u65e0\u6cd5\u8bc1\u660e\u5f20\u91cf\u56fe\u91cd\u5199\u5728\u4efb\u610f\u79e9\u548c\u5927\u5c0f\u4e0b\u7684\u8bed\u4e49\u4fdd\u6301\u6027\u3002", "method": "TensorRight\u901a\u8fc7\u5f15\u5165TensorRight DSL\u6838\u5fc3\u8bed\u8a00\u548c\u805a\u5408\u8f74\u5b9a\u4e49\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65e0\u754c\u9650\u8f74\u6570\u7684\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u6709\u9650\u6570\u91cf\u7684\u6709\u754c\u9a8c\u8bc1\u8bc1\u660e\u4e49\u52a1\uff0c\u5229\u7528SMT\u6c42\u89e3\u5668\u81ea\u52a8\u9a8c\u8bc1\u91cd\u5199\u89c4\u5219\u7684\u6b63\u786e\u6027\u3002", "result": "TensorRight\u5728XLA\u4ee3\u6570\u7b80\u5316\u5668\u4e2d\u9a8c\u8bc1\u4e86175\u6761\u89c4\u5219\u4e2d\u7684115\u6761\uff0c\u800c\u73b0\u6709\u7684\u6709\u754c\u9a8c\u8bc1\u7cfb\u7edf\u53ea\u80fd\u8868\u8fbe\u5176\u4e2d\u768418\u6761\u3002", "conclusion": "TensorRight\u6210\u529f\u586b\u8865\u4e86\u81ea\u52a8\u9a8c\u8bc1\u65e0\u754c\u9650\u5f20\u91cf\u56fe\u91cd\u5199\u7684\u7a7a\u767d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u80fd\u529b\u548c\u6548\u7387\u3002"}}
{"id": "2511.18658", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.18658", "abs": "https://arxiv.org/abs/2511.18658", "authors": ["Karolina Drabent", "Ond\u0159ej Kub\u00ed\u010dek", "Viliam Lis\u00fd"], "title": "Understanding Optimal Portfolios of Strategies for Solving Two-player Zero-sum Games", "comment": null, "summary": "In large-scale games, approximating the opponent's strategy space with a small portfolio of representative strategies is a common and powerful technique. However, the construction of these portfolios often relies on domain-specific knowledge or heuristics with no theoretical guarantees. This paper establishes a formal foundation for portfolio-based strategy approximation. We define the problem of finding an optimal portfolio in two-player zero-sum games and prove that this optimization problem is NP-hard. We demonstrate that several intuitive heuristics-such as using the support of a Nash Equilibrium or building portfolios incrementally - can lead to highly suboptimal solutions. These negative results underscore the problem's difficulty and motivate the need for robust, empirically-validated heuristics. To this end, we introduce an analytical framework to bound portfolio quality and propose a methodology for evaluating heuristic approaches. Our evaluation of several heuristics shows that their success heavily depends on the specific game being solved. Our code is publicly available.", "AI": {"tldr": "\u672c\u6587\u4e3a\u57fa\u4e8e\u7ec4\u5408\u7684\u7b56\u7565\u8fd1\u4f3c\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5728\u96f6\u548c\u53cc\u4eba\u6e38\u620f\u4e2d\u5bfb\u627e\u6700\u4f18\u7ec4\u5408\u7684\u95ee\u9898\u662fNP\u96be\u7684\uff0c\u5e76\u5c55\u793a\u4e86\u76f4\u89c9\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u6e38\u620f\u4e2d\uff0c\u7528\u5c0f\u90e8\u5206\u4ee3\u8868\u6027\u7b56\u7565\u903c\u8fd1\u5bf9\u624b\u7684\u7b56\u7565\u7a7a\u95f4\u662f\u5e38\u89c1\u4e14\u5f3a\u5927\u7684\u6280\u672f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u57fa\u7840\u548c\u5206\u6790\u6846\u67b6\u3002", "method": "\u5b9a\u4e49\u4e86\u5728\u53cc\u4eba\u96f6\u548c\u6e38\u620f\u4e2d\u5bfb\u627e\u6700\u4f18\u7ec4\u5408\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5176NP\u96be\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u6846\u67b6\u548c\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u76f4\u89c9\u542f\u53d1\u5f0f\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u9ad8\u5ea6\u6b21\u4f18\u89e3\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6210\u529f\u4e0e\u5426\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5177\u4f53\u6e38\u620f\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u95ee\u9898\u7684\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.18209", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2511.18209", "abs": "https://arxiv.org/abs/2511.18209", "authors": ["Yi-Yang Zhang", "Tengjiao Sun", "Pengcheng Fang", "Deng-Bao Wang", "Xiaohao Cai", "Min-Ling Zhang", "Hansung Kim"], "title": "MotionDuet: Dual-Conditioned 3D Human Motion Generation with Video-Regularized Text Learning", "comment": null, "summary": "3D Human motion generation is pivotal across film, animation, gaming, and embodied intelligence. Traditional 3D motion synthesis relies on costly motion capture, while recent work shows that 2D videos provide rich, temporally coherent observations of human behavior. Existing approaches, however, either map high-level text descriptions to motion or rely solely on video conditioning, leaving a gap between generated dynamics and real-world motion statistics. We introduce MotionDuet, a multimodal framework that aligns motion generation with the distribution of video-derived representations. In this dual-conditioning paradigm, video cues extracted from a pretrained model (e.g., VideoMAE) ground low-level motion dynamics, while textual prompts provide semantic intent. To bridge the distribution gap across modalities, we propose Dual-stream Unified Encoding and Transformation (DUET) and a Distribution-Aware Structural Harmonization (DASH) loss. DUET fuses video-informed cues into the motion latent space via unified encoding and dynamic attention, while DASH aligns motion trajectories with both distributional and structural statistics of video features. An auto-guidance mechanism further balances textual and visual signals by leveraging a weakened copy of the model, enhancing controllability without sacrificing diversity. Extensive experiments demonstrate that MotionDuet generates realistic and controllable human motions, surpassing strong state-of-the-art baselines.", "AI": {"tldr": "MotionDuet\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6761\u4ef6\u8303\u5f0f\uff08\u89c6\u9891\u548c\u6587\u672c\uff09\u751f\u6210\u903c\u771f\u4e14\u53ef\u63a7\u76843D\u4eba\u4f53\u52a8\u4f5c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u52a8\u4f5c\u751f\u6210\u4e0e\u771f\u5b9e\u4e16\u754c\u52a8\u4f5c\u7edf\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "3D\u4eba\u4f53\u52a8\u4f5c\u751f\u6210\u5728\u5f71\u89c6\u3001\u52a8\u753b\u3001\u6e38\u620f\u548c\u5177\u8eab\u667a\u80fd\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u52a8\u4f5c\u6355\u6349\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u6587\u672c\u63cf\u8ff0\u4e0e\u89c6\u9891\u6761\u4ef6\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u52a8\u4f5c\u4e0e\u771f\u5b9e\u7edf\u8ba1\u4e0d\u7b26\u3002", "method": "MotionDuet\u901a\u8fc7\u53cc\u6761\u4ef6\u8303\u5f0f\uff08\u89c6\u9891\u548c\u6587\u672c\uff09\u751f\u6210\u52a8\u4f5c\uff0c\u63d0\u51fa\u4e86DUET\uff08\u53cc\u91cd\u6d41\u7edf\u4e00\u7f16\u7801\u4e0e\u8f6c\u6362\uff09\u548cDASH\uff08\u5206\u5e03\u611f\u77e5\u7ed3\u6784\u534f\u8c03\u635f\u5931\uff09\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5f15\u5bfc\u673a\u5236\u5e73\u8861\u6587\u672c\u4e0e\u89c6\u89c9\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMotionDuet\u751f\u6210\u76843D\u4eba\u4f53\u52a8\u4f5c\u903c\u771f\u4e14\u53ef\u63a7\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u3002", "conclusion": "MotionDuet\u901a\u8fc7\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u635f\u5931\u4f18\u5316\uff0c\u6210\u529f\u586b\u8865\u4e86\u52a8\u4f5c\u751f\u6210\u4e0e\u771f\u5b9e\u7edf\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a3D\u52a8\u4f5c\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19225", "categories": ["cs.GT", "cs.DS", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.19225", "abs": "https://arxiv.org/abs/2511.19225", "authors": ["Jordana Blazek", "Frederick C. Harris"], "title": "Bipartiteness in Progressive Second-Price Multi-Auction Networks with Perfect Substitute", "comment": null, "summary": "We consider a bipartite network of buyers and sellers, where the sellers run locally independent Progressive Second-Price (PSP) auctions, and buyers may participate in multiple auctions, forming a multi-auction market with perfect substitute. The paper develops a projection-based influence framework for decentralized PSP auctions. We formalize primary and expanded influence sets using projections on the active bid index set and show how partial orders on bid prices govern allocation, market shifts, and the emergence of saturated one-hop shells. Our results highlight the robustness of PSP auctions in decentralized environments by introducing saturated components and a structured framework for phase transitions in multi-auction dynamics. This structure ensures deterministic coverage of the strategy space, enabling stable and truthful embedding in the larger game. We further model intra-round dynamics using an index to capture coordinated asynchronous seller updates coupled through buyers' joint constraints. Together, these constructions explain how local interactions propagate across auctions and gives premise for coherent equilibria--without requiring global information or centralized control.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e70\u65b9\u548c\u5356\u65b9\u7ec4\u6210\u7684\u4e8c\u5206\u7f51\u7edc\u4e2d\u7684\u6e10\u8fdb\u7b2c\u4e8c\u4ef7\u683c\uff08PSP\uff09\u62cd\u5356\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6295\u5f71\u7684\u5f71\u54cd\u529b\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5206\u6563\u5f0fPSP\u62cd\u5356\u7684\u52a8\u6001\u548c\u5747\u8861\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u5206\u6563\u5f0f\u62cd\u5356\u73af\u5883\u4e2d\u4e70\u65b9\u53c2\u4e0e\u591a\u4e2a\u62cd\u5356\u65f6\u7684\u52a8\u6001\u884c\u4e3a\u53ca\u5747\u8861\u95ee\u9898\uff0c\u586b\u8865\u4e86\u591a\u62cd\u5356\u5e02\u573a\u52a8\u6001\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6295\u5f71\u7684\u5f71\u54cd\u529b\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u4e3b\u8981\u548c\u6269\u5c55\u5f71\u54cd\u529b\u96c6\uff0c\u5e76\u5229\u7528\u6807\u4e66\u4ef7\u683c\u7684\u90e8\u5206\u5e8f\u6765\u7814\u7a76\u5206\u914d\u3001\u5e02\u573a\u53d8\u5316\u53ca\u9971\u548c\u5355\u8df3\u58f3\u7684\u51fa\u73b0\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u7d22\u5f15\u6a21\u578b\u6355\u6349\u5356\u65b9\u5f02\u6b65\u66f4\u65b0\u7684\u534f\u540c\u6548\u5e94\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cPSP\u62cd\u5356\u5728\u5206\u6563\u5f0f\u73af\u5883\u4e2d\u5177\u6709\u9c81\u68d2\u6027\uff0c\u9971\u548c\u7ec4\u4ef6\u548c\u591a\u62cd\u5356\u52a8\u6001\u7684\u76f8\u4f4d\u8f6c\u6362\u7ed3\u6784\u786e\u4fdd\u4e86\u7b56\u7565\u7a7a\u95f4\u7684\u786e\u5b9a\u6027\u8986\u76d6\uff0c\u4e3a\u7a33\u5b9a\u548c\u771f\u5b9e\u7684\u5747\u8861\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u7684\u7ed3\u8bba\u662f\uff0c\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u5728\u591a\u62cd\u5356\u95f4\u4f20\u64ad\u7684\u673a\u5236\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5168\u5c40\u4fe1\u606f\u6216\u96c6\u4e2d\u63a7\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e00\u81f4\u7684\u5747\u8861\u72b6\u6001\uff0c\u4e3a\u5206\u6563\u5f0f\u62cd\u5356\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2511.18241", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2511.18241", "abs": "https://arxiv.org/abs/2511.18241", "authors": ["Shixun Huang", "Eitan Grinspun", "Yue Chang"], "title": "A Convex-Inspired Neural Construction for Structured and Generalizable Nonlinear Model Reduction", "comment": null, "summary": "Real-time simulation of deformable objects relies on model reduction to achieve interactive performance while maintaining physical fidelity. Traditional linear methods, such as principal component analysis (PCA), provide structured and predictable behavior thanks to their linear formulation, but are limited in expressiveness. Nonlinear model reduction, typically implemented with neural networks, offers richer representations and higher compression; however, without structural constraints, the learned mappings often fail to generalize beyond the training distribution, leading to unstable or implausible deformations. We present a symmetric, convex-inspired neural formulation that bridges the gap between linear and nonlinear model reduction. Our approach adopts an input-convex neural network (ICNN) augmented with symmetry constraints to impose structure on the nonlinear decoder. This design retains the flexibility of neural mappings while embedding physical consistency, yielding coherent and stable displacements even under unseen conditions. We evaluate our method on challenging deformation scenarios involving forces of different magnitudes, inverse directions, and sparsely sampled training data. Our approach demonstrates superior generalization while maintaining compact reduced spaces, and supports real-time interactive applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u7684\u5bf9\u79f0\u51f8\u795e\u7ecf\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u6a21\u62df\u53ef\u53d8\u5f62\u7269\u4f53\uff0c\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u7ebf\u6027\u65b9\u6cd5\uff08\u5982PCA\uff09\u867d\u7ed3\u6784\u6e05\u6670\u4f46\u8868\u8fbe\u80fd\u529b\u6709\u9650\uff0c\u800c\u975e\u7ebf\u6027\u65b9\u6cd5\uff08\u5982\u795e\u7ecf\u7f51\u7edc\uff09\u867d\u538b\u7f29\u7387\u9ad8\u4f46\u7f3a\u4e4f\u7ed3\u6784\u7ea6\u675f\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u91c7\u7528\u5bf9\u79f0\u51f8\u795e\u7ecf\u7f51\u7edc\uff08ICNN\uff09\u589e\u5f3a\u975e\u7ebf\u6027\u89e3\u7801\u5668\u7684\u7ed3\u6784\u7ea6\u675f\uff0c\u7ed3\u5408\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u7075\u6d3b\u4e14\u7a33\u5b9a\u7684\u4f4d\u79fb\u6a21\u62df\u3002", "result": "\u5728\u591a\u79cd\u6311\u6218\u6027\u53d8\u5f62\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u5b9e\u65f6\u4ea4\u4e92\u4e14\u4fdd\u6301\u7d27\u51d1\u7684\u964d\u7ef4\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u586b\u8865\u4e86\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u964d\u7ef4\u7684\u9e3f\u6c9f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7269\u7406\u4e00\u81f4\u7684\u5b9e\u65f6\u6a21\u62df\u3002"}}
{"id": "2511.19307", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19307", "abs": "https://arxiv.org/abs/2511.19307", "authors": ["Michail Fasoulakis", "Leonidas Bakopoulos", "Charilaos Akasiadis", "Georgios Chalkiadakis"], "title": "On Altruism and Spite in Bimatrix Games", "comment": null, "summary": "One common assumption in game theory is that any player optimizes a utility function that takes into account only its own payoff. However, it has long been observed that in real life players may adopt an altruistic or even spiteful behaviour. As such, there are numerous attempts in the economics literature that strive to explain the fact that players are not entirely selfish, but most of these works do not focus on the algorithmic implications of altruism or spite in games. In this paper, we relax the aforementioned ``self-interest'' assumption, and initiate the study of algorithmic aspects of bimatrix games -- such as the complexity and the quality of their (approximate) Nash equilibria -- under altruism or spite. We provide both a theoretical and an experimental treatment of these topics. Moreover, we demonstrate the potential for learning the degree of an opponent's altruistic/spiteful behaviour, and employing this for opponent selection and transfer of knowledge in bimatrix games.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u5143\u77e9\u9635\u535a\u5f08\u4e2d\u7b97\u6cd5\u5c42\u9762\u7684\u5229\u4ed6\u6216\u6076\u610f\u884c\u4e3a\uff0c\u63a2\u8ba8\u4e86\u5176\u590d\u6742\u6027\u548c\u8fd1\u4f3c\u7eb3\u4ec0\u5747\u8861\u7684\u8d28\u91cf\uff0c\u5e76\u7ed3\u5408\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5c55\u793a\u4e86\u5b66\u4e60\u5bf9\u624b\u884c\u4e3a\u7a0b\u5ea6\u7684\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u535a\u5f08\u8bba\u5047\u8bbe\u73a9\u5bb6\u4ec5\u4f18\u5316\u81ea\u8eab\u6536\u76ca\uff0c\u4f46\u73b0\u5b9e\u4e2d\u73a9\u5bb6\u53ef\u80fd\u8868\u73b0\u51fa\u5229\u4ed6\u6216\u6076\u610f\u884c\u4e3a\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u7ecf\u6d4e\u5b66\u6587\u732e\u4e2d\u5173\u4e8e\u8fd9\u4e9b\u884c\u4e3a\u5bf9\u7b97\u6cd5\u5f71\u54cd\u7684\u7a7a\u767d\u3002", "method": "\u672c\u6587\u653e\u5bbd\u4e86\u201c\u81ea\u5229\u201d\u5047\u8bbe\uff0c\u7814\u7a76\u4e86\u4e8c\u5143\u77e9\u9635\u535a\u5f08\u4e2d\u5229\u4ed6\u6216\u6076\u610f\u884c\u4e3a\u7684\u7b97\u6cd5\u5c42\u9762\u95ee\u9898\uff0c\u5305\u62ec\u590d\u6742\u6027\u5206\u6790\u548c\u8fd1\u4f3c\u7eb3\u4ec0\u5747\u8861\u8d28\u91cf\u8bc4\u4f30\u3002\u540c\u65f6\u8fdb\u884c\u4e86\u7406\u8bba\u548c\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5229\u4ed6\u6216\u6076\u610f\u884c\u4e3a\u5bf9\u535a\u5f08\u7684\u590d\u6742\u6027\u548c\u5747\u8861\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u901a\u8fc7\u5b66\u4e60\u5bf9\u624b\u884c\u4e3a\u7a0b\u5ea6\u8fdb\u884c\u5bf9\u624b\u9009\u62e9\u548c\u77e5\u8bc6\u8f6c\u79fb\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e8c\u5143\u77e9\u9635\u535a\u5f08\u4e2d\u975e\u81ea\u5229\u884c\u4e3a\u7684\u7b97\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u884c\u4e3a\u5bf9\u535a\u5f08\u52a8\u6001\u7684\u6df1\u8fdc\u5f71\u54cd\u3002"}}
{"id": "2511.18680", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18680", "abs": "https://arxiv.org/abs/2511.18680", "authors": ["Xiang Gao", "Xinmu Wang", "Xiaolong Wu", "Jiazhi Li", "Jingyu Shi", "Yu Guo", "Yuanpeng Liu", "Xiyun Song", "Heather Yu", "Zongfang Lin", "Xianfeng David Gu"], "title": "Inverse Rendering for High-Genus Surface Meshes from Multi-View Images", "comment": "3DV2026 Accepted (Poster)", "summary": "We present a topology-informed inverse rendering approach for reconstructing high-genus surface meshes from multi-view images. Compared to 3D representations like voxels and point clouds, mesh-based representations are preferred as they enable the application of differential geometry theory and are optimized for modern graphics pipelines. However, existing inverse rendering methods often fail catastrophically on high-genus surfaces, leading to the loss of key topological features, and tend to oversmooth low-genus surfaces, resulting in the loss of surface details. This failure stems from their overreliance on Adam-based optimizers, which can lead to vanishing and exploding gradients. To overcome these challenges, we introduce an adaptive V-cycle remeshing scheme in conjunction with a re-parametrized Adam optimizer to enhance topological and geometric awareness. By periodically coarsening and refining the deforming mesh, our method informs mesh vertices of their current topology and geometry before optimization, mitigating gradient issues while preserving essential topological features. Additionally, we enforce topological consistency by constructing topological primitives with genus numbers that match those of ground truth using Gauss-Bonnet theorem. Experimental results demonstrate that our inverse rendering approach outperforms the current state-of-the-art method, achieving significant improvements in Chamfer Distance and Volume IoU, particularly for high-genus surfaces, while also enhancing surface details for low-genus surfaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u4fe1\u606f\u7684\u9006\u5411\u6e32\u67d3\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u591a\u89c6\u56fe\u56fe\u50cf\u4e2d\u91cd\u5efa\u9ad8\u4e8f\u683c\u8868\u9762\u7f51\u683c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u4e8f\u683c\u8868\u9762\u4e0a\u4e22\u5931\u5173\u952e\u62d3\u6251\u7279\u5f81\u548c\u4f4e\u4e8f\u683c\u8868\u9762\u8fc7\u5ea6\u5e73\u6ed1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u9006\u5411\u6e32\u67d3\u65b9\u6cd5\u5728\u9ad8\u4e8f\u683c\u8868\u9762\u4e0a\u5f80\u5f80\u5931\u8d25\uff0c\u5bfc\u81f4\u5173\u952e\u62d3\u6251\u7279\u5f81\u4e22\u5931\uff0c\u800c\u5728\u4f4e\u4e8f\u683c\u8868\u9762\u4e0a\u8fc7\u5ea6\u5e73\u6ed1\uff0c\u4e22\u5931\u7ec6\u8282\u3002\u4e3b\u8981\u539f\u56e0\u662f\u8fc7\u5ea6\u4f9d\u8d56Adam\u4f18\u5316\u5668\uff0c\u5bfc\u81f4\u68af\u5ea6\u6d88\u5931\u6216\u7206\u70b8\u3002", "method": "\u5f15\u5165\u4e86\u81ea\u9002\u5e94V\u5faa\u73af\u91cd\u65b0\u7f51\u683c\u5316\u65b9\u6848\u548c\u91cd\u65b0\u53c2\u6570\u5316\u7684Adam\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5468\u671f\u6027\u7c97\u5316\u548c\u7ec6\u5316\u53d8\u5f62\u7f51\u683c\uff0c\u4f18\u5316\u524d\u544a\u77e5\u9876\u70b9\u5f53\u524d\u62d3\u6251\u548c\u51e0\u4f55\u4fe1\u606f\u3002\u8fd8\u5229\u7528Gauss-Bonnet\u5b9a\u7406\u6784\u5efa\u62d3\u6251\u57fa\u5143\u4ee5\u4fdd\u6301\u62d3\u6251\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u4e8f\u683c\u8868\u9762\u4e0a\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86Chamfer Distance\u548cVolume IoU\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u4f4e\u4e8f\u683c\u8868\u9762\u7684\u7ec6\u8282\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94V\u5faa\u73af\u7f51\u683c\u5316\u548c\u4f18\u5316\u5668\u6539\u8fdb\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u4e8f\u683c\u548c\u4f4e\u4e8f\u683c\u8868\u9762\u7684\u9006\u5411\u6e32\u67d3\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u62d3\u6251\u548c\u51e0\u4f55\u7ec6\u8282\u7684\u4fdd\u6301\u80fd\u529b\u3002"}}
{"id": "2511.19346", "categories": ["cs.GT", "math.DS", "math.SP"], "pdf": "https://arxiv.org/pdf/2511.19346", "abs": "https://arxiv.org/abs/2511.19346", "authors": ["Pablo Lechon-Alonso", "Andrew Dennehy", "Ruizheng Bai", "Nicolas Sanchez", "Derek K. Wise", "David Sewell", "David Rosenbluth", "Alexander Strang"], "title": "Disc Game Dynamics: A Latent Space Perspective on Selection and Learning in Games", "comment": null, "summary": "Evolutionary game theory studies populations that change in response to an underlying game. Often, the functional form relating outcome to player attributes or strategy is complex, preventing mathematical progress. In this work, we axiomatically derive a latent space representation for pairwise, symmetric, zero-sum games by seeking a coordinate space in which the optimal training direction for an agent responding to an opponent depends only on their opponent's coordinates. The associated embedding represents the original game as a linear combination of copies of a simple game, the disc game, in a new coordinate space. In this article, we show that disc-game embedding is useful for studying learning dynamics. We demonstrate that a series of classical evolutionary processes simplify to constrained oscillator equations in the latent space. In particular, the continuous replicator equation reduces to a Hamiltonian system of coupled oscillators that exhibit Poincar\u00e9 recurrence. This reduction allows exact, finite-dimensional closure when the underlying game is finite-rank, and optimal approximation otherwise. It also establishes an exact equivalence between the continuous replicator equation and adaptive dynamics in the transformed coordinates. By identifying a minimal rank representation, the disc game embedding offers numerical methods that could decouple the cost of simulation from the number of attributes used to define agents. These results generalize to metapopulation models that mix inhomogeneously, and to any time-differentiable dynamic where the rate of growth of a type, relative to its expected payout, is a nonnegative function of its frequency. We recommend disc-game embedding as an organizing paradigm for learning and selection in response to symmetric two-player zero-sum games.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6f5c\u7a7a\u95f4\u8868\u793a\u7b80\u5316\u4e86\u5bf9\u79f0\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u7684\u7814\u7a76\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u7ebf\u6027\u7ec4\u5408\u7684\u76d8\u6e38\u620f\u3002\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u548c\u8fdb\u5316\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b66\u5de5\u5177\u3002", "motivation": "\u5728\u8fdb\u5316\u535a\u5f08\u8bba\u4e2d\uff0c\u6e38\u620f\u7ed3\u679c\u4e0e\u73a9\u5bb6\u5c5e\u6027\u6216\u7b56\u7565\u4e4b\u95f4\u7684\u5173\u7cfb\u901a\u5e38\u590d\u6742\uff0c\u96be\u4ee5\u8fdb\u884c\u6570\u5b66\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6f5c\u7a7a\u95f4\u8868\u793a\u7b80\u5316\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u672c\u6587\u516c\u7406\u5316\u5730\u63a8\u5bfc\u4e86\u4e00\u79cd\u6f5c\u7a7a\u95f4\u8868\u793a\uff0c\u5c06\u5bf9\u79f0\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u8f6c\u5316\u4e3a\u76d8\u6e38\u620f\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5e76\u5728\u65b0\u5750\u6807\u7a7a\u95f4\u4e2d\u7814\u7a76\u4e86\u5b66\u4e60\u548c\u8fdb\u5316\u52a8\u529b\u5b66\u7684\u7b80\u5316\u5f62\u5f0f\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u6f5c\u7a7a\u95f4\u4e2d\u7684\u8fdb\u5316\u8fc7\u7a0b\u53ef\u7b80\u5316\u4e3a\u7ea6\u675f\u7684\u632f\u8361\u65b9\u7a0b\u3002\u7279\u522b\u662f\u8fde\u7eed\u590d\u5236\u52a8\u529b\u5b66\u5728\u6f5c\u7a7a\u95f4\u4e2d\u8868\u73b0\u4e3a\u54c8\u5bc6\u987f\u7cfb\u7edf\u7684\u8026\u5408\u632f\u8361\u5668\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u63d0\u4f9b\u4e86\u6570\u503c\u6a21\u62df\u7684\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "\u76d8\u6e38\u620f\u5d4c\u5165\u4e3a\u5bf9\u79f0\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u7684\u5b66\u4e60\u548c\u9009\u62e9\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u8303\u5f0f\uff0c\u9002\u7528\u4e8e\u975e\u5747\u5300\u6df7\u5408\u7684\u7fa4\u4f53\u6a21\u578b\u548c\u5176\u4ed6\u65f6\u95f4\u53ef\u5fae\u7684\u52a8\u6001\u7cfb\u7edf\u3002"}}
{"id": "2511.18794", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18794", "abs": "https://arxiv.org/abs/2511.18794", "authors": ["Zhongtao Wang", "Jiaqi Dai", "Qingtian Zhu", "Yilong Li", "Mai Su", "Fei Zhu", "Meng Gai", "Shaorong Wang", "Chengwei Pan", "Yisong Chen", "Guoping Wang"], "title": "ChronoGS: Disentangling Invariants and Changes in Multi-Period Scenes", "comment": null, "summary": "Multi-period image collections are common in real-world applications. Cities are re-scanned for mapping, construction sites are revisited for progress tracking, and natural regions are monitored for environmental change. Such data form multi-period scenes, where geometry and appearance evolve. Reconstructing such scenes is an important yet underexplored problem. Existing pipelines rely on incompatible assumptions: static and in-the-wild methods enforce a single geometry, while dynamic ones assume smooth motion, both failing under long-term, discontinuous changes. To solve this problem, we introduce ChronoGS, a temporally modulated Gaussian representation that reconstructs all periods within a unified anchor scaffold. It's also designed to disentangle stable and evolving components, achieving temporally consistent reconstruction of multi-period scenes. To catalyze relevant research, we release ChronoScene dataset, a benchmark of real and synthetic multi-period scenes, capturing geometric and appearance variation. Experiments demonstrate that ChronoGS consistently outperforms baselines in reconstruction quality and temporal consistency. Our code and the ChronoScene dataset are publicly available at https://github.com/ZhongtaoWang/ChronoGS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ChronoGS\uff0c\u4e00\u79cd\u65f6\u95f4\u8c03\u5236\u7684\u9ad8\u65af\u8868\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cd\u5efa\u591a\u65f6\u671f\u573a\u666f\u4e2d\u7684\u51e0\u4f55\u548c\u5916\u89c2\u53d8\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u957f\u671f\u3001\u4e0d\u8fde\u7eed\u53d8\u5316\u4e0b\u7684\u4e0d\u8db3\u3002", "motivation": "\u591a\u65f6\u671f\u56fe\u50cf\u96c6\u5408\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u957f\u671f\u3001\u4e0d\u8fde\u7eed\u7684\u51e0\u4f55\u548c\u5916\u89c2\u53d8\u5316\u3002", "method": "ChronoGS\u91c7\u7528\u65f6\u95f4\u8c03\u5236\u7684\u9ad8\u65af\u8868\u793a\u65b9\u6cd5\uff0c\u5728\u7edf\u4e00\u7684\u951a\u652f\u67b6\u4e2d\u91cd\u5efa\u6240\u6709\u65f6\u671f\uff0c\u5e76\u5206\u79bb\u7a33\u5b9a\u548c\u53d8\u5316\u7684\u7ec4\u4ef6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cChronoGS\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ChronoGS\u5728\u591a\u65f6\u671f\u573a\u666f\u91cd\u5efa\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6ChronoScene\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.19358", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2511.19358", "abs": "https://arxiv.org/abs/2511.19358", "authors": ["Paul D\u00fctting", "Tomer Ezra", "Michal Feldman", "Thomas Kesselheim"], "title": "Black-Box Lifting and Robustness Theorems for Multi-Agent Contracts", "comment": null, "summary": "Multi-agent contract design has largely evaluated contracts through the lens of pure Nash equilibria (PNE). This focus, however, is not without loss: In general, the principal can strictly gain by recommending a complex, possibly correlated, distribution over actions, while preserving incentive compatibility. In this work, we extend the analysis of multi-agent contracts beyond pure Nash equilibria to encompass more general equilibrium notions, including mixed Nash equilibria as well as (coarse-)correlated equilibria (CCE). The latter, in particular, captures the limiting outcome of agents engaged in learning dynamics.\n  Our main result shows that for submodular and, more generally, XOS rewards, such complex recommendations yield at most a constant-factor gain: there exists a contract and a PNE whose utility is within a constant factor of the best CCE achievable by any contract. This provides a black-box lifting: results established against the best PNE automatically apply with respect to the best CCE, with only a constant factor loss. For submodular rewards, we further show how to transform a contract and a PNE of that contract into a new contract such that any of its CCEs gives a constant approximation to the PNE. This yields black-box robustness: up to constant factors, guarantees established for a specific contract and PNE automatically extend to the modified contract and any of its CCEs. We thus expand prior guarantees for multi-agent contracts and lower the barrier to new ones. As an important corollary, we obtain poly-time algorithms for submodular rewards that achieve constant approximations in any CCE, against the best CCE under the best contract. Such worst-case guarantees are provably unattainable for XOS rewards. Finally, we bound the gap between different equilibrium notions for subadditive, supermodular, and general rewards.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86\u591a\u667a\u80fd\u4f53\u5408\u540c\u8bbe\u8ba1\u7684\u5206\u6790\uff0c\u8d85\u8d8a\u7eaf\u7eb3\u4ec0\u5747\u8861\uff08PNE\uff09\uff0c\u6db5\u76d6\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u548c\u76f8\u5173\u5747\u8861\uff08CCE\uff09\u3002\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u6b21\u6a21\u548cXOS\u5956\u52b1\uff0c\u590d\u6742\u63a8\u8350\u6700\u591a\u5e26\u6765\u5e38\u6570\u500d\u7684\u589e\u76ca\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u5408\u540c\u8bbe\u8ba1\u4e3b\u8981\u57fa\u4e8e\u7eaf\u7eb3\u4ec0\u5747\u8861\uff08PNE\uff09\uff0c\u4f46\u8fd9\u79cd\u5206\u6790\u5ffd\u7565\u4e86\u53ef\u80fd\u901a\u8fc7\u590d\u6742\u7684\u76f8\u5173\u63a8\u8350\u5b9e\u73b0\u7684\u989d\u5916\u6536\u76ca\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u66f4\u4e00\u822c\u7684\u5747\u8861\u6982\u5ff5\uff08\u5982\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u548cCCE\uff09\u5bf9\u5408\u540c\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e86\u6b21\u6a21\u3001XOS\u53ca\u5176\u4ed6\u5956\u52b1\u7ed3\u6784\u4e0b\u4e0d\u540c\u5747\u8861\u6982\u5ff5\u7684\u6548\u7528\u5dee\u5f02\u3002\u4e3b\u8981\u65b9\u6cd5\u662f\u6784\u5efa\u5408\u540c\u548c\u5747\u8861\uff0c\u5e76\u8bc1\u660e\u5176\u8fd1\u4f3c\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u6b21\u6a21\u548cXOS\u5956\u52b1\uff0c\u590d\u6742\u63a8\u8350\u7684\u589e\u76ca\u6700\u591a\u4e3a\u5e38\u6570\u500d\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u80fd\u591f\u5728CCE\u4e0b\u83b7\u5f97\u5e38\u6570\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "conclusion": "\u8bba\u6587\u6269\u5c55\u4e86\u591a\u667a\u80fd\u4f53\u5408\u540c\u8bbe\u8ba1\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u67d0\u4e9b\u5956\u52b1\u7ed3\u6784\u4e0b\uff0c\u590d\u6742\u5747\u8861\u5e26\u6765\u7684\u589e\u76ca\u6709\u9650\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5b9e\u7528\u6027\u5f3a\u7684\u7b97\u6cd5\u3002"}}
{"id": "2511.18900", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.18900", "abs": "https://arxiv.org/abs/2511.18900", "authors": ["Xiuchao Wu", "Pengfei Zhu", "Jiangjing Lyu", "Xinguo Liu", "Jie Guo", "Yanwen Guo", "Weiwei Xu", "Chengfei Lyu"], "title": "MatMart: Material Reconstruction of 3D Objects via Diffusion", "comment": null, "summary": "Applying diffusion models to physically-based material estimation and generation has recently gained prominence. In this paper, we propose \\ttt, a novel material reconstruction framework for 3D objects, offering the following advantages. First, \\ttt\\ adopts a two-stage reconstruction, starting with accurate material prediction from inputs and followed by prior-guided material generation for unobserved views, yielding high-fidelity results. Second, by utilizing progressive inference alongside the proposed view-material cross-attention (VMCA), \\ttt\\ enables reconstruction from an arbitrary number of input images, demonstrating strong scalability and flexibility. Finally, \\ttt\\ achieves both material prediction and generation capabilities through end-to-end optimization of a single diffusion model, without relying on additional pre-trained models, thereby exhibiting enhanced stability across various types of objects. Extensive experiments demonstrate that \\ttt\\ achieves superior performance in material reconstruction compared to existing methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\ttt\u7684\u65b0\u578b3D\u7269\u4f53\u6750\u8d28\u91cd\u5efa\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u91cd\u5efa\u548c\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u5ea6\u7684\u6750\u8d28\u9884\u6d4b\u548c\u751f\u6210\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5c06\u6269\u6563\u6a21\u578b\u5e94\u7528\u4e8e\u57fa\u4e8e\u7269\u7406\u7684\u6750\u8d28\u4f30\u8ba1\u4e0e\u751f\u6210\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u4fdd\u771f\u5ea6\u548c\u7075\u6d3b\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e24\u9636\u6bb5\u91cd\u5efa\uff08\u6750\u8d28\u9884\u6d4b\u548c\u5148\u9a8c\u5f15\u5bfc\u7684\u751f\u6210\uff09\u3001\u89c6\u56fe-\u6750\u8d28\u4ea4\u53c9\u6ce8\u610f\u529b\uff08VMCA\uff09\u673a\u5236\u4ee5\u53ca\u7aef\u5230\u7aef\u4f18\u5316\u7684\u5355\u4e00\u6269\u6563\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\\ttt\u5728\u6750\u8d28\u91cd\u5efa\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\\ttt\u6846\u67b6\u57283D\u6750\u8d28\u91cd\u5efa\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4f9d\u8d56\u989d\u5916\u9884\u8bad\u7ec3\u6a21\u578b\u3002"}}
{"id": "2511.19189", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2511.19189", "abs": "https://arxiv.org/abs/2511.19189", "authors": ["Mengtian Li", "Shengxiang Yao", "Yichen Pan", "Haiyao Xiao", "Zhongmei Li", "Zhifeng Xie", "Keyu Chen"], "title": "AvatarBrush: Monocular Reconstruction of Gaussian Avatars with Intuitive Local Editing", "comment": null, "summary": "The efficient reconstruction of high-quality and intuitively editable human avatars presents a pressing challenge in the field of computer vision. Recent advancements, such as 3DGS, have demonstrated impressive reconstruction efficiency and rapid rendering speeds. However, intuitive local editing of these representations remains a significant challenge. In this work, we propose AvatarBrush, a framework that reconstructs fully animatable and locally editable avatars using only a monocular video input. We propose a three-layer model to represent the avatar and, inspired by mesh morphing techniques, design a framework to generate the Gaussian model from local information of the parametric body model. Compared to previous methods that require scanned meshes or multi-view captures as input, our approach reduces costs and enhances editing capabilities such as body shape adjustment, local texture modification, and geometry transfer. Our experimental results demonstrate superior quality across two datasets and emphasize the enhanced, user-friendly, and localized editing capabilities of our method.", "AI": {"tldr": "AvatarBrush\u662f\u4e00\u79cd\u901a\u8fc7\u5355\u76ee\u89c6\u9891\u8f93\u5165\u91cd\u5efa\u53ef\u52a8\u753b\u5316\u4e14\u5c40\u90e8\u53ef\u7f16\u8f91\u7684\u4eba\u4f53\u5316\u8eab\u7684\u6846\u67b6\uff0c\u91c7\u7528\u4e09\u5c42\u6a21\u578b\u8868\u793a\uff0c\u5e76\u7ed3\u5408\u7f51\u683c\u53d8\u5f62\u6280\u672f\uff0c\u63d0\u5347\u4e86\u7f16\u8f91\u80fd\u529b\u548c\u964d\u4f4e\u4e86\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u8feb\u5207\u9700\u8981\u9ad8\u6548\u91cd\u5efa\u9ad8\u8d28\u91cf\u4e14\u53ef\u76f4\u89c2\u7f16\u8f91\u7684\u4eba\u4f53\u5316\u8eab\u3002\u5c3d\u7ba13DGS\u7b49\u6700\u65b0\u6280\u672f\u5c55\u793a\u4e86\u51fa\u8272\u7684\u91cd\u5efa\u6548\u7387\u548c\u6e32\u67d3\u901f\u5ea6\uff0c\u4f46\u5176\u5c40\u90e8\u7f16\u8f91\u80fd\u529b\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86AvatarBrush\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u5c42\u6a21\u578b\u8868\u793a\u5316\u8eab\uff0c\u5e76\u57fa\u4e8e\u7f51\u683c\u53d8\u5f62\u6280\u672f\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4ece\u53c2\u6570\u5316\u8eab\u4f53\u6a21\u578b\u7684\u5c40\u90e8\u4fe1\u606f\u751f\u6210\u9ad8\u65af\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e8e\u9700\u8981\u626b\u63cf\u7f51\u683c\u6216\u591a\u89c6\u89d2\u6355\u6349\u7684\u65b9\u6cd5\uff0cAvatarBrush\u5728\u6210\u672c\u548c\u7f16\u8f91\u80fd\u529b\uff08\u5982\u4f53\u5f62\u8c03\u6574\u3001\u5c40\u90e8\u7eb9\u7406\u4fee\u6539\u548c\u51e0\u4f55\u8f6c\u79fb\uff09\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u8d28\u91cf\u3002", "conclusion": "AvatarBrush\u4e0d\u4ec5\u964d\u4f4e\u4e86\u8f93\u5165\u6210\u672c\u548c\u63d0\u5347\u4e86\u7f16\u8f91\u80fd\u529b\uff0c\u8fd8\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u53cb\u597d\u548c\u672c\u5730\u5316\u7684\u7f16\u8f91\u4f53\u9a8c\u3002"}}
