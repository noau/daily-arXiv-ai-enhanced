{"id": "2510.06517", "categories": ["cs.GR", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.06517", "abs": "https://arxiv.org/abs/2510.06517", "authors": ["Xavier F. C. Sánchez-Díaz", "Ole Jakob Mengshoel"], "title": "Visualizing Multimodality in Combinatorial Search Landscapes", "comment": "18 pages, 9 figures, Poster presented at the 2025 Symposium of the\n  Norwegian Artificial Intelligence Society (NAIS 2025) on June 18, 2025", "summary": "This work walks through different visualization techniques for combinatorial\nsearch landscapes, focusing on multimodality. We discuss different techniques\nfrom the landscape analysis literature, and how they can be combined to provide\na more comprehensive view of the search landscape. We also include examples and\ndiscuss relevant work to show how others have used these techniques in\npractice, based on the geometric and aesthetic elements of the Grammar of\nGraphics. We conclude that there is no free lunch in visualization, and provide\nrecommendations for future work as there are several paths to continue the work\nin this field."}
{"id": "2510.06802", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.06802", "abs": "https://arxiv.org/abs/2510.06802", "authors": ["Islomjon Shukhratov", "Sergey Gorinsky"], "title": "Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity", "comment": null, "summary": "Capturing and rendering three-dimensional (3D) objects in real time remain a\nsignificant challenge, yet hold substantial potential for applications in\naugmented reality, digital twin systems, remote collaboration and prototyping.\nWe present an end-to-end pipeline that leverages 3D Gaussian Splatting (3D GS)\nto enable rapid acquisition and interactive rendering of real-world objects\nusing a mobile device, cloud processing and a local computer. Users scan an\nobject with a smartphone video, upload it for automated 3D reconstruction, and\nvisualize it interactively in Unity at an average of 150 frames per second\n(fps) on a laptop. The system integrates mobile capture, cloud-based 3D GS and\nUnity rendering to support real-time telepresence. Our experiments show that\nthe pipeline processes scans in approximately 10 minutes on a graphics\nprocessing unit (GPU) achieving real-time rendering on the laptop."}
{"id": "2510.07275", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2510.07275", "abs": "https://arxiv.org/abs/2510.07275", "authors": ["Tianyu Huang"], "title": "Geometric Queries on Closed Implicit Surfaces for Walk on Stars", "comment": "SA Technical Communications '25 short paper, project page:\n  https://illumiart.net/implicit-wost/", "summary": "Walk on stars (WoSt) is currently one of the most advanced Monte Carlo\nsolvers for PDEs. Unfortunately, the lack of reliable geometric query\napproaches has hindered its applicability to boundaries defined by implicit\nsurfaces. This work proposes a geometric query framework over closed implicit\nsurfaces for WoSt, under the scope of walkin' Robin. Our key observation is\nthat all WoSt queries can be formulated as constrained global optimization or\nconstraint satisfaction problems. Based on our formulations, to solve the\nhighly non-convex problems, we adopt a branch-and-bound approach based on\ninterval analysis. To the best of our knowledge, our method is the first to\nstudy closest silhouette point queries and Robin radius bound queries on closed\nimplicit surfaces. Our formulations and methods first enable mesh-free PDE\nsolving via WoSt when boundaries are defined by closed implicit surfaces."}
{"id": "2510.06296", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06296", "abs": "https://arxiv.org/abs/2510.06296", "authors": ["Lingfei Zeng", "Fengdi Che", "Xuhan Huang", "Fei Ye", "Xu Xu", "Binhang Yuan", "Jie Fu"], "title": "VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code", "comment": null, "summary": "Formal verification is the next frontier for ensuring the correctness of code\ngenerated by Large Language Models (LLMs). While methods that co-generate code\nand formal specifications in formal languages, like Dafny, can, in principle,\nprove alignment with user intent, progress is bottlenecked by specification\nquality evaluation. Current benchmarks rely on matching against ground-truth\nspecifications, a manual and expertise-intensive process that has limited\nexisting datasets to a few hundred simple problems and also suffers from a\nreliability issue. To address this, we introduce VeriEquivBench, a new\nbenchmark with $2,389$ complex algorithmic problems that probe the limitations\nof current models in both code generation and formal reasoning. Our evaluation\nframework replaces ground-truth matching with a formally grounded metric, the\nequivalence score, and rigorously verifies the quality of generated\nspecifications and code. Our results show that generating formally verifiable\ncode remains a profound challenge for state-of-the-art LLMs. This underscores\nboth the difficulty of the task and the need for benchmarks like VeriEquivBench\nto drive progress toward scalable and reliable coding agents."}
{"id": "2510.06581", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.06581", "abs": "https://arxiv.org/abs/2510.06581", "authors": ["Bo Li", "Fangxiao Wang", "Shiji Xing"], "title": "Constant Weighted Maximin Share Approximations for Chores", "comment": null, "summary": "We study the fair allocation of indivisible chores among agents with\nasymmetric weights. Among the various fairness notions, weighted maximin share\n(WMMS) stands out as particularly compelling. However, whether WMMS admits a\nconstant-factor approximation has remained unknown and is one of the important\nopen problems in weighted fair division [ALMW22, Suk25]. So far, the best known\napproximation ratio is O(log n), where n is the number of agents. In this\npaper, we advance the state of the art and present the first constant-factor\napproximate WMMS algorithm. To this end, we introduce canonical instance\nreductions and different bounds of agents' valuations. We also prove that\nguaranteeing better than 2-approximation is not possible, which improves the\nbest-known lower bound of 1.366."}
