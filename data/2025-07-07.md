<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Gbake: Baking 3D Gaussian Splats into Reflection Probes](https://arxiv.org/abs/2507.02257)
*Stephen Pasch,Joel K. Salzman,Changxi Zheng*

Main category: cs.GR

TL;DR: GBake是一种专用工具，用于从高斯散射场景中烘焙反射探针，使得传统3D网格在Unity游戏引擎中能够实现真实的反射映射。


<details>
  <summary>Details</summary>
Motivation: 随着3D高斯散射技术的普及，需要将传统计算机图形技术与高斯散射环境结合。由于3D高斯原始数据同时编码了光照和几何信息，直接插入的网格会出现不自然的照明效果。

Method: 通过引入GBake工具，从高斯散射场景中烘焙反射探针，从而在Unity中实现传统3D网格的反射映射。

Result: GBake能够解决网格在高斯散射环境中不自然照明的问题，实现更真实的渲染效果。

Conclusion: GBake提供了一种有效的方法，将传统3D网格与高斯散射环境融合，提升了渲染的真实性。

Abstract: The growing popularity of 3D Gaussian Splatting has created the need to
integrate traditional computer graphics techniques and assets in splatted
environments. Since 3D Gaussian primitives encode lighting and geometry jointly
as appearance, meshes are relit improperly when inserted directly in a mixture
of 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a
specialized tool for baking reflection probes from Gaussian-splatted scenes
that enables realistic reflection mapping of traditional 3D meshes in the Unity
game engine.

</details>


### [2] [Real-time Image-based Lighting of Glints](https://arxiv.org/abs/2507.02674)
*Tom Kneiphof,Reinhard Klein*

Main category: cs.GR

TL;DR: 提出了一种高效的图像光照近似方法，专门针对具有闪光或闪烁外观的材料，实现了动态材质特性和环境贴图的实时渲染。


<details>
  <summary>Details</summary>
Motivation: 基于图像的光照技术在再现真实世界光照条件下的阴影时广泛使用，但对于具有闪光或闪烁外观的材料（由表面离散微面引起）的渲染仍具有挑战性。

Method: 提出了一种新颖的近似方法，结合实时闪烁渲染和区域光照，并采用了标准环境贴图过滤技术。方法假设环境贴图分为少量均匀辐射区域，通过正态分布函数过滤相应的指示函数，获得微面反射光的概率。

Result: 验证表明，该实时近似方法在多种材质特性和光照条件下与真实渲染结果接近，性能稳定且开销低，仅需存储预过滤环境贴图的两倍内存。

Conclusion: 该方法有效解决了闪光材料在图像光照下的实时渲染问题，性能优越且开销合理，适用于动态材质和环境贴图。

Abstract: Image-based lighting is a widely used technique to reproduce shading under
real-world lighting conditions, especially in real-time rendering applications.
A particularly challenging scenario involves materials exhibiting a sparkling
or glittering appearance, caused by discrete microfacets scattered across their
surface. In this paper, we propose an efficient approximation for image-based
lighting of glints, enabling fully dynamic material properties and environment
maps. Our novel approach is grounded in real-time glint rendering under area
light illumination and employs standard environment map filtering techniques.
Crucially, our environment map filtering process is sufficiently fast to be
executed on a per-frame basis. Our method assumes that the environment map is
partitioned into few homogeneous regions of constant radiance. By filtering the
corresponding indicator functions with the normal distribution function, we
obtain the probabilities for individual microfacets to reflect light from each
region. During shading, these probabilities are utilized to hierarchically
sample a multinomial distribution, facilitated by our novel dual-gated Gaussian
approximation of binomial distributions. We validate that our real-time
approximation is close to ground-truth renderings for a range of material
properties and lighting conditions, and demonstrate robust and stable
performance, with little overhead over rendering glints from a single
directional light. Compared to rendering smooth materials without glints, our
approach requires twice as much memory to store the prefiltered environment
map.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
*Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 文章介绍了一种名为DecoRTL的新型运行时解码策略，通过结合自一致性采样和语法感知温度调整，显著提升了大型语言模型在RTL代码生成中的语法有效性、功能正确性和输出多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM解码策略在设计RTL代码时常因结构或语义问题导致输出不合格，文章旨在解决这一问题。

Method: DecoRTL整合了自一致性采样（生成多个候选并重排序）和语法感知温度调整（根据语法和功能角色调整采样温度）。

Result: 实验验证表明，DecoRTL在VerilogEval基准测试中显著提升了语法有效性、功能正确性和输出多样性，且执行开销可忽略不计。

Conclusion: DecoRTL是一种高效的运行时解码策略，无需额外微调即可提升LLM在RTL代码生成中的表现。

Abstract: As one of their many applications, large language models (LLMs) have recently
shown promise in automating register transfer level (RTL) code generation.
However, conventional LLM decoding strategies, originally designed for natural
language, often fail to meet the structural and semantic demands of RTL,
leading to hallucinated, repetitive, or invalid code outputs. In this paper, we
first investigate the root causes of these decoding failures through an
empirical analysis of token-level entropy during RTL generation. Our findings
reveal that LLMs exhibit low confidence in regions of structural ambiguity or
semantic complexity, showing that standard decoding strategies fail to
differentiate between regions requiring determinism (syntax-critical regions)
and those that benefit from creative exploratory variability (design-critical
regions). Then, to overcome this, we introduce DecoRTL, a novel run-time
decoding strategy, that is both syntax-aware and contrastive for RTL code
generation. DecoRTL integrates two complementary components: (i)
self-consistency sampling, which generates multiple candidates and re-ranks
them based on token-level agreement to promote correctness while maintaining
diversity; and (ii) syntax-aware temperature adaptation, which classifies
tokens by their syntactical and functional roles and adjusts the sampling
temperature accordingly, enforcing low temperature for syntax-critical tokens
and higher temperature for exploratory ones. Our approach operates entirely at
inference time without requiring any additional model fine-tuning. Through
evaluations on multiple open-source LLMs using the VerilogEval benchmark, we
demonstrate significant improvements in syntactic validity, functional
correctness, and output diversity, while the execution overhead (performance
overhead) is imperceptible.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems](https://arxiv.org/abs/2507.02464)
*Craig S Wright*

Main category: cs.GT

TL;DR: 本文提出了一个基于自动机理论和经济学基础的框架，将CAP定理中的权衡问题重新表述为约束优化问题，通过经济激励层和博弈论机制，证明了在有限误差范围内可以同时保证可用性和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的CAP定理认为在分布式系统中，一致性、可用性和分区容错性之间存在三难选择。本文旨在通过引入经济学和自动机理论，重新框架这一权衡问题。

Method: 论文将分布式系统建模为分区感知的状态机，并嵌入经济激励层以稳定对抗性分区网络中的共识行为。通过将博弈论机制融入全局转换语义，定义了关于收敛性、活跃性和正确性的可证明边界。

Result: 研究结果表明，通过形式化的经济控制，可以在有限误差范围内同时保持可用性和一致性，从而扩展了经典CAP定理的限制。

Conclusion: 本文通过结合经济学和自动机理论，提出了一种新的方法来解决分布式系统中的CAP权衡问题，证明了在特定条件下可以同时优化一致性和可用性。

Abstract: The CAP theorem asserts a trilemma between consistency, availability, and
partition tolerance. This paper introduces a rigorous automata-theoretic and
economically grounded framework that reframes the CAP trade-off as a constraint
optimization problem. We model distributed systems as partition-aware state
machines and embed economic incentive layers to stabilize consensus behavior
across adversarially partitioned networks. By incorporating game-theoretic
mechanisms into the global transition semantics, we define provable bounds on
convergence, liveness, and correctness. Our results demonstrate that
availability and consistency can be simultaneously preserved within bounded
epsilon margins, effectively extending the classical CAP limits through formal
economic control.

</details>


### [5] [TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games](https://arxiv.org/abs/2507.02675)
*Zhaoqilin Yang,Xin Wang,Ruichen Zhang,Chanchan Li,Youliang Tian*

Main category: cs.GT

TL;DR: 团队效用约束近端策略优化(TUC-PPO)是一种新的深度强化学习框架，通过在空间公共物品游戏中集成团队福利目标，扩展了PPO。该方法通过双层目标优化策略梯度和团队效用约束，实现了更快的合作均衡收敛和更强的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，合作通常间接来自个体奖励，无法直接优化团队福利。该论文旨在通过TUC-PPO框架，将团队目标显式整合到策略更新中，以解决多代理社会困境问题。

Method: TUC-PPO扩展了PPO，通过自适应拉格朗日乘子进行约束优化，集成策略梯度和团队效用约束的双层目标，使代理能够动态平衡自私与合作激励。

Result: 与未修改的PPO和进化博弈论基线相比，TUC-PPO在合作均衡收敛速度和稳定性方面表现更优，能够更好地抵御背叛者的入侵。

Conclusion: TUC-PPO为多代理深度强化学习提供了一种新框架，将团队目标正式整合到策略更新中，同时为进化博弈论研究提供了新的计算工具。

Abstract: We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO),
a new deep reinforcement learning framework. It extends Proximal Policy
Optimization (PPO) by integrating team welfare objectives specifically for
spatial public goods games. Unlike conventional approaches where cooperation
emerges indirectly from individual rewards, TUC-PPO instead optimizes a
bi-level objective integrating policy gradients and team utility constraints.
Consequently, all policy updates explicitly incorporate collective payoff
thresholds. The framework preserves PPO's policy gradient core while
incorporating constrained optimization through adaptive Lagrangian multipliers.
Therefore, decentralized agents dynamically balance selfish and cooperative
incentives. The comparative analysis demonstrates superior performance of this
constrained deep reinforcement learning approach compared to unmodified PPO and
evolutionary game theory baselines. It achieves faster convergence to
cooperative equilibria and greater stability against invasion by defectors. The
framework formally integrates team objectives into policy updates. This work
advances multi-agent deep reinforcement learning for social dilemmas while
providing new computational tools for evolutionary game theory research.

</details>


### [6] [Learning to Coordinate Bidders in Non-Truthful Auctions](https://arxiv.org/abs/2507.02801)
*Hu Fu,Tao Lin*

Main category: cs.GT

TL;DR: 该论文研究了在非真实拍卖（如第一价格拍卖和全支付拍卖）中学习贝叶斯相关均衡（BCE）的样本复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 由于独立战略行为（贝叶斯纳什均衡）在非真实拍卖中难以刻画且可能导致不良结果，论文探讨了通过协调竞标者（通过BCE）来改进拍卖系统的方法。然而，BCE的实施需要竞标者私人估值的分布信息，而这些信息通常不可得。

Method: 论文通过将学习BCE的问题转化为估计竞标者预期效用的问题，并结合对竞标者所有单调投标策略类的伪维数分析，提出了一种学习方法。

Result: 证明了在包括第一价格拍卖和全支付拍卖在内的一类非真实拍卖中，BCE可以通过多项式样本量（$\tilde O(\frac{n}{\varepsilon^2})$）从竞标者的价值分布中学习到。

Conclusion: 研究表明，尽管BCE的实施通常需要估值分布的先验知识，但通过样本学习的方式，可以在多项式样本复杂度下实现有效的BCE学习，为非真实拍卖系统的改进提供了新的技术路径。

Abstract: In non-truthful auctions such as first-price and all-pay auctions, the
independent strategic behaviors of bidders, with the corresponding equilibrium
notion -- Bayes Nash equilibria -- are notoriously difficult to characterize
and can cause undesirable outcomes. An alternative approach to designing better
auction systems is to coordinate the bidders: let a mediator make
incentive-compatible recommendations of correlated bidding strategies to the
bidders, namely, implementing a Bayes correlated equilibrium (BCE). The
implementation of BCE, however, requires knowledge of the distribution of
bidders' private valuations, which is often unavailable. We initiate the study
of the sample complexity of learning Bayes correlated equilibria in
non-truthful auctions. We prove that the BCEs in a large class of non-truthful
auctions, including first-price and all-pay auctions, can be learned with a
polynomial number $\tilde O(\frac{n}{\varepsilon^2})$ of samples from the
bidders' value distributions. Our technique is a reduction to the problem of
estimating bidders' expected utility from samples, combined with an analysis of
the pseudo-dimension of the class of all monotone bidding strategies of
bidders.

</details>
