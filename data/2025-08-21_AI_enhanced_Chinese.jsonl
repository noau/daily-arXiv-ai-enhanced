{"id": "2508.14194", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.14194", "abs": "https://arxiv.org/abs/2508.14194", "authors": ["Jing Leng", "Sanjukta Roy"], "title": "Algorithms for Stable Roommate with Externalities", "comment": "Accepted to ECAI 2025", "summary": "In the roommate matching model, given a set of 2n agents and n rooms, we find\nan assignment of a pair of agents to a room. Although the roommate matching\nproblem is well studied, the study of the model when agents have preference\nover both rooms and roommates was recently initiated by Chan et al. [11]. We\nstudy two types of stable roommate assignments, namely, 4-person stable (4PS)\nand 2-person stable (2PS) in conjunction with efficiency and\nstrategy-proofness. We design a simple serial dictatorship based algorithm for\nfinding a 4PS assignment that is Pareto optimal and strategy-proof. However,\nthe serial dictatorship algorithm is far from being 2PS. Next, we study top\ntrading cycle (TTC) based algorithms. We show that variations of TTC cannot be\nstrategy-proof or PO. Finally, as Chan et al. (2016) showed that deciding the\nexistence of 2PS assignment is NP-complete, we identify preference structures\nwhere a 2PS assignment can be found in polynomial time.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5ba4\u53cb\u5339\u914d\u6a21\u578b\u4e2d\u4e24\u79cd\u7a33\u5b9a\u7684\u5206\u914d\u65b9\u5f0f\uff084PS\u548c2PS\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u7684\u6548\u7387\u4e0e\u7b56\u7565\u8bc1\u660e\u6027\u3002\u901a\u8fc7\u8bbe\u8ba1\u57fa\u4e8e\u5e8f\u5217\u72ec\u88c1\u7684\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e864PS\u5206\u914d\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u548c\u7b56\u7565\u8bc1\u660e\u6027\uff0c\u4f46\u53d1\u73b0\u5176\u4e0d\u9002\u7528\u4e8e2PS\u3002\u540c\u65f6\uff0c\u5206\u6790\u4e86\u57fa\u4e8eTTC\u7684\u7b97\u6cd5\u5728\u7b56\u7565\u8bc1\u660e\u6027\u548cPO\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u8bc6\u522b\u4e86\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u627e\u52302PS\u5206\u914d\u7684\u7279\u6b8a\u504f\u597d\u7ed3\u6784\u3002", "motivation": "\u5ba4\u53cb\u5339\u914d\u95ee\u9898\u5728\u4ee3\u7406\u4eba\u540c\u65f6\u5bf9\u623f\u95f4\u548c\u5ba4\u53cb\u6709\u504f\u597d\u7684\u60c5\u51b5\u4e0b\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u8ba8\u4e24\u79cd\u7a33\u5b9a\u5206\u914d\u65b9\u5f0f\uff084PS\u548c2PS\uff09\u7684\u6548\u7387\u4e0e\u7b56\u7565\u8bc1\u660e\u6027\uff0c\u5e76\u63d0\u51fa\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5e8f\u5217\u72ec\u88c1\u7b97\u6cd5\u8bbe\u8ba1\u7528\u4e8e4PS\u5206\u914d\uff0c\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u548c\u7b56\u7565\u8bc1\u660e\u6027\uff1b\u5206\u6790\u57fa\u4e8eTTC\u7684\u7b97\u6cd5\u5728\u7b56\u7565\u8bc1\u660e\u6027\u548cPO\u65b9\u9762\u7684\u5c40\u9650\u6027\uff1b\u8bc6\u522b\u7279\u5b9a\u504f\u597d\u7ed3\u6784\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u627e\u52302PS\u5206\u914d\u3002", "result": "\u5e8f\u5217\u72ec\u88c1\u7b97\u6cd5\u9002\u7528\u4e8e4PS\u5206\u914d\u4f46\u4e0d\u9002\u7528\u4e8e2PS\uff1bTTC\u7b97\u6cd5\u7684\u53d8\u79cd\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u7b56\u7565\u8bc1\u660e\u6027\u548cPO\uff1b\u5728\u7279\u5b9a\u504f\u597d\u7ed3\u6784\u4e0b\uff0c2PS\u5206\u914d\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u5728\u5ba4\u53cb\u5339\u914d\u6a21\u578b\u4e2d\uff0c4PS\u5206\u914d\u53ef\u901a\u8fc7\u7b80\u5355\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u548c\u7b56\u7565\u8bc1\u660e\u6027\uff0c\u800c2PS\u5206\u914d\u7684\u590d\u6742\u6027\u548c\u8ba1\u7b97\u96be\u5ea6\u5219\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002\u540c\u65f6\uff0c\u67d0\u4e9b\u7279\u6b8a\u504f\u597d\u7ed3\u6784\u53ef\u4ee5\u7b80\u53162PS\u5206\u914d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.14196", "categories": ["cs.GT", "cs.DS", "econ.TH"], "pdf": "https://arxiv.org/pdf/2508.14196", "abs": "https://arxiv.org/abs/2508.14196", "authors": ["Yiling Chen", "Tao Lin", "Wei Tang", "Jamie Tucker-Foltz"], "title": "Explainable Information Design", "comment": "32 pages, 5 figures", "summary": "The optimal signaling schemes in information design (Bayesian persuasion)\nproblems often involve non-explainable randomization or disconnected partitions\nof state space, which are too intricate to be audited or communicated. We\npropose explainable information design in the context of information design\nwith a continuous state space, restricting the information designer to use\n$K$-partitional signaling schemes defined by deterministic and monotone\npartitions of the state space, where a unique signal is sent for all states in\neach part. We first prove that the price of explainability (PoE) -- the ratio\nbetween the performances of the optimal explainable signaling scheme and\nunrestricted signaling scheme -- is exactly $1/2$ in the worst case, meaning\nthat partitional signaling schemes are never worse than arbitrary signaling\nschemes by a factor of 2.\n  We then study the complexity of computing optimal explainable signaling\nschemes. We show that the exact optimization problem is NP-hard in general. But\nfor Lipschitz utility functions, an $\\varepsilon$-approximately optimal\nexplainable signaling scheme can be computed in polynomial time. And for\npiecewise constant utility functions, we provide an efficient algorithm to find\nan explainable signaling scheme that provides a $1/2$ approximation to the\noptimal unrestricted signaling scheme, which matches the worst-case PoE bound.\n  A technical tool we develop is a conversion from any optimal signaling scheme\n(which satisfies a bi-pooling property) to a partitional signaling scheme that\nachieves $1/2$ fraction of the expected utility of the former. We use this tool\nin the proofs of both our PoE result and algorithmic result.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4fe1\u606f\u8bbe\u8ba1\u4e2d\u53ef\u89e3\u91ca\u7684\u4fe1\u53f7\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u53ef\u5206\u533a\u4fe1\u53f7\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u4e0d\u4f1a\u6bd4\u4efb\u610f\u4fe1\u53f7\u65b9\u6848\u5dee\u8d85\u8fc72\u500d\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u548c\u7b97\u6cd5\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u8bbe\u8ba1\u4e2d\u7684\u6700\u4f18\u4fe1\u53f7\u65b9\u6848\u5e38\u5e38\u6d89\u53ca\u96be\u4ee5\u89e3\u91ca\u6216\u5ba1\u8ba1\u7684\u968f\u673a\u5316\u6216\u590d\u6742\u5206\u533a\u3002\u8bba\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u4fe1\u53f7\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u4fbf\u66f4\u6613\u4e8e\u5ba1\u8ba1\u548c\u6c9f\u901a\u3002", "method": "\u8bba\u6587\u5c06\u4fe1\u606f\u8bbe\u8ba1\u9650\u5236\u4e3a\u4f7f\u7528\u786e\u5b9a\u6027\u4e14\u5355\u8c03\u7684\u5206\u533a\u4fe1\u53f7\u65b9\u6848\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6c\u6362\u65b9\u6cd5\uff0c\u5c06\u4efb\u610f\u6700\u4f18\u4fe1\u53f7\u65b9\u6848\u8f6c\u6362\u4e3a\u5206\u533a\u4fe1\u53f7\u65b9\u6848\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u6027\u80fd\u4e0a\u4e0d\u4f1a\u4f4e\u4e8e\u539f\u65b9\u6848\u76841/2\u3002", "result": "\u8bc1\u660e\u4e86\u5206\u533a\u4fe1\u53f7\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u4e0d\u4f1a\u6bd4\u4efb\u610f\u4fe1\u53f7\u65b9\u6848\u5dee\u8d85\u8fc72\u500d\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u7b97\u6cd5\u6548\u7387\uff0c\u5982\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u8fd1\u4f3c\u8ba1\u7b97\u548c1/2\u8fd1\u4f3c\u6bd4\u7684\u7b97\u6cd5\u3002", "conclusion": "\u8bba\u6587\u5c55\u793a\u4e86\u53ef\u89e3\u91ca\u7684\u5206\u533a\u4fe1\u53f7\u65b9\u6848\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u8bbe\u8ba1\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2508.14439", "categories": ["cs.GT", "cs.DS", "91B12 (Primary) 91B14 (Secondary)", "F.2.2; G.2.1; G.2.3; J.4"], "pdf": "https://arxiv.org/pdf/2508.14439", "abs": "https://arxiv.org/abs/2508.14439", "authors": ["Paula B\u00f6hm", "Robert Bredereck", "Till Fluschnik"], "title": "Properties of Egalitarian Sequences of Committees: Theory and Experiments", "comment": "A short version was published in the proceedings of ECAI '25", "summary": "We study the task of electing egalitarian sequences of $\\tau$ committees\ngiven a set of agents with additive utilities for candidates available on each\nof $\\tau$ levels. We introduce several rules for electing an egalitarian\ncommittee sequence as well as properties for such rules. We settle the\ncomputational complexity of finding a winning sequence for our rules and\nclassify them against our properties. Additionally, we transform sequential\nelection data from existing election data from the literature. Using this data\nset, we compare our rules empirically and test them experimentally against our\nproperties.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u9009\u4e3e\u5e73\u7b49\u4e3b\u4e49\u7684\u59d4\u5458\u4f1a\u5e8f\u5217\uff0c\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u89c4\u5219\u5e76\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u548c\u5b9e\u8bc1\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u5728\u591a\u4e2a\u5c42\u7ea7\u4e0a\u5982\u4f55\u9009\u4e3e\u4ee3\u8868\u516c\u5e73\u6027\u7684\u59d4\u5458\u4f1a\u5e8f\u5217\uff0c\u4ee5\u6ee1\u8db3\u4ee3\u7406\u4eba\u5bf9\u5019\u9009\u4eba\u7684\u7d2f\u52a0\u6548\u7528\u9700\u6c42\u3002", "method": "\u5f15\u5165\u4e86\u51e0\u79cd\u9009\u4e3e\u5e73\u7b49\u4e3b\u4e49\u59d4\u5458\u4f1a\u5e8f\u5217\u7684\u89c4\u5219\uff0c\u5e76\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u89c4\u5219\u7684\u6027\u8d28\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u548c\u5206\u7c7b\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u89c4\u5219\u7684\u6027\u80fd\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5b83\u4eec\u662f\u5426\u7b26\u5408\u5b9a\u4e49\u7684\u6027\u8d28\u3002", "conclusion": "\u63d0\u51fa\u7684\u89c4\u5219\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u591a\u5c42\u7ea7\u59d4\u5458\u4f1a\u9009\u4e3e\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14705", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14705", "abs": "https://arxiv.org/abs/2508.14705", "authors": ["Phurinut Srisawad", "Juergen Branke", "Long Tran-Thanh"], "title": "Learning in Repeated Multi-Objective Stackelberg Games with Payoff Manipulation", "comment": "Extended version of the paper accepted at the 28th European\n  Conference on Artificial Intelligence (ECAI 2025); Paper ID: M2635", "summary": "We study payoff manipulation in repeated multi-objective Stackelberg games,\nwhere a leader may strategically influence a follower's deterministic best\nresponse, e.g., by offering a share of their own payoff. We assume that the\nfollower's utility function, representing preferences over multiple objectives,\nis unknown but linear, and its weight parameter must be inferred through\ninteraction. This introduces a sequential decision-making challenge for the\nleader, who must balance preference elicitation with immediate utility\nmaximisation. We formalise this problem and propose manipulation policies based\non expected utility (EU) and long-term expected utility (longEU), which guide\nthe leader in selecting actions and offering incentives that trade off\nshort-term gains with long-term impact. We prove that under infinite repeated\ninteractions, longEU converges to the optimal manipulation. Empirical results\nacross benchmark environments demonstrate that our approach improves cumulative\nleader utility while promoting mutually beneficial outcomes, all without\nrequiring explicit negotiation or prior knowledge of the follower's utility\nfunction.", "AI": {"tldr": "\u7814\u7a76\u591a\u76ee\u6807Stackelberg\u535a\u5f08\u4e2d\u7684\u56de\u62a5\u64cd\u7eb5\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u9884\u671f\u6548\u7528\u548c\u957f\u671f\u9884\u671f\u6548\u7528\u7684\u64cd\u7eb5\u7b56\u7565\uff0c\u5e73\u8861\u77ed\u671f\u6536\u76ca\u4e0e\u957f\u671f\u5f71\u54cd\u3002", "motivation": "\u5728\u91cd\u590d\u7684\u591a\u76ee\u6807Stackelberg\u535a\u5f08\u4e2d\uff0c\u9886\u8896\u5982\u4f55\u901a\u8fc7\u7b56\u7565\u6027\u64cd\u7eb5\u56de\u62a5\u6765\u5f71\u54cd\u8ffd\u968f\u8005\u7684\u6700\u4f73\u54cd\u5e94\uff0c\u65e0\u9700\u663e\u5f0f\u8c08\u5224\u6216\u9884\u5148\u4e86\u89e3\u8ffd\u968f\u8005\u7684\u6548\u7528\u51fd\u6570\u3002", "method": "\u5047\u8bbe\u8ffd\u968f\u8005\u7684\u6548\u7528\u51fd\u6570\u4e3a\u7ebf\u6027\u4f46\u672a\u77e5\uff0c\u63d0\u51fa\u57fa\u4e8e\u9884\u671f\u6548\u7528\uff08EU\uff09\u548c\u957f\u671f\u9884\u671f\u6548\u7528\uff08longEU\uff09\u7684\u64cd\u7eb5\u7b56\u7565\uff0c\u5e73\u8861\u504f\u597d\u63a2\u7d22\u4e0e\u5373\u65f6\u6548\u7528\u6700\u5927\u5316\u3002", "result": "\u5728\u65e0\u9650\u91cd\u590d\u4ea4\u4e92\u6761\u4ef6\u4e0b\uff0clongEU\u6536\u655b\u4e8e\u6700\u4f18\u64cd\u7eb5\uff1b\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u63d0\u5347\u9886\u8896\u7d2f\u79ef\u6548\u7528\u5e76\u4fc3\u8fdb\u4e92\u60e0\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u65e0\u9700\u663e\u5f0f\u8c08\u5224\u6216\u9884\u5148\u77e5\u8bc6\uff0c\u6709\u6548\u63d0\u5347\u9886\u8896\u7684\u957f\u671f\u6548\u7528\uff0c\u5e76\u5728\u591a\u76ee\u6807\u73af\u5883\u4e2d\u5b9e\u73b0\u4e92\u60e0\u3002"}}
{"id": "2508.14394", "categories": ["cs.PL", "cs.SE", "D.3; D.2.5; G.3"], "pdf": "https://arxiv.org/pdf/2508.14394", "abs": "https://arxiv.org/abs/2508.14394", "authors": ["Ryan Tjoa", "Poorva Garg", "Harrison Goldstein", "Todd Millstein", "Benjamin Pierce", "Guy Van den Broeck"], "title": "Tuning Random Generators: Property-Based Testing as Probabilistic Programming", "comment": "Extended version of OOPSLA '25 paper", "summary": "Property-based testing validates software against an executable specification\nby evaluating it on randomly generated inputs. The standard way that PBT users\ngenerate test inputs is via generators that describe how to sample test inputs\nthrough random choices. To achieve a good distribution over test inputs, users\nmust tune their generators, i.e., decide on the weights of these individual\nrandom choices. Unfortunately, it is very difficult to understand how to choose\nindividual generator weights in order to achieve a desired distribution, so\ntoday this process is tedious and limits the distributions that can be\npractically achieved.\n  In this paper, we develop techniques for the automatic and offline tuning of\ngenerators. Given a generator with undetermined symbolic weights and an\nobjective function, our approach automatically learns values for these weights\nthat optimize for the objective. We describe useful objective functions that\nallow users to (1) target desired distributions and (2) improve the diversity\nand validity of their test cases. We have implemented our approach in a novel\ndiscrete probabilistic programming system, Loaded Dice, that supports\ndifferentiation and parameter learning, and use it as a language for\ngenerators. We empirically demonstrate that our approach is effective at\noptimizing generator distributions according to the specified objective\nfunctions. We also perform a thorough evaluation on PBT benchmarks,\ndemonstrating that, when automatically tuned for diversity and validity, the\ngenerators exhibit a 3.1-7.4x speedup in bug finding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u79bb\u7ebf\u8c03\u6574\u751f\u6210\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u76ee\u6807\u51fd\u6570\u81ea\u52a8\u5b66\u4e60\u7b26\u53f7\u6743\u91cd\uff0c\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u6d4b\u8bd5\u8f93\u5165\u5206\u5e03\u548c\u66f4\u9ad8\u7684\u6d4b\u8bd5\u6848\u4f8b\u591a\u6837\u6027\u53ca\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5c5e\u6027\u7684\u6d4b\u8bd5\u4e2d\uff0c\u7528\u6237\u9700\u8981\u624b\u52a8\u8c03\u6574\u751f\u6210\u5668\u7684\u6743\u91cd\u4ee5\u8fbe\u5230\u7406\u60f3\u7684\u6d4b\u8bd5\u8f93\u5165\u5206\u5e03\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u7e41\u7410\u4e14\u9650\u5236\u4e86\u5b9e\u9645\u53ef\u5b9e\u73b0\u7684\u5206\u5e03\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed9\u5b9a\u5e26\u6709\u672a\u786e\u5b9a\u7b26\u53f7\u6743\u91cd\u7684\u751f\u6210\u5668\u548c\u76ee\u6807\u51fd\u6570\uff0c\u81ea\u52a8\u5b66\u4e60\u8fd9\u4e9b\u6743\u91cd\u4ee5\u4f18\u5316\u76ee\u6807\u3002\u91c7\u7528\u4e86\u79bb\u6563\u6982\u7387\u7f16\u7a0b\u7cfb\u7edfLoaded Dice\u4f5c\u4e3a\u751f\u6210\u5668\u7684\u8bed\u8a00\uff0c\u652f\u6301\u5fae\u5206\u548c\u53c2\u6570\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u751f\u6210\u5668\u7684\u5206\u5e03\uff0c\u4e14\u5728\u81ea\u52a8\u8c03\u6574\u540e\uff0c\u751f\u6210\u5668\u5728bug\u53d1\u73b0\u4e0a\u8868\u73b0\u51fa3.1-7.4\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u8c03\u6574\u751f\u6210\u5668\u7684\u6743\u91cd\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6848\u4f8b\u7684\u591a\u6837\u6027\u548c\u6709\u6548\u6027\uff0c\u4ece\u800c\u66f4\u5feb\u5730\u53d1\u73b0\u8f6f\u4ef6\u4e2d\u7684bug\u3002"}}
{"id": "2508.14411", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14411", "abs": "https://arxiv.org/abs/2508.14411", "authors": ["Seokjun Choi", "Hoon-Gyu Chung", "Yujin Jeon", "Giljoo Nam", "Seung-Hwan Baek"], "title": "A Real-world Display Inverse Rendering Dataset", "comment": null, "summary": "Inverse rendering aims to reconstruct geometry and reflectance from captured\nimages. Display-camera imaging systems offer unique advantages for this task:\neach pixel can easily function as a programmable point light source, and the\npolarized light emitted by LCD displays facilitates diffuse-specular\nseparation. Despite these benefits, there is currently no public real-world\ndataset captured using display-camera systems, unlike other setups such as\nlight stages. This absence hinders the development and evaluation of\ndisplay-based inverse rendering methods. In this paper, we introduce the first\nreal-world dataset for display-based inverse rendering. To achieve this, we\nconstruct and calibrate an imaging system comprising an LCD display and stereo\npolarization cameras. We then capture a diverse set of objects with diverse\ngeometry and reflectance under one-light-at-a-time (OLAT) display patterns. We\nalso provide high-quality ground-truth geometry. Our dataset enables the\nsynthesis of captured images under arbitrary display patterns and different\nnoise levels. Using this dataset, we evaluate the performance of existing\nphotometric stereo and inverse rendering methods, and provide a simple, yet\neffective baseline for display inverse rendering, outperforming\nstate-of-the-art inverse rendering methods. Code and dataset are available on\nour project page at https://michaelcsj.github.io/DIR/", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u57fa\u4e8e\u663e\u793a\u5668\u76f8\u673a\u7684\u771f\u5b9e\u4e16\u754c\u9006\u6e32\u67d3\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u4f7f\u7528\u663e\u793a\u5668\u76f8\u673a\u7cfb\u7edf\u6355\u83b7\u7684\u516c\u5f00\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u963b\u788d\u4e86\u57fa\u4e8e\u663e\u793a\u5668\u7684\u9006\u6e32\u67d3\u65b9\u6cd5\u7684\u53d1\u5c55\u4e0e\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542bLCD\u663e\u793a\u5668\u548c\u7acb\u4f53\u504f\u632f\u76f8\u673a\u7684\u6210\u50cf\u7cfb\u7edf\uff0c\u6355\u83b7\u4e86\u591a\u79cd\u51e0\u4f55\u548c\u53cd\u5c04\u7387\u7684\u7269\u4f53\u5728\u5355\u5149\u6a21\u5f0f\u4e0b\u7684\u56fe\u50cf\uff0c\u5e76\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u771f\u5b9e\u51e0\u4f55\u6570\u636e\u3002", "result": "\u6570\u636e\u96c6\u652f\u6301\u4efb\u610f\u663e\u793a\u6a21\u5f0f\u548c\u4e0d\u540c\u566a\u58f0\u7ea7\u522b\u7684\u56fe\u50cf\u5408\u6210\uff0c\u8bc4\u4f30\u663e\u793a\u65b0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u9006\u6e32\u67d3\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u663e\u793a\u5668\u9006\u6e32\u67d3\u6280\u672f\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u4f46\u9ad8\u6548\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2508.14614", "categories": ["cs.PL", "D.3.0; D.3.1"], "pdf": "https://arxiv.org/pdf/2508.14614", "abs": "https://arxiv.org/abs/2508.14614", "authors": ["Ashish Mishra", "Suresh Jagannathan"], "title": "Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity", "comment": null, "summary": "Component-based synthesis (CBS) aims to generate loop-free programs from a\nset of libraries whose methods are annotated with specifications and whose\noutput must satisfy a set of logical constraints, expressed as a query. The\neffectiveness of a CBS algorithm critically depends on the severity of the\nconstraints imposed by the query. The more exact these constraints are, the\nsparser the space of feasible solutions. This maxim also applies when we enrich\nthe expressiveness of the specifications affixed to library methods. In both\ncases, the search must now contend with constraints that may only hold over a\nsmall number of the possible execution paths that can be enumerated by a CBS\nprocedure.\n  In this paper, we address this challenge by equipping CBS search with the\nability to reason about logical similarities among the paths it explores. Our\nsetting considers library methods equipped with refinement-type specifications\nthat enrich ordinary base types with a set of rich logical qualifiers to\nconstrain the set of values accepted by that type. We perform a search over a\ntree automata variant called Qualified Tree Automata that intelligently records\ninformation about enumerated terms, leveraging subtyping constraints over the\nrefinement types associated with these terms to enable reasoning about\nsimilarity among candidate solutions as search proceeds, thereby avoiding\nexploration of semantically similar paths.\n  We present an implementation of this idea in a tool called \\name, and provide\na comprehensive evaluation that demonstrates \\name's ability to synthesize\nsolutions to complex CBS queries that go well-beyond the capabilities of the\nexisting state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ec4\u4ef6\u5408\u6210\uff08CBS\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u641c\u7d22\u4e2d\u5229\u7528\u903b\u8f91\u76f8\u4f3c\u6027\u6765\u907f\u514d\u63a2\u7d22\u8bed\u4e49\u76f8\u4f3c\u7684\u8def\u5f84\uff0c\u4ece\u800c\u66f4\u9ad8\u6548\u5730\u5408\u6210\u6ee1\u8db3\u590d\u6742\u67e5\u8be2\u7684\u5faa\u73af\u65e0\u7a0b\u5e8f\u3002", "motivation": "\u4f20\u7edf\u7684\u7ec4\u4ef6\u5408\u6210\u65b9\u6cd5\u5728\u9762\u5bf9\u4e25\u683c\u7684\u903b\u8f91\u7ea6\u675f\u65f6\uff0c\u53ef\u884c\u89e3\u7684\u641c\u7d22\u7a7a\u95f4\u4f1a\u53d8\u5f97\u975e\u5e38\u7a00\u758f\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u5728\u590d\u6742\u7684\u7ea6\u675f\u6761\u4ef6\u4e0b\u9ad8\u6548\u5408\u6210\u7a0b\u5e8f\u6210\u4e3a\u4e86\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fee\u6b63\u7c7b\u578b\u89c4\u8303\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u5229\u7528\u79f0\u4e3a\u201c\u9650\u5b9a\u6811\u81ea\u52a8\u673a\u201d\u7684\u53d8\u4f53\u6765\u8bb0\u5f55\u679a\u4e3e\u9879\u7684\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u5b50\u7c7b\u578b\u7ea6\u675f\u63a8\u7406\u5019\u9009\u89e3\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u907f\u514d\u63a2\u7d22\u8bed\u4e49\u76f8\u4f3c\u7684\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u5de5\u5177\\name\u7684\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u5408\u6210\u8fdc\u8d85\u73b0\u6709\u6280\u672f\u7684\u590d\u6742CBS\u67e5\u8be2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u903b\u8f91\u76f8\u4f3c\u6027\u63a8\u7406\uff0c\u672c\u6587\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7ec4\u4ef6\u5408\u6210\u7684\u80fd\u529b\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u590d\u6742\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u7a0b\u5e8f\u5408\u6210\u95ee\u9898\u3002"}}
{"id": "2508.14879", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14879", "abs": "https://arxiv.org/abs/2508.14879", "authors": ["Bingquan Dai", "Li Ray Luo", "Qihong Tang", "Jie Wang", "Xinyu Lian", "Hao Xu", "Minghan Qin", "Xudong Xu", "Bo Dai", "Haoqian Wang", "Zhaoyang Lyu", "Jiangmiao Pang"], "title": "MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds", "comment": null, "summary": "Reconstructing 3D objects into editable programs is pivotal for applications\nlike reverse engineering and shape editing. However, existing methods often\nrely on limited domain-specific languages (DSLs) and small-scale datasets,\nrestricting their ability to model complex geometries and structures. To\naddress these challenges, we introduce MeshCoder, a novel framework that\nreconstructs complex 3D objects from point clouds into editable Blender Python\nscripts. We develop a comprehensive set of expressive Blender Python APIs\ncapable of synthesizing intricate geometries. Leveraging these APIs, we\nconstruct a large-scale paired object-code dataset, where the code for each\nobject is decomposed into distinct semantic parts. Subsequently, we train a\nmultimodal large language model (LLM) that translates 3D point cloud into\nexecutable Blender Python scripts. Our approach not only achieves superior\nperformance in shape-to-code reconstruction tasks but also facilitates\nintuitive geometric and topological editing through convenient code\nmodifications. Furthermore, our code-based representation enhances the\nreasoning capabilities of LLMs in 3D shape understanding tasks. Together, these\ncontributions establish MeshCoder as a powerful and flexible solution for\nprogrammatic 3D shape reconstruction and understanding.", "AI": {"tldr": "MeshCoder\u662f\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u5c063D\u70b9\u4e91\u91cd\u5efa\u4e3a\u53ef\u7f16\u8f91\u7684Blender Python\u811a\u672c\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548cLLM\u6280\u672f\u5b9e\u73b0\u590d\u6742\u51e0\u4f55\u7684\u5efa\u6a21\u548c\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u76843D\u5bf9\u8c61\u91cd\u5efa\u65b9\u6cd5\u4f9d\u8d56\u6709\u9650\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u5efa\u6a21\u590d\u6742\u51e0\u4f55\u548c\u7ed3\u6784\u3002MeshCoder\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u5957\u5168\u9762\u7684Blender Python API\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u914d\u5bf9\u5bf9\u8c61-\u4ee3\u7801\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86\u591a\u6a21\u6001LLM\uff0c\u5c06\u70b9\u4e91\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u811a\u672c\u3002", "result": "MeshCoder\u5728\u5f62\u72b6\u5230\u4ee3\u7801\u91cd\u5efa\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u76f4\u89c2\u7684\u51e0\u4f55\u548c\u62d3\u6251\u7f16\u8f91\uff0c\u5e76\u901a\u8fc7\u4ee3\u7801\u8868\u793a\u589e\u5f3aLLM\u76843D\u5f62\u72b6\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "MeshCoder\u4e3a3D\u5f62\u72b6\u7684\u7a0b\u5e8f\u5316\u91cd\u5efa\u548c\u7406\u89e3\u63d0\u4f9b\u4e86\u5f3a\u5927\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.14892", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14892", "abs": "https://arxiv.org/abs/2508.14892", "authors": ["Jia Lu", "Taoran Yi", "Jiemin Fang", "Chen Yang", "Chuiyun Wu", "Wei Shen", "Wenyu Liu", "Qi Tian", "Xinggang Wang"], "title": "Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds", "comment": "Project page: https://hustvl.github.io/Snap-Snap/", "summary": "Reconstructing 3D human bodies from sparse views has been an appealing topic,\nwhich is crucial to broader the related applications. In this paper, we propose\na quite challenging but valuable task to reconstruct the human body from only\ntwo images, i.e., the front and back view, which can largely lower the barrier\nfor users to create their own 3D digital humans. The main challenges lie in the\ndifficulty of building 3D consistency and recovering missing information from\nthe highly sparse input. We redesign a geometry reconstruction model based on\nfoundation reconstruction models to predict consistent point clouds even input\nimages have scarce overlaps with extensive human data training. Furthermore, an\nenhancement algorithm is applied to supplement the missing color information,\nand then the complete human point clouds with colors can be obtained, which are\ndirectly transformed into 3D Gaussians for better rendering quality.\nExperiments show that our method can reconstruct the entire human in 190 ms on\na single NVIDIA RTX 4090, with two images at a resolution of 1024x1024,\ndemonstrating state-of-the-art performance on the THuman2.0 and cross-domain\ndatasets. Additionally, our method can complete human reconstruction even with\nimages captured by low-cost mobile devices, reducing the requirements for data\ncollection. Demos and code are available at\nhttps://hustvl.github.io/Snap-Snap/.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u4ec5\u4e24\u5f20\u56fe\u50cf\uff08\u524d\u89c6\u56fe\u548c\u540e\u89c6\u56fe\uff09\u91cd\u5efa3D\u4eba\u4f53\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7528\u6237\u521b\u5efa3D\u6570\u5b57\u4eba\u7684\u95e8\u69db\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u4ece\u7a00\u758f\u89c6\u56fe\u91cd\u5efa3D\u4eba\u4f53\uff0c\u4ee5\u6269\u5c55\u76f8\u5173\u5e94\u7528\u8303\u56f4\uff0c\u5c24\u5176\u662f\u964d\u4f4e\u7528\u6237\u521b\u5efa3D\u6570\u5b57\u4eba\u7684\u96be\u5ea6\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u57fa\u4e8e\u57fa\u7840\u91cd\u5efa\u6a21\u578b\u8bbe\u8ba1\u7684\u51e0\u4f55\u91cd\u5efa\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u4e00\u81f4\u7684\u70b9\u4e91\uff0c\u4ee5\u53ca\u589e\u5f3a\u7b97\u6cd5\u8865\u5145\u7f3a\u5931\u7684\u989c\u8272\u4fe1\u606f\uff0c\u6700\u540e\u5c06\u70b9\u4e91\u8f6c\u6362\u4e3a3D\u9ad8\u65af\u6a21\u578b\u4ee5\u63d0\u9ad8\u6e32\u67d3\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5355\u5f20NVIDIA RTX 4090\u4e0a\u4ec5\u9700190\u6beb\u79d2\u5373\u53ef\u5b8c\u6210\u91cd\u5efa\uff0c\u4e14\u5728THuman2.0\u548c\u8de8\u57df\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8fd8\u80fd\u9002\u914d\u4f4e\u6210\u672c\u79fb\u52a8\u8bbe\u5907\u91c7\u96c6\u7684\u56fe\u50cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758f\u8f93\u5165\u4e0b\u91cd\u5efa3D\u4eba\u4f53\u7684\u6311\u6218\uff0c\u964d\u4f4e\u4e86\u6570\u636e\u91c7\u96c6\u8981\u6c42\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
