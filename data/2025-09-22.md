<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 8]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows](https://arxiv.org/abs/2509.15236)
*Shubham Kavane,Kajol Kulkarni,Harald Koestler*

Main category: cs.GR

TL;DR: ChannelFlow-Tools是一个配置驱动的框架，标准化了从CAD几何生成到ML输入和目标的3D通道流处理流程，支持可复现的ML训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D通道流数据生成和ML输入准备中的一致性和可复现性问题，提供了一个标准化的工具链。

Method: 该框架整合了几何合成、可行性检查、SDF体素化、HPC上的求解器自动化和多分辨率张量重采样，所有步骤由单一配置管理。

Result: 案例中生成了10,000多个场景，展示了存储权衡的端到端评估，以及标准化表示对ML训练的支持。

Conclusion: ChannelFlow-Tools将数据集创建转变为可配置和可复现的流程，适用于CFD替代模型开发。

Abstract: We present ChannelFlow-Tools, a configuration-driven framework that
standardizes the end-to-end path from programmatic CAD solid generation to
ML-ready inputs and targets for 3D obstructed channel flows. The toolchain
integrates geometry synthesis with feasibility checks, signed distance field
(SDF) voxelization, automated solver orchestration on HPC (waLBerla LBM), and
Cartesian resampling to co-registered multi-resolution tensors. A single
Hydra/OmegaConf configuration governs all stages, enabling deterministic
reproduction and controlled ablations. As a case study, we generate 10k+ scenes
spanning Re=100-15000 with diverse shapes and poses. An end-to-end evaluation
of storage trade-offs directly from the emitted artifacts, a minimal 3D U-Net
at 128x32x32, and example surrogate models with dataset size illustrate that
the standardized representations support reproducible ML training.
ChannelFlow-Tools turns one-off dataset creation into a reproducible,
configurable pipeline for CFD surrogate modeling.

</details>


### [2] [GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing](https://arxiv.org/abs/2509.15246)
*Nomi Yu,Md Ferdous Alam,A. John Hart,Faez Ahmed*

Main category: cs.GR

TL;DR: 本文提出了GenCAD-3D，一种多模态生成框架，结合对比学习和潜在扩散模型，用于从非参数数据生成CAD程序。同时，引入了SynthBal数据增强策略，显著提升了复杂CAD几何的重建精度和生成性能。


<details>
  <summary>Details</summary>
Motivation: 目前深度生成模型在自动化CAD生成方面因数据不平衡和不足而受限，特别是缺乏复杂CAD程序的表示。

Method: GenCAD-3D框架结合对比学习和潜在扩散模型，SynthBal策略用于数据增强。

Result: 实验显示SynthBal显著提升了重建精度，减少了无效CAD模型的生成，并在高复杂度几何上表现优异。

Conclusion: 该研究成果有望优化逆向工程并推动工程设计的自动化进程，相关数据集和代码将公开。

Abstract: CAD programs, structured as parametric sequences of commands that compile
into precise 3D geometries, are fundamental to accurate and efficient
engineering design processes. Generating these programs from nonparametric data
such as point clouds and meshes remains a crucial yet challenging task,
typically requiring extensive manual intervention. Current deep generative
models aimed at automating CAD generation are significantly limited by
imbalanced and insufficiently large datasets, particularly those lacking
representation for complex CAD programs. To address this, we introduce
GenCAD-3D, a multimodal generative framework utilizing contrastive learning for
aligning latent embeddings between CAD and geometric encoders, combined with
latent diffusion models for CAD sequence generation and retrieval.
Additionally, we present SynthBal, a synthetic data augmentation strategy
specifically designed to balance and expand datasets, notably enhancing
representation of complex CAD geometries. Our experiments show that SynthBal
significantly boosts reconstruction accuracy, reduces the generation of invalid
CAD models, and markedly improves performance on high-complexity geometries,
surpassing existing benchmarks. These advancements hold substantial
implications for streamlining reverse engineering and enhancing automation in
engineering design. We will publicly release our datasets and code, including a
set of 51 3D-printed and laser-scanned parts on our project site.

</details>


### [3] [Causal Reasoning Elicits Controllable 3D Scene Generation](https://arxiv.org/abs/2509.15249)
*Shen Chen,Ruiyu Zhao,Jiale Zhou,Zongkai Wu,Jenq-Neng Hwang,Lei Li*

Main category: cs.GR

TL;DR: CausalStruct通过因果推理增强3D场景生成，提升逻辑一致性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以建模对象间的复杂逻辑依赖和物理约束，限制了动态和真实环境的适应性。

Method: 嵌入因果推理框架，利用LLMs构建因果图，通过PID控制器优化对象位置和尺度，结合3D高斯飞溅和分数蒸馏采样提高准确性。

Result: 实验表明，CausalStruct生成的3D场景具有更强的逻辑一致性、真实空间交互和鲁棒适应性。

Conclusion: CausalStruct通过因果推理和物理约束的有效结合，显著提升了3D场景生成的真实感和动态适应性。

Abstract: Existing 3D scene generation methods often struggle to model the complex
logical dependencies and physical constraints between objects, limiting their
ability to adapt to dynamic and realistic environments. We propose
CausalStruct, a novel framework that embeds causal reasoning into 3D scene
generation. Utilizing large language models (LLMs), We construct causal graphs
where nodes represent objects and attributes, while edges encode causal
dependencies and physical constraints. CausalStruct iteratively refines the
scene layout by enforcing causal order to determine the placement order of
objects and applies causal intervention to adjust the spatial configuration
according to physics-driven constraints, ensuring consistency with textual
descriptions and real-world dynamics. The refined scene causal graph informs
subsequent optimization steps, employing a
Proportional-Integral-Derivative(PID) controller to iteratively tune object
scales and positions. Our method uses text or images to guide object placement
and layout in 3D scenes, with 3D Gaussian Splatting and Score Distillation
Sampling improving shape accuracy and rendering stability. Extensive
experiments show that CausalStruct generates 3D scenes with enhanced logical
coherence, realistic spatial interactions, and robust adaptability.

</details>


### [4] [Geometric Integration for Neural Control Variates](https://arxiv.org/abs/2509.15538)
*Daniel Meister,Takahiro Harada*

Main category: cs.GR

TL;DR: 该论文研究了如何将多层感知器（MLP）作为控制变量应用于蒙特卡罗积分中，提出了一种基于积分域细分的方法来解决其解析积分问题，并在光传输模拟中展示了其效果。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡罗积分中的控制变量是一种降低方差的技术，但通用的神经网络难以进行解析积分。本文旨在探索一种简单神经网络模型的解析积分方法，以提升蒙特卡罗积分的效率。

Method: 论文采用多层感知器（MLP）作为模型，结合连续分段线性激活函数，提出了一种基于积分域细分的解析积分方法，并利用计算几何技术在2D中解决这一问题。

Result: 研究发现MLP可以作为控制变量与提出的积分方法结合使用，并在光传输模拟中验证了其有效性。

Conclusion: 论文证明了MLP作为控制变量在蒙特卡罗积分中的潜力，为解决神经网络解析积分问题提供了新思路。

Abstract: Control variates are a variance-reduction technique for Monte Carlo
integration. The principle involves approximating the integrand by a function
that can be analytically integrated, and integrating using the Monte Carlo
method only the residual difference between the integrand and the
approximation, to obtain an unbiased estimate. Neural networks are universal
approximators that could potentially be used as a control variate. However, the
challenge lies in the analytic integration, which is not possible in general.
In this manuscript, we study one of the simplest neural network models, the
multilayered perceptron (MLP) with continuous piecewise linear activation
functions, and its possible analytic integration. We propose an integration
method based on integration domain subdivision, employing techniques from
computational geometry to solve this problem in 2D. We demonstrate that an MLP
can be used as a control variate in combination with our integration method,
showing applications in the light transport simulation.

</details>


### [5] [Implicit Modeling for 3D-printed Multi-material Computational Object Design via Python](https://arxiv.org/abs/2509.15562)
*Charles Wade,Devon Beck,Robert MacCurdy*

Main category: cs.GR

TL;DR: 本文介绍了一种开源贡献，旨在推动体积多材料增材制造和超材料设计的研究。我们提供了一个基于Python的灵活API，支持多材料梯度的参数化表达、外部库集成、多材料晶格结构设计以及与有限元建模的互操作性。


<details>
  <summary>Details</summary>
Motivation: 加速多材料增材制造和超材料设计的研究，提供一种灵活的工具链，支持从设计到模拟的完整流程。

Method: 采用新颖的隐式多材料建模技术，实现晶格结构中多尺度的详细空间分级，并结合有限元分析进行预测性模拟。

Result: 通过案例研究展示了这些工具的实用性，包括功能梯度晶格、算法生成的结构以及模拟驱动的设计，如优化的多材料自行车座椅。

Conclusion: 本文提出的框架通过灵活的API和兼容标准切片软件的网格导出策略，显著提高了多材料计算设计方法的可访问性和采用率。

Abstract: This paper introduces open-source contributions designed to accelerate
research in volumetric multi-material additive manufacturing and metamaterial
design. We present a flexible Python-based API facilitating parametric
expression of multi-material gradients, integration with external libraries,
multi-material lattice structure design, and interoperability with finite
element modeling. Novel implicit multi-material modeling techniques enable
detailed spatial grading at multiple scales within lattice structures.
Additionally, our framework integrates with finite element analysis, offering
predictive simulations via adaptive mesh sizing and direct import of simulation
results to guide material distributions. Practical case studies illustrate the
utility of these contributions, including functionally graded lattices,
algorithmically generated structures, and simulation-informed designs,
exemplified by a multi-material bicycle seat optimized for mechanical
performance and rider comfort. Finally, we introduce a mesh export strategy
compatible with standard slicing software, significantly broadening the
accessibility and adoption of functionality graded computational design
methodologies for multi-material fabrication.

</details>


### [6] [Fast subdivision of Bézier curves](https://arxiv.org/abs/2509.15691)
*Paweł Woźny,Filip Chudy*

Main category: cs.GR

TL;DR: 本文展示了如何使用快速傅里叶变换及其逆变换，将多项式贝塞尔曲线的细分问题从O(dn²)时间优化到O(dn log n)时间，并通过实验验证了改进后算法的数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现行de Casteljau算法在细分多项式贝塞尔曲线时时间复杂度过高的问题，提出了一种更高效的替代方法。

Method: 利用快速傅里叶变换及其逆变换，将细分问题的时间复杂度降低到O(dn log n)，并探讨了算法的数值稳定性及其改进版本。

Result: 实验表明，新方法在数值稳定性上有良好的表现，特别是经过改进后的版本。此外，新方法在扩展控制点时只需O(d)时间即可完成更新。

Conclusion: 新方法不仅显著提高了细分效率，还适用于有理贝塞尔曲线和矩形贝塞尔曲面的细分，以及贝塞尔曲线导数的快速计算。

Abstract: It is well-known that a $d$-dimensional polynomial B\'{e}zier curve of degree
$n$ can be subdivided into two segments using the famous de Casteljau algorithm
in $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper,
we show that it is possible to do this in $O(dn\log{n})$ time using the fast
Fourier transform and its inverse. Experiments show that the direct application
of the new method performs well only for small values of $n$, as the algorithm
is numerically unstable. However, a slightly modified version -- which still
has $O(dn\log{n})$ computational complexity -- offers good numerical quality,
which is confirmed by numerical experiments conducted in \textsf{Python}.
Moreover, the new method has a nice property: if a B\'{e}zier curve is extended
by an additional control point, the subdivision can be updated in $O(d)$ time.
  A similar idea can be applied to speed up the subdivision of rational
B\'{e}zier curves and rectangular B\'{e}zier surfaces, as well as to compute
the derivatives of B\'{e}zier curves more efficiently.

</details>


### [7] [MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes](https://arxiv.org/abs/2509.15892)
*Mohamed Ebbed,Zorah Lähner*

Main category: cs.GR

TL;DR: 本文提出了一种用于高细节动态场景重建的新框架，解决了现有方法在动态场景中提取的网格噪声大或过于平滑的问题。


<details>
  <summary>Details</summary>
Motivation: 动态场景的多视角视频重建在计算机视觉中是一个基础性挑战，现有的动态方法在新视角合成方面表现良好，但提取的网格质量不高，且几何保真度低。

Method: 该框架基于静态3D重建方法NeuralAngelo，通过从初始帧生成高质量的模板场景重建，并联合优化变形场以跟踪模板并基于时间序列进行细化。

Result: 在ActorsHQ数据集上，该方法展示了优于现有最先进方法的重建精度。

Conclusion: 该框架通过灵活的模板和联合优化的变形场，能够有效地处理动态场景中的几何变化，实现了高质量的重建结果。

Abstract: Dynamic scene reconstruction from multi-view videos remains a fundamental
challenge in computer vision. While recent neural surface reconstruction
methods have achieved remarkable results in static 3D reconstruction, extending
these approaches with comparable quality for dynamic scenes introduces
significant computational and representational challenges. Existing dynamic
methods focus on novel-view synthesis, therefore, their extracted meshes tend
to be noisy. Even approaches aiming for geometric fidelity often result in too
smooth meshes due to the ill-posedness of the problem. We present a novel
framework for highly detailed dynamic reconstruction that extends the static 3D
reconstruction method NeuralAngelo to work in dynamic settings. To that end, we
start with a high-quality template scene reconstruction from the initial frame
using NeuralAngelo, and then jointly optimize deformation fields that track the
template and refine it based on the temporal sequence. This flexible template
allows updating the geometry to include changes that cannot be modeled with the
deformation field, for instance occluded parts or the changes in the topology.
We show superior reconstruction accuracy in comparison to previous
state-of-the-art methods on the ActorsHQ dataset.

</details>


### [8] [Generating Detailed Character Motion from Blocking Poses](https://arxiv.org/abs/2509.16064)
*Purvi Goel,Guy Tevet,C. K. Liu,Kayvon Fatahalian*

Main category: cs.GR

TL;DR: 本文提出一种使用生成扩散模型解决运动细节化任务的方法，将粗糙的角色动画转化为自然细腻的动画效果。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型可以修正不精确时间点的姿势，但缺乏有效方法利用扩散先验将稀疏的阻挡姿势增强为更多细节的姿势。

Method: 采用推理时的简单技巧：在扩散步骤中，将无条件扩散模型的输出与输入阻挡姿势约束通过容忍权重混合，作为输入传递给已有的运动重时模型。

Result: 该方法显著优于现有通过混合模型输出或通过表达阻挡姿势约束作为指导的方法，首次实现了将阻挡级姿势稳健地转化为可信的细节化角色动画。

Conclusion: 通过结合无条件扩散模型和阻挡姿势约束的方法，成功开发出首个能够将粗糙动画转化为自然细腻动画的扩散模型。

Abstract: We focus on the problem of using generative diffusion models for the task of
motion detailing: converting a rough version of a character animation,
represented by a sparse set of coarsely posed, and imprecisely timed blocking
poses, into a detailed, natural looking character animation. Current diffusion
models can address the problem of correcting the timing of imprecisely timed
poses, but we find that no good solution exists for leveraging the diffusion
prior to enhance a sparse set of blocking poses with additional pose detail. We
overcome this challenge using a simple inference-time trick. At certain
diffusion steps, we blend the outputs of an unconditioned diffusion model with
input blocking pose constraints using per-blocking-pose tolerance weights, and
pass this result in as the input condition to an pre-existing motion retiming
model. We find this approach works significantly better than existing
approaches that attempt to add detail by blending model outputs or via
expressing blocking pose constraints as guidance. The result is the first
diffusion model that can robustly convert blocking-level poses into plausible
detailed character animations.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [9] [Automatic layout of railroad diagrams](https://arxiv.org/abs/2509.15834)
*Shardul Chiplunkar,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 本文提出了铁路图（语法图）布局的第一个正式处理方法，并通过一个原则性的实现解决了布局问题。


<details>
  <summary>Details</summary>
Motivation: 铁路图作为一种直观的语法可视化工具，由于缺乏正式布局方法和有限工具支持，通常仅用于手绘文档。本文旨在填补这一空白。

Method: 通过将问题描述为从‘图语言’（指定概念组件及其连接方式）到‘布局语言’（指定基本图形及其大小和位置）的编译，实现了一个编译器，支持自动换行、对齐和调整。

Result: 实验表明，该编译器能够将常见语法（如正则表达式和巴科斯范式）转换为铁路图，其输出与手绘图和其他工具的输出相比具有实用性。

Conclusion: 本文提出的方法为铁路图布局提供了首个正式解决方案，并通过实验验证了其有效性，为语法可视化工具的改进奠定了基础。

Abstract: Railroad diagrams (also called "syntax diagrams") are a common, intuitive
visualization of grammars, but limited tooling and a lack of formal attention
to their layout mostly confines them to hand-drawn documentation. We present
the first formal treatment of railroad diagram layout along with a principled,
practical implementation. We characterize the problem as compiling a *diagram
language* (specifying conceptual components and how they connect and compose)
to a *layout language* (specifying basic graphical shapes and their sizes and
positions). We then implement a compiler that performs *line wrapping* to meet
a target width, as well as vertical *alignment* and horizontal *justification*
per user-specified policies. We frame line wrapping as an optimization problem,
where we describe principled dimensions of optimality and implement
corresponding heuristics. For front-end evaluation, we show that our diagram
language is well-suited for common applications by describing how regular
expressions and Backus-Naur form can be compiled to it. For back-end
evaluation, we argue that our compiler is practical by comparing its output to
diagrams laid out by hand and by other tools.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [10] [Diversity of Structured Domains via k-Kemeny Scores](https://arxiv.org/abs/2509.15812)
*Piotr Faliszewski,Krzysztof Sornat,Stanisław Szufa,Tomasz Wąs*

Main category: cs.GT

TL;DR: 本文研究了k-Kemeny问题在多个结构化领域中的表现，发现其在大多数领域下仍然难以解决，并利用该问题对领域的多样性进行了排名。


<details>
  <summary>Details</summary>
Motivation: 研究k-Kemeny问题在结构化领域中的计算复杂性及其对领域多样性的衡量能力。

Method: 通过分析单峰、单交叉、群可分离和欧几里得等结构化领域，探讨k-Kemeny问题的计算复杂性。

Result: 研究结果表明，k-Kemeny在大多数结构化领域下仍然难以解决，尤其是对于k=2的情况。同时，该问题被用于对这些领域的多样性进行排名。

Conclusion: k-Kemeny问题在结构化领域中的计算复杂性较高，但它为衡量这些领域的多样性提供了有效的工具。

Abstract: In the k-Kemeny problem, we are given an ordinal election, i.e., a collection
of votes ranking the candidates from best to worst, and we seek the smallest
number of swaps of adjacent candidates that ensure that the election has at
most k different rankings. We study this problem for a number of structured
domains, including the single-peaked, single-crossing, group-separable, and
Euclidean ones. We obtain two kinds of results: (1) We show that k-Kemeny
remains intractable under most of these domains, even for k=2, and (2) we use
k-Kemeny to rank these domains in terms of their diversity.

</details>


### [11] [Strategy Improvement, the Simplex Algorithm and Lopsidedness](https://arxiv.org/abs/2509.16075)
*Matthew Maat*

Main category: cs.GT

TL;DR: 证明了策略改进算法与单纯形算法之间的直接联系，表明多种策略改进变体在非退化假设下是单纯形算法的实例，并揭示了图游戏策略集的组合性质。


<details>
  <summary>Details</summary>
Motivation: 探索策略改进算法与单纯形算法的相似性及其理论联系，弥补了先前研究中需要通过中间马尔可夫决策过程的局限性。

Method: 通过非退化假设，证明策略改进算法在公平性和均值支付博弈中是单纯形算法的实例。

Result: 建立了策略改进与单纯形算法的直接联系，揭示了图游戏中策略集的组合性质，特别是与不平衡集的关联。

Conclusion: 研究不仅深化了对策略改进算法的理解，还拓宽了其在博弈论和优化领域的应用潜力。

Abstract: The strategy improvement algorithm for mean payoff games and parity games is
a local improvement algorithm, just like the simplex algorithm for linear
programs. Their similarity has turned out very useful: many lower bounds on
running time for the simplex method have been created from lower bounds for
strategy improvement. However, earlier connections between these algorithms
required constructing an intermediate Markov decision process, which is not
always possible. We prove a formal, direct connection between the two
algorithms, showing that many variants of strategy improvement for parity and
mean payoff games are truly an instance of the simplex algorithm, under mild
nondegeneracy assumptions. As a result of this, we derive some combinatorial
properties of the structure of strategy sets of various related games on
graphs. In particular, we show a connection to lopsided sets.

</details>


### [12] [Strategic Analysis of Just-In-Time Liquidity Provision in Concentrated Liquidity Market Makers](https://arxiv.org/abs/2509.16157)
*Bruno Llacer Trotti,Weizhao Tang,Rachid El-Azouzi,Giulia Fanti,Daniel Sadoc Menasche*

Main category: cs.GT

TL;DR: 本文首次正式建模了集中流动性做市商（CLMMs）中的即时流动性提供（JIT LPs）行为，揭示其优化策略及对市场的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对即时流动性提供者（JIT LPs）行为的系统性理解，这些策略性代理通过单次交换试图获取高额费用，本文旨在填补这一空白。

Method: 通过建立交易级模型，分析了CLMMs中的价格影响和费用分配，并公式化JIT LPs的非线性优化问题，证明了最优策略的存在。

Result: 研究表明，在风险资产流动性池中，现有JIT LPs行为与最优策略存在显著差距，若考虑价格影响，收益可提高69%。此外，JIT流动性可提高市场效率，减少交易滑点，但会降低被动LP收益。

Conclusion: 本文为JIT LPs行为提供了理论模型和最优策略，展示了其对市场效率和被动LP收益的双重影响。

Abstract: Liquidity providers (LPs) are essential figures in the operation of automated
market makers (AMMs); in exchange for transaction fees, LPs lend the liquidity
that allows AMMs to operate. While many prior works have studied the incentive
structures of LPs in general, we currently lack a principled understanding of a
special class of LPs known as Just-In-Time (JIT) LPs. These are strategic
agents who momentarily supply liquidity for a single swap, in an attempt to
extract disproportionately high fees relative to the remaining passive LPs.
This paper provides the first formal, transaction-level model of JIT liquidity
provision for a widespread class of AMMs known as Concentrated Liquidity Market
Makers (CLMMs), as seen in Uniswap V3, for instance. We characterize the
landscape of price impact and fee allocation in these systems, formulate and
analyze a non-linear optimization problem faced by JIT LPs, and prove the
existence of an optimal strategy. By fitting our optimal solution for JIT LPs
to real-world CLMMs, we observe that in liquidity pools (particularly those
with risky assets), there is a significant gap between observed and optimal JIT
behavior. Existing JIT LPs often fail to account for price impact; doing so, we
estimate they could increase earnings by up to 69% on average over small time
windows. We also show that JIT liquidity, when deployed strategically, can
improve market efficiency by reducing slippage for traders, albeit at the cost
of eroding average passive LP profits by up to 44% per trade.

</details>
