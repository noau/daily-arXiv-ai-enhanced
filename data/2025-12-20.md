<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [A Fast Volumetric Capture and Reconstruction Pipeline for Dynamic Point Clouds and Gaussian Splats](https://arxiv.org/abs/2512.15719)
*Athanasios Charisoudis,Simone Croci,Lam Kit Yung,Pascal Frossard,Aljosa Smolic*

Main category: cs.GR

TL;DR: 快速高效的体积捕获与重建系统，支持RGB-D或RGB输入，生成点云和高斯溅射的3D表示，适用于野外操作和多相机配置。


<details>
  <summary>Details</summary>
Motivation: 现有的体积捕获和重建系统在处理RGB-D或RGB输入时，往往面临计算效率低和设置复杂的问题，研究团队旨在开发一个高效、易部署的系统，支持各种环境和相机配置。

Method: 改进了GPS-Gaussian回归器，实现了高质量的重建，并通过开源框架支持标准格式（如PLY、MPEG V-PCC和SPLAT）输出，提供实时预览。

Result: 系统在非受控光照和任意背景下表现良好，支持稀疏相机配置，并能以5-10 FPS的速度提供实时预览，具有良好的部署性和灵活性。

Conclusion: 提出的系统高效且易于部署，适用于多种环境和相机配置，开源框架进一步促进了研究的可重复性和扩展性。

Abstract: We present a fast and efficient volumetric capture and reconstruction system that processes either RGB-D or RGB-only input to generate 3D representations in the form of point clouds and Gaussian splats. For Gaussian splat reconstructions, we took the GPS-Gaussian regressor and improved it, enabling high-quality reconstructions with minimal overhead. The system is designed for easy setup and deployment, supporting in-the-wild operation under uncontrolled illumination and arbitrary backgrounds, as well as flexible camera configurations, including sparse setups, arbitrary camera numbers and baselines. Captured data can be exported in standard formats such as PLY, MPEG V-PCC, and SPLAT, and visualized through a web-based viewer or Unity/Unreal plugins. A live on-location preview of both input and reconstruction is available at 5-10 FPS. We present qualitative findings focused on deployability and targeted ablations. The complete framework is open-source, facilitating reproducibility and further research.

</details>


### [2] [Enhancing Line Density Plots with Outlier Control and Bin-based Illumination](https://arxiv.org/abs/2512.16017)
*Yumeng Xue,Bin Chen,Patrick Paetzold,Yunhai Wang,Christophe Hurter,Oliver Deussen*

Main category: cs.GR

TL;DR: 提出了一种基于分箱的照明模型，用于增强线基数据集的可视化，同时突出显示稀疏异常值，并在交互式分析中平衡主要趋势和异常值。


<details>
  <summary>Details</summary>
Motivation: 密度图在处理点数据集时有效，但在处理线基数据（如轨迹或时间序列）时会破坏路径连续性，掩盖平滑趋势和罕见异常。需要一种既能保持连续性又能突出异常值的方法。

Method: 使用基于分箱的照明模型，将结构与密度分离，并通过局部自适应光照在亮度通道中突出选定模式。此外，引入基于分箱的异常值度量来对轨迹进行排序。

Result: 该方法能够显著降低颜色失真（CIEDE2000），并支持高达10,000条线的交互式更新，表现出比简单替代方法更好的细节揭示能力。

Conclusion: 该方法在保持原始色彩映射的同时，有效增强了线基数据集的可视化，使分析师能够灵活地权衡主要趋势和异常值的关注。

Abstract: Density plots effectively summarize large numbers of points, which would otherwise lead to severe overplotting in, for example, a scatter plot. However, when applied to line-based datasets, such as trajectories or time series, density plots alone are insufficient, as they disrupt path continuity, obscuring smooth trends and rare anomalies. We propose a bin-based illumination model that decouples structure from density to enhance flow and reveal sparse outliers while preserving the original colormap. We introduce a bin-based outlierness metric to rank trajectories. Guided by this ranking, we construct a structural normal map and apply locally-adaptive lighting in the luminance channel to highlight chosen patterns -- from dominant trends to atypical paths -- with acceptable color distortion. Our interactive method enables analysts to prioritize main trends, focus on outliers, or strike a balance between the two. We demonstrate our method on several real-world datasets, showing it reveals details missed by simpler alternatives, achieves significantly lower CIEDE2000 color distortion than standard shading, and supports interactive updates for up to 10,000 lines.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2512.15766)
*Yijie Zhi,Yayu Cao,Jianhua Dai,Xiaoyang Han,Jingwen Pu,Qingran Wu,Sheng Cheng,Ming Cai*

Main category: cs.PL

TL;DR: LOOPRAG是一种新颖的检索增强生成框架，旨在通过参数驱动的方法和反馈机制指导LLMs进行有效的循环优化，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在循环变换优化中表现不佳，常导致错误或次优优化，LOOPRAG旨在解决这一问题。

Method: 提出LOOPRAG框架，结合循环特性触发的参数驱动方法、平衡相似性和多样性的检索算法，以及基于反馈的迭代机制。

Result: 在PolyBench、TSVC和LORE基准测试中，LOOPRAG相比基础编译器和LLMs分别实现了最高11.20×、14.34×和9.29×的性能提升。

Conclusion: LOOPRAG通过检索增强和反馈机制显著提升了LLMs在循环优化中的表现，优于现有编译器和LLMs。

Abstract: Loop transformations are semantics-preserving optimization techniques, widely used to maximize objectives such as parallelism. Despite decades of research, applying the optimal composition of loop transformations remains challenging due to inherent complexities, including cost modeling for optimization objectives. Recent studies have explored the potential of Large Language Models (LLMs) for code optimization. However, our key observation is that LLMs often struggle with effective loop transformation optimization, frequently leading to errors or suboptimal optimization, thereby missing opportunities for performance improvements. To bridge this gap, we propose LOOPRAG, a novel retrieval-augmented generation framework designed to guide LLMs in performing effective loop optimization on Static Control Part. We introduce a parameter-driven method to harness loop properties, which trigger various loop transformations, and generate diverse yet legal example codes serving as a demonstration source. To effectively obtain the most informative demonstrations, we propose a loop-aware algorithm based on loop features, which balances similarity and diversity for code retrieval. To enhance correct and efficient code generation, we introduce a feedback-based iterative mechanism that incorporates compilation, testing and performance results as feedback to guide LLMs. Each optimized code undergoes mutation, coverage and differential testing for equivalence checking. We evaluate LOOPRAG on PolyBench, TSVC and LORE benchmark suites, and compare it against compilers (GCC-Graphite, Clang-Polly, Perspective and ICX) and representative LLMs (DeepSeek and GPT-4). The results demonstrate average speedups over base compilers of up to 11.20$\times$, 14.34$\times$, and 9.29$\times$ for PolyBench, TSVC, and LORE, respectively, and speedups over base LLMs of up to 11.97$\times$, 5.61$\times$, and 11.59$\times$.

</details>


### [4] [Automated Formalization of Probabilistic Requirements from Structured Natural Language](https://arxiv.org/abs/2512.15788)
*Anastasia Mavridou,Marie Farrell,Gricel Vázquez,Tom Pressburger,Timothy E. Wang,Radu Calinescu,Michael Fisher*

Main category: cs.PL

TL;DR: 本文提出了一种扩展NASA形式化需求获取工具（FRET）的方法，支持使用结构化自然语言明确指定概率性需求，并自动化转换为概率时态逻辑公式，从而降低开发者的认知负担。


<details>
  <summary>Details</summary>
Motivation: 在安全和任务关键系统中，不确定性需求难以用传统方式表达，且直接使用复杂的形式化语言容易出错。因此，需要一种既能捕获不确定性又能降低开发者负担的方法。

Method: 扩展FRET工具的结构化自然语言支持，支持概率性需求的明确表达，并通过自动化方法将其转换为概率时态逻辑公式。

Result: 开发了一种自动化翻译方法，能够生成符合语义要求的概率时态逻辑公式，并通过验证框架和形式化证明确保其正确性。

Conclusion: 扩展后的FRET工具使开发者能够以结构化自然语言指定概率性需求，并自动化转换为形式化逻辑，为自主和自适应系统的形式化分析提供了更实用且低错误率的方法。

Abstract: Integrating autonomous and adaptive behavior into software-intensive systems presents significant challenges for software development, as uncertainties in the environment or decision-making processes must be explicitly captured. These challenges are amplified in safety- and mission-critical systems, which must undergo rigorous scrutiny during design and development. Key among these challenges is the difficulty of specifying requirements that use probabilistic constructs to capture the uncertainty affecting these systems. To enable formal analysis, such requirements must be expressed in precise mathematical notations such as probabilistic logics. However, expecting developers to write requirements directly in complex formalisms is unrealistic and highly error-prone. We extend the structured natural language used by NASA's Formal Requirement Elicitation Tool (FRET) with support for the specification of unambiguous and correct probabilistic requirements, and develop an automated approach for translating these requirements into logical formulas. We propose and develop a formal, compositional, and automated approach for translating structured natural-language requirements into formulas in probabilistic temporal logic. To increase trust in our formalizations, we provide assurance that the generated formulas are well-formed and conform to the intended semantics through an automated validation framework and a formal proof. The extended FRET tool enables developers to specify probabilistic requirements in structured natural language, and to automatically translate them into probabilistic temporal logic, making the formal analysis of autonomous and adaptive systems more practical and less error-prone.

</details>


### [5] [A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning](https://arxiv.org/abs/2512.15816)
*Daragh King,Vasileios Koutavas,Laura Kovacs*

Main category: cs.PL

TL;DR: NeuroInv是一种结合神经推理和符号验证的方法，用于生成循环不变量，在150个Java程序中实现了99.5%的成功率，并在复杂场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化程序验证中的循环不变量生成仍是一个瓶颈，现有LLM方法缺乏可靠且结构化的方法论，且与程序验证理论结合不足。

Method: NeuroInv由神经推理模块（利用LLM和Hoare逻辑通过反向链式最弱前置条件推理生成和优化候选不变量）和验证引导的符号模块（利用OpenJML的反例迭代修复不变量）组成。

Result: 在150个Java程序的综合基准测试中，NeuroInv实现了99.5%的成功率，显著优于其他方法；在10个大型多循环程序中也展示了优异的扩展性。

Conclusion: NeuroInv是一种高效且可扩展的循环不变量生成方法，适用于复杂的程序验证场景。

Abstract: Loop invariant generation remains a critical bottleneck in automated program verification. Recent work has begun to explore the use of Large Language Models (LLMs) in this area, yet these approaches tend to lack a reliable and structured methodology, with little reference to existing program verification theory. This paper presents NeuroInv, a neurosymbolic approach to loop invariant generation. NeuroInv comprises two key modules: (1) a neural reasoning module that leverages LLMs and Hoare logic to derive and refine candidate invariants via backward-chaining weakest precondition reasoning, and (2) a verification-guided symbolic module that iteratively repairs invariants using counterexamples from OpenJML. We evaluate NeuroInv on a comprehensive benchmark of 150 Java programs, encompassing single and multiple (sequential) loops, multiple arrays, random branching, and noisy code segments. NeuroInv achieves a $99.5\%$ success rate, substantially outperforming the other evaluated approaches. Additionally, we introduce a hard benchmark of $10$ larger multi-loop programs (with an average of $7$ loops each); NeuroInv's performance in this setting demonstrates that it can scale to more complex verification scenarios.

</details>


### [6] [Optimizing Agentic Language Model Inference via Speculative Tool Calls](https://arxiv.org/abs/2512.15834)
*Daniel Nichols,Prajwal Singhania,Charles Jekel,Abhinav Bhatele,Harshitha Menon*

Main category: cs.PL

TL;DR: 本文介绍了针对语言模型工具调用性能瓶颈的系统优化方法，通过推测工具调用和保持序列驻留以减少开销，显著提高了推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越依赖外部工具，工具调用成为推理过程中的性能瓶颈。本文旨在解决这一问题，优化推理效率。

Method: 提出了一种新颖的系统优化方法，包括推测工具调用和保持序列驻留在推理引擎中，以减少开销。并通过理论分析确定了最佳性能的推测配置。

Result: 优化后的系统在语言模型代理的推理吞吐量上实现了每秒数百个令牌的提升。

Conclusion: 本文提出的优化方法显著提高了推理效率，并建议引入"工具缓存"API端点以便语言模型提供商轻松采用这些优化。

Abstract: Language models (LMs) are becoming increasingly dependent on external tools. LM-based agentic frameworks frequently interact with their environment via such tools to search files, run code, call APIs, etc. Further, modern reasoning-based LMs use tools such as web search and Python code execution to enhance their reasoning capabilities. While tools greatly improve the capabilities of LMs, they also introduce performance bottlenecks during the inference process. In this paper, we introduce novel systems optimizations to address such performance bottlenecks by speculating tool calls and forcing sequences to remain resident in the inference engine to minimize overheads. Our optimizations lead to throughput improvements of several hundred tokens per second when hosting inference for LM agents. We provide a theoretical analysis of our algorithms to provide insights into speculation configurations that will yield the best performance. Further, we recommend a new "tool cache" API endpoint to enable LM providers to easily adopt these optimizations.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Algorithmic Monetary Policies for Blockchain Participation Games](https://arxiv.org/abs/2512.16514)
*Diodato Ferraioli,Paolo Penna,Manvir Schneider,Carmine Ventre*

Main category: cs.GT

TL;DR: 论文提出了一种区块链代币经济学的框架，通过算法货币政策在重复参与游戏中平衡短期性能激励与长期去中心化目标。分析了两种代理行为下的均衡情况，并探讨了虚拟股权的作用。


<details>
  <summary>Details</summary>
Motivation: 区块链代币经济学中，短期性能激励与长期去中心化目标之间存在矛盾。论文旨在设计一种框架来解决这一矛盾。

Method: 提出了一个算法货币政策框架，代理根据类型和股权选择参与或放弃，政策通过概率选择高类型代理执行任务以最大化吞吐量，同时分配奖励以维持去中心化。分析了短视和远见代理行为下的均衡。

Result: 短期内，以性能为中心的政策可能导致中心化，而远见行为能够实现稳定的去中心化。虚拟股权的初始分配对长期结果有重要影响。

Conclusion: 政策需要间接管理去中心化，虚拟股权作为一种混合方法可能更有效。

Abstract: A central challenge in blockchain tokenomics is aligning short-term performance incentives with long-term decentralization goals. We propose a framework for algorithmic monetary policies that navigates this tradeoff in repeated participation games. Agents, characterized by type (capability) and stake, choose to participate or abstain at each round; the policy (probabilistically) selects high-type agents for task execution (maximizing throughput) while distributing rewards to sustain decentralization. We analyze equilibria under two agent behaviors: myopic (short-term utility maximization) and foresighted (multi-round planning). For myopic agents, performance-centric policies risk centralization, but foresight enables stable decentralization with some volatility to the token value. We further discuss virtual stake--a hybrid of type and stake--as an alternative approach. We show that the initial virtual stake distribution critically impacts long-term outcomes, suggesting that policies must indirectly manage decentralization.

</details>


### [8] [Online Resource Allocation via Static Bundle Pricing](https://arxiv.org/abs/2512.16570)
*Dimitris Fotakis,Charalampos Platanos,Thanos Tolias*

Main category: cs.GT

TL;DR: 该论文研究了在线资源分配问题，特别关注买家评估互补性的情况，开发了一种统一的静态捆绑定价机制，应用于三个领域，并在理论和实际上提供了性能保障。


<details>
  <summary>Details</summary>
Motivation: 现有机制难以有效处理买家评估互补性的情况，标准的物品定价机制和静态捆绑定价机制分别存在不足。论文旨在开发一种统一的方法来解决这些问题。

Method: 论文提出了一种统一的静态匿名捆绑定价技术，应用于三个领域：(i) 最大捆绑大小为$d$的单目标组合拍卖，(ii) 一般单目标组合拍卖，(iii) 基于图的流路由模型。该方法利用物品容量的指数级改进性能。

Result: 在$d$-单目标设置中，最小物品容量为$B$时，获得了$O(d^{1/B})$-竞争机制；在一般单目标组合拍卖和图形路由模型中，获得了$O(m^{1/(B+1)})$-竞争机制。论文还提出了信息理论下界，表明在这些情况下无法超越特定竞争比率。

Conclusion: 论文揭示了与极值组合问题的深刻联系，提供了一种高效处理在线资源分配中互补性问题的方法，并在理论和实际上证明了其优越性。

Abstract: Online Resource Allocation addresses the problem of efficiently allocating limited resources to buyers with incomplete knowledge of future requests. In our setting, buyers arrive sequentially demanding a set of items, each with a value drawn from a known distribution. We study environments where buyers' valuations exhibit complementarities. In such settings, standard item-pricing mechanisms fail to leverage item multiplicities, while existing static bundle-pricing mechanisms rely on problem-specific arguments that do not generalize.
  We develop a unified technique for online resource allocation with complementarities for three domains: (i) single-minded combinatorial auctions with maximum bundle size $d$, (ii) general single-minded combinatorial auctions, and (iii) a graph-based routing model in which buyers request to route a unit of flow from a source node $s$ to a target node $t$ in a capacitated graph. Our approach yields static and anonymous bundle-pricing mechanisms whose performance improves exponentially with item capacities. For the $d$-single-minded setting with minimum item capacity $B$, we obtain an $O(d^{1/B})$-competitive mechanism, recovering the known $O(d)$ bound for unit capacities ($B=1$) and achieving exponentially better guarantees as capacities grow. For general single-minded combinatorial auctions and the graph-routing model, we obtain $O(m^{1/(B+1)})$-competitive mechanisms, where $m$ is the number of items.
  We complement these results with information-theoretic lower bounds. We show that no online algorithm can achieve a competitive ratio better than $Ω((m/\ln m)^{1/(B+2)})$ in the general single-minded setting and $Ω((d/\ln d)^{1/(B+1)})$ in the $d$-single-minded setting. In doing so, we reveal a deep connection to the extremal combinatorics problem of determining the maximum number of qualitatively independent partitions of a ground set.

</details>


### [9] [On the Edge of Core (Non-)Emptiness: An Automated Reasoning Approach to Approval-Based Multi-Winner Voting](https://arxiv.org/abs/2512.16895)
*Ratip Emin Berker,Emanuel Tewolde,Vincent Conitzer,Mingyu Guo,Marijn Heule,Lirong Xia*

Main category: cs.GT

TL;DR: 该论文研究了在多人投票中选择委员会时核心稳定性是否存在的问题，提出了一种基于混合整数线性规划的方法，并揭示了核心稳定性与其他理想性质之间的关系。


<details>
  <summary>Details</summary>
Motivation: 核心稳定性是多获胜者投票中群体公平性的一个重要概念，但在选民对候选人表示赞同或不赞同的情况下，是否存在核心稳定的委员会仍是一个未解决的问题。本文旨在解决这一问题。

Method: 论文采用基于混合整数线性规划的方法，相较于计算社会科学中常见的基于SAT的方法，该方法能够针对特定数量的候选人生成证明，而与选民数量无关。

Result: 该方法不仅提高了计算效率，还通过基于对偶性的重新表述，得到了在特定情况下核心稳定性的新存在性结果。此外，该方法揭示了核心稳定性与其他性质（如priceability）之间先前未知的关系。

Conclusion: 通过新的方法和框架，论文为解决核心稳定性的存在问题提供了新的途径，并丰富了对此类公平性问题的理解。

Abstract: Core stability is a natural and well-studied notion for group fairness in multi-winner voting, where the task is to select a committee from a pool of candidates. We study the setting where voters either approve or disapprove of each candidate; here, it remains a major open problem whether a core-stable committee always exists. In this work, we develop an approach based on mixed-integer linear programming for deciding whether and when core-stable committees are guaranteed to exist. In contrast to SAT-based approaches popular in computational social choice, our method can produce proofs for a specific number of candidates independent of the number of voters. In addition to these computational gains, our program lends itself to a novel duality-based reformulation of the core stability problem, from which we obtain new existence results in special cases. Further, we use our framework to reveal previously unknown relationships between core stability and other desirable properties, such as notions of priceability.

</details>
