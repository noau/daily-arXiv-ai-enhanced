<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [VoroUDF: Meshing Unsigned Distance Fields with Voronoi Optimization](https://arxiv.org/abs/2602.02907)
*Ningna Wang,Zilong Wang,Xiana Carrera,Xiaohu Guo,Silvia Sellán*

Main category: cs.GR

TL;DR: VoroUDF是一种从无符号距离场(UDFs)重建高质量三角网格的算法，支持非流形几何、锐利特征和开放边界，且不依赖于易错的内部/外部估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建非流形几何和复杂拓扑时存在局限，VoroUDF旨在解决这些问题，提高拓扑一致性和几何保真度。

Method: 基于Voronoi的算法结合L_1切向最小化和特征感知排斥，无需依赖误差敏感的优化或查找表。

Result: 相比现有方法，VoroUDF显著提升了拓扑一致性和几何精度，生成适用于实时交互应用的轻量级网格。

Conclusion: VoroUDF在复杂表面重建中表现出色，为下游应用提供了高质量的几何模型。

Abstract: We present VoroUDF, an algorithm for reconstructing high-quality triangle meshes from Unsigned Distance Fields (UDFs). Our algorithm supports non-manifold geometry, sharp features, and open boundaries, without relying on error-prone inside/outside estimation, restrictive look-up tables nor topologically noisy optimization. Our Voronoi-based formulation combines a L_1 tangent minimization with feature-aware repulsion to robustly recover complex surface topology. It achieves significantly improved topological consistency and geometric fidelity compared to existing methods, while producing lightweight meshes suitable for downstream real-time and interactive applications.

</details>


### [2] [Role of Graphics in Disaster Communication: Practitioner Perspectives on Use, Challenges, and Inclusivity](https://arxiv.org/abs/2602.02947)
*Anuradha Madugall,Yuqing Xiao,John Grundy*

Main category: cs.GR

TL;DR: 该论文探讨了灾害风险沟通中信息图形的使用现状、挑战及其包容性问题，发现尽管图形被广泛依赖，但在视觉障碍者、老年人及多元文化群体中仍存在可访问性差距。


<details>
  <summary>Details</summary>
Motivation: 灾害信息图形在风险沟通中至关重要，但现有研究对其实际效果和包容性缺乏实证分析。

Method: 通过半结构化访谈，研究了灾害信息图形的制作与使用现状，以及弱势群体面临的障碍。

Result: 研究显示，虽然图形被广泛依赖，但弱势群体的可访问性仍存在显著差距，且紧急情况下难以实现包容性调整。

Conclusion: 研究提出了提升灾害图形包容性的一系列建议，并为技术支持和适应性设计指明了研究方向。

Abstract: Information graphics, such as hazard maps, evacuation diagrams, and pictorial action guides, are widely used in disaster risk communication. These visuals are important because they convey hazard information quickly, reduce reliance on lengthy text, and support decision-making in time-critical situations. However, despite their importance, disaster information graphics do not work equally well for all audiences. In practice, many graphics remain difficult to interpret, and their accessibility for vulnerable populations is still uneven and underexplored. Despite their central role, there has been little empirical work examining how graphics shape disaster communication, what challenges practitioners face in using them, and, most importantly, how inclusive current disaster graphics are in real-world settings. To address this gap, we examine how information graphics are currently produced and used in disaster communication, what issues emerge in practice, and how inclusivity is addressed. We conducted semi-structured interviews with disaster communication practitioners and researchers to examine the role of graphics across preparedness, warning, and response contexts, as well as the barriers experienced by vulnerable communities. Our findings show that graphics are widely expected and heavily relied upon, yet significant accessibility gaps persist for groups such as people with vision impairments, older adults, and culturally and linguistically diverse communities. Participants also highlighted that inclusive adaptations are difficult to achieve during unfolding emergencies due to operational constraints, limited guidance, and resource barriers. Based on these findings, we outline recommendations for disaster management agencies and graphic designers and identify research directions for technological and adaptive support to make disaster graphics more inclusive at scale.

</details>


### [3] [WebSplatter: Enabling Cross-Device Efficient Gaussian Splatting in Web Browsers via WebGPU](https://arxiv.org/abs/2602.03207)
*Yudong Han,Chao Xu,Xiaodan Ye,Weichen Bi,Zilong Dong,Yun Ma*

Main category: cs.GR

TL;DR: WebSplatter是一种面向异构Web生态系统的端到端GPU渲染管线，通过无等待分层基数排序和不透明度感知的几何剔除，显著提升了渲染速度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决WebGPU中缺乏全局原子操作的问题，并优化渲染管线的性能，以适应多样化的硬件环境。

Method: 引入无等待分层基数排序规避WebGPU的限制，并设计了动态剔除阶段以减少过度绘制和内存占用。

Result: WebSplatter在评估中表现出1.2倍到4.5倍的速度提升，优于当前最先进的Web渲染器。

Conclusion: WebSplatter通过创新的排序和剔除技术，为异构Web生态系统提供了高效且稳定的渲染解决方案。

Abstract: We present WebSplatter, an end-to-end GPU rendering pipeline for the heterogeneous web ecosystem. Unlike naive ports, WebSplatter introduces a wait-free hierarchical radix sort that circumvents the lack of global atomics in WebGPU, ensuring deterministic execution across diverse hardware. Furthermore, we propose an opacity-aware geometry culling stage that dynamically prunes splats before rasterization, significantly reducing overdraw and peak memory footprint. Evaluation demonstrates that WebSplatter consistently achieves 1.2$\times$ to 4.5$\times$ speedups over state-of-the-art web viewers.

</details>


### [4] [Pi-GS: Sparse-View Gaussian Splatting with Dense π^3 Initialization](https://arxiv.org/abs/2602.03327)
*Manuel Hofer,Markus Steinberger,Thomas Köhler*

Main category: cs.GR

TL;DR: 提出了一种基于π^3网络的鲁棒方法，用于稀疏视角下的3D高斯泼溅（3DGS）初始化，结合密集初始化和几何正则化，实现了高性能的新视角合成。


<details>
  <summary>Details</summary>
Motivation: 3DGS在稀疏视角下依赖准确的相机姿态和高质量点云初始化，传统方法（如SfM）难以胜任，现有学习方法对参考视角和姿态误差敏感，亟需一种更鲁棒的解决方案。

Method: 提出了基于π^3网络的无参考点云估计方法，结合密集初始化与正则化方案（不确定性引导的深度监督、法线一致性损失和深度扭曲）。

Result: 在Tanks and Temples、LLFF、DTU和MipNeRF360数据集上实现了最先进的性能。

Conclusion: 该方法通过鲁棒的点云初始化和几何正则化，显著提升了稀疏视角下的3D高斯泼溅性能。

Abstract: Novel view synthesis has evolved rapidly, advancing from Neural Radiance Fields to 3D Gaussian Splatting (3DGS), which offers real-time rendering and rapid training without compromising visual fidelity. However, 3DGS relies heavily on accurate camera poses and high-quality point cloud initialization, which are difficult to obtain in sparse-view scenarios. While traditional Structure from Motion (SfM) pipelines often fail in these settings, existing learning-based point estimation alternatives typically require reliable reference views and remain sensitive to pose or depth errors. In this work, we propose a robust method utilizing π^3, a reference-free point cloud estimation network. We integrate dense initialization from π^3 with a regularization scheme designed to mitigate geometric inaccuracies. Specifically, we employ uncertainty-guided depth supervision, normal consistency loss, and depth warping. Experimental results demonstrate that our approach achieves state-of-the-art performance on the Tanks and Temples, LLFF, DTU, and MipNeRF360 datasets.

</details>


### [5] [Split&Splat: Zero-Shot Panoptic Segmentation via Explicit Instance Modeling and 3D Gaussian Splatting](https://arxiv.org/abs/2602.03809)
*Leonardo Monchieri,Elena Camuffo,Francesco Barbato,Pietro Zanuttigh,Simone Milani*

Main category: cs.GR

TL;DR: Split&Splat提出了一种基于3D高斯泼溅（GS）的泛光场景重建框架，通过显式建模物体实例并嵌入语义描述符，实现了高效且语义感知的场景重建。


<details>
  <summary>Details</summary>
Motivation: 传统的3D高斯泼溅方法在场景重建中缺乏对象一致性和语义感知结构，Split&Splat旨在解决这一问题。

Method: Split&Splat首先使用深度信息在多视角中传播实例掩码，生成视角一致的2D掩码；然后独立重建每个物体并精细边界；最后嵌入实例级语义描述符。

Result: 该方法在ScanNetv2分割基准测试中达到了最先进的性能，并支持泛光分割、物体检索和3D编辑等应用。

Conclusion: Split&Splat通过先分割场景再独立重建物体的设计，不仅解决了传统方法的局限性，还为下游任务提供了自然支持。

Abstract: 3D Gaussian Splatting (GS) enables fast and high-quality scene reconstruction, but it lacks an object-consistent and semantically aware structure. We propose Split&Splat, a framework for panoptic scene reconstruction using 3DGS. Our approach explicitly models object instances. It first propagates instance masks across views using depth, thus producing view-consistent 2D masks. Each object is then reconstructed independently and merged back into the scene while refining its boundaries. Finally, instance-level semantic descriptors are embedded in the reconstructed objects, supporting various applications, including panoptic segmentation, object retrieval, and 3D editing. Unlike existing methods, Split&Splat tackles the problem by first segmenting the scene and then reconstructing each object individually. This design naturally supports downstream tasks and allows Split&Splat to achieve state-of-the-art performance on the ScanNetv2 segmentation benchmark.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Layered Modal ML: Syntax and Full Abstraction](https://arxiv.org/abs/2602.03033)
*Haoxuan Yin,Andrzej S. Murawski,C. -H. Luke Ong*

Main category: cs.PL

TL;DR: LMML是一种新型的元编程语言，首次支持在强类型安全保证下存储和运行开放代码，并通过语义模型验证程序优化的等价性。


<details>
  <summary>Details</summary>
Motivation: 为了解决高阶引用代码中自由变量逃脱绑定器的问题，同时确保类型安全，本文提出了LMML语言。

Method: 使用上下文模态类型系统跟踪和推理代码中的自由变量，并通过操作游戏语义推导的迹建立语义模型。

Result: LMML是第一个支持开放代码存储和运行的强类型安全元编程语言，并首次实现了命令式MetaML风格语言的完全抽象结果。

Conclusion: LMML的类型系统和语义模型为元编程提供了可靠的类型安全和程序等价性验证方法。

Abstract: MetaML-style metaprogramming languages allow programmers to construct, manipulate and run code. In the presence of higher-order references for code, ensuring type safety is challenging, as free variables can escape their binders. In this paper, we present Layered Modal ML (LMML), \textit{the first metaprogramming language that supports storing and running open code under a strong type safety guarantee}. The type system utilises contextual modal types to track and reason about free variables in code explicitly.
  A crucial concern in metaprogramming-based program optimisations is whether the optimised program preserves the meaning of the original program. Addressing this question requires a notion of program equivalence and techniques to reason about it. In this paper, we provide a semantic model that captures contextual equivalence for LMML, establishing \textit{the first full abstraction result for an imperative MetaML-style language}. Our model is based on traces derived via operational game semantics, where the meaning of a program is modelled by its possible interactions with the environment. We also establish a novel closed instances of use theorem that accounts for both call-by-value and call-by-name closing substitutions.

</details>


### [7] [From Separate Compilation to Sound Language Composition](https://arxiv.org/abs/2602.03777)
*Federico Bruzzone,Walter Cazzola,Luca Favalli*

Main category: cs.PL

TL;DR: 本文介绍了 nlgcheck，一种基于数据流分析的静态分析工具，用于解决 Neverlang 语言工作台中因属性文法扩展导致的运行时错误问题，同时保持了模块化和灵活性。


<details>
  <summary>Details</summary>
Motivation: 为了解决编程语言扩展中因属性文法扩展导致的运行时错误问题，特别是在支持单独编译的情况下，现有方法（如 Neverlang 的动态映射）以牺牲编译时正确性为代价换取灵活性。本文旨在通过静态分析工具 nlgcheck 提供更强的静态正确性保证。

Method: nlgcheck 是一种基于数据流分析的静态分析工具，专门针对 Neverlang 语言工作台设计。它通过静态分析检测潜在的运行时错误（如未定义属性访问），以确保单独编译时的正确性。

Result: 实验评估表明，nlgcheck 在 Neverlang 项目中有效提升了鲁棒性，且不影响模块化或灵活性。其性能水平足以支持日常开发活动。

Conclusion: nlgcheck 通过数据流分析解决了属性文法扩展中的潜在问题，为 Neverlang 提供了更强的静态正确性保障，同时保持了开发效率和灵活性。

Abstract: The development of programming languages involves complex theoretical and practical challenges, particularly when addressing modularity and reusability through language extensions. While language workbenches aim to enable modular development under the constraints of the language extension problem, one critical constraint -- separate compilation -- is often relaxed due to its complexity. However, this relaxation undermines artifact reusability and integration with common dependency systems. A key difficulty under separate compilation arises from managing attribute grammars, as extensions may introduce new attributes that invalidate previously generated abstract syntax tree structures. Existing approaches, such as the use of dynamic maps in the Neverlang workbench, favor flexibility at the cost of compile-time correctness, leading to potential runtime errors due to undefined attributes. This work addresses this issue by introducing nlgcheck, a theoretically sound static analysis tool based on data-flow analysis for the Neverlang language workbench. nlgcheck detects potential runtime errors -- such as undefined attribute accesses -- at compile time, preserving separate compilation while maintaining strong static correctness guarantees. Experimental evaluation using mutation testing on Neverlang-based projects demonstrates that nlgcheck effectively enhances robustness without sacrificing modularity or flexibility and with a level of performance that does not impede its adoption in daily development activities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [8] [A two-player version of the assignment problem](https://arxiv.org/abs/2602.02628)
*Florian Galliot,Nacim Oijid,Jonas Sénizergues*

Main category: cs.GT

TL;DR: 本文介绍了一个名为竞争分配问题的双玩家版本分配问题，Alice和Bob轮流选择代理，并通过最优分配计算得分，目标是最大化或最小化得分。


<details>
  <summary>Details</summary>
Motivation: 该问题的动机是模拟体育和卡牌游戏中的选秀过程，或者更一般地，两个实体争夺资源并利用资源竞争的场景。

Method: Alice和Bob轮流选择代理，之后分别计算各自代理集的最优分配值s_A和s_B，定义得分为s_A-s_B。

Result: 证明了该问题在代理最多有两个非零效率时是PSPACE完全的；在代理最多有一个非零效率时，问题属于XP参数化类，且在两任务时可以在线性时间内计算最优得分。

Conclusion: 竞争分配问题在特定情况下具有高效解，但在一般情况下是计算复杂的。

Abstract: We introduce the competitive assignment problem, a two-player version of the well-known assignment problem. Given a set of tasks and a set of agents with different efficiencies for different tasks, Alice and Bob take turns picking agents one by one. Once all agents have been picked, Alice and Bob compute the optimal values $s_A$ and $s_B$ for the assignment problem on their respective sets of agents, i.e. they assign their own agents to tasks (with at most one agent per task and at most one task per agent) so as to maximize the sum of the efficiencies. The score of the game is then defined as $s_A-s_B$. Alice aims at maximizing the score, while Bob aims at minimizing it. This problem can model drafts in sports and card games, or more generally situations where two entities fight for the same resources and then use them to compete against each other. We show that the problem is PSPACE-complete, even restricted to agents that have at most two nonzero efficiencies. On the other hand, in the case of agents having at most one nonzero efficiency, the problem lies in XP parameterized by the number of tasks, and the optimal score can be computed in linear time when there are only two tasks.

</details>


### [9] [Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow](https://arxiv.org/abs/2602.03145)
*Ya-Ting Yang,Quanyan Zhu*

Main category: cs.GT

TL;DR: 本文提出了一种名为“智能代理互联网”的可扩展代理智能框架，通过分布式、异构的代理动态形成联盟执行任务驱动的工作流。


<details>
  <summary>Details</summary>
Motivation: 现有的代理智能架构多为集中式和单体式，限制了可扩展性、专业化和互操作性。本文旨在解决这些问题。

Method: 作者形式化了代理协作的网络原生模型，引入了激励兼容的工作流联盟可行性框架，并提出了一种去中心化的联盟形成算法。

Result: 提出的框架可以作为模型上下文协议（MCP）上方的协调层运行，医疗案例研究表明其在可扩展性、弹性和经济可行性方面的优势。

Conclusion: 本文为新兴的智能代理互联网时代提供了基础的协调和可扩展性原则。

Abstract: Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, and interoperability. This paper proposes a framework for scalable agentic intelligence, termed the Internet of Agentic AI, in which autonomous, heterogeneous agents distributed across cloud and edge infrastructure dynamically form coalitions to execute task-driven workflows. We formalize a network-native model of agentic collaboration and introduce an incentive-compatible workflow-coalition feasibility framework that integrates capability coverage, network locality, and economic implementability. To enable scalable coordination, we formulate a minimum-effort coalition selection problem and propose a decentralized coalition formation algorithm. The proposed framework can operate as a coordination layer above the Model Context Protocol (MCP). A healthcare case study demonstrates how domain specialization, cloud-edge heterogeneity, and dynamic coalition formation enable scalable, resilient, and economically viable agentic workflows. This work lays the foundation for principled coordination and scalability in the emerging era of Internet of Agentic AI.

</details>


### [10] [Dynamic Programming for Epistemic Uncertainty in Markov Decision Processes](https://arxiv.org/abs/2602.03381)
*Axel Benyamine,Julien Grand-Clément,Marek Petrik,Michael I. Jordan,Alain Durmus*

Main category: cs.GT

TL;DR: 本文提出了一种普遍理论，用于处理不确定性MDP中的模糊规避问题，通过将不确定的转移概率视为随机变量，并用风险度量评估策略的随机回报。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于统一几种具有认知不确定性的MDP模型，并通过特定的风险度量选择，扩展动态规划原则的应用范围。

Method: 方法包括将价值函数和贝尔曼算子的概念扩展到模糊规避MDP框架中，并建立动态规划原则的后果（如静态策略的存在性、价值和策略迭代算法）。

Result: 结果展示了在动态规划范式下哪些风险度量是兼容的，并完全刻画了其适用范围。

Conclusion: 结论是，该框架揭示了多种MDP变体之间的联系，并明确了动态规划范式的边界。

Abstract: In this paper, we propose a general theory of ambiguity-averse MDPs, which treats the uncertain transition probabilities as random variables and evaluates a policy via a risk measure applied to its random return. This ambiguity-averse MDP framework unifies several models of MDPs with epistemic uncertainty for specific choices of risk measures. We extend the concepts of value functions and Bellman operators to our setting. Based on these objects, we establish the consequences of dynamic programming principles in this framework (existence of stationary policies, value and policy iteration algorithms), and we completely characterize law-invariant risk measures compatible with dynamic programming. Our work draws connections among several variants of MDP models and fully delineates what is possible under the dynamic programming paradigm and which risk measures require leaving it.

</details>


### [11] [Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation](https://arxiv.org/abs/2602.03387)
*Zhengwei Ni,Zhidu Li,Wei Chen,Zhaoyang Zhang,Zehua Wang,F. Richard Yu,Victor C. M. Leung*

Main category: cs.GT

TL;DR: 该论文提出了基于最小核心（LC）概念的收益分配框架，以解决联邦学习中的公平性和稳定性问题，并实现了计算效率与分配精度的平衡。


<details>
  <summary>Details</summary>
Motivation: 随着新兴网络范式和应用对隐私保护的联邦学习（FL）需求的增长，确保协作环境的公平性和稳定性成为关键挑战。

Method: 论文引入最小核心（LC）概念，通过基于堆栈的剪枝算法实现高效计算，最大化减少潜在子群的不满，确保联邦的凝聚力。

Result: 案例研究表明，该机制能准确识别关键贡献者和战略联盟，证实其实用LC框架能促进稳定协作和可持续的FL生态系统。

Conclusion: 论文证实，最小核心框架在联邦学习中具有促进稳定性和可持续性的潜力，为未来类似系统提供了理论支持和实践指导。

Abstract: Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem.

</details>


### [12] [Sequential Linear Contracts on Matroids](https://arxiv.org/abs/2602.03543)
*Kanstantsin Pashkovich,Jacob Skitsko,Yun Xing*

Main category: cs.GT

TL;DR: 研究了在拟序约束下的序贯契约问题，重点分析了线性契约的优化与拟序可靠性问题的关系。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在拟序约束下设计最优线性契约，以激励代理人为委托人获取最大回报。

Method: 采用拟序可靠性问题的方法，将线性契约的优化问题转化为拟序元素的并行扩展问题。

Result: 确立了最优线性契约的计算与拟序可靠性问题的等价性，并提出了相应的处理方法。

Conclusion: 研究表明，通过拟序元素的扩展，线性契约的优化问题可以有效地转化为拟序可靠性问题来解决。

Abstract: In this work, we study sequential contracts under matroid constraints. In the sequential setting, an agent can take actions one by one. After each action, the agent observes the stochastic value of the action and then decides which action to take next, if any. At the end, the agent decides what subset of taken actions to use for the principal's reward; and the principal receives the total value of this subset as a reward. Taking each action induces a certain cost for the agent. Thus, to motivate the agent to take actions the principal is expected to offer an appropriate contract. A contract describes the payment from the principal to the agent as a function of the principal's reward obtained through the agent's actions. In this work, we concentrate on studying linear contracts, i.e.\ the contracts where the principal transfers a fraction of their total reward to the agent. We assume that the total principal's reward is calculated based on a subset of actions that forms an independent set in a given matroid. We establish a relationship between the problem of finding an optimal linear contract (or computing the corresponding principal's utility) and the so called matroid (un)reliability problem. Generally, the above problems turn out to be equivalent subject to adding parallel copies of elements to the given matroid.

</details>


### [13] [Efficient Investment in Multi-Agent Models of Public Transportation](https://arxiv.org/abs/2602.03687)
*Martin Bullinger,Edith Elkind,Kassian Köck*

Main category: cs.GT

TL;DR: 研究两个多代理模型，分别用于在公共交通工具上投资有限且不可分割的资源。第一个模型在线图拓扑中寻找最优站点选择，发现计算平等福利的近似最优解是NP完全问题。第二个模型在加权图中优化固定数量的边，展示了多项式时间算法和NP完全性结果。


<details>
  <summary>Details</summary>
Motivation: 探索在多代理环境下，如何高效投资有限资源于公共交通系统，尤其是在不同拓扑结构和福利目标下的计算复杂性。

Method: 第一个模型使用线性图拓扑研究站点选择问题；第二个模型结合Dijkstra算法和动态规划，优化加权图中的边改进。

Result: 第一个模型中发现平等福利的近似最优解是NP完全的；第二个模型中展示了多项式时间算法的有效性，同时揭示了多代理情况下的NP完全性和不可近似性。

Conclusion: 该研究揭示了公共交通资源分配问题在不同拓扑和福利目标下的计算复杂性，为进一步研究铁路网络设计提供了理论依据。

Abstract: We study two stylized, multi-agent models aimed at investing a limited, indivisible resource in public transportation. In the first model, we face the decision of which potential stops to open along a (e.g., bus) path, given agents' travel demands. While it is known that utilitarian optimal solutions can be identified in polynomial time, we find that computing approximately optimal solutions with respect to egalitarian welfare is NP-complete. This is surprising as we operate on the simple topology of a line graph.
  In the second model, agents navigate a more complex network modeled by a weighted graph where edge weights represent distances. We face the decision of improving travel time along a fixed number of edges. We provide a polynomial-time algorithm that combines Dijkstra's algorithm with a dynamical program to find the optimal decision for one or two agents. By contrast, if the number of agents is variable, we find \np-completeness and inapproximability results for utilitarian and egalitarian welfare. Moreover, we demonstrate implications of our results for a related model of railway network design.

</details>
