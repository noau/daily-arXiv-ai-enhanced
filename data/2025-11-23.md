<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 提出了一种统一的实时双向触觉交互框架，用于虚拟现实中的刚体、可变形物体和拉格朗日流体的交互，解决了多物理系统中力反馈计算的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于多物理系统中流体、刚体和可变形材料的物理模拟计算复杂，尤其是在需要实时交互时，支持准确的力响应具有挑战性，因此需要一种统一的解决方案以增强虚拟环境中的触觉沉浸感。

Method: 采用平滑粒子流体动力学（SPH）结合双向力耦合和反馈平滑技术，以确保稳定性并生成物理上有意义的触觉响应。

Result: 框架成功实现了用户在流体中操作物体并感受到流体-结构行为的反作用力，展示了流体搅拌、软组织操作和刚体交互的虚拟现实场景。

Conclusion: 该系统通过将流体、软体和刚体动力学统一到一个平台上，推动了支持触觉的多物理模拟的发展，适用于沉浸式教育应用。

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [2] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 本文提出了一种名为可控层分解（CLD）的方法，用于实现对光栅图像的细粒度和可控的多层分离。通过两个关键模块LD-DiT和MLCA，CLD在分解质量和可控性上优于现有方法，并且生成的分离层可直接在设计工具中进行编辑。


<details>
  <summary>Details</summary>
Motivation: 设计师在生成和编辑光栅图像时，通常会独立处理每个RGBA层后再合成最终图像，但合成后的图像无法再进行层级的编辑。现有方法依赖于图像抠图和修复，但在可控性和分割精度上存在局限性。

Method: CLD方法包含两个核心模块：LayerDecompose-DiT（LD-DiT）用于解耦图像元素为独立层并实现细粒度控制；Multi-Layer Conditional Adapter（MLCA）用于将目标图像信息注入多层标记中，实现精准条件生成。

Result: 实验结果表明，CLD在分解质量和可控性上均优于现有方法。分离后的层可直接在常用设计工具（如PowerPoint）中操作，展示了其在实际工作流程中的实用性和适用性。

Conclusion: CLD通过创新的模块设计解决了现有方法的局限性，显著提升了多层分离的精度和可控性，同时具备直接应用于实际设计工作流程的优势。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: Polarity语言旨在对称处理归纳和共归纳类型，但目前缺乏隐式参数等现代依赖类型语言特性。本文提供了一种算法类型系统和推断隐式参数的统一算法，覆盖了任意归纳和共归纳类型。


<details>
  <summary>Details</summary>
Motivation: 解决依赖类型语言中归纳和共归纳类型不对称的问题，特别是隐式参数支持的不足。

Method: 设计了一个算法类型系统和统一算法，涵盖任意归纳和共归纳类型，并提供缩减语义、转换检查和模式匹配的统一规则。

Result: 实现了Polarity语言的完整算法描述和统一算法，支持隐式参数的推断。

Conclusion: 本文的工作为其他依赖类型语言提供了支持对称处理归纳和共归纳类型的蓝图。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [4] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一种为Elixir设计的编排编程语言，旨在构建稳健的分布式应用，能够容忍参与者故障并通过检查点恢复状态。


<details>
  <summary>Details</summary>
Motivation: 当前分布式应用中对参与者故障的处理不够稳健，Chorex通过编排编程和检查点机制解决了这一问题。

Method: Chorex通过元编程实现完整功能的编排语言，支持故障恢复和状态检查点，并静态报告参与者实现与编排要求的匹配问题。

Result: Chorex在多个示例中展示了其功能，包括高阶书商和安全远程密码协议，同时验证了检查点机制的开销。

Conclusion: Chorex的投影策略（生成无状态函数集）为其他语言支持可重启参与者提供了一种可行的方案。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [5] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本文提出了一种分散式虚拟机（VM），通过将尽可能多的组件卸载到主机上，利用主机的丰富内存和强大处理能力，为内存有限的微控制器提供丰富的功能。


<details>
  <summary>Details</summary>
Motivation: 微控制器虚拟机（VM）由于内存限制，功能有限且交互性和执行速度不足。现有研究虽有尝试卸载部分组件，但可卸载的类型仍受限制。本文旨在解决这一问题。

Method: 设计并实现了BlueScript VM，一种分散式虚拟机，将大部分组件卸载到主机上，并通过称为“影子机”的数据结构减少主机与微控制器间的通信开销。

Result: 实验证实，卸载组件不会显著影响预期效益；卸载的增量编译器在执行速度上优于MicroPython和Espruino，同时保持与MicroPython相当的交互性。动态编译器的卸载也提升了虚拟机性能。

Conclusion: 研究表明，即使针对内存有限的微控制器，也能通过分散式虚拟机提供丰富的功能，验证了其可行性。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [6] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一个基于Rust的工作流引擎，通过新颖的命名维度形式化和显式依赖关系，解决了不规则数据的处理和依赖管理问题。


<details>
  <summary>Details</summary>
Motivation: 现有工作流引擎缺乏对不规则数据的原生支持，用户需手动管理复杂的索引和依赖关系，亟需高效解决方案。

Method: Operon引入了一种领域特定语言，通过静态验证维度注释的动态任务调度，支持并行环境下的确定性执行。

Result: 实验表明，Operon减少了14.94倍的基线开销，并在大规模机器学习数据生成流水线中保持近线性输出速率。

Conclusion: Operon通过显式建模部分已知状态和高效并行架构，成为不规则数据处理的高效解决方案。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Prior-free Collusion-proof Dynamic Mechanisms](https://arxiv.org/abs/2511.15727)
*Endre Csóka*

Main category: cs.GT

TL;DR: 本文提出了先验无关的TU-GUM和NTU-GUM机制，用于动态随机多玩家问题，解决了效率实现问题。


<details>
  <summary>Details</summary>
Motivation: 研究目的是为了解决动态随机多玩家问题中的效率实现问题，特别是在缺乏先验知识的情况下。

Method: 定义了先验无关的TU-GUM和NTU-GUM机制，并将其应用于具体问题，如重复单商品分配问题。

Result: 新的先验无关NTU-GUM机制在重复单商品分配问题中实现了1.283倍的帕累托效率近似。

Conclusion: 提出的先验无关机制成功解决了效率实现问题，并为未来研究提供了方向。

Abstract: For a general class of dynamic stochastic multi-player problems, Csóka, Liu, Rodivilov, and Teytelboym (2024) proposed prior-dependent mechanisms. The Guaranteed Utility Mechanism with transfers (TU-GUM) implements efficiency in a Guaranteed Utility Equilibrium (GUE). Its transfer-free variant (NTU-GUM) implements approximate efficiency in ε-GUE. In this paper, we define prior-free versions of both TU-GUM and NTU-GUM. As a special case, we believe that the new prior-free NTU-GUM implements a 1.283-approximation to Pareto efficiency for the repeated single good allocation problem in Fikioris, Banerjee, and Tardos (2024).

</details>


### [8] [Polynomial-Time Algorithms for Computing the Nucleolus: An Assessment](https://arxiv.org/abs/2511.16517)
*Holger I. Meinhardt*

Main category: cs.GT

TL;DR: Maggiorano等人声称开发了一种基于简化博弈和子模函数最小化方法的强多项式时间组合算法，用于计算凸博弈的核心，但论文指出其忽视了Davis/Maschler简化博弈属性的错误应用，导致计算失败。


<details>
  <summary>Details</summary>
Motivation: 论文旨在揭示Maggiorano等人的算法在计算凸博弈核心时的错误，并探讨其他方法（如椭球法和Fenchel-Moreau共轭方法）在此问题上的有效性。

Method: 通过分析Davis/Maschler简化博弈属性的错误应用，比较椭球法和Fenchel-Moreau共轭方法在计算预核元素时的表现。

Result: 指出Maggiorano等人的算法存在严重的选择问题，无法正确计算凸博弈的核心，而Fenchel-Moreau共轭方法在预核为单点时能高效计算预核元素。

Conclusion: 论文强调了Maggiorano等人的算法的缺陷，并展示了其他方法在处理特定类凸博弈时的优势，尤其是预核为单点时的高效性。

Abstract: Recently, Maggiorano et al. (2025) claimed that they have developed a strongly polynomial-time combinatorial algorithm for the nucleolus in convex games that is based on the reduced game approach and submodular function minimization method. Thereby, avoiding the ellipsoid method with its negative side effects in numerical computation completely. However, we shall argue that this is a fallacy based on an incorrect application of the Davis/Maschler reduced game property (RGP). Ignoring the fact that despite the pre-nucleolus, other solutions like the core, pre-kernel, and semi-reactive pre-bargaining set possess this property as well. This causes a severe selection issue, leading to the failure to compute the nucleolus of convex games using the reduced games approach. In order to assess this finding in its context, the ellipsoid method of Faigle et al. (2001) and the Fenchel-Moreau conjugation-based approach from convex analysis of Meinhardt (2013) to compute a pre-kernel element were resumed. In the latter case, it was exploited that for TU games with a single-valued pre-kernel, both solution concepts coincide. Implying that one has computed the pre-nucleolus if one has found the sole pre-kernel element of the game. Though it is a specialized and highly optimized algorithm for the pre-kernel, it assures runtime complexity of O(n^3) for computing the pre-nucleolus whenever the pre-kernel is a single point, which indicates a polynomial-time algorithm for this class of games.

</details>
