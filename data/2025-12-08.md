<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [PESTalk: Speech-Driven 3D Facial Animation with Personalized Emotional Styles](https://arxiv.org/abs/2512.05121)
*Tianshun Han,Benjia Zhou,Ajian Liu,Yanyan Liang,Du Zhang,Zhen Lei,Jun Wan*

Main category: cs.GR

TL;DR: PESTalk是一种直接从语音生成具有个性化情感风格的3D面部动画的新方法，通过双流情感提取器和情感风格建模模块，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成个性化情感风格的3D面部动画方面存在局限性，PESTalk旨在通过创新技术解决这些问题。

Method: PESTalk引入了双流情感提取器（DSEE）和时间频率域音频特征分析，结合情感风格建模模块（ESMM）和3D-EmoStyle数据集。

Result: 评估表明，PESTalk在生成逼真且个性化的面部动画方面优于现有最先进方法。

Conclusion: PESTalk通过创新的双流提取器和情感建模模块，成功实现了高质量的个性化3D面部动画生成。

Abstract: PESTalk is a novel method for generating 3D facial animations with personalized emotional styles directly from speech. It overcomes key limitations of existing approaches by introducing a Dual-Stream Emotion Extractor (DSEE) that captures both time and frequency-domain audio features for fine-grained emotion analysis, and an Emotional Style Modeling Module (ESMM) that models individual expression patterns based on voiceprint characteristics. To address data scarcity, the method leverages a newly constructed 3D-EmoStyle dataset. Evaluations demonstrate that PESTalk outperforms state-of-the-art methods in producing realistic and personalized facial animations.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM](https://arxiv.org/abs/2512.05224)
*Miguel de Oliveira Guerreiro*

Main category: cs.PL

TL;DR: NVLang是一种静态类型的功能语言，旨在为BEAM虚拟机提供全面的类型安全保障，同时保留actor模型的简单性和强大功能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于actor的系统（如Erlang/OTP）缺乏对消息协议的静态保证，导致协议违规只能在运行时被发现，从而可能引发生产故障。

Method: NVLang通过代数数据类型（ADTs）编码actor消息协议，使用类型化的进程标识符（Pid[T]）和类型化的未来（Future[T]）确保编译时的协议一致性。

Result: NVLang消除了消息传递错误的整个类别，同时保持了与动态类型替代方案相当的简洁语法，并与现有Erlang生态无缝互操作。

Conclusion: NVLang通过静态类型系统确保了actor协议的一致性，证明了良好类型的NVLang程序不会发送违反actor协议的消息。

Abstract: Actor-based systems like Erlang/OTP power critical infrastructure -- from telecommunications to messaging platforms -- handling millions of concurrent connections with legendary reliability. Yet these systems lack static guarantees about message protocols: processes communicate by sending arbitrary messages that pattern-matched at runtime, deferring protocol violations to production failures.
  We present NVLang, a statically typed functional language that brings comprehensive type safety to the BEAM virtual machine while preserving actor model's simplicity and power. NVLang's central contribution that algebraic data types (ADTs) naturally encode actor message protocols: each actor declares the sum type representing its message vocabulary, and the type system enforces protocol conformance at compile time. We introduce typed process identifiers (Pid[T]) that encode the protocol an actor expects, and typed futures (Future[T]) that provide type-safe request-reply patterns.
  By extending Hindley-Milner type inference to track message protocols, NVLang eliminates an entire class of message-passing errors while maintaining clean syntax that rivals dynamically typed alternatives. Our implementation compiles to Core Erlang, enabling seamless interoperability with the existing Erlang ecosystem. We formalize the type system and provide proof sketches for type soundness, demonstrating that well-typed NVLang programs cannot send messages that violate actor protocols.

</details>


### [3] [Verified VCG and Verified Compiler for Dafny](https://arxiv.org/abs/2512.05262)
*Daniel Nezamabadi,Magnus O. Myreen,Yong Kiam Tan*

Main category: cs.PL

TL;DR: 该论文展示了如何为Dafny工具提供基础的正确性保证，包括验证条件生成器（VCG）和编译器的形式化验证。


<details>
  <summary>Details</summary>
Motivation: Dafny是一种带有编译器和静态程序验证器的编程语言，但这些工具本身未被验证，且存在正确性问题。论文旨在为这些工具提供形式化的正确性保证。

Method: 论文提出了Dafny的一个子集的功能性大步语义，并基于此语义实现了验证的VCG和编译器。这些工具能够处理递归方法调用、循环和数组等复杂特性。

Result: 验证的VCG可用于证明注释Dafny程序的功能正确性，验证的编译器可将Dafny程序编译为CakeML程序，并通过CakeML编译器生成可执行机器码。

Conclusion: 通过HOL4定理证明器实现的形式化工作，Dafny工具链能够维持源程序的功能正确性保证。

Abstract: Dafny is a verification-aware programming language that comes with a compiler and static program verifier. However, neither the compiler nor the verifier is proved correct; in fact, soundness bugs have been found in both tools. This paper shows that the aforementioned Dafny tools can be developed with foundational correctness guarantees. We present a functional big-step semantics for an imperative subset of Dafny and, based on this semantics, a verified verification condition generator (VCG) and a verified compiler for Dafny. The subset of Dafny we have formalized includes mutually recursive method calls, while loops, and arrays -- these language features are significant enough to cover challenging examples such as McCarthy's 91 function and array-based programs that are used when teaching Dafny. The verified VCG allows one to prove functional correctness of annotated Dafny programs, while the verified compiler can be used to compile verified Dafny programs to CakeML programs. From there, one can obtain executable machine code via the (already verified) CakeML compiler, all while provably maintaining the functional correctness guarantees that were proved for the source-level Dafny programs. Our work has been mechanized in the HOL4 theorem prover.

</details>


### [4] [Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware](https://arxiv.org/abs/2512.05516)
*Pawel K. Radtke,Tobias Weinzierl*

Main category: cs.PL

TL;DR: 本研究评估了在多个GPU平台上对降精度数据布局进行AoS-to-SoA转换的效果，发现SoA特别适合SIMT架构，并通过编译器注释优化了转换流程。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨AoS和SoA数据布局在降精度数据处理中的表现差异，以及在CPU和GPU之间如何高效地进行数据转换和计算卸载。

Method: 方法包括引入编译器注释以支持数据转换和GPU卸载的编程控制，并在Nvidia G200和AMD MI300A平台上进行性能测试。

Result: 结果显示，Nvidia G200平台实现了约2.6倍的加速，而AMD MI300A表现更稳健但收益较少。

Conclusion: 结论表明，基于编译器的技术适用于广泛的拉格朗日代码及其他场景，但仍需进一步优化以适应不同平台。

Abstract: This study evaluates AoS-to-SoA transformations over reduced-precision data layouts for a particle simulation code on several GPU platforms: We hypothesize that SoA fits particularly well to SIMT, while AoS is the preferred storage format for many Lagrangian codes. Reduced-precision (below IEEE accuracy) is an established tool to address bandwidth constraints, although it remains unclear whether AoS and precision conversions should execute on a CPU or be deployed to a GPU if the compute kernel itself must run on an accelerator. On modern superchips where CPUs and GPUs share (logically) one data space, it is also unclear whether it is advantageous to stream data to the accelerator prior to the calculation, or whether we should let the accelerator transform data on demand, i.e.~work in-place logically. We therefore introduce compiler annotations to facilitate such conversions and to give the programmer the option to orchestrate the conversions in combination with GPU offloading. For some of our compute kernels of interest, Nvidia's G200 platforms yield a speedup of around 2.6 while AMD's MI300A exhibits more robust performance yet profits less. We assume that our compiler-based techniques are applicable to a wide variety of Lagrangian codes and beyond.

</details>


### [5] [Compiling Away the Overhead of Race Detection](https://arxiv.org/abs/2512.05555)
*Alexey Paznikov,Andrey Kogutenko,Yaroslav Osipov,Michael Schwarz,Umang Mathur*

Main category: cs.PL

TL;DR: 提出了一种静态编译集成方法，通过消除冗余检测，显著降低动态数据竞争检测器的运行时开销。


<details>
  <summary>Details</summary>
Motivation: 动态数据竞争检测器的高运行时开销限制了其广泛应用，主要原因是大量冗余的内存访问检测。本文旨在解决这一效率问题。

Method: 采用静态分析技术，包括内存访问模式、同步和线程创建的分析，以消除冗余检测。此外，引入了基于支配关系的等价类分析，进一步减少冗余。

Result: 实验表明，该方法显著降低了运行时开销，平均提速1.34倍，在高线程争用下峰值提速可达2.5倍，且对编译时间影响极小。

Conclusion: 该方法无需开发者额外负担，已被ThreadSanitizer维护者接受，并正在集成到上游代码中。

Abstract: Dynamic data race detectors are indispensable for flagging concurrency errors in software, but their high runtime overhead limits their adoption. This overhead stems primarily from pervasive instrumentation of memory accesses - a significant fraction of which is redundant. We addresses this inefficiency through a static, compiler-integrated approach that identifies and eliminates redundant instrumentation, drastically reducing the runtime cost of dynamic data race detectors. We introduce a suite of interprocedural static analyses reasoning about memory access patterns, synchronization, and thread creation to eliminate instrumentation for provably race-free accesses and show that the completeness properties of the data race detector are preserved. We further observe that many inserted checks flag a race if and only if a preceding check has already flagged an equivalent race for the same memory location - albeit potentially at a different access. We characterize this notion of equivalence and show that, when limiting reporting to at least one representative for each equivalence class, a further class of redundant checks can be eliminated. We identify such accesses using a novel dominance-based elimination analysis. Based on these two insights, we have implemented five static analyses within the LLVM, integrated with the instrumentation pass of the race detector ThreadSanitizer. Our experimental evaluation on a diverse suite of real-world applications demonstrates that our approach significantly reduces race detection overhead, achieving a geomean speedup of 1.34x, with peak speedups reaching 2.5x under high thread contention. This performance is achieved with a negligible increase in compilation time and, being fully automatic, places no additional burden on developers. Our optimizations have been accepted by the ThreadSanitizer maintainers and are in the process of being upstreamed.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Strategyproof Tournament Rules for Teams with a Constant Degree of Selfishness](https://arxiv.org/abs/2512.05235)
*David Pennock,Daniel Schoepflin,Kangning Wang*

Main category: cs.GT

TL;DR: 研究设计了一种新型锦标赛规则，策略证明性强，要求自利参数λ低至11，并引入了乘性对非操纵性概念，确保两队操纵结果的收益总和不超过乘性因子3.5。


<details>
  <summary>Details</summary>
Motivation: 解决现有锦标赛规则在策略证明性上要求高自利参数（λ=Ω(n)）的问题，设计更高效的规则以减少操纵可能性。

Method: 提出一种新锦标赛规则，满足单调性和Condorcet一致性，并通过乘性对非操纵性概念限制操纵行为的收益。

Result: 成功设计出λ=11的策略证明性规则，并提供δ=3.5的乘性对非操纵性规则。

Conclusion: 新规则显著降低了对自利参数的要求，解决了长期存在的开放性问题，并为锦标赛规则的公平性提供了新思路。

Abstract: We revisit the well-studied problem of designing fair and manipulation-resistant tournament rules. In this problem, we seek a mechanism that (probabilistically) identifies the winner of a tournament after observing round-robin play among $n$ teams in a league. Such a mechanism should satisfy the natural properties of monotonicity and Condorcet consistency. Moreover, from the league's perspective, the winner-determination tournament rule should be strategyproof, meaning that no team can do better by losing a game on purpose.
  Past work considered settings in which each team is fully selfish, caring only about its own probability of winning, and settings in which each team is fully selfless, caring only about the total winning probability of itself and the team to which it deliberately loses. More recently, researchers considered a mixture of these two settings with a parameter $λ$. Intermediate selfishness $λ$ means that a team will not lose on purpose unless its pair gains at least $λs$ winning probability, where $s$ is the individual team's sacrifice from its own winning probability. All of the dozens of previously known tournament rules require $λ= Ω(n)$ to be strategyproof, and it has been an open problem to find such a rule with the smallest $λ$.
  In this work, we make significant progress by designing a tournament rule that is strategyproof with $λ= 11$. Along the way, we propose a new notion of multiplicative pairwise non-manipulability that ensures that two teams cannot manipulate the outcome of a game to increase the sum of their winning probabilities by more than a multiplicative factor $δ$ and provide a rule which is multiplicatively pairwise non-manipulable for $δ= 3.5$.

</details>


### [7] [Robust forecast aggregation via additional queries](https://arxiv.org/abs/2512.05271)
*Rafael Frongillo,Mary Monroe,Eric Neyman,Bo Waggoner*

Main category: cs.GT

TL;DR: 本文研究鲁棒预测聚合问题，提出了一种通过结构化查询从专家获取更丰富信息的新框架，证明了在最坏情况下可以实现最优聚合，并建立了准确性与查询复杂性之间的紧密权衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，在自然假设下，专家的个体预测聚合无法胜过随机跟随单个专家。本文旨在通过引入更丰富的查询框架解决这一问题，提升鲁棒预测聚合的能力。

Method: 提出了一个允许通过结构化查询从专家获取更丰富信息的框架，确保专家真实报告其潜在信念，并定义了查询复杂性的概念。

Result: 在最坏情况下实现了最优聚合，且每个复杂性度量均低于专家数量$n$；证明了准确性与查询复杂性之间的线性递减关系，聚合误差在"推理顺序"和查询相关专家数量为$ω(\sqrt{n})$时消失。

Conclusion: 新的查询框架显著增强了鲁棒预测聚合的能力，有望为该领域开辟一条富有成果的研究方向。

Abstract: We study the problem of robust forecast aggregation: combining expert forecasts with provable accuracy guarantees compared to the best possible aggregation of the underlying information. Prior work shows strong impossibility results, e.g. that even under natural assumptions, no aggregation of the experts' individual forecasts can outperform simply following a random expert (Neyman and Roughgarden, 2022).
  In this paper, we introduce a more general framework that allows the principal to elicit richer information from experts through structured queries. Our framework ensures that experts will truthfully report their underlying beliefs, and also enables us to define notions of complexity over the difficulty of asking these queries. Under a general model of independent but overlapping expert signals, we show that optimal aggregation is achievable in the worst case with each complexity measure bounded above by the number of agents $n$. We further establish tight tradeoffs between accuracy and query complexity: aggregation error decreases linearly with the number of queries, and vanishes when the "order of reasoning" and number of agents relevant to a query is $ω(\sqrt{n})$. These results demonstrate that modest extensions to the space of expert queries dramatically strengthen the power of robust forecast aggregation. We therefore expect that our new query framework will open up a fruitful line of research in this area.

</details>


### [8] [Correlation of Rankings in Matching Markets](https://arxiv.org/abs/2512.05304)
*Rémi Castera,Patrick Loiseau,Bary S. R. Pradelski*

Main category: cs.GT

TL;DR: 研究匹配市场中相关性对群体不平等的影响，发现相关性差异会系统性影响不同群体的匹配结果。


<details>
  <summary>Details</summary>
Motivation: 探索多重决策者在同一候选人池中选择时相关性对群体不平等的影响，特别是在学校选择、大学录取和工作中。

Method: 建立一个模型，描述候选人优先级得分在不同决策者间的相关性差异，并分析其对匹配结果的影响。

Result: 较高的相关性对整体效率有利，但对特定群体不利，低相关性群体更具优势。

Conclusion: 相关性差异是被忽视的系统性不平等来源，需要更多关注以减少不公平现象。

Abstract: We study the role of correlation in matching markets, where multiple decision-makers simultaneously face selection problems from the same pool of candidates. We propose a model in which a candidate's priority scores across different decision-makers exhibit varying levels of correlation dependent on the candidate's sociodemographic group. Such differential correlation can arise in school choice due to the varying prevalence of selection criteria, in college admissions due to test-optional policies, or due to algorithmic monoculture, that is, when decision-makers rely on the same algorithms and data sets to evaluate candidates. We show that higher correlation for one of the groups generally improves the outcome for all groups, leading to higher efficiency. However, students from a given group are more likely to remain unmatched as their own correlation level increases. This implies that it is advantageous to belong to a low-correlation group. Finally, we extend the tie-breaking literature to multiple priority classes and intermediate levels of correlation. Overall, our results point to differential correlation as a previously overlooked systemic source of group inequalities in school, university, and job admissions.

</details>


### [9] [On Dynamic Programming Theory for Leader-Follower Stochastic Games](https://arxiv.org/abs/2512.05667)
*Jilles Steeve Dibangoye,Thibaut Le Marre,Ocan Sankur,François Schwarzentruber*

Main category: cs.GT

TL;DR: 该论文提出了一个动态编程框架，用于计算领导-追随者一般和随机博弈中的强Stackelberg均衡，通过状态抽象和Bellman递归实现，并在标准基准测试中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决领导-追随者在非对称承诺下的决策问题，通过提出一种新的计算框架来优化领导者的策略，并在复杂环境下验证其有效性。

Method: 论文采用动态编程框架，基于Bellman递归和状态抽象（可信集）来建模追随者的理性最佳响应，并证明了问题可简化为马尔可夫决策过程。

Result: 论文证明了寻找最优领导者策略是NP难问题，并开发了具有领导者可利用性保证的ε-最优动态编程算法，实验验证了算法在领导价值和时间效率上的优势。

Conclusion: 论文成功提出了一种高效的动态编程方法，用于计算强Stackelberg均衡，并在多种复杂场景下展示了其优越性能。

Abstract: Leader-follower general-sum stochastic games (LF-GSSGs) model sequential decision-making under asymmetric commitment, where a leader commits to a policy and a follower best responds, yielding a strong Stackelberg equilibrium (SSE) with leader-favourable tie-breaking. This paper introduces a dynamic programming (DP) framework that applies Bellman recursion over credible sets-state abstractions formally representing all rational follower best responses under partial leader commitments-to compute SSEs. We first prove that any LF-GSSG admits a lossless reduction to a Markov decision process (MDP) over credible sets. We further establish that synthesising an optimal memoryless deterministic leader policy is NP-hard, motivating the development of ε-optimal DP algorithms with provable guarantees on leader exploitability. Experiments on standard mixed-motive benchmarks-including security games, resource allocation, and adversarial planning-demonstrate empirical gains in leader value and runtime scalability over state-of-the-art methods.

</details>


### [10] [Invariant Price of Anarchy: a Metric for Welfarist Traffic Control](https://arxiv.org/abs/2512.05843)
*Ilia Shilov,Mingjia He,Heinrich H. Nax,Emilio Frazzoli,Gioele Zardini,Saverio Bolognani*

Main category: cs.GT

TL;DR: 论文提出了不变的无政府状态价格（Invariant PoA）来解决传统PoA分析因成本缩放和平移而产生的效率评估不一致问题。


<details>
  <summary>Details</summary>
Motivation: 传统PoA分析依赖于精确数值成本，但在许多情况下，成本仅代表代理偏好且可能因缩放和平移而定义模糊，导致效率评估不一致。

Method: 作者通过结合社会选择理论的结果，定义了不变PoA，并通过将允许的转换与代理成本的比较度连接，推导出确保效率评估不受成本缩放或平移影响的社会福利函数。

Result: 通过玩具示例和苏黎世网络的案例研究，表明相同的收费策略在不同比较假设下可能导致显著不同的效率估计。

Conclusion: 论文表明，明确的公理化基础对于定义效率指标和在大规模基础设施设计中稳健有效地指导政策是必要的。

Abstract: The Price of Anarchy (PoA) is a standard metric for quantifying inefficiency in socio-technical systems, widely used to guide policies like traffic tolling. Conventional PoA analysis relies on exact numerical costs. However, in many settings, costs represent agents' preferences and may be defined only up to possibly arbitrary scaling and shifting, representing informational and modeling ambiguities. We observe that while such transformations preserve equilibrium and optimal outcomes, they change the PoA value. To resolve this issue, we rely on results from Social Choice Theory and define the Invariant PoA. By connecting admissible transformations to degrees of comparability of agents' costs, we derive the specific social welfare functions which ensure that efficiency evaluations do not depend on arbitrary rescalings or translations of individual costs. Case studies on a toy example and the Zurich network demonstrate that identical tolling strategies can lead to substantially different efficiency estimates depending on the assumed comparability. Our framework thus demonstrates that explicit axiomatic foundations are necessary in order to define efficiency metrics and to appropriately guide policy in large-scale infrastructure design robustly and effectively.

</details>
