<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 3]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 7]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [MiGumi: Making Tightly Coupled Integral Joints Millable](https://arxiv.org/abs/2510.13168)
*Aditya Ganeshan,Kurt Fleischer,Wenzel Jakob,Ariel Shamir,Daniel Ritchie,Takeo Igarashi,Maria Larsson*

Main category: cs.GR

TL;DR: 研究提出了Millable Extrusion Geometry (MXG)语言和优化方法，以解决CNC加工传统木榫时几何偏差导致的装配问题，使其适用于现代制造流程。


<details>
  <summary>Details</summary>
Motivation: 传统木榫虽强度高、耐用且优雅，但因手动加工成本高且困难，在现代制造中罕见。CNC铣削虽有潜力，但直接加工会导致几何偏差（如圆角），影响装配效果。

Method: 提出MXG语言表示可铣削几何，建模为平头钻头的减法操作；并通过表面接近度和路径约束的优化损失函数，恢复榫卯的紧密耦合。

Result: 在30种传统榫卯设计上验证，MXG方法成功生成CNC兼容且紧密拟合的几何结构，保留了原始设计特征。

Conclusion: MXG方法将传统榫卯重新诠释为CNC兼容设计，延续了这一传统工艺的演变，并确保其在未来制造实践中的相关性。

Abstract: Traditional integral wood joints, despite their strength, durability, and
elegance, remain rare in modern workflows due to the cost and difficulty of
manual fabrication. CNC milling offers a scalable alternative, but directly
milling traditional joints often fails to produce functional results because
milling induces geometric deviations, such as rounded inner corners, that alter
the target geometries of the parts. Since joints rely on tightly fitting
surfaces, such deviations introduce gaps or overlaps that undermine fit or
block assembly. We propose to overcome this problem by (1) designing a language
that represent millable geometry, and (2) co-optimizing part geometries to
restore coupling. We introduce Millable Extrusion Geometry (MXG), a language
for representing geometry as the outcome of milling operations performed with
flat-end drill bits. MXG represents each operation as a subtractive extrusion
volume defined by a tool direction and drill radius. This parameterization
enables the modeling of artifact-free geometry under an idealized zero-radius
drill bit, matching traditional joint designs. Increasing the radius then
reveals milling-induced deviations, which compromise the integrity of the
joint. To restore coupling, we formalize tight coupling in terms of both
surface proximity and proximity constraints on the mill-bit paths associated
with mating surfaces. We then derive two tractable, differentiable losses that
enable efficient optimization of joint geometry. We evaluate our method on 30
traditional joint designs, demonstrating that it produces CNC-compatible,
tightly fitting joints that approximates the original geometry. By
reinterpreting traditional joints for CNC workflows, we continue the evolution
of this heritage craft and help ensure its relevance in future making
practices.

</details>


### [2] [HRM^2Avatar: High-Fidelity Real-Time Mobile Avatars from Monocular Phone Scans](https://arxiv.org/abs/2510.13587)
*Chao Shi,Shenghao Jia,Jinhui Liu,Yong Zhang,Liangchao Zhu,Zhonglei Yang,Jinze Ma,Chaoyue Niu,Chengfei Lv*

Main category: cs.GR

TL;DR: HRM$^2$Avatar是一个从单目手机扫描创建高保真虚拟化身的框架，支持在移动设备上实时渲染和动画化。


<details>
  <summary>Details</summary>
Motivation: 为了解决从单视角视频序列重建高保真虚拟化身的挑战，本框架利用智能手机捕获的静态姿态序列和动态运动序列，提出了一个轻量级但高效的方法。

Method: 该方法在数据层面利用静态和动态序列，在表示层面采用轻量级表达方式重建高分辨率数字人类，并通过提取衣物网格和光照感知高斯表面实现高效渲染。

Result: 实验表明，HRM$^2$Avatar在移动设备上实现了120 FPS的渲染速度，并在视觉真实感和实时交互性上优于现有单目方法。

Conclusion: HRM$^2$Avatar通过高效的渲染管道和新型表示方法，成功实现了高保真虚拟化身的实时创建和渲染，推动了AR/VR和社交游戏的发展。

Abstract: We present HRM$^2$Avatar, a framework for creating high-fidelity avatars from
monocular phone scans, which can be rendered and animated in real time on
mobile devices. Monocular capture with smartphones provides a low-cost
alternative to studio-grade multi-camera rigs, making avatar digitization
accessible to non-expert users. Reconstructing high-fidelity avatars from
single-view video sequences poses challenges due to limited visual and
geometric data. To address these limitations, at the data level, our method
leverages two types of data captured with smartphones: static pose sequences
for texture reconstruction and dynamic motion sequences for learning
pose-dependent deformations and lighting changes. At the representation level,
we employ a lightweight yet expressive representation to reconstruct
high-fidelity digital humans from sparse monocular data. We extract garment
meshes from monocular data to model clothing deformations effectively, and
attach illumination-aware Gaussians to the mesh surface, enabling high-fidelity
rendering and capturing pose-dependent lighting. This representation
efficiently learns high-resolution and dynamic information from monocular data,
enabling the creation of detailed avatars. At the rendering level, real-time
performance is critical for animating high-fidelity avatars in AR/VR, social
gaming, and on-device creation. Our GPU-driven rendering pipeline delivers 120
FPS on mobile devices and 90 FPS on standalone VR devices at 2K resolution,
over $2.7\times$ faster than representative mobile-engine baselines.
Experiments show that HRM$^2$Avatar delivers superior visual realism and
real-time interactivity, outperforming state-of-the-art monocular methods.

</details>


### [3] [MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control](https://arxiv.org/abs/2510.13794)
*Xue Bin Peng*

Main category: cs.GR

TL;DR: MimicKit 是一个开源的框架，用于通过动作模仿和强化学习训练动作控制器，支持计算机图形学和机器人学的研究与应用。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个统一的训练框架，支持计算机图形学和机器人学的研究与应用，MimicKit 旨在通过标准化的环境、智能体和数据结构，简化动作控制器的开发过程。

Method: MimicKit 结合动作模仿和强化学习技术，实现了常用的动作模仿方法和强化学习算法。其代码库设计为模块化和可配置的，便于修改和扩展到新的任务和角色。

Result: 开源代码库提供了统一的环境、智能体和数据结构，支持模块化和可配置的训练框架，方便研究人员和开发者使用。

Conclusion: MimicKit 作为一个开源框架，成功地提供了一个灵活且标准化的工具，推动了动作模仿和强化学习在计算机图形学和机器人学领域的应用。

Abstract: MimicKit is an open-source framework for training motion controllers using
motion imitation and reinforcement learning. The codebase provides
implementations of commonly-used motion-imitation techniques and RL algorithms.
This framework is intended to support research and applications in computer
graphics and robotics by providing a unified training framework, along with
standardized environment, agent, and data structures. The codebase is designed
to be modular and easily configurable, enabling convenient modification and
extension to new characters and tasks. The open-source codebase is available
at: https://github.com/xbpeng/MimicKit.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [4] [Imperative Quantum Programming with Ownership and Borrowing in Guppy](https://arxiv.org/abs/2510.13082)
*Mark Koch,Agustín Borgna,Craig Roy,Alan Lawrence,Kartik Singhal,Seyon Sivarajah,Ross Duncan*

Main category: cs.PL

TL;DR: 本文旨在开发一种量子类型系统，结合易用的线性类型和命令式语义，同时保持安全性保证。


<details>
  <summary>Details</summary>
Motivation: 线性类型在函数式量子编程中强制执行“不可克隆”和“不可删除”定理，但在命令式量子编程中尚未广泛应用。

Method: 开发一种量子类型系统，结合易用的线性类型和命令式语义，并确保安全性。

Result: 所有提出的观点已在Quantinuum的Guppy编程语言中实现。

Conclusion: 本文成功设计了一种结合线性类型和命令式语义的量子类型系统，保持了安全性，并在实际语言中得到验证。

Abstract: Linear types enforce no-cloning and no-deleting theorems in functional
quantum programming. However, in imperative quantum programming, they have not
gained widespread adoption. This work aims to develop a quantum type system
that combines ergonomic linear typing with imperative semantics and maintains
safety guarantees. All ideas presented here have been implemented in
Quantinuum's Guppy programming language.

</details>


### [5] [Extensibility in Programming Languages: An overview](https://arxiv.org/abs/2510.13236)
*Sebastian mateos Nicolajsen*

Main category: cs.PL

TL;DR: 这篇论文探讨了编程语言的可扩展性，强调了常规语言设计中常被忽视的组成部分，并通过文献综述提出了宏、模块、类型和反射等关键主题。


<details>
  <summary>Details</summary>
Motivation: 作者在研究中发现缺乏对编程语言可扩展性的全面概述，因此希望通过本文填补这一空白，为未来的语言设计者提供启发。

Method: 通过文献综述，作者识别了可扩展性的关键主题（宏、模块、类型和反射），并分析了跨主题属性（参数化和一等公民行为）。

Result: 研究突出了编程语言结构中自定义性和灵活性的重要性，并为未来语言设计提供了多维度的思考框架。

Conclusion: 作者希望通过概述现有编程语言和研究的这些方面，激励未来的语言设计者在设计中更批判性地评估和考虑可扩展性。

Abstract: I here conduct an exploration of programming language extensibility, making
an argument for an often overlooked component of conventional language design.
Now, this is not a technical detailing of these components, rather, I attempt
to provide an overview as I myself have lacked during my time investigating
programming languages. Thus, read this as an introduction to the magical world
of extensibility. Through a literature review, I identify key extensibility
themes - Macros, Modules, Types, and Reflection - highlighting diverse
strategies for fostering extensibility. The analysis extends to cross-theme
properties such as Parametricism and First-class citizen behaviour, introducing
layers of complexity by highlighting the importance of customizability and
flexibility in programming language constructs. By outlining these facets of
existing programming languages and research, I aim to inspire future language
designers to assess and consider the extensibility of their creations
critically.

</details>


### [6] [Fast Trigonometric Functions using the RLIBM Approach](https://arxiv.org/abs/2510.13426)
*Sehyeok Park,Santosh Nagarakatte*

Main category: cs.PL

TL;DR: 本论文描述了使用RLIBM方法为三角函数开发多项式近似的过程，这些近似可以在多种表示和舍入模式下产生正确舍入的结果。关键挑战在于使用“pi”进行范围缩减，导致舍入误差放大并可能产生错误结果。作者提出快速范围缩减技术，保持“pi”的高精度，从而在所有输入上实现快速且正确的32位浮点数计算。


<details>
  <summary>Details</summary>
Motivation: 三角函数的多项式近似在高性能计算中具有重要意义，但传统方法在范围缩减过程中因“pi”的舍入误差导致结果不准确。本文旨在解决这一问题，确保在所有输入上正确舍入。

Method: 采用RLIBM方法，提出快速范围缩减技术，通过浮点数和整数计算保持“pi”的高精度，以减少舍入误差的放大效应。

Result: 开发的三角函数实现快速，且能够在所有输入上为多达32位的多种表示产生正确舍入的结果。

Conclusion: 通过高精度的范围缩减技术，成功解决了三角函数多项式近似中的关键挑战，为高性能计算提供了可靠且高效的实现。

Abstract: This paper describes our experience developing polynomial approximations for
trigonometric functions that produce correctly rounded results for multiple
representations and rounding modes using the RLIBM approach. A key challenge
with trigonometric functions concerns range reduction with "pi", which reduces
a given input in the domain of a 32-bit float to a small domain. Any rounding
error in the value of "pi" is amplified during range reduction, which can
result in wrong results. We describe our experience implementing fast range
reduction techniques that maintain a large number of bits of "pi" both with
floating-point and integer computations. The resulting implementations for
trigonometric functions are fast and produce correctly rounded results for all
inputs for multiple representations up to 32-bits with a single implementation.

</details>


### [7] [A Complementary Approach to Incorrectness Typing](https://arxiv.org/abs/2510.13725)
*Celia Mengyue Li,Sophie Pull,Steven Ramsay*

Main category: cs.PL

TL;DR: 本文介绍了一种新的双面类型系统，用于验证带有原子和模式匹配的功能程序的正确性和不正确性，通过定义类型范围在范式集合上并引入补集算子来实现否定。


<details>
  <summary>Details</summary>
Motivation: 为了解决功能程序中验证正确性和不正确性的问题，特别是针对带有原子和模式匹配的场景，需要一种能够覆盖广泛错误检测的类型系统。

Method: 采用双面类型系统，定义类型范围为范式集合而非值集合，并引入补集算子作为类型公式的否定。通过子类型化的表达性公理化展示了其可决定性。

Result: 补集算子允许在系统内推导广泛的否定原则，包括类型理论中的共蕴涵类比，并成功验证了许多类似Erlang程序的错误。整个类型系统不仅被证明是可靠的，而且对范式是完备的。

Conclusion: 该类型系统通过在范式上定义类型和补集算子，不仅实现了对程序错误的广泛检测，还保持了系统的可靠性和完备性。

Abstract: We introduce a new two-sided type system for verifying the correctness and
incorrectness of functional programs with atoms and pattern matching. A key
idea in the work is that types should range over sets of normal forms, rather
than sets of values, and this allows us to define a complement operator on
types that acts as a negation on typing formulas. We show that the complement
allows us to derive a wide range of refutation principles within the system,
including the type-theoretic analogue of co-implication, and we use them to
certify that a number of Erlang-like programs go wrong. An expressive
axiomatisation of the complement operator via subtyping is shown decidable, and
the type system as a whole is shown to be not only sound, but also complete for
normal forms.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [8] [Finding a Nash equilibrium of a random win-lose game in expected polynomial time](https://arxiv.org/abs/2510.12846)
*Andrea Collevecchio,Gabor Lugosi,Adrian Vetta,Rui-Ray Zhang*

Main category: cs.GT

TL;DR: 研究随机赢输博弈中纳什均衡的多项式时间算法，证明了对于几乎所有参数p(n)，存在预期多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 解决算法博弈论中长期未解决的开放性问题，即是否存在多项式时间算法计算随机双矩阵博弈的纳什均衡。

Method: 研究随机赢输博弈，其中n×n支付矩阵的条目是独立同分布的伯努利随机变量，参数为p(n)。根据不同参数范围设计算法。

Result: 证明对于几乎所有p(n)的参数范围（如p∼cn^{-a}，a≠1/2,1），存在预期多项式时间算法。部分特殊情况（如a=1/2或a=1）也提供了高效算法。

Conclusion: 在随机赢输博弈中，对于大多数参数p(n)，存在预期多项式时间算法计算纳什均衡，为开放性问题提供了部分解决方案。

Abstract: A long-standing open problem in algorithmic game theory asks whether or not
there is a polynomial time algorithm to compute a Nash equilibrium in a random
bimatrix game. We study random win-lose games, where the entries of the
$n\times n$ payoff matrices are independent and identically distributed
(i.i.d.) Bernoulli random variables with parameter $p=p(n)$. We prove that, for
nearly all values of the parameter $p=p(n)$, there is an expected
polynomial-time algorithm to find a Nash equilibrium in a random win-lose game.
More precisely, if $p\sim cn^{-a}$ for some parameters $a,c\ge 0$, then there
is an expected polynomial-time algorithm whenever $a\not\in \{1/2, 1\}$. In
addition, if $a = 1/2$ there is an efficient algorithm if either $c \le e^{-52}
2^{-8} $ or $c\ge 0.977$. If $a=1$, then there is an expected polynomial-time
algorithm if either $c\le 0.3849$ or $c\ge \log^9 n$.

</details>


### [9] [Equilibria in routing games with connected autonomous vehicles will not be strong, as exclusive clubs may form](https://arxiv.org/abs/2510.12862)
*Rafał Kucharski,Anastasia Psarou,Natello Descormier*

Main category: cs.GT

TL;DR: 研究首次展示了联网自动驾驶车辆（CAVs）通过形成联盟偏离用户均衡（User Equilibrium）的现象，这种行为可能对其他用户和交通系统产生负面影响。


<details>
  <summary>Details</summary>
Motivation: 传统的用户均衡假设驾驶员独立选择路线，但联网自动驾驶车辆的出现使其能够通过协作形成联盟，从而改变交通均衡状态。

Method: 通过精心设计的玩具网络示例，研究展示了由三辆自动驾驶车辆组成的“俱乐部”如何通过偏离用户均衡来获得更快的到达时间。

Result: 研究发现，这种联盟的形成会对未加入联盟的其他用户和系统产生负面影响，导致交通系统失衡。

Conclusion: 研究揭示了如果不加以限制，CAV运营商可能会故意打破传统的纳什均衡，导致交通系统不公平，并可能形成排他性的CAV精英群体。

Abstract: User Equilibrium is the standard representation of the so-called routing game
in which drivers adjust their route choices to arrive at their destinations as
fast as possible. Asking whether this Equilibrium is strong or not was
meaningless for human drivers who did not form coalitions due to technical and
behavioral constraints. This is no longer the case for connected autonomous
vehicles (CAVs), which will be able to communicate and collaborate to jointly
form routing coalitions.
  We demonstrate this for the first time on a carefully designed toy-network
example, where a `club` of three autonomous vehicles jointly decides to deviate
from the user equilibrium and benefit (arrive faster). The formation of such a
club has negative consequences for other users, who are not invited to join it
and now travel longer, and for the system, making it suboptimal and
disequilibrated, which triggers adaptation dynamics.
  This discovery has profound implications for the future of our cities. We
demonstrate that, if not prevented, CAV operators may intentionally
disequilibrate traffic systems from their classic Nash equilibria, benefiting
their own users and imposing costs on others. These findings suggest the
possible emergence of an exclusive CAV elite, from which human-driven vehicles
and non-coalition members may be excluded, potentially leading to
systematically longer travel times for those outside the coalition, which would
be harmful for the equity of public road networks.

</details>


### [10] [Efficiency of Constant Log Utility Market Makers](https://arxiv.org/abs/2510.12952)
*Maneesha Papireddygari,Xintong Wang,Bo Waggoner,David M. Pennock*

Main category: cs.GT

TL;DR: 本文研究了一种名为CLUM的自动化做市商机制，与LMSR相比，CLUM具有固定的最坏情况损失，适用于动态添加结果甚至无限多结果的场景。本文证明了CLUM定价问题的计算复杂度为#P难，并提出了一种基于概率的高效近似算法。


<details>
  <summary>Details</summary>
Motivation: 研究CLUM机制的动机在于解决传统LMSR做市商在最坏情况下损失随结果数量增长的问题，同时提升其在动态和无限结果市场中的实用性。

Method: 文章首先通过将2-SAT模型计数问题归约为CLUM定价问题，证明了其计算复杂度为#P难。随后提出了一种基于特定oracle的近似算法，该oracle能在多项式时间内处理区间证券。

Result: 研究结果表明，CLUM机制在固定最坏情况损失方面表现出色，且提出的近似算法在概率意义上高效运行，适用于金融期权设计等场景。

Conclusion: CLUM作为一种新型自动化做市商机制，优于传统LMSR，并在动态市场中展现出更强的适应性和实用性。提出的近似算法为其实际应用提供了可行性。

Abstract: Automated Market Makers (AMMs) are used to provide liquidity for
combinatorial prediction markets that would otherwise be too thinly traded.
They offer both buy and sell prices for any of the doubly exponential many
possible securities that the market can offer. The problem of setting those
prices is known to be #P-hard for the original and most well-known AMM, the
logarithmic market scoring rule (LMSR) market maker [Chen et al., 2008]. We
focus on another natural AMM, the Constant Log Utility Market Maker (CLUM).
Unlike LMSR, whose worst-case loss bound grows with the number of outcomes,
CLUM has constant worst-case loss, allowing the market to add outcomes on the
fly and even operate over countably infinite many outcomes, among other
features. Simpler versions of CLUM underpin several Decentralized Finance
(DeFi) mechanisms including the Uniswap protocol that handles billions of
dollars of cryptocurrency trades daily. We first establish the computational
complexity of the problem: we prove that pricing securities is #P-hard for
CLUM, via a reduction from the model counting 2-SAT problem. In order to make
CLUM more practically viable, we propose an approximation algorithm for pricing
securities that works with high probability. This algorithm assumes access to
an oracle capable of determining the maximum shares purchased of any one
outcome and the total number of outcomes that has that maximum amount
purchased. We then show that this oracle can be implemented in polynomial time
when restricted to interval securities, which are used in designing financial
options.

</details>


### [11] [Repeated Sales with Heterogeneous Buyer Sophistication](https://arxiv.org/abs/2510.13088)
*Rishi Patel,Emmanouil Pountourakis,Samuel Taggart*

Main category: cs.GT

TL;DR: 研究探讨了在无承诺能力的卖方与非耐用品长期买方互动中，行为定价策略的影响，分析了前瞻性与短视买方的混合对卖方收入和需求减少的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在无承诺能力的卖方与混合类型买方（前瞻性与短视）互动中，行为定价策略的动态及其对卖方学习和收入的影响。

Method: 使用两期模型分析短期影响，无限期模型分析长期影响，研究不同类型买方对卖方策略和需求的动态效应。

Result: 短期模型中，引入短视买方加剧需求减少；长期模型中，短视买方的存在抵消了极端需求减少，卖方收入接近有承诺能力的收入。

Conclusion: 研究表明，买方类型和时间范围对卖方策略和收入有显著影响，短视买方的引入在长期中可以提升卖方收入。

Abstract: This paper considers behavior-based price discrimination in the repeated sale
of a non-durable good to a single long-lived buyer, by a seller without
commitment power. We assume that there is a mixed population of forward-looking
``sophisticated'' buyers and myopic ``naive'' buyers. We investigate the impact
of these dynamics on the seller's ability to learn about the buyer and exploit
this learning for revenue. We obtain conclusions that differ dramatically with
the time horizon of the interactions. To understand short time horizons, we
analyze a two-period model, and find that the strategic demand reduction
observed with fully sophisticated buyers is robust to the introduction of naive
types. In fact, despite the inability of naive buyers to game the pricing
algorithm, their introduction can further harm the seller's revenue, due to
more intense demand reduction overall. For long horizons, we consider an
infinite-horizon model with time discounting. We find that the extreme demand
reduction predicted by previous work does not survive the introduction of naive
buyers. Instead, we observe equilibria where the seller learns meaningfully
despite the sophisticated buyers' demand reduction. We prove that for a natural
family of such equilibria, the seller's revenue is not just high, but
approximates the revenue attainable with commitment power, even when the
fraction of naive types is vanishingly small.

</details>


### [12] [A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version](https://arxiv.org/abs/2510.13261)
*Björn Filter,Ralf Möller,Özgür Lütfü Özçep*

Main category: cs.GT

TL;DR: 本文提出了一种基于比例的Shapley值方法，用于协作机器学习中公平奖励分配，取代了传统的加法形式，更适合贡献比例重要性高于绝对值差异的场景。


<details>
  <summary>Details</summary>
Motivation: 协作机器学习中，如何公平奖励各数据所有者的贡献且保持激励相容性是一个关键挑战。

Method: 引入基于比例的Shapley值，替代传统的加法形式，重新定义贡献的相对度量，同时保留原有激励框架。

Result: 证明基于比例的Shapley值满足相同的激励条件（公平性、个体理性、稳定性），且在贡献比例更重要时更具优势。

Conclusion: 本文提出了一种数学上严格的替代方案，特别适合贡献比例意义重大的协作机器学习场景。

Abstract: Collaborative machine learning enables multiple data owners to jointly train
models for improved predictive performance. However, ensuring incentive
compatibility and fair contribution-based rewards remains a critical challenge.
Prior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative
machine learning with incentive-aware model rewards. In: International
conference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by
allocating model rewards, which are non-monetary and freely replicable, based
on the Shapley value of each party's data contribution, measured via
information gain. In this paper, we introduce a ratio-based Shapley value that
replaces the standard additive formulation with a relative contribution
measure. While our overall reward framework, including the incentive
definitions and model-reward setting, remains aligned with that of Sim and
colleagues, the underlying value function is fundamentally different. Our
alternative valuation induces a different distribution of model rewards and
offers a new lens through which to analyze incentive properties. We formally
define the ratio-based value and prove that it satisfies the same set of
incentive conditions as the additive formulation, including adapted versions of
fairness, individual rationality, and stability. Like the original approach,
our method faces the same fundamental trade-offs between these incentives. Our
contribution is a mathematically grounded alternative to the additive Shapley
framework, potentially better suited to contexts where proportionality among
contributors is more meaningful than additive differences.

</details>


### [13] [Nash Flows Over Time with Tolls](https://arxiv.org/abs/2510.13518)
*Shaul Rosner,Marc Schröder,Laura Vargas Koch*

Main category: cs.GT

TL;DR: 研究了基于动态路由博弈的交通流模型，引入了收费机制，分析了非原子均衡条件下的路径选择和稳态计算问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过引入收费机制，增强Vickrey瓶颈模型的动态路由博弈分析，以更好地模拟实际交通流中的路径选择和成本分担问题。

Method: 方法包括在Vickrey瓶颈模型基础上引入收费机制，研究非原子均衡条件下的动态均衡，并提出计算稳态状态的算法。

Result: 结果显示，与未收费模型不同，动态均衡在成本和稳态方面不具备唯一性；研究还提供了一种计算稳态的方法。

Conclusion: 结论指出，引入收费机制后，动态均衡的复杂性增加，但通过提出的算法可以计算稳态状态。

Abstract: We study a dynamic routing game motivated by traffic flows. The base model
for an edge is the Vickrey bottleneck model. That is, edges are equipped with a
free flow transit time and a capacity. When the inflow into an edge exceeds its
capacity, a queue forms and the following particles experience a waiting time.
In this paper, we enhance the model by introducing tolls, i.e., a cost each
flow particle must pay for traversing an edge. In this setting we consider
non-atomic equilibria, which means flows over time in which every particle is
on a cheapest path, when summing up toll and travel time. We first show that
unlike in the non-tolled version of this model, dynamic equilibria are not
unique in terms of costs and do not necessarily reach a steady state. As a main
result, we provide a procedure to compute steady states in the model with
tolls.

</details>


### [14] [Online Fair Division With Subsidy: When Do Envy-Free Allocations Exist, and at What Cost?](https://arxiv.org/abs/2510.13633)
*Pooja Kulkarni,Ruta Mehta,Vishnu V. Narayan,Tomasz Ponitka*

Main category: cs.GT

TL;DR: 研究了在线公平分配不可分割物品的问题，侧重于保持无嫉妒性和补贴需求的分析。


<details>
  <summary>Details</summary>
Motivation: 解决在线分配不可分割物品时的公平性问题，尤其是在无嫉妒性分配可能不存在的情况下。

Method: 通过在在线环境中设计算法来保持无嫉妒性，并研究所需的补贴量。

Result: 展示了在某些估值类型下无法在线保持无嫉妒性，但在其他类型下可能通过有限补贴实现。

Conclusion: 对于特定估值类型，可以在线实现无嫉妒性分配，但补贴需求因情况而异。

Abstract: We study the problem of fairly allocating $m$ indivisible items arriving
online, among $n$ (offline) agents. Although envy-freeness has emerged as the
archetypal fairness notion, envy-free (EF) allocations need not exist with
indivisible items. To bypass this, a prominent line of research demonstrates
that there exist allocations that can be made envy-free by allowing a subsidy.
Extensive work in the offline setting has focused on finding such envy-freeable
allocations with bounded subsidy. We extend this literature to an online
setting where items arrive one at a time and must be immediately and
irrevocably allocated. Our contributions are two-fold:
  1. Maintaining EF Online: We show that envy-freeability cannot always be
preserved online when the valuations are submodular or supermodular, even with
binary marginals. In contrast, we design online algorithms that maintain
envy-freeability at every step for the class of additive valuations, and for
its superclasses including $k$-demand and SPLC valuations.
  2. Ensuring Low Subsidy: We investigate the quantity of subsidy required to
guarantee envy-freeness online. Surprisingly, even for additive valuations, the
minimum subsidy may be as large as $\Omega(mn)$, in contrast to the offline
setting, where the bound is $O(n)$. On the positive side, we identify valuation
classes where the minimum subsidy is small (i.e., does not depend on $m$),
including $k$-valued, rank-one, restricted additive, and identical valuations,
and we obtain (mostly) tight subsidy bounds for these classes.

</details>
