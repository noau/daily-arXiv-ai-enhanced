<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [RLGS: Reinforcement Learning-Based Adaptive Hyperparameter Tuning for Gaussian Splatting](https://arxiv.org/abs/2508.04078)
*Zhan Li,Huangying Zhan,Changyang Li,Qingan Yan,Yi Xu*

Main category: cs.GR

TL;DR: RLGS是一种基于强化学习的自适应超参数调优框架，用于3D高斯溅射（3DGS）技术，通过轻量级策略模块动态调整关键超参数，无需修改现有架构即可提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS的超参数调优过程需要大量人工参与且结果不稳定，RLGS旨在解决这一问题，通过自动化调优提升重建质量和效率。

Method: 提出RLGS框架，利用强化学习方法动态调整学习率和密集化阈值等关键超参数，框架与现有3DGS流程无缝集成且模型无关。

Result: RLGS在多个3DGS变体（如Taming-3DGS和3DGS-MCMC）上表现出色，提升了渲染质量（如Taming-3DGS在TNT数据集上的PSNR提高0.7dB）。

Conclusion: RLGS为3DGS训练中的超参数调优提供了有效且通用的自动化解决方案，填补了强化学习在3DGS中应用的空白。

Abstract: Hyperparameter tuning in 3D Gaussian Splatting (3DGS) is a labor-intensive
and expert-driven process, often resulting in inconsistent reconstructions and
suboptimal results. We propose RLGS, a plug-and-play reinforcement learning
framework for adaptive hyperparameter tuning in 3DGS through lightweight policy
modules, dynamically adjusting critical hyperparameters such as learning rates
and densification thresholds. The framework is model-agnostic and seamlessly
integrates into existing 3DGS pipelines without architectural modifications. We
demonstrate its generalization ability across multiple state-of-the-art 3DGS
variants, including Taming-3DGS and 3DGS-MCMC, and validate its robustness
across diverse datasets. RLGS consistently enhances rendering quality. For
example, it improves Taming-3DGS by 0.7dB PSNR on the Tanks and Temple (TNT)
dataset, under a fixed Gaussian budget, and continues to yield gains even when
baseline performance saturates. Our results suggest that RLGS provides an
effective and general solution for automating hyperparameter tuning in 3DGS
training, bridging a gap in applying reinforcement learning to 3DGS.

</details>


### [2] [Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research](https://arxiv.org/abs/2508.04326)
*Ke Li,Mana Masuda,Susanne Schmidt,Shohei Mori*

Main category: cs.GR

TL;DR: 本文系统调查了辐射场（RF）技术在XR领域的应用现状，分析了其潜在机会和研究空白，并提供了XR社区在RF快速发展的导航资源。


<details>
  <summary>Details</summary>
Motivation: 尽管辐射场（如3D高斯泼溅和神经辐射场）在交互式逼真视图合成方面取得了巨大进展，但它们在XR领域的贡献仍然较少。为了理解这一研究空白，作者进行了系统性调查。

Method: 研究人员收集了365篇与XR相关的RF研究论文，并从多个学科领域（如计算机视觉、计算机图形学、机器人技术等）进行分析，重点研究了其中66篇详细探讨XR应用的论文。

Result: 调查发现，RF技术在XR领域的应用和实现仍有待深入探索，研究团队为XR社区提供了一个导航资源，帮助其在RF快速发展中定位研究方向。

Conclusion: 通过系统调查，作者扩展并定位了XR特定的RF研究主题，为XR社区在RF研究中提供了宝贵的指导和资源。

Abstract: The development of radiance fields (RF), such as 3D Gaussian Splatting (3DGS)
and Neural Radiance Fields (NeRF), has revolutionized interactive
photorealistic view synthesis and presents enormous opportunities for XR
research and applications. However, despite the exponential growth of RF
research, RF-related contributions to the XR community remain sparse. To better
understand this research gap, we performed a systematic survey of current RF
literature to analyze (i) how RF is envisioned for XR applications, (ii) how
they have already been implemented, and (iii) the remaining research gaps. We
collected 365 RF contributions related to XR from computer vision, computer
graphics, robotics, multimedia, human-computer interaction, and XR communities,
seeking to answer the above research questions. Among the 365 papers, we
performed an analysis of 66 papers that already addressed a detailed aspect of
RF research for XR. With this survey, we extended and positioned XR-specific RF
research topics in the broader RF research field and provide a helpful resource
for the XR community to navigate within the rapid development of RF research.

</details>


### [3] [Surf3R: Rapid Surface Reconstruction from Sparse RGB Views in Seconds](https://arxiv.org/abs/2508.04508)
*Haodong Zhu,Changbai Li,Yangyang Ren,Zichao Feng,Xuhui Liu,Hanlin Chen,Xiantong Zhen,Baochang Zhang*

Main category: cs.GR

TL;DR: Surf3R是一种端到端的前馈方法，能够在无需相机位姿估计的情况下，从稀疏视图中重建3D表面，并在10秒内完成整个场景。


<details>
  <summary>Details</summary>
Motivation: 当前的多视图3D重建方法依赖准确的相机标定和位姿估计，需要复杂且耗时的预处理，限制了其实际应用。

Method: Surf3R采用多分支和多视图解码架构，通过分支处理、跨视图注意力和分支间融合，有效捕获互补的几何线索。此外，引入了基于显式3D高斯表示的D-Normal正则器，联合优化3D几何。

Result: 实验结果表明，Surf3R在ScanNet++和Replica数据集上的多个表面重建指标中达到了最先进的性能，展示了出色的泛化能力和高效性。

Conclusion: Surf3R通过创新的架构和正则化方法，显著提高了3D一致性和表面细节准确性，推动了无需相机标定的多视图3D重建技术的发展。

Abstract: Current multi-view 3D reconstruction methods rely on accurate camera
calibration and pose estimation, requiring complex and time-intensive
pre-processing that hinders their practical deployment. To address this
challenge, we introduce Surf3R, an end-to-end feedforward approach that
reconstructs 3D surfaces from sparse views without estimating camera poses and
completes an entire scene in under 10 seconds. Our method employs a
multi-branch and multi-view decoding architecture in which multiple reference
views jointly guide the reconstruction process. Through the proposed
branch-wise processing, cross-view attention, and inter-branch fusion, the
model effectively captures complementary geometric cues without requiring
camera calibration. Moreover, we introduce a D-Normal regularizer based on an
explicit 3D Gaussian representation for surface reconstruction. It couples
surface normals with other geometric parameters to jointly optimize the 3D
geometry, significantly improving 3D consistency and surface detail accuracy.
Experimental results demonstrate that Surf3R achieves state-of-the-art
performance on multiple surface reconstruction metrics on ScanNet++ and Replica
datasets, exhibiting excellent generalization and efficiency.

</details>


### [4] [MienCap: Realtime Performance-Based Facial Animation with Live Mood Dynamics](https://arxiv.org/abs/2508.04687)
*Ye Pan,Ruisi Zhang,Jingying Wang,Nengfu Chen,Yilin Qiu,Yu Ding,Kenny Mitchell*

Main category: cs.GR

TL;DR: 该论文提出了一种结合传统混合形状动画技术和机器学习模型的方法，用于驱动逼真的3D风格化角色表情。提出了非实时和实时系统，均显著优于商业产品Faceware。


<details>
  <summary>Details</summary>
Motivation: 旨在改进基于性能的动画，以驱动真正感知的逼真3D风格化角色，提升表情生成的速度和准确性。

Method: 结合传统混合形状动画技术与多种机器学习模型，提出了非实时（3D情感迁移网络）和实时（混合形状适应网络）两个系统。

Result: 与非实时商业产品Faceware相比，系统的表情识别度、强度和吸引力评分显著更高。

Conclusion: 该系统可应用于动画制作流程，帮助动画师快速准确地创建所需表情。

Abstract: Our purpose is to improve performance-based animation which can drive
believable 3D stylized characters that are truly perceptual. By combining
traditional blendshape animation techniques with multiple machine learning
models, we present both non-real time and real time solutions which drive
character expressions in a geometrically consistent and perceptually valid way.
For the non-real time system, we propose a 3D emotion transfer network makes
use of a 2D human image to generate a stylized 3D rig parameters. For the real
time system, we propose a blendshape adaption network which generates the
character rig parameter motions with geometric consistency and temporally
stability. We demonstrate the effectiveness of our system by comparing to a
commercial product Faceware. Results reveal that ratings of the recognition,
intensity, and attractiveness of expressions depicted for animated characters
via our systems are statistically higher than Faceware. Our results may be
implemented into the animation pipeline, and provide animators with a system
for creating the expressions they wish to use more quickly and accurately.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [If-T: A Benchmark for Type Narrowing](https://arxiv.org/abs/2508.03830)
*Hanwen Guo,Ben Greenman*

Main category: cs.PL

TL;DR: 该论文提出了If-T，一种语言无关的设计基准，用于评估类型细化系统在不同语言中的实现效果，旨在平衡精度与性能。


<details>
  <summary>Details</summary>
Motivation: 动态类型语言中，类型细化（type narrowing）是确保程序正确性的关键机制，但缺乏统一的设计标准和评估方法。If-T旨在填补这一空白。

Method: If-T通过文献综述、渐进式语言（如TypeScript）的文档和类型检查器实验，提出了类型细化的核心技术维度，并为每个维度设计了正负示例程序作为基准。

Result: 在五种类型检查器（TypeScript、Flow、Typed Racket、mypy和Pyright）上实现If-T，揭示了它们在逻辑变量跟踪和用户定义细化谓词等方面的差异。

Conclusion: If-T为未来类型系统设计提供了权衡精度、注解负担和性能的工具，帮助研究者和语言设计者更好地理解类型细化系统的复杂性与实用性。

Abstract: **Context:** The design of static type systems that can validate
dynamically-typed programs (**gradually**) is an ongoing challenge. A key
difficulty is that dynamic code rarely follows datatype-driven design. Programs
instead use runtime tests to narrow down the proper usage of incoming data.
Type systems for dynamic languages thus need a **type narrowing** mechanism
that refines the type environment along individual control paths based on
dominating tests, a form of flow-sensitive typing. In order to express
refinements, the type system must have some notion of sets and subsets. Since
set-theoretic types are computationally and ergonomically complex, the need for
type narrowing raises design questions about how to balance precision and
performance. **Inquiry:** To date, the design of type narrowing systems has
been driven by intuition, past experience, and examples from users in various
language communities. There is no standard that captures desirable and
undesirable behaviors. Prior formalizations of narrowing are also significantly
more complex than a standard type system, and it is unclear how the extra
complexity pays off in terms of concrete examples. This paper addresses the
problems through If-T, a language-agnostic **design benchmark** for type
narrowing that characterizes the abilities of implementations using simple
programs that draw attention to fundamental questions. Unlike a traditional
performance-focused benchmark, If-T measures a narrowing system's ability to
validate correct code and reject incorrect code. Unlike a test suite, systems
are not required to fully conform to If-T. Deviations are acceptable provided
they are justified by well-reasoned design considerations, such as compile-time
performance. **Approach:** If-T is guided by the literature on type narrowing,
the documentation of gradual languages such as TypeScript, and experiments with
typechecker implementations. We have identified a set of core technical
dimensions for type narrowing. For each dimension, the benchmark contains a set
of topics and (at least) two characterizing programs per topic: one that should
typecheck and one that should not typecheck. **Knowledge:** If-T provides a
baseline to measure type narrowing systems. For researchers, it provides
criteria to categorize future designs via its collection of positive and
negative examples. For language designers, the benchmark demonstrates the
payoff of typechecker complexity in terms of concrete examples. Designers can
use the examples to decide whether supporting a particular example is
worthwhile. Both the benchmark and its implementations are freely available
online. **Grounding:** We have implemented the benchmark for five typecheckers:
TypeScript, Flow, Typed Racket, mypy, and Pyright. The results highlight
important differences, such as the ability to track logical implications among
program variables and typechecking for user-defined narrowing predicates.
**Importance:** Type narrowing is essential for gradual type systems, but the
tradeoffs between systems with different complexity have been unclear. If-T
clarifies these tradeoffs by illustrating the benefits and limitations of each
level of complexity. With If-T as a way to assess implementations in a fair,
cross-language manner, future type system designs can strive for a better
balance among precision, annotation burden, and performance.

</details>


### [6] [A Type System for Data Privacy Compliance in Active Object Languages](https://arxiv.org/abs/2508.03831)
*Chinmayi Prabhu Baramashetru,Paola Giannini,Silvia Lizeth Tapia Tarifa,Olaf Owe*

Main category: cs.PL

TL;DR: 本文提出了一种基于语言的隐私集成方法，通过静态和运行时技术结合，将GDPR合规性验证嵌入系统执行中，实现了数据保护的自动化与系统性。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护法规（如GDPR）要求系统性考虑敏感数据的信息流和交互，但将抽象原则转化为具体方法仍具挑战性。

Method: 采用基于语言的隐私集成方法，结合静态类型检查和类型推断，跟踪授权数据流，并根据用户同意自动生成运行时约束。

Result: 通过类型系统将合规检查与用户同意变更集成，框架能确保个人数据处理符合GDPR约束，并通过示例和健全性证明展示了其可行性。

Conclusion: 该工作为隐私感知系统设计提供了系统化、自动化的方法，推动了GDPR合规性在编程语言中的集成，对医疗或金融等领域的可信系统构建具有重要意义。

Abstract: Data protection laws such as GDPR aim to give users unprecedented control
over their personal data. Compliance with these regulations requires
systematically considering information flow and interactions among entities
handling sensitive data. Privacy-by-design principles advocate embedding data
protection into system architectures as a default. However, translating these
abstract principles into concrete, explicit methods remains a significant
challenge. This paper addresses this gap by proposing a language-based approach
to privacy integration, combining static and runtime techniques. By employing
type checking and type inference in an active object language, the framework
enables the tracking of authorised data flows and the automatic generation of
constraints checked at runtime based on user consent. This ensures that
personal data is processed in compliance with GDPR constraints. The key
contribution of this work is a type system that gather the compliance checks
and the changes to users consent and integrates data privacy compliance
verification into system execution. The paper demonstrates the feasibility of
this approach through a soundness proof and several examples, illustrating how
the proposed language addresses common GDPR requirements, such as user consent,
purpose limitation, and data subject rights. This work advances the state of
the art in privacy-aware system design by offering a systematic and automated
method for integrating GDPR compliance into programming languages. This
capability has implications for building trustworthy systems in domains such as
healthcare or finance, where data privacy is crucial.

</details>


### [7] [Generating Inputs for Grammar Mining using Dynamic Symbolic Execution](https://arxiv.org/abs/2508.03832)
*Andreas Pointner,Josef Pichler,Herbert Prähofer*

Main category: cs.PL

TL;DR: 本文介绍了一种自动化生成输入以解决语法挖掘中数据不完整问题的新方法，通过动态符号执行和迭代扩展机制，能够提取出更全面的语法规范。


<details>
  <summary>Details</summary>
Motivation: 现有语法挖掘方法依赖于完整输入数据，而实际运行中仅能获取部分输入数据，导致生成的语法规范不完整，无法覆盖边缘情况或已支持但不再使用的功能。

Method: 基于动态符号执行（DSE），提出了一种三阶段的输入生成方法，通过迭代扩展和分阶段输入生成机制，克服了DSE在结构化输入解析中的限制。

Result: 在11个基准应用中测试表明，该方法提取的语法精确度和覆盖率接近现有方法如Mimid，且能发现常规方法忽略的细微功能和边缘情况。

Conclusion: 该方法为软件工程研究人员和从业者提供了一种自动化、可扩展且精确的语法挖掘解决方案，无需手动输入生成即可提升提取语法的全面性和鲁棒性。

Abstract: A vast number of software systems include components that parse and process
structured input. In addition to programming languages, which are analyzed by
compilers or interpreters, there are numerous components that process
standardized or proprietary data formats of varying complexity. Even if such
components were initially developed and tested based on a specification, such
as a grammar, numerous modifications and adaptations over the course of
software evolution can make it impossible to precisely determine which inputs
they actually accept. In this situation, grammar mining can be used to
reconstruct the specification in the form of a grammar. Established approaches
already produce useful results, provided that sufficient input data is
available to fully cover the input language. However, achieving this
completeness is a major challenge. In practice, only input data recorded during
the operation of the software systems is available. If this data is used for
grammar mining, the resulting grammar reflects only the actual processed inputs
but not the complete grammar of the input language accepted by the software
component. As a result, edge cases or previously supported features that no
longer appear in the available input data are missing from the generated
grammar. This work addresses this challenge by introducing a novel approach for
the automatic generation of inputs for grammar mining. Although input
generators have already been used for fuzz testing, it remains unclear whether
they are also suitable for grammar miners. Building on the grammar miner Mimid,
this work presents a fully automated approach to input generation. The approach
leverages Dynamic Symbolic Execution (DSE) and extends it with two mechanisms
to overcome the limitations of DSE regarding structured input parsers. First,
the search for new inputs is guided by an iterative expansion that starts with
a single-character input and gradually extends it. Second, input generation is
structured into a novel three-phase approach, which separates the generation of
inputs for parser functions. The proposed method was evaluated against a
diverse set of eleven benchmark applications from the existing literature.
Results demonstrate that the approach achieves precision and recall for
extracted grammars close to those derived from state-of-the-art grammar miners
such as Mimid. Notably, it successfully uncovers subtle features and edge cases
in parsers that are typically missed by such grammar miners. The effectiveness
of the method is supported by empirical evidence, showing that it can achieve
high performance in various domains without requiring prior input samples. This
contribution is significant for researchers and practitioners in software
engineering, offering an automated, scalable, and precise solution for grammar
mining. By eliminating the need for manual input generation, the approach not
only reduces workload but also enhances the robustness and comprehensiveness of
the extracted grammars. Following this approach, software engineers can
reconstruct specification from existing (legacy) parsers.

</details>


### [8] [Weak Memory Model Formalisms: Introduction and Survey](https://arxiv.org/abs/2508.04115)
*Roger C. Su,Robert J. Colvin*

Main category: cs.PL

TL;DR: 本文调查了弱内存模型的正式化领域，包括其规范、对执行的影响以及用于推理代码的工具和推理系统。


<details>
  <summary>Details</summary>
Motivation: 由于微架构特性或编译器转换，程序顺序不能可靠地指示执行顺序，因此需要内存一致性模型来定义并发系统中共享内存访问的观察顺序。这对于开发安全和安全关键的低级软件至关重要。

Method: 本文通过介绍两种常见的正式表示风格（操作语义和公理语义）并简化示例（如Intel的x86），讨论了弱内存模型的规范及其影响。

Result: 调查涵盖了导致可观察弱行为的长期硬件特性、实践和理论中的历史发展概述、可计算性和复杂性结果，以及当前和未来的研究方向。

Conclusion: 本文通过综述弱内存模型的正式化方法和工具，为开发人员提供了一种理解和应对弱内存效应的途径，并展望了未来的研究趋势。

Abstract: Memory consistency models define the order in which accesses to shared memory
in a concurrent system may be observed to occur. Such models are a necessity
since program order is not a reliable indicator of execution order, due to
microarchitectural features or compiler transformations. Concurrent
programming, already a challenging task, is thus made even harder when weak
memory effects must be addressed. A rigorous specification of weak memory
models is therefore essential to make this problem tractable for developers of
safety- and security-critical, low-level software.
  In this paper we survey the field of formalisations of weak memory models,
including their specification, their effects on execution, and tools and
inference systems for reasoning about code. To assist the discussion we also
provide an introduction to two styles of formal representation found commonly
in the literature (using a much simplified version of Intel's x86 as the
example): a step-by-step construction of traces of the system (operational
semantics); and with respect to relations between memory events (axiomatic
semantics). The survey covers some long-standing hardware features that lead to
observable weak behaviours, a description of historical developments in
practice and in theory, an overview of computability and complexity results,
and outlines current and future directions in the field.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Mechanism Design for Facility Location using Predictions](https://arxiv.org/abs/2508.03818)
*Toby Walsh*

Main category: cs.GT

TL;DR: 研究了设施位置问题中结合预测最佳位置的机制，强调从平等视角（考虑最大距离和最小效用）的新见解，并设计了更鲁棒的新机制，通过调整参数平衡鲁棒性和一致性。此外，提出了用于定位两个设施的策略证明机制。


<details>
  <summary>Details</summary>
Motivation: 现有设施位置问题的研究多关注最大距离，而忽略了最小效用等其他因素。本研究旨在通过结合预测和综合考虑多个因素来优化设施位置的选择机制。

Method: 提出了结合预测的机制设计方法，通过调整参数权衡鲁棒性和一致性，并设计了新的策略证明机制用于两个设施的定位问题。

Result: 研究表明，综合考虑最大距离和最小效用的机制优于仅考虑最大距离的机制。新设计的机制在鲁棒性和一致性之间实现了更好的平衡。

Conclusion: 通过引入预测和多元视角，本研究提出了更高效的设施位置选择机制，为未来的相关研究提供了新的方向。

Abstract: We study mechanisms for the facility location problem augmented with
predictions of the optimal facility location. We demonstrate that an
egalitarian viewpoint which considers both the maximum distance of any agent
from the facility and the minimum utility of any agent provides important new
insights compared to a viewpoint that just considers the maximum distance. As
in previous studies, we consider performance in terms of consistency (worst
case when predictions are accurate) and robustness (worst case irrespective of
the accuracy of predictions). By considering how mechanisms with predictions
can perform poorly, we design new mechanisms that are more robust. Indeed, by
adjusting parameters, we demonstrate how to trade robustness for consistency.
We go beyond the single facility problem by designing novel strategy proof
mechanisms for locating two facilities with bounded consistency and robustness
that use two predictions for where to locate the two facilities.

</details>


### [10] [What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives](https://arxiv.org/abs/2508.03824)
*Hamzah I. Khan,Jingqi Li,David Fridovich-Keil*

Main category: cs.GT

TL;DR: 该论文通过“level-2推理”框架解决了多智能体交互中目标推断的局限性，揭示了传统“level-1推理”在现实场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有逆向博弈理论中的“level-1推理”假设所有智能体完全了解彼此目标，这在分散式决策场景（如城市驾驶和谈判）中不成立。论文旨在解决由于智能体对彼此目标的异质性估计而导致的推断误差问题。

Method: 论文提出了“level-2推理”框架，重点关注每个智能体对其他智能体目标的估计。即使在良性设置（如线性二次博弈）中，该问题也是非凸的，因此作者开发了一种基于梯度的高效局部求解方法。

Result: 通过在合成城市驾驶场景中的实验，论文证明了“level-2推理”能够揭示传统方法忽略的微妙目标偏差。

Conclusion: 该研究证明了推断智能体对彼此目标的异质性估计的重要性，并提出了一种高效的方法来改进多智能体交互中的目标推断。

Abstract: Effectively interpreting strategic interactions among multiple agents
requires us to infer each agent's objective from limited information. Existing
inverse game-theoretic approaches frame this challenge in terms of a "level-1"
inference problem, in which we take the perspective of a third-party observer
and assume that individual agents share complete knowledge of one another's
objectives. However, this assumption breaks down in decentralized, real-world
decision scenarios like urban driving and bargaining, in which agents may act
based on conflicting views of one another's objectives. We demonstrate the
necessity of inferring agents' heterogeneous estimates of each other's
objectives through empirical examples, and by theoretically characterizing the
prediction error of level-1 inference on fictitious gameplay data from
linear-quadratic games. To address this fundamental issue, we propose a
framework for level-2 inference to address the question: "What does each agent
believe about all agents' objectives?" We prove that the level-2 inference
problem is non-convex even in benign settings like linear-quadratic games, and
we develop an efficient gradient-based approach for identifying local
solutions. Experiments on a synthetic urban driving example show that our
approach uncovers nuanced misalignments that level-1 methods miss.

</details>


### [11] [Inequality in the Age of Pseudonymity](https://arxiv.org/abs/2508.04668)
*Aviv Yaish,Nir Chemaya,Lin William Cong,Dahlia Malkhi*

Main category: cs.GT

TL;DR: 论文探讨了在匿名或区块链平台中，因虚假身份（Sybils）的存在导致不平等度量（如基尼系数）失真的问题，并提出了一些具有抗Sybil特性的新度量方法。


<details>
  <summary>Details</summary>
Motivation: 由于不平等度量（如基尼系数）在政策制定和数字平台中的应用日益广泛，本研究旨在解决在匿名环境中因虚假身份（Sybils）导致度量失真的问题。

Method: 通过分析满足经典不平等度量性质的度量方法，研究提出了几类具有抗Sybil特性的新度量，并对其进行了全面刻画。

Result: 研究发现，传统不平等度量（如基尼系数）易受Sybil攻击，而抗Sybil度量在精细评估不平等时存在局限性。

Conclusion: 论文揭示了Sybils对不平等度量的影响，并提出了一些抗Sybil的度量方法，尽管这些方法在精细评估不平等时存在限制。

Abstract: Inequality measures such as the Gini coefficient are used to inform and
motivate policymaking, and are increasingly applied to digital platforms. We
analyze how measures fare in pseudonymous settings, as common to internet-based
or blockchain-based platforms. One key challenge that arises is the ability of
actors to create multiple fake identities under fictitious false names, also
known as ``Sybils.'' While some actors may do so to preserve their privacy, we
show that this can inadvertently distort inequality metrics. As we show, when
using inequality measures that satisfy literature's canonical set of desired
properties, the presence of Sybils in an economy implies that it is impossible
to properly measure the economy's inequality. Then, we present several classes
of Sybil-proof measures that satisfy relaxed versions of the aforementioned
desired properties, and, by fully characterizing them, we prove that the
structure imposed restricts their ability to assess inequality at a
fine-grained level. In addition, we prove that popular inequality metrics,
including the famous Gini coefficient, are vulnerable to Sybil manipulations,
and examine the dynamics that result in the creation of Sybils, whether in
pseudonymous settings or traditional ones.

</details>
