{"id": "2508.00398", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.00398", "abs": "https://arxiv.org/abs/2508.00398", "authors": ["Sunjae Yoon", "Gwanhyeong Koo", "Younghwan Lee", "Ji Woo Hong", "Chang D. Yoo"], "title": "Occlusion-robust Stylization for Drawing-based 3D Animation", "comment": "11 pages, 13 figures, ICCV 2025", "summary": "3D animation aims to generate a 3D animated video from an input image and a\ntarget 3D motion sequence. Recent advances in image-to-3D models enable the\ncreation of animations directly from user-hand drawings. Distinguished from\nconventional 3D animation, drawing-based 3D animation is crucial to preserve\nartist's unique style properties, such as rough contours and distinct stroke\npatterns. However, recent methods still exhibit quality deterioration in style\nproperties, especially under occlusions caused by overlapping body parts,\nleading to contour flickering and stroke blurring. This occurs due to a\n`stylization pose gap' between training and inference in stylization networks\ndesigned to preserve drawing styles in drawing-based 3D animation systems. The\nstylization pose gap denotes that input target poses used to train the\nstylization network are always in occlusion-free poses, while target poses\nencountered in an inference include diverse occlusions under dynamic motions.\nTo this end, we propose Occlusion-robust Stylization Framework (OSF) for\ndrawing-based 3D animation. We found that while employing object's edge can be\neffective input prior for guiding stylization, it becomes notably inaccurate\nwhen occlusions occur at inference. Thus, our proposed OSF provides\nocclusion-robust edge guidance for stylization network using optical flow,\nensuring a consistent stylization even under occlusions. Furthermore, OSF\noperates in a single run instead of the previous two-stage method, achieving\n2.4x faster inference and 2.1x less memory.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u6d41\u7684\u906e\u6321\u9c81\u68d2\u8fb9\u7f18\u5f15\u5bfc\u6846\u67b6\uff08OSF\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u7ed8\u56fe\u98ce\u683c\u57283D\u52a8\u753b\u4e2d\u7684\u9000\u5316\u95ee\u9898\uff0c\u5c24\u5176\u662f\u906e\u6321\u5bfc\u81f4\u7684\u8f6e\u5ed3\u95ea\u70c1\u548c\u7b14\u753b\u6a21\u7cca\u3002", "motivation": "\u4f20\u7edf3D\u52a8\u753b\u65b9\u6cd5\u5728\u4fdd\u7559\u827a\u672f\u5bb6\u72ec\u7279\u7ed8\u56fe\u98ce\u683c\uff08\u5982\u7c97\u7cd9\u8f6e\u5ed3\u548c\u7b14\u753b\uff09\u65f6\uff0c\u7531\u4e8e\u906e\u6321\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e0e\u63a8\u7406\u59ff\u52bf\u5dee\u5f02\uff08\u201c\u98ce\u683c\u5316\u59ff\u52bf\u5dee\u8ddd\u201d\uff09\uff0c\u4f1a\u51fa\u73b0\u8d28\u91cf\u9000\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u906e\u6321\u9c81\u68d2\u98ce\u683c\u5316\u6846\u67b6\uff08OSF\uff09\uff0c\u5229\u7528\u5149\u6d41\u63d0\u4f9b\u906e\u6321\u9c81\u68d2\u7684\u8fb9\u7f18\u5f15\u5bfc\uff0c\u907f\u514d\u8fb9\u7f18\u4fe1\u606f\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u5355\u6b21\u8fd0\u884c\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u3002", "result": "OSF\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e00\u81f4\u7684\u98ce\u683c\u5316\u6548\u679c\uff0c\u76f8\u6bd4\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0\u4e862.4\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u548c2.1\u500d\u7684\u5185\u5b58\u51cf\u5c11\u3002", "conclusion": "OSF\u6709\u6548\u5730\u89e3\u51b3\u4e86\u7ed8\u56fe\u98ce\u683c\u5728\u52a8\u6001\u8fd0\u52a8\u548c\u906e\u6321\u4e0b\u7684\u9000\u5316\u95ee\u9898\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u3002"}}
{"id": "2508.00424", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.00424", "abs": "https://arxiv.org/abs/2508.00424", "authors": ["Kresimir Matkovic", "Rainer Splechtna", "Denis Gracanin", "Helwig Hauser"], "title": "CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data", "comment": "Will be published in TVCG and presented at IEEE VIS", "summary": "The interactive visual analysis of set-typed data, i.e., data with attributes\nthat are of type set, is a rewarding area of research and applications.\nValuable prior work has contributed solutions that enable the study of such\ndata with individual set-typed dimensions. In this paper, we present CrossSet,\na novel method for the joint study of two set-typed dimensions and their\ninterplay. Based on a task analysis, we describe a new, multi-scale approach to\nthe interactive visual exploration and analysis of such data. Two set-typed\ndata dimensions are jointly visualized using a hierarchical matrix layout,\nenabling the analysis of the interactions between two set-typed attributes at\nseveral levels, in addition to the analysis of individual such dimensions.\nCrossSet is anchored at a compact, large-scale overview that is complemented by\ndrill-down opportunities to study the relations between and within the\nset-typed dimensions, enabling an interactive visual multi-scale exploration\nand analysis of bivariate set-typed data. Such an interactive approach makes it\npossible to study single set-typed dimensions in detail, to gain an overview of\nthe interaction and association between two such dimensions, to refine one of\nthe dimensions to gain additional details at several levels, and to drill down\nto the specific interactions of individual set-elements from the set-typed\ndimensions. To demonstrate the effectiveness and efficiency of CrossSet, we\nhave evaluated the new method in the context of several application scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCrossSet\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5206\u6790\u4e24\u7c7b\u96c6\u5408\u7c7b\u578b\u6570\u636e\u7684\u8054\u5408\u7814\u7a76\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u4e2a\u96c6\u5408\u7c7b\u578b\u6570\u636e\u7684\u5206\u6790\uff0c\u7f3a\u4e4f\u5bf9\u4e24\u7c7b\u96c6\u5408\u7c7b\u578b\u6570\u636e\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u7684\u8054\u5408\u7814\u7a76\u9700\u6c42\u7684\u652f\u6301\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u5c3a\u5ea6\u7684\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u5206\u5c42\u77e9\u9635\u5e03\u5c40\u8054\u5408\u53ef\u89c6\u5316\u4e24\u7c7b\u96c6\u5408\u7c7b\u578b\u6570\u636e\u3002", "result": "CrossSet\u901a\u8fc7\u7d27\u51d1\u7684\u5927\u89c4\u6a21\u6982\u89c8\u548c\u8be6\u7ec6\u94bb\u53d6\u529f\u80fd\uff0c\u652f\u6301\u591a\u5c3a\u5ea6\u4ea4\u4e92\u5f0f\u5206\u6790\uff0c\u5e76\u5728\u591a\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002", "conclusion": "CrossSet\u4e3a\u96c6\u5408\u7c7b\u578b\u6570\u636e\u7684\u8054\u5408\u5206\u6790\u548c\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u6269\u5c55\u4e86\u73b0\u6709\u7814\u7a76\u7684\u80fd\u529b\u3002"}}
{"id": "2508.00428", "categories": ["cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.00428", "abs": "https://arxiv.org/abs/2508.00428", "authors": ["Nan Xiang", "Tianyi Liang", "Haiwen Huang", "Shiqi Jiang", "Hao Huang", "Yifei Huang", "Liangyu Chen", "Changbo Wang", "Chenhui Li"], "title": "Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation", "comment": "IEEE VIS VAST 2025 ACM 2012 CCS - Human-centered computing,\n  Visualization, Visualization design and evaluation methods", "summary": "Text-to-3D (T23D) generation has transformed digital content creation, yet\nremains bottlenecked by blind trial-and-error prompting processes that yield\nunpredictable results. While visual prompt engineering has advanced in\ntext-to-image domains, its application to 3D generation presents unique\nchallenges requiring multi-view consistency evaluation and spatial\nunderstanding. We present Sel3DCraft, a visual prompt engineering system for\nT23D that transforms unstructured exploration into a guided visual process. Our\napproach introduces three key innovations: a dual-branch structure combining\nretrieval and generation for diverse candidate exploration; a multi-view hybrid\nscoring approach that leverages MLLMs with innovative high-level metrics to\nassess 3D models with human-expert consistency; and a prompt-driven visual\nanalytics suite that enables intuitive defect identification and refinement.\nExtensive testing and user studies demonstrate that Sel3DCraft surpasses other\nT23D systems in supporting creativity for designers.", "AI": {"tldr": "Sel3DCraft\u662f\u4e00\u4e2a\u7528\u4e8e\u6587\u672c\u52303D\u751f\u6210\u7684\u89c6\u89c9\u63d0\u793a\u5de5\u7a0b\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u7ed3\u6784\u3001\u591a\u89c6\u56fe\u6df7\u5408\u8bc4\u5206\u548c\u53ef\u89c6\u5316\u5206\u6790\u5957\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6548\u679c\u548c\u8bbe\u8ba1\u5e08\u7684\u521b\u9020\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u6587\u672c\u52303D\u751f\u6210\u6280\u672f\u53d7\u9650\u4e8e\u76f2\u76ee\u7684\u8bd5\u9519\u63d0\u793a\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9884\u6d4b\u3002\u89c6\u89c9\u63d0\u793a\u5de5\u7a0b\u5728\u6587\u672c\u5230\u56fe\u50cf\u9886\u57df\u5df2\u6709\u8fdb\u5c55\uff0c\u4f46\u57283D\u751f\u6210\u4e2d\u9762\u4e34\u591a\u89c6\u56fe\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u7406\u89e3\u7b49\u72ec\u7279\u6311\u6218\u3002", "method": "Sel3DCraft\u5f15\u5165\u4e86\u53cc\u5206\u652f\u7ed3\u6784\uff08\u68c0\u7d22\u4e0e\u751f\u6210\u7ed3\u5408\uff09\u3001\u591a\u89c6\u56fe\u6df7\u5408\u8bc4\u5206\u65b9\u6cd5\uff08\u5229\u7528MLLM\u548c\u9ad8\u5c42\u6b21\u6307\u6807\u8bc4\u4f303D\u6a21\u578b\u7684\u4e00\u81f4\u6027\uff09\u4ee5\u53ca\u53ef\u89c6\u5316\u5206\u6790\u5957\u4ef6\uff08\u5b9e\u73b0\u76f4\u89c2\u7684\u7f3a\u9677\u8bc6\u522b\u4e0e\u6539\u8fdb\uff09\u3002", "result": "\u7ecf\u8fc7\u5e7f\u6cdb\u6d4b\u8bd5\u548c\u7528\u6237\u7814\u7a76\uff0cSel3DCraft\u5728\u652f\u6301\u8bbe\u8ba1\u5e08\u521b\u9020\u529b\u65b9\u9762\u8d85\u8d8a\u4e86\u5176\u4ed6\u6587\u672c\u52303D\u751f\u6210\u7cfb\u7edf\u3002", "conclusion": "Sel3DCraft\u6210\u529f\u5c06\u65e0\u7ed3\u6784\u7684\u63a2\u7d22\u8f6c\u5316\u4e3a\u5f15\u5bfc\u5f0f\u7684\u89c6\u89c9\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e863D\u751f\u6210\u7684\u6548\u679c\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002"}}
{"id": "2508.00782", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.00782", "abs": "https://arxiv.org/abs/2508.00782", "authors": ["Kien T. Pham", "Yingqing He", "Yazhou Xing", "Qifeng Chen", "Long Chen"], "title": "SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation", "comment": "The 33rd ACM Multimedia Conference (MM '25)", "summary": "Audio-driven video generation aims to synthesize realistic videos that align\nwith input audio recordings, akin to the human ability to visualize scenes from\nauditory input. However, existing approaches predominantly focus on exploring\nsemantic information, such as the classes of sounding sources present in the\naudio, limiting their ability to generate videos with accurate content and\nspatial composition. In contrast, we humans can not only naturally identify the\nsemantic categories of sounding sources but also determine their deeply encoded\nspatial attributes, including locations and movement directions. This useful\ninformation can be elucidated by considering specific spatial indicators\nderived from the inherent physical properties of sound, such as loudness or\nfrequency. As prior methods largely ignore this factor, we present SpA2V, the\nfirst framework explicitly exploits these spatial auditory cues from audios to\ngenerate videos with high semantic and spatial correspondence. SpA2V decomposes\nthe generation process into two stages: 1) Audio-guided Video Planning: We\nmeticulously adapt a state-of-the-art MLLM for a novel task of harnessing\nspatial and semantic cues from input audio to construct Video Scene Layouts\n(VSLs). This serves as an intermediate representation to bridge the gap between\nthe audio and video modalities. 2) Layout-grounded Video Generation: We develop\nan efficient and effective approach to seamlessly integrate VSLs as conditional\nguidance into pre-trained diffusion models, enabling VSL-grounded video\ngeneration in a training-free manner. Extensive experiments demonstrate that\nSpA2V excels in generating realistic videos with semantic and spatial alignment\nto the input audios.", "AI": {"tldr": "SpA2V\u662f\u4e00\u4e2a\u57fa\u4e8e\u97f3\u9891\u9a71\u52a8\u7684\u89c6\u9891\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u97f3\u9891\u4e2d\u7684\u7a7a\u95f4\u548c\u8bed\u4e49\u7ebf\u7d22\u751f\u6210\u4e0e\u8f93\u5165\u97f3\u9891\u5728\u8bed\u4e49\u548c\u7a7a\u95f4\u4e0a\u5bf9\u9f50\u7684\u89c6\u9891\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u97f3\u9891\u7684\u8bed\u4e49\u4fe1\u606f\uff0c\u800c\u5ffd\u7565\u4e86\u7a7a\u95f4\u5c5e\u6027\uff08\u5982\u4f4d\u7f6e\u548c\u8fd0\u52a8\u65b9\u5411\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u751f\u6210\u89c6\u9891\u7684\u5185\u5bb9\u548c\u7a7a\u95f4\u51c6\u786e\u6027\u3002SpA2V\u901a\u8fc7\u5229\u7528\u7a7a\u95f4\u542c\u89c9\u7ebf\u7d22\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "SpA2V\u5206\u4e24\u9636\u6bb5\u751f\u6210\u89c6\u9891\uff1a1) \u97f3\u9891\u5f15\u5bfc\u7684\u89c6\u9891\u89c4\u5212\uff0c\u5229\u7528MLLM\u4ece\u97f3\u9891\u4e2d\u63d0\u53d6\u7a7a\u95f4\u548c\u8bed\u4e49\u7ebf\u7d22\u6784\u5efa\u89c6\u9891\u573a\u666f\u5e03\u5c40\uff08VSL\uff09\uff1b2) \u5e03\u5c40\u5f15\u5bfc\u7684\u89c6\u9891\u751f\u6210\uff0c\u5c06VSL\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u751f\u6210\u89c6\u9891\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSpA2V\u80fd\u751f\u6210\u4e0e\u8f93\u5165\u97f3\u9891\u5728\u8bed\u4e49\u548c\u7a7a\u95f4\u4e0a\u9ad8\u5ea6\u5bf9\u9f50\u7684\u73b0\u5b9e\u89c6\u9891\u3002", "conclusion": "SpA2V\u901a\u8fc7\u663e\u5f0f\u5229\u7528\u7a7a\u95f4\u542c\u89c9\u7ebf\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u97f3\u9891\u9a71\u52a8\u89c6\u9891\u751f\u6210\u7684\u8bed\u4e49\u548c\u7a7a\u95f4\u51c6\u786e\u6027\u3002"}}
{"id": "2508.00005", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.00005", "abs": "https://arxiv.org/abs/2508.00005", "authors": ["Tilman Hinnerichs", "Bart Swinkels", "Jaap de Jong", "Reuben Gardos Reid", "Tudor Magirescu", "Neil Yorke-Smith", "Sebastijan Dumancic"], "title": "Modelling Program Spaces in Program Synthesis with Constraints", "comment": null, "summary": "A core challenge in program synthesis is taming the large space of possible\nprograms. Since program synthesis is essentially a combinatorial search, the\ncommunity has sought to leverage powerful combinatorial constraint solvers.\nHere, constraints are used to express the program semantics, but not as a\npotentially potent tool to remove unwanted programs. Recent inductive logic\nprogramming approaches introduce constraints on the program's syntax to be\nsynthesized. These syntactic constraints allow for checking and propagating a\nconstraint without executing the program, and thus for arbitrary operators. In\nthis work, we leverage syntactic constraints to model program spaces, defining\nnot just solutions that are feasible, but also ones that are likely useful. To\ndemonstrate this idea, we introduce BART, a solver that efficiently propagates\nand solves these constraints. We evaluate BART on program space enumeration\ntasks, finding that the constraints eliminate up to 99 percent of the program\nspace, and that modeling program spaces significantly reduces enumeration time.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8bed\u6cd5\u7ea6\u675f\u6765\u7f29\u5c0f\u7a0b\u5e8f\u641c\u7d22\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86BART\u6c42\u89e3\u5668\u4ee5\u9ad8\u6548\u5904\u7406\u548c\u89e3\u51b3\u8fd9\u4e9b\u7ea6\u675f\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7a0b\u5e8f\u7a7a\u95f4\u679a\u4e3e\u65f6\u95f4\u548c\u8303\u56f4\u3002", "motivation": "\u7a0b\u5e8f\u5408\u6210\u7684\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5904\u7406\u5e9e\u5927\u7684\u7a0b\u5e8f\u7a7a\u95f4\u3002\u5c3d\u7ba1\u73b0\u6709\u7684\u65b9\u6cd5\u5229\u7528\u4e86\u7ec4\u5408\u7ea6\u675f\u6c42\u89e3\u5668\u6765\u8868\u8fbe\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4f46\u672a\u80fd\u6709\u6548\u79fb\u9664\u4e0d\u60f3\u8981\u7684\u7a0b\u5e8f\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u8bed\u6cd5\u7ea6\u675f\u6765\u8fdb\u4e00\u6b65\u4f18\u5316\u7a0b\u5e8f\u7a7a\u95f4\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86BART\u6c42\u89e3\u5668\uff0c\u5229\u7528\u8bed\u6cd5\u7ea6\u675f\u6765\u5efa\u6a21\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u4e0d\u4ec5\u80fd\u8868\u8fbe\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8fd8\u80fd\u8bc6\u522b\u53ef\u80fd\u6709\u7528\u7684\u7a0b\u5e8f\u3002\u8fd9\u4e9b\u7ea6\u675f\u65e0\u9700\u6267\u884c\u7a0b\u5e8f\u5373\u53ef\u68c0\u67e5\u548c\u4f20\u64ad\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u64cd\u4f5c\u7b26\u3002", "result": "\u5728\u7a0b\u5e8f\u7a7a\u95f4\u679a\u4e3e\u4efb\u52a1\u4e2d\uff0cBART\u901a\u8fc7\u8bed\u6cd5\u7ea6\u675f\u6d88\u9664\u4e86\u9ad8\u8fbe99%\u7684\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u679a\u4e3e\u65f6\u95f4\u3002", "conclusion": "\u901a\u8fc7\u8bed\u6cd5\u7ea6\u675f\u5efa\u6a21\u7a0b\u5e8f\u7a7a\u95f4\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7a0b\u5e8f\u5408\u6210\u7684\u6548\u7387\uff0cBART\u6c42\u89e3\u5668\u5728\u8fd9\u4e00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.00130", "categories": ["cs.GT", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.00130", "abs": "https://arxiv.org/abs/2508.00130", "authors": ["Drew Gao", "Yihang Sun", "Jan Vondr\u00e1k"], "title": "Computation of Approximately Stable Committees in Approval-based Elections", "comment": "18 pages, 2 figures", "summary": "Approval-based committee selection is a model of significant interest in\nsocial choice theory. In this model, we have a set of voters $\\mathcal{V}$, a\nset of candidates $\\mathcal{C}$, and each voter has a set $A_v \\subset\n\\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to\nchoose $K$ candidates to represent the voters' preferences. We study a\ncriterion known as \\emph{approximate stability}, where a committee is\n$\\lambda$-approximately-stable if there is no other committee $T$ preferred by\nat least $\\frac{\\lambda|T|}{k} |\\mathcal{V}| $ voters. We prove that a\n$3.65$-approximately stable committee always exists and can be computed\nalgorithmically in this setting. Our approach is based on finding a Lindahl\nequilibrium and sampling from a strongly Rayleigh distribution associated with\nit.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6279\u51c6\u7684\u59d4\u5458\u4f1a\u9009\u62e9\u6a21\u578b\u4e2d\u7684\u8fd1\u4f3c\u7a33\u5b9a\u6027\u51c6\u5219\uff0c\u8bc1\u660e\u4e86\u5728\u8fd9\u79cd\u8bbe\u7f6e\u4e0b\u53ef\u4ee5\u7b97\u6cd5\u5316\u5730\u8ba1\u7b97\u51fa\u4e00\u4e2a3.65\u8fd1\u4f3c\u7a33\u5b9a\u7684\u59d4\u5458\u4f1a\u3002", "motivation": "\u57fa\u4e8e\u6279\u51c6\u7684\u59d4\u5458\u4f1a\u9009\u62e9\u6a21\u578b\u5728\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u65e8\u5728\u627e\u5230\u4e00\u4e2a\u80fd\u591f\u4ee3\u8868\u9009\u6c11\u504f\u597d\u7684\u59d4\u5458\u4f1a\uff0c\u6ee1\u8db3\u8fd1\u4f3c\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u4ee5\u63d0\u9ad8\u9009\u62e9\u7684\u516c\u5e73\u6027\u548c\u5408\u7406\u6027\u3002", "method": "\u901a\u8fc7\u5bfb\u627eLindahl\u5747\u8861\u5e76\u4ece\u4e0e\u4e4b\u76f8\u5173\u7684\u5f3aRayleigh\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4f3c\u7a33\u5b9a\u6027\u59d4\u5458\u4f1a\u7684\u7b97\u6cd5\u5316\u8ba1\u7b97\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u8fd9\u79cd\u8bbe\u7f6e\u4e0b\uff0c\u4e00\u4e2a3.65\u8fd1\u4f3c\u7a33\u5b9a\u7684\u59d4\u5458\u4f1a\u603b\u662f\u5b58\u5728\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u7b97\u6cd5\u8ba1\u7b97\u51fa\u6765\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u57fa\u4e8e\u6279\u51c6\u7684\u59d4\u5458\u4f1a\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8fd1\u4f3c\u7a33\u5b9a\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.00013", "categories": ["cs.PL", "I.2.6; F.1.1"], "pdf": "https://arxiv.org/pdf/2508.00013", "abs": "https://arxiv.org/abs/2508.00013", "authors": ["Zurabi Kobaladze", "Anna Arnania", "Tamar Sanikidze"], "title": "From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms", "comment": "78 pages. Undergraduate thesis project submitted in partial\n  fulfillment of the requirements for the Bachelor's degree in Computer Science\n  at Kutaisi International University", "summary": "Program synthesis--the automated generation of executable code from\nhigh-level specifications--has been a central goal of computer science for over\nfifty years. This thesis provides a comparative literature review of the main\nparadigms that have shaped the field, tracing its evolution from formal logic\nbased methods to recent advances using large scale neural models. We examine\nfive key approaches: logic based (deductive) synthesis, inductive (example\nbased) synthesis, sketch/schema based synthesis, large language model based\nsynthesis, and neuro-symbolic hybrids. For each, we analyze foundational\nprinciples, notable systems, and practical applications, highlighting trade\noffs between correctness guarantees, specification requirements, search\ncomplexity, and expressive power. By reviewing developments from formally\nverified synthesis tools such as KIDS and Coq to data driven models generating\nprobabilistic code from natural language like Codex, we present a comprehensive\nnarrative of progress and ongoing challenges. This work emphasizes the\ntransition from symbolic to hybrid neuro-symbolic methods and outlines future\ndirections for reliable and scalable program synthesis.", "AI": {"tldr": "\u8bba\u6587\u7efc\u8ff0\u4e86\u7a0b\u5e8f\u5408\u6210\u9886\u57df\u4e94\u5341\u5e74\u6765\u7684\u4e3b\u8981\u65b9\u6cd5\uff0c\u4ece\u57fa\u4e8e\u5f62\u5f0f\u903b\u8f91\u7684\u65b9\u6cd5\u5230\u73b0\u4ee3\u5927\u89c4\u6a21\u795e\u7ecf\u6a21\u578b\uff0c\u5206\u6790\u4e86\u4e94\u79cd\u5173\u952e\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u53ca\u5176\u6f14\u8fdb\u3002", "motivation": "\u7a0b\u5e8f\u5408\u6210\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u6838\u5fc3\u76ee\u6807\u4e4b\u4e00\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6bd4\u8f83\u6587\u732e\u56de\u987e\uff0c\u63a2\u8ba8\u8be5\u9886\u57df\u7684\u6f14\u8fdb\u53ca\u5176\u4e3b\u8981\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u63a8\u52a8\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u7a0b\u5e8f\u5408\u6210\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u4e94\u79cd\u5173\u952e\u65b9\u6cd5\uff1a\u57fa\u4e8e\u903b\u8f91\u7684\u6f14\u7ece\u5408\u6210\u3001\u57fa\u4e8e\u793a\u4f8b\u7684\u5f52\u7eb3\u5408\u6210\u3001\u57fa\u4e8e\u8349\u56fe/\u6a21\u5f0f\u7684\u5408\u6210\u3001\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5408\u6210\u4ee5\u53ca\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\uff0c\u5206\u6790\u5404\u81ea\u7684\u539f\u7406\u3001\u7cfb\u7edf\u548c\u5e94\u7528\u3002", "result": "\u7814\u7a76\u603b\u7ed3\u4e86\u7a0b\u5e8f\u5408\u6210\u4ece\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\uff08\u5982KIDS\u548cCoq\uff09\u5230\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff08\u5982Codex\uff09\u7684\u6f14\u8fdb\uff0c\u5f3a\u8c03\u4e86\u4ece\u7b26\u53f7\u65b9\u6cd5\u5230\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u7684\u8f6c\u53d8\u53ca\u5176\u6311\u6218\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u7a0b\u5e8f\u5408\u6210\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5\u662f\u672a\u6765\u53d1\u5c55\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2508.00349", "categories": ["cs.GT", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2508.00349", "abs": "https://arxiv.org/abs/2508.00349", "authors": ["Yuga Kanaya", "Kenjiro Takazawa"], "title": "On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings", "comment": null, "summary": "Popular matchings provide a model of matching under preferences in which a\nsolution corresponds to a Condorcet winner in voting systems. In a bipartite\ngraph in which the vertices have preferences over their neighbours, a matching\nis defined to be popular if it does not lose in a majority vote against any\nmatching. In this paper, we study the following three primary problems: only\nthe vertices on one side have preferences; a generalization of this problem\nallowing ties in the preferences; and the vertices on both sides have\npreferences. A principal issue in the algorithmic aspects of popular matchings\nis how to determine the popularity of a matching, because it requires\nexponential time if the definition is simply applied. In the literature, we\nhave the following two types of characterizations: a graph-structural\ncharacterization; and an optimization-based characterization described by\nmaximum-weight matchings. The graph-structural characterizations are\nspecifically designed for each problem and provide a combinatorial structure of\nthe popular matchings. The optimization-based characterizations work in the\nsame manner for all problems, while they do not reveal the structure of the\npopular matchings. A main contribution of this paper is to provide a direct\nconnection of the above two types of characterizations for all of the three\nproblems. Specifically, we prove that each characterization can be derived from\nthe other, without relying on the fact that they characterize popular\nmatchings. Our proofs offer a comprehensive understanding of the equivalence of\nthe two types of characterizations, and suggest a new interpretation of the\ngraph-structural characterization in terms of the dual optimal solution for the\nmaximum-weight matching problem.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e8c\u5206\u56fe\u4e2d\u57fa\u4e8e\u504f\u597d\u7684\u6d41\u884c\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u79cd\u8868\u5f81\u65b9\u6cd5\u7684\u76f4\u63a5\u8fde\u63a5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u89e3\u3002", "motivation": "\u6d41\u884c\u5339\u914d\u5728\u6295\u7968\u7cfb\u7edf\u4e2d\u7c7b\u4f3c\u4e8e\u5b54\u591a\u585e\u80dc\u8005\uff0c\u4f46\u5176\u7b97\u6cd5\u95ee\u9898\u662f\u786e\u5b9a\u5339\u914d\u7684\u6d41\u884c\u6027\u9700\u8981\u6307\u6570\u65f6\u95f4\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8868\u5f81\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4e86\u4e09\u7c7b\u95ee\u9898\uff1a\u5355\u8fb9\u504f\u597d\u3001\u5141\u8bb8\u504f\u597d\u4e2d\u7684\u5e73\u5c40\u548c\u53cc\u8fb9\u504f\u597d\uff0c\u5e76\u901a\u8fc7\u56fe\u7ed3\u6784\u8868\u5f81\u548c\u4f18\u5316\u8868\u5f81\u7684\u76f4\u63a5\u8fde\u63a5\u6765\u5206\u6790\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u8868\u5f81\u65b9\u6cd5\u53ef\u4ee5\u76f8\u4e92\u63a8\u5bfc\uff0c\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u5b83\u4eec\u5bf9\u6d41\u884c\u5339\u914d\u7684\u8868\u5f81\u6027\u8d28\uff0c\u63ed\u793a\u4e86\u5bf9\u5076\u6700\u4f18\u89e3\u7684\u65b0\u89e3\u91ca\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6d41\u884c\u5339\u914d\u7684\u8868\u5f81\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c6\u89d2\uff0c\u5f3a\u5316\u4e86\u5bf9\u56fe\u7ed3\u6784\u8868\u5f81\u4e0e\u4f18\u5316\u8868\u5f81\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u89e3\u3002"}}
{"id": "2508.00016", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.00016", "abs": "https://arxiv.org/abs/2508.00016", "authors": ["Matt Kaufmann", "Yahya Sohail", "Warren A. Hunt Jr"], "title": "Extended Abstract: Mutable Objects with Several Implementations", "comment": "In Proceedings ACL2 2025, arXiv:2507.18567", "summary": "This extended abstract outlines an ACL2 feature, attach-stobj, that first\nappeared in ACL2 Version 8.6 (October, 2024). This feature supports different\nexecutable operations for a given abstract stobj, without requiring\nrecertification of the book that introduces that stobj or theorems about it.\nThe paper provides background as well as a user-level overview and some\nimplementation notes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86ACL2\u4e2d\u7684\u4e00\u4e2a\u65b0\u7279\u6027attach-stobj\uff0c\u5b83\u5141\u8bb8\u5bf9\u62bd\u8c61stobj\u8fdb\u884c\u4e0d\u540c\u7684\u53ef\u6267\u884c\u64cd\u4f5c\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8ba4\u8bc1\u76f8\u5173\u7684\u4e66\u7c4d\u6216\u5b9a\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728ACL2\u4e2d\u5bf9\u62bd\u8c61stobj\u8fdb\u884c\u64cd\u4f5c\u65f6\u9700\u8981\u8fdb\u884c\u7e41\u7410\u7684\u91cd\u65b0\u8ba4\u8bc1\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4e86attach-stobj\u8fd9\u4e00\u65b0\u7279\u6027\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u63d0\u4f9b\u80cc\u666f\u4fe1\u606f\u3001\u7528\u6237\u5c42\u9762\u7684\u6982\u8ff0\u4ee5\u53ca\u4e00\u4e9b\u5b9e\u73b0\u8bf4\u660e\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86attach-stobj\u7279\u6027\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86attach-stobj\u5982\u4f55\u5728\u4e0d\u9700\u91cd\u65b0\u8ba4\u8bc1\u7684\u60c5\u51b5\u4e0b\u652f\u6301\u5bf9\u62bd\u8c61stobj\u7684\u4e0d\u540c\u64cd\u4f5c\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u8ba4\u4e3aattach-stobj\u662f\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u63d0\u9ad8ACL2\u4e2d\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.00811", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.00811", "abs": "https://arxiv.org/abs/2508.00811", "authors": ["Matthew M. Casey", "Edith Elkind"], "title": "Justified Representation: From Hare to Droop", "comment": null, "summary": "The study of proportionality in multiwinner voting with approval ballots has\nreceived much attention in recent years. Typically, proportionality is captured\nby variants of the Justified Representation axiom, which say that cohesive\ngroups of at least $\\ell\\cdot\\frac{n}{k}$ voters (where $n$ is the total number\nof voters and $k$ is the desired number of winners) deserve $\\ell$\nrepresentatives. The quantity $\\frac{n}{k}$ is known as the Hare quota in the\nsocial choice literature. Another -- more demanding -- choice of quota is the\nDroop quota, defined as $\\lfloor\\frac{n}{k+1}\\rfloor+1$. This quota is often\nused in multiwinner voting with ranked ballots: in algorithms such as Single\nTransferable Voting, and in proportionality axioms, such as Droop's\nProportionality Criterion. A few authors have considered it in the context of\napproval ballots, but the existing analysis is far from comprehensive. The\ncontribution of our work is a systematic study of JR-style axioms (and voting\nrules that satisfy them) defined using the Droop quota instead of the Hare\nquota. For each of the standard JR axioms (namely, JR, PJR, EJR, FPJR, FJR,\nPJR+ and EJR+), we identify a voting rule that satisfies the Droop version of\nthis axiom. In some cases, it suffices to consider known rules (modifying the\ncorresponding Hare proof, sometimes quite substantially), and in other cases it\nis necessary to modify the rules from prior work. Each axiom is more difficult\nto satisfy when defined using the Droop quota, so our results expand the\nfrontier of satisfiable proportionality axioms. We complement our theoretical\nresults with an experimental study, showing that for many probabilistic models\nof voter approvals, Droop JR/EJR+ are considerably more demanding than standard\n(Hare) JR/EJR+.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6027\u7814\u7a76\u4e86\u5728\u6279\u51c6\u6295\u7968\u4e2d\u4f7f\u7528Droop\u914d\u989d\u800c\u975eHare\u914d\u989d\u7684\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u53ca\u5176\u6ee1\u8db3\u89c4\u5219\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5e76\u6269\u5c55\u4e86\u53ef\u6ee1\u8db3\u7684\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u8303\u56f4\u3002", "motivation": "\u76ee\u524d\uff0c\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u5728\u6279\u51c6\u6295\u7968\u4e2d\u7684\u7814\u7a76\u4e3b\u8981\u57fa\u4e8eHare\u914d\u989d\uff0c\u800c\u5bf9\u66f4\u4e25\u683c\u7684Droop\u914d\u989d\u7684\u7814\u7a76\u8f83\u5c11\u4e14\u4e0d\u5168\u9762\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u63a2\u7d22Droop\u914d\u989d\u4e0b\u7684\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u53ca\u5176\u89c4\u5219\u3002", "method": "\u8bba\u6587\u5bf9\u6bcf\u4e2a\u6807\u51c6JR\u516c\u7406\uff08\u5982JR\u3001PJR\u3001EJR\u7b49\uff09\u63d0\u51fa\u4e86Droop\u914d\u989d\u7248\u672c\uff0c\u5e76\u627e\u5230\u6216\u4fee\u6539\u4e86\u76f8\u5e94\u7684\u6295\u7968\u89c4\u5219\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u516c\u7406\u3002\u90e8\u5206\u60c5\u51b5\u4e0b\u4fee\u6539\u73b0\u6709\u89c4\u5219\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u9700\u8981\u5168\u65b0\u8bbe\u8ba1\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cDroop\u914d\u989d\u4e0b\u7684\u516c\u7406\u66f4\u96be\u6ee1\u8db3\uff0c\u4f46\u6210\u529f\u627e\u5230\u6216\u8bbe\u8ba1\u4e86\u6ee1\u8db3\u6bcf\u4e2a\u516c\u7406\u7684\u6295\u7968\u89c4\u5219\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDroop\u914d\u989d\u4e0b\u7684\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u6bd4Hare\u914d\u989d\u66f4\u4e3a\u4e25\u683c\u3002", "conclusion": "\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7814\u7a76Droop\u914d\u989d\u4e0b\u7684\u6bd4\u4f8b\u6b63\u4e49\u516c\u7406\u53ca\u5176\u89c4\u5219\uff0c\u6269\u5c55\u4e86\u53ef\u6ee1\u8db3\u7684\u516c\u7406\u8303\u56f4\uff0c\u4e3a\u591a\u8d62\u5bb6\u6295\u7968\u4e2d\u7684\u6bd4\u4f8b\u6b63\u4e49\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2508.00422", "categories": ["cs.PL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.00422", "abs": "https://arxiv.org/abs/2508.00422", "authors": ["Varun Bharti", "Shashwat Jha", "Dhruv Kumar", "Pankaj Jalote"], "title": "Automated Type Annotation in Python Using Large Language Models", "comment": "Under Review", "summary": "Type annotations in Python enhance maintainability and error detection.\nHowever, generating these annotations manually is error prone and requires\nextra effort. Traditional automation approaches like static analysis, machine\nlearning, and deep learning struggle with limited type vocabularies, behavioral\nover approximation, and reliance on large labeled datasets. In this work, we\nexplore the use of LLMs for generating type annotations in Python. We develop a\ngenerate check repair pipeline: the LLM proposes annotations guided by a\nConcrete Syntax Tree representation, a static type checker (Mypy) verifies\nthem, and any errors are fed back for iterative refinement. We evaluate four\nLLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini\n(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.\nWe first measure the proportion of code snippets annotated by LLMs for which\nMyPy reported no errors (i.e., consistent results): GPT 4oMini achieved\nconsistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,\nand O4Mini each reached approximately 88.6% consistency (around 11.4%\nfailures). To measure annotation quality, we then compute exact-match and\nbase-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini\nperform the best, achieving up to 70.5% exact match and 79.1% base type\naccuracy, requiring under one repair iteration on average. Our results\ndemonstrate that general-purpose and reasoning optimized LLMs, without any task\nspecific fine tuning or additional training can be effective in generating\nconsistent type annotations.They perform competitively with traditional deep\nlearning techniques which require large labeled dataset for training. While our\nwork focuses on Python, the pipeline can be extended to other optionally typed\nimperative languages like Ruby", "AI": {"tldr": "\u5229\u7528LLMs\u81ea\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\uff0c\u901a\u8fc7\u751f\u6210-\u68c0\u67e5-\u4fee\u590d\u6d41\u7a0b\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u624b\u52a8\u751f\u6210Python\u7c7b\u578b\u6ce8\u91ca\u8017\u65f6\u4e14\u6613\u9519\uff0c\u4f20\u7edf\u81ea\u52a8\u5316\u65b9\u6cd5\u56e0\u8bcd\u6c47\u9650\u5236\u3001\u884c\u4e3a\u8fc7\u5ea6\u8fd1\u4f3c\u548c\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u800c\u53d7\u9650\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u751f\u6210-\u68c0\u67e5-\u4fee\u590d\u6d41\u7a0b\uff1aLLMs\u57fa\u4e8e\u8bed\u6cd5\u6811\u751f\u6210\u6ce8\u91ca\uff0cMypy\u9a8c\u8bc1\uff0c\u9519\u8bef\u5219\u53cd\u9988\u4ee5\u8fed\u4ee3\u5b8c\u5584\u3002\u8bc4\u4f30\u4e86\u56db\u79cdLLM\u53d8\u4f53\u3002", "result": "GPT 4.1mini\u548cO3Mini\u8868\u73b0\u6700\u4f73\uff0c\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u6700\u9ad8\uff0c\u5206\u522b\u8fbe\u523088.6%\u4e00\u81f4\u6027\u548c70.5%\u7cbe\u786e\u5339\u914d\uff0c\u5e73\u5747\u4fee\u590d\u6b21\u6570\u5c11\u4e8e\u4e00\u6b21\u3002", "conclusion": "\u901a\u7528\u548c\u63a8\u7406\u4f18\u5316\u7684LLMs\u5728\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u6216\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u6709\u6548\u751f\u6210\u4e00\u81f4\u7684\u7c7b\u578b\u6ce8\u91ca\uff0c\u6027\u80fd\u4e0e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ade\u4e89\u3002"}}
{"id": "2508.00482", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.00482", "abs": "https://arxiv.org/abs/2508.00482", "authors": ["Erdem Yildirim", "Albert Schimpf", "Stefan Wehr", "Annette Bieniusa"], "title": "Semantic Subtyping for Maps in Erlang", "comment": null, "summary": "In this paper we will construct a set-theoretic model of types featuring type\nvariables, base types, set-theoretic types and map types. Syntax of map types\nspans all the map types available in Erlang. The model of types is used to\ndefine a semantic subtyping relation based on set containment. The novelty of\nthis work is the definition of subtyping over parameteric map types.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7c7b\u578b\u53d8\u91cf\u3001\u57fa\u7c7b\u578b\u3001\u96c6\u5408\u8bba\u7c7b\u578b\u548c\u6620\u5c04\u7c7b\u578b\u7684\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u96c6\u5408\u5305\u542b\u5173\u7cfb\u5b9a\u4e49\u4e86\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u4e3a\u4e86\u5728Erlang\u8bed\u8a00\u4e2d\u5b9a\u4e49\u6620\u5c04\u7c7b\u578b\u7684\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u7279\u522b\u662f\u9488\u5bf9\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u65b0\u9896\u5b50\u7c7b\u578b\u5b9a\u4e49\u3002", "method": "\u901a\u8fc7\u6784\u9020\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u7c7b\u578b\u7684\u96c6\u5408\u8bba\u6a21\u578b\uff0c\u5e76\u5229\u7528\u96c6\u5408\u5305\u542b\u5173\u7cfb\u6765\u5b9a\u4e49\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u4e00\u4e2a\u9002\u7528\u4e8eErlang\u6620\u5c04\u7c7b\u578b\u7684\u8bed\u4e49\u5b50\u7c7b\u578b\u5173\u7cfb\uff0c\u7279\u522b\u662f\u9488\u5bf9\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u96c6\u5408\u8bba\u6a21\u578b\u548c\u5b50\u7c7b\u578b\u5b9a\u4e49\u65b9\u6cd5\u4e3aErlang\u8bed\u8a00\u7684\u7c7b\u578b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u53c2\u6570\u5316\u6620\u5c04\u7c7b\u578b\u65f6\u8868\u73b0\u51fa\u521b\u65b0\u6027\u3002"}}
{"id": "2508.00534", "categories": ["cs.PL", "cs.CL", "D.3.2; F.3.2; D.3.1"], "pdf": "https://arxiv.org/pdf/2508.00534", "abs": "https://arxiv.org/abs/2508.00534", "authors": ["Mikel Vandeloise"], "title": "Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations", "comment": "Preprint submitted to the Journal of Object Technology on July 29,\n  2025. Data available upon request until peer-review is completed", "summary": "The rise of multi-paradigm languages challenges traditional classification\nmethods, leading to practical software engineering issues like interoperability\ndefects. This systematic literature review (SLR) maps the formal foundations of\nprogramming paradigms. Our objective is twofold: (1) to assess the state of the\nart of classification formalisms and their limitations, and (2) to identify the\nconceptual primitives and mathematical frameworks for a more powerful,\nreconstructive approach.\n  Based on a synthesis of 74 primary studies, we find that existing taxonomies\nlack conceptual granularity, a unified formal basis, and struggle with hybrid\nlanguages. In response, our analysis reveals a strong convergence toward a\ncompositional reconstruction of paradigms. This approach identifies a minimal\nset of orthogonal, atomic primitives and leverages mathematical frameworks,\npredominantly Type theory, Category theory and Unifying Theories of Programming\n(UTP), to formally guarantee their compositional properties.\n  We conclude that the literature reflects a significant intellectual shift\naway from classification towards these promising formal, reconstructive\nframeworks. This review provides a map of this evolution and proposes a\nresearch agenda for their unification.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u591a\u8303\u5f0f\u8bed\u8a00\u7684\u5206\u7c7b\u65b9\u6cd5\u53ca\u5176\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6570\u5b66\u6846\u67b6\u7684\u91cd\u6784\u65b9\u6cd5\u3002", "motivation": "\u591a\u8303\u5f0f\u8bed\u8a00\u7684\u5174\u8d77\u5bf9\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u5bfc\u81f4\u5982\u4e92\u64cd\u4f5c\u6027\u7f3a\u9677\u7b49\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u3002", "method": "\u57fa\u4e8e74\u9879\u4e3b\u8981\u7814\u7a76\u7684\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u73b0\u6709\u5206\u7c7b\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u7c7b\u578b\u7406\u8bba\u3001\u8303\u7574\u7406\u8bba\u548c\u7edf\u4e00\u7f16\u7a0b\u7406\u8bba\uff08UTP\uff09\u7684\u539f\u5b50\u539f\u8bed\u91cd\u6784\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u5206\u7c7b\u6cd5\u7f3a\u4e4f\u6982\u5ff5\u7c92\u5ea6\u4e0e\u7edf\u4e00\u7684\u5f62\u5f0f\u57fa\u7840\uff0c\u800c\u91cd\u6784\u65b9\u6cd5\u5219\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u7ec4\u5408\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u6587\u732e\u53cd\u6620\u51fa\u4ece\u5206\u7c7b\u8f6c\u5411\u5f62\u5f0f\u5316\u91cd\u6784\u6846\u67b6\u7684\u663e\u8457\u8d8b\u52bf\uff0c\u672c\u6587\u4e3a\u6b64\u63d0\u51fa\u4e86\u7814\u7a76\u8bae\u7a0b\u3002"}}
