<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 9]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Variational Green's Functions for Volumetric PDEs](https://arxiv.org/abs/2602.12349)
*Joao Teixeira,Eitan Grinspun,Otman Benchekroun*

Main category: cs.GR

TL;DR: 论文提出了一种名为Variational Green's Function (VGF)的方法，通过学习Green函数的平滑可微分表示，解决了其在任意几何离散化上计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: Green函数在偏微分方程的基础解和应用中至关重要，但在任意几何离散化上的计算成本过高，限制了其广泛应用。

Method: VGF方法将Green函数分解为解析的自由空间分量和学习的校正分量，利用变分基础自然施加Neumann边界条件，并通过投影层处理Dirichlet边界条件。

Result: 所得到的Green函数计算速度快，对源应用可微分，并能基于几何参数的其他信号进行条件化。

Conclusion: VGF方法提供了一种高效且灵活的方式来表示和计算Green函数，适用于多种线性自伴PDE算子的求解。

Abstract: Green's functions characterize the fundamental solutions of partial differential equations; they are essential for tasks ranging from shape analysis to physical simulation, yet they remain computationally prohibitive to evaluate on arbitrary geometric discretizations. We present Variational Green's Function (VGF), a method that learns a smooth, differentiable representation of the Green's function for linear self-adjoint PDE operators, including the Poisson, the screened Poisson, and the biharmonic equations. To resolve the sharp singularities characteristic of the Green's functions, our method decomposes the Green's function into an analytic free-space component, and a learned corrector component. Our method leverages a variational foundation to impose Neumann boundary conditions naturally, and imposes Dirichlet boundary conditions via a projective layer on the output of the neural field. The resulting Green's functions are fast to evaluate, differentiable with respect to source application, and can be conditioned on other signals parameterizing our geometry.

</details>


### [2] [Real-time Rendering with a Neural Irradiance Volume](https://arxiv.org/abs/2602.12949)
*Arno Coomans,Giacomo Nazzaro,Edoardo A. Dominici,Christian Döring,Floor Verhoeven,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: 提出了一种名为NIV的神经渲染技术，通过神经压缩方法实时渲染漫反射全局光照，解决了传统基于探针方法的内存消耗和伪影问题。


<details>
  <summary>Details</summary>
Motivation: 传统的基于3D探针的漫反射全局光照实时渲染方法存在伪影和高内存消耗的问题，需要新的技术来克服这些限制。

Method: 使用神经压缩技术创建自适应的辐照度表示，避免了基于网格方法的立方缩放问题，并在严格实时约束下工作。

Result: 在相同内存预算下，NIV方法的渲染质量提升了至少10倍，且能高效处理时间变化或动态效果，推理速度快（约1毫秒每帧）。

Conclusion: NIV技术提供了一种高效、低内存占用且高质量的实时全局光照渲染方案，优于传统方法和其他神经渲染技术。

Abstract: Rendering diffuse global illumination in real-time is often approximated by pre-computing and storing irradiance in a 3D grid of probes. As long as most of the scene remains static, probes approximate irradiance for all surfaces immersed in the irradiance volume, including novel dynamic objects. This approach, however, suffers from aliasing artifacts and high memory consumption. We propose Neural Irradiance Volume (NIV), a neural-based technique that allows accurate real-time rendering of diffuse global illumination via a compact pre-computed model, overcoming the limitations of traditional probe-based methods, such as the expensive memory footprint, aliasing artifacts, and scene-specific heuristics. The key insight is that neural compression creates an adaptive and amortized representation of irradiance, circumventing the cubic scaling of grid-based methods. Our superior memory-scaling improves quality by at least 10x at the same memory budget, and enables a straightforward representation of higher-dimensional irradiance fields, allowing rendering of time-varying or dynamic effects without requiring additional computation at runtime. Unlike other neural rendering techniques, our method works within strict real-time constraints, providing fast inference (around 1 ms per frame on consumer GPUs at full HD resolution), reduced memory usage (1-5 MB for medium-sized scenes), and only requires a G-buffer as input, without expensive ray tracing or denoising.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Meta-Monomorphizing Specializations](https://arxiv.org/abs/2602.12973)
*Federico Bruzzone,Walter Cazzola*

Main category: cs.PL

TL;DR: 本文提出了一种名为"元单态化特化"的新框架，通过编译时代码生成重新利用单态化，从而在不修改主机编译器的情况下实现零成本特化。


<details>
  <summary>Details</summary>
Motivation: 在编程语言和编译器设计中，实现零成本特化一直是一个基本挑战，通常需要在表达能力和类型系统完备性之间进行权衡。传统方法可能导致意外的连贯性违反和形式模型复杂性的增加。

Method: 本文引入了一种新颖的框架，即"元单态化特化"，通过编译时代码生成重新利用单态化。该方法生成元单态化的特质和实现，将特化约束直接编码到类型结构中，从而实现确定性、连贯的派发。

Result: 基于Rust实现的评估表明，元单态化能够支持之前被编译器拒绝的表达性特化模式，同时完全兼容标准的优化流程。公开Rust代码库的综合研究进一步验证了该方法，揭示了许多可被消除的变通方法。

Conclusion: 本文表明特化可以通过一种有纪律的代码生成层实现，为高性能抽象提供了一种实用的、与语言无关的路径。

Abstract: Achieving zero-cost specialization remains a fundamental challenge in programming language and compiler design. It often necessitates trade-offs between expressive power and type system soundness, as the interaction between conditional compilation and static dispatch can easily lead to unforeseen coherence violations and increased complexity in the formal model. This paper introduces meta-monomorphizing specializations, a novel framework that achieves specialization by repurposing monomorphization through compile-time metaprogramming. Instead of modifying the host compiler, our approach generates meta-monomorphized traits and implementations that encode specialization constraints directly into the type structure, enabling deterministic, coherent dispatch without overlapping instances. We formalize this method for first-order, predicate-based, and higher-ranked polymorphic specialization, also in presence of lifetime parameters. Our evaluation, based on a Rust implementation using only existing macro facilities, demonstrates that meta-monomorphization enables expressive specialization patterns -- previously rejected by the compiler -- while maintaining full compatibility with standard optimization pipelines. We show that specialization can be realized as a disciplined metaprogramming layer, offering a practical, language-agnostic path to high-performance abstraction. A comprehensive study of public Rust codebases further validates our approach, revealing numerous workarounds that meta-monomorphization can eliminate, leading to more idiomatic and efficient code.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Truthful Fair Division under Stochastic Valuations](https://arxiv.org/abs/2602.12359)
*Daniel Halpern,Alexandros Psomas,Shirley Zhang*

Main category: cs.GT

TL;DR: 研究在随机模型中，针对具有加性偏好的策略性代理人分配不可分割物品的无金钱机制，探讨其公平性和效率。


<details>
  <summary>Details</summary>
Motivation: 由于最坏情况下的不可能性表明真实性严重限制了公平性和效率，因此研究真实性机制在随机实例中是否表现不佳。

Method: 首先研究支配策略激励兼容（DSIC）机制，建立福利近似的新连接，并将其推广到n个代理人；然后转向贝叶斯激励兼容（BIC）机制。

Result: 发现DSIC机制的预期福利近似上限为$\\frac{2+\\sqrt{2}}{4}$，并提出匹配该边界的机制；BIC机制在i.i.d.估值下几乎无成本地实现高效率和公平性。

Conclusion: 真实性机制在随机模型中可以实现较高的福利和公平性，尤其是在BIC框架下表现更为优越。

Abstract: We study no-money mechanisms for allocating indivisible items to strategic agents with additive preferences under a stochastic model. In this model, items' values are drawn from an underlying distribution and mechanisms are evaluated with respect to this draw (e.g., in expectation, or with high probability). Motivated by worst-case impossibilities which show that truthfulness severely restricts fairness and efficiency, we ask whether truthful mechanisms continue to perform poorly on random instances.
  We first focus on dominant-strategy incentive compatible (DSIC) mechanisms. For two agents, we obtain a tight picture. Specifically, we show that there exists a distribution under which no DSIC mechanism achieves an expected welfare approximation better than $\frac{2+\sqrt{2}}{4}\approx 0.854$, and we give a DSIC mechanism that matches this bound for all distributions simultaneously. We further show that, for every distribution, there exists a DSIC mechanism that is envy-free with high probability and obtains the same welfare. A key ingredient is a new, tight connection between welfare guarantees of a family of DSIC, no-money mechanisms and i.i.d.\ prophet inequalities. This connection allows us to generalize to $n$ agents; in particular, we obtain a DSIC mechanism that achieves a $\approx 0.745$ approximation to welfare, and another DSIC mechanism achieving a $1/2$-approximation welfare that is envy-free with high probability.
  We then turn to Bayesian incentive compatibility (BIC). Under i.i.d.\ valuations, we show that BIC comes at essentially no cost: we design a prior-independent BIC mechanism that achieves a $(1-\varepsilon)$-approximation to the optimal welfare, while being envy-free with high probability. Under independent but non-identical priors, we obtain BIC mechanisms that are $(1-\varepsilon)$-approximately Pareto efficient and envy-free with high probability.

</details>


### [5] [Online Advertising with Spatial Interactions](https://arxiv.org/abs/2602.12481)
*Gagan Aggarwal,Yifan Wang,Mingfei Zhao*

Main category: cs.GT

TL;DR: 论文提出了一种新的在线广告空间外部性框架，考虑了广告位置和周围广告配置的影响，并提出了两种模型的分析和算法。


<details>
  <summary>Details</summary>
Motivation: 在线广告平台需要在有限的屏幕空间内分配多个广告，而广告的效果不仅取决于自身位置，还受周围广告竞争的影响。现有的拍卖和分配模型通常将广告位视为独立或一维排序，忽略了空间外部性的影响。

Method: 论文将广告位建模为度量空间中的点，广告价值由其出价和周围广告配置决定的折扣因子共同决定。提出了两种模型：最近邻模型（Nearest-Neighbor）和乘积距离模型（Product-Distance），并分别分析了它们的近似算法和计算复杂性。

Result: 对于最近邻模型，论文提出了一个多项式时间算法，实现了恒定近似比，并且分配规则单调，可实现真实机制。在二维欧几里得空间的特殊情况下，提供了PTAS。而对于乘积距离模型，证明了除非P=NP，否则不存在多项式因子的近似算法。

Conclusion: 研究结果为理解广告分配中的空间外部性提供了理论基础，并为设计高效、真实的机制提供了方向。

Abstract: Online advertising platforms must decide how to allocate multiple ads across limited screen real estate, where each ad's effectiveness depends not only on its own placement but also on nearby ads competing for user attention. Such spatial externalities - arising from proximity, clutter, or crowding - can significantly alter welfare and revenue outcomes, yet existing auction and allocation models typically treat ad slots as independent or ordered along a single dimension.
  We introduce a new framework for spatial externalities in online advertising, in which the value of an ad depends on both its slot and the configuration of surrounding ads. We model ad slots as points in a metric space, and model an advertiser's value as a function of both their bid and a discount factor determined by the configuration of other displayed ads. Within this framework, we analyze two natural models. For the Nearest-Neighbor model, where the value suppression depends only on the closest neighboring ad, we present a polynomial-time algorithm that achieves a constant approximation for the general case. We show that the allocation rule is monotone and can be implemented as a truthful mechanism. For a structured setting of 2D Euclidean space, we provide a PTAS. In contrast, for the Product-Distance model, where interference is aggregated multiplicatively across all neighbors, we establish a strong (and nearly-tight) hardness of approximation - no polynomial-time algorithm can achieve any polynomial-factor approximation unless P=NP, via a reduction from Max-Independent-Set.
  Our results provide a foundation for reasoning about spatial externalities in ad allocation and for designing efficient, truthful mechanisms under such interactions.

</details>


### [6] [Opinion dynamics and mutual influence with LLM agents through dialog simulation](https://arxiv.org/abs/2602.12583)
*Yulong He,Dutao Zhang,Sergey Kovalchuk,Pengyi Li,Artem Sedakov*

Main category: cs.GT

TL;DR: 本文提出了一种使用大型语言模型（LLM）代理的多轮对话模拟框架，以解决意见动态研究中真实世界纵向数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 意见动态研究面临的一个基本挑战是缺乏真实世界的纵向意见数据，这使得理论模型的验证变得复杂。

Method: 通过在多轮结构化对话中使用LLM代理，模拟了意见动态的迭代更新过程，并结合了DeGroot模型和Friedkin-Johnsen模型的特性。

Result: 该框架在缺乏真实数据的情况下，提供了一种可扩展的工具来模拟和分析意见形成过程。

Conclusion: 这一研究将经典意见动态模型与现代多代理LLM系统相结合，为解决数据稀缺问题提供了新的思路和方法。

Abstract: A fundamental challenge in opinion dynamics research is the scarcity of real-world longitudinal opinion data, which complicates the validation of theoretical models. To address this, we propose a novel simulation framework using large language model (LLM) agents in structured multi-round dialogs. Each agent's dialog history is iteratively updated with its own previously stated opinions and those of others analogous to the classical DeGroot model. Furthermore, by retaining each agent's initial opinion throughout the dialog, we simulate anchoring effects consistent with the Friedkin-Johnsen model of opinion dynamics. Our framework thus bridges classical opinion dynamics models and modern multi-agent LLM systems, providing a scalable tool for simulating and analyzing opinion formation when real-world data is limited or inaccessible.

</details>


### [7] [Feature-based Uncertainty Model for School Choice](https://arxiv.org/abs/2602.12615)
*Yao Zhang,Makoto Yokoo*

Main category: cs.GT

TL;DR: 该研究探讨了一种基于特征的学校选择不确定模型，旨在提高学生的稳定性概率（ProS）和激励相容性（IC），并展示了不同策略在这两个目标上的表现。


<details>
  <summary>Details</summary>
Motivation: 学生在选择学校时往往无法准确比较偏好的优先级，但可以通过比较学校的特定特征（如声誉、位置和设施）来形成偏好。这促使研究者提出了一种基于特征的模型来处理这种不确定性。

Method: 研究者提出了一个基于线性组合的特征模型，其中学生偏好的组合系数被视为随机变量。他们分析了学生提议的延迟接受（DA）算法，并探讨了两种不同策略：一种是优先考虑期望排名较高的学校，另一种是使用精心定义的迭代比较向量。

Result: 研究表明，优先考虑期望排名较高的DA算法在ProS上可以实现$(1/n)^n$的最坏近似比；而使用迭代比较向量的DA算法可以保证最强形式的IC。此外，模型在某些特定限制下还提供了额外结果。

Conclusion: 研究得出结论，在一般情况下，ProS和IC是相互冲突的目标。然而，通过不同的DA策略，可以在一定程度上平衡或优化这两个目标。

Abstract: In this work, we consider a school choice scenario where a student does not exactly know which college is better for her. Although it is hard for a student to obtain an exact preference, she can usually compare specific features of colleges, such as reputation, location, and campus facilities. Motivated by this, we propose a feature-based uncertainty model for school choice where a student's preference is based on a linear combination of her utilities over different features, and the coefficients of the combination are treated as random variables. Our main goal is to achieve a higher probability of stability (ProS) and incentive compatibility (IC) for students. Unfortunately, these two goals are incompatible in general. We show that a student-proposing deferred acceptance (DA) that prioritizes colleges with higher expected ranking can achieve a worst-case approximation ratio of $(1/n)^n$ on ProS, while a DA with a carefully defined iterated comparison vector can guarantee the strongest achievable form of IC. Finally, we provide additional results for some specific restrictions on the model.

</details>


### [8] [Decentralized Optimal Equilibrium Learning in Stochastic Games via Single-bit Feedback](https://arxiv.org/abs/2602.12830)
*Seref Taha Kiremitci,Ahmed Said Donmez,Muhammed O. Sayin*

Main category: cs.GT

TL;DR: 研究了在严重信息和通信约束下的随机博弈中的分散均衡选择问题，并提出了一种信号机制来优化社会福利目标。


<details>
  <summary>Details</summary>
Motivation: 在随机博弈中，存在多个均衡且其福利性质差异显著，仅收敛到均衡不足以解决问题。因此，需要在分散化环境中选择最优均衡。

Method: 采用分散化的学习方法，代理仅观察全局状态轨迹和自身奖励，并通过每轮交换一个随机比特的信号来隐含地对齐社会福利目标。开发了探索-提交和在线变体方法。

Result: 提出了适用于一般随机博弈的框架，支持异构的基于模型或无模型方法，并在温和条件下实现了对数级别的有限时间遗憾保障。

Conclusion: 该方法通过简单的信号机制实现了分散化的最优均衡选择，并在理论上验证了其性能。

Abstract: We study decentralized equilibrium selection in stochastic games under severe information and communication constraints. In such settings, convergence to equilibrium alone is insufficient, as stochastic games typically admit many equilibria with markedly different welfare properties. We address decentralized optimal equilibrium selection, where agents coordinate on equilibria that optimize a designer-specified social welfare objective while allowing heterogeneous tolerance to deviations from strict best responses. Agents observe only the global state trajectory and their realized rewards, and exchange a single randomized bit of feedback per agent per round. This semantic content/discontent signaling mechanism implicitly aligns decentralized learning dynamics with the global welfare objective. We develop explore-and-commit and online variants applicable to general stochastic games, accommodating heterogeneous model-based or model-free methods for solving the induced Markov decision processes, and establish explicit finite-time regret guarantees, showing logarithmic expected regret under mild conditions.

</details>


### [9] [Experimentation, Biased Learning, and Conjectural Variations in Competitive Dynamic Pricing](https://arxiv.org/abs/2602.12888)
*Bar Light,Wenyu Wang*

Main category: cs.GT

TL;DR: 本文研究了多卖家之间的竞争性动态定价问题，揭示了实验设计和学习偏差如何影响长期均衡结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于零售和在线市场中大规模实验和算法定价的兴起。卖家通过简单的学习规则反复定价，但仅能观察到自身价格和需求，尽管需求受所有卖家价格和随机冲击的影响。

Method: 卖家采用两点A/B价格实验，基于自身数据拟合线性需求估计来更新基准价格。通过相关实验（如同步重新定价）引发的学习偏差，研究了动态收敛到推测变化（CV）均衡的条件。

Result: 结果表明，相关实验会导致学习偏差和超竞争价格的长期均衡；而独立实验则消除了偏差，动态收敛到标准纳什均衡。此外，提供了收敛的简单充分条件及有限样本保证。

Conclusion: 结论指出，实验设计可作为市场设计工具，通过实用的学习算法选择达到的均衡状态。

Abstract: We study competitive dynamic pricing among multiple sellers, motivated by the rise of large-scale experimentation and algorithmic pricing in retail and online marketplaces. Sellers repeatedly set prices using simple learning rules and observe only their own prices and realized demand, even though demand depends on all sellers' prices and is subject to random shocks. Each seller runs two-point A/B price experiments, in the spirit of switchback-style designs, and updates a baseline price using a linear demand estimate fitted to its own data. Under certain conditions on demand, the resulting dynamics converge to a Conjectural Variations (CV) equilibrium, a classic static equilibrium notion in which each seller best responds under a conjecture that rivals' prices respond systematically to changes in its own price. Unlike standard CV models that treat conjectures as behavioral primitives, we show that these conjectures arise endogenously from the bias in demand learning induced by correlated experimentation (e.g., due to synchronized repricing schedules). This learning bias selects the long-run equilibrium, often leading to supra-competitive prices. Notably, we show that under independent experimentation, this bias vanishes and the learning dynamics converge to the standard Nash equilibrium. We provide simple sufficient conditions on demand for convergence in standard models and establish a finite-sample guarantee: up to logarithmic factors, the squared price error decays on the order of $T^{-1/2}$. Our results imply that in competitive markets, experimentation design can serve as a market design lever, selecting the equilibrium reached by practical learning algorithms.

</details>


### [10] [Contextual Online Bilateral Trade](https://arxiv.org/abs/2602.12903)
*Romain Cosson,Federico Fusco,Anupam Gupta,Stefano Leonardi,Renato Paes Leme,Matteo Russo*

Main category: cs.GT

TL;DR: 论文研究了上下文估值下的重复双边贸易问题，设计了在不同反馈模式下实现低后悔的算法，证明了其在最优动态策略下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在动态且上下文相关的贸易环境中，如何通过有限的反馈信息（如两比特或单比特反馈）设计高效的定价策略，以最大化交易增益或利润。

Method: 论文提出了一种基于上下文向量的学习方法，分别设计了两比特反馈和单比特反馈下的算法。两比特反馈下算法实现$O(d\log d)$和$O(d \log\log T + d\log d)$后悔；单比特反馈下则通过允许少量负利润实现类似性能。

Result: 在两比特反馈下，算法在交易增益和利润最大化上分别达到$O(d\log d)$和$O(d \log\log T + d\log d)$后悔界；单比特反馈下仍可达到类似后悔界，但可能产生少量负利润。

Conclusion: 论文表明，即使在有限的反馈信息下，算法仍能接近最优动态策略性能，但单比特反馈与预算平衡结合时会导致对维度的指数依赖。

Abstract: We study repeated bilateral trade when the valuations of the sellers and the buyers are contextual. More precisely, the agents' valuations are given by the inner product of a context vector with two unknown $d$-dimensional vectors -- one for the buyers and one for the sellers.
  At each time step $t$, the learner receives a context and posts two prices, one for the seller and one for the buyer, and the trade happens if both agents accept their price. We study two objectives for this problem, gain from trade and profit, proving no-regret with respect to a surprisingly strong benchmark: the best omniscient dynamic strategy.
  In the natural scenario where the learner observes \emph{separately} whether the agents accept their price -- the so-called \emph{two-bit} feedback -- we design algorithms that achieve $O(d\log d)$ regret for gain from trade, and $O(d \log\log T + d\log d)$ regret for profit maximization. Both results are tight, up to the $\log(d)$ factor, and implement per-step budget balance, meaning that the learner never incurs negative profit.
  In the less informative \emph{one-bit} feedback model, the learner only observes whether a trade happens or not. For this scenario, we show that the tight two-bit regret regimes are still attainable, at the cost of allowing the learner to possibly incur a small negative profit of order $O(d\log d)$, which is notably independent of the time horizon. As a final set of results, we investigate the combination of one-bit feedback and per-step budget balance. There, we design an algorithm for gain from trade that suffers regret independent of the time horizon, but \emph{exponential} in the dimension $d$. For profit maximization, we maintain this exponential dependence on the dimension, which gets multiplied by a $\log T$ factor.

</details>


### [11] [Nonparametric Contextual Online Bilateral Trade](https://arxiv.org/abs/2602.12904)
*Emanuele Coccia,Martino Bernasconi,Andrea Celli*

Main category: cs.GT

TL;DR: 本文研究了情境在线双边贸易问题，提出了一种在非参数设置下运行的算法，利用分层树结构处理情境信息，并证明了其遗憾边界的最优性。


<details>
  <summary>Details</summary>
Motivation: 为了解决情境在线双边贸易中，传统的线性模型无法处理非参数情境的问题，并满足单比特反馈和强预算平衡的严格限制。

Method: 设计了一种基于分层树构造的算法，能够处理任意Lipschitz函数描述的情境依赖估值，并保证遗憾边界为$\widetilde{O}(T^{{(d-1)}/d})$。

Result: 算法在单比特反馈和强预算平衡的限制下表现优异，并在全反馈设置中证明了遗憾边界的最优性。

Conclusion: 本文提出的算法在非参数情境下实现了高效的贸易定价，且遗憾边界最优，为实际应用提供了理论支持。

Abstract: We study the problem of contextual online bilateral trade. At each round, the learner faces a seller-buyer pair and must propose a trade price without observing their private valuations for the item being sold. The goal of the learner is to post prices to facilitate trades between the two parties. Before posting a price, the learner observes a $d$-dimensional context vector that influences the agent's valuations. Prior work in the contextual setting has focused on linear models. In this work, we tackle a general nonparametric setting in which the buyer's and seller's valuations behave according to arbitrary Lipschitz functions of the context. We design an algorithm that leverages contextual information through a hierarchical tree construction and guarantees regret $\widetilde{O}(T^{{(d-1)}/d})$. Remarkably, our algorithm operates under two stringent features of the setting: (1) one-bit feedback, where the learner only observes whether a trade occurred or not, and (2) strong budget balance, where the learner cannot subsidize or profit from the market participants. We further provide a matching lower bound in the full-feedback setting, demonstrating the tightness of our regret bound.

</details>


### [12] [Solving Qualitative Multi-Objective Stochastic Games](https://arxiv.org/abs/2602.12927)
*Moritz Graf,Anthony Lin,Rupak Majumdar*

Main category: cs.GT

TL;DR: 研究两玩家随机博弈的复杂性和内存需求，特别是定性可达性和安全性目标的布尔组合。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的组合合成与验证问题（如理性验证和概率系统中的假设保证验证）需要研究两玩家随机博弈的复杂性及其目标组合。

Method: 分析定性可达性和安全性目标的布尔组合的复杂性及内存需求，探讨确定性及其复杂度。

Result: 证明具有AS和NZ可达性及安全性目标的博弈是确定的，且判定胜负是PSPACE完全的；而完全布尔组合的目标博弈则不具备确定性且是NEXPTIME困难的。

Conclusion: 结果揭示了随机博弈与部分有序量化逻辑的联系，扩展了多目标随机博弈的复杂性图景。

Abstract: Many problems in compositional synthesis and verification of multi-agent systems -- such as rational verification and assume-guarantee verification in probabilistic systems -- reduce to reasoning about two-player multi-objective stochastic games. This motivates us to study the problem of characterizing the complexity and memory requirements for two-player stochastic games with Boolean combinations of qualitative reachability and safety objectives. Reachability objectives require that a given set of states is reached; safety requires that a given set is invariant. A qualitative winning condition asks that an objective is satisfied almost surely (AS) or (in negated form) with non-zero (NZ) probability.
  We study the determinacy and complexity landscape of the problem. We show that games with conjunctions of AS and NZ reachability and safety objectives are determined, and determining the winner is PSPACE-complete. The same holds for positive boolean combinations of AS reachability and safety, as well as for negations thereof. On the other hand, games with full Boolean combinations of qualitative objectives are not determined, and are NEXPTIME-hard. Our hardness results show a connection between stochastic games and logics with partially-ordered quantification. Our results shed light on the relationship between determinacy and complexity, and extend the complexity landscape for stochastic games in the multi-objective setting.

</details>
