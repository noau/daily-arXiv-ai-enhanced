<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Applying Medical Imaging Tractography Techniques to Painterly Rendering of Images](https://arxiv.org/abs/2511.00702)
*Alberto Di Biase*

Main category: cs.GR

TL;DR: 本文探讨了扩散张量成像（DTI）和纤维追踪技术在图像绘画风格渲染中的应用，提出了基于结构张量的画笔笔触放置方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将医学影像中的DTI和纤维追踪技术跨界应用于艺术领域，模拟人类艺术家的绘画过程。

Method: 方法利用纤维追踪算法，通过结构张量（而非传统梯度）提供更好的局部方向信息，从而确定画笔笔触的放置方式。

Result: 研究结果表明，该方法能够有效模拟艺术家的绘画笔触，并在肖像和普通图像中展示了这一技术的应用效果。

Conclusion: 本文初步探索了DTI技术在图像渲染领域的跨界应用，为未来研究提供了新的思路。

Abstract: Doctors and researchers routinely use diffusion tensor imaging (DTI) and
tractography to visualize the fibrous structure of tissues in the human body.
This paper explores the connection of these techniques to the painterly
rendering of images. Using a tractography algorithm the presented method can
place brush strokes that mimic the painting process of human artists,
analogously to how fibres are tracked in DTI. The analogue to the diffusion
tensor for image orientation is the structural tensor, which can provide better
local orientation information than the gradient alone. I demonstrate this
technique in portraits and general images, and discuss the parallels between
fibre tracking and brush stroke placement, and frame it in the language of
tractography. This work presents an exploratory investigation into the
cross-domain application of diffusion tensor imaging techniques to painterly
rendering of images. All the code is available at
https://github.com/tito21/st-python

</details>


### [2] [Empowering LLMs with Structural Role Inference for Zero-Shot Graph Learning](https://arxiv.org/abs/2511.00898)
*Heng Zhang,Jing Liu,Jiajun Wu,Haochen You,Lubin Gan,Yuling Shi,Xiaodong Gu,Zijian Zhang,Shuai Chen,Wenjun Huang,Jin Huang*

Main category: cs.GR

TL;DR: DuoGLM是一种无需训练的双视角框架，通过局部和全局视角的结构感知推理，提升大型语言模型在图学习中的表现，特别在零样本节点分类和跨域转移任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的图学习方法在结构重要节点（如桥梁和枢纽）上表现不佳，原因是缺乏从拓扑模式到角色解释的推理支架，尤其在零样本场景中。

Method: DuoGLM采用局部视角（构建关系感知模板）和全局视角（拓扑到角色的推理），为LLMs提供显式推理机制，以区分拓扑相似但语义不同的节点。

Result: 在八个基准数据集上的实验表明，DuoGLM在零样本节点分类中准确率提升14.3%，跨域转移任务中AUC提高7.6%。

Conclusion: DuoGLM通过显式角色推理显著提升了LLMs在图理解中的表现，验证了其对拓扑模式的有效解释能力。

Abstract: Large Language Models have emerged as a promising approach for graph learning
due to their powerful reasoning capabilities. However, existing methods exhibit
systematic performance degradation on structurally important nodes such as
bridges and hubs. We identify the root cause of these limitations. Current
approaches encode graph topology into static features but lack reasoning
scaffolds to transform topological patterns into role-based interpretations.
This limitation becomes critical in zero-shot scenarios where no training data
establishes structure-semantics mappings. To address this gap, we propose
DuoGLM, a training-free dual-perspective framework for structure-aware graph
reasoning. The local perspective constructs relation-aware templates capturing
semantic interactions between nodes and neighbors. The global perspective
performs topology-to-role inference to generate functional descriptions of
structural positions. These complementary perspectives provide explicit
reasoning mechanisms enabling LLMs to distinguish topologically similar but
semantically different nodes. Extensive experiments across eight benchmark
datasets demonstrate substantial improvements. DuoGLM achieves 14.3\% accuracy
gain in zero-shot node classification and 7.6\% AUC improvement in cross-domain
transfer compared to existing methods. The results validate the effectiveness
of explicit role reasoning for graph understanding with LLMs.

</details>


### [3] [G2rammar: Bilingual Grammar Modeling for Enhanced Text-attributed Graph Learning](https://arxiv.org/abs/2511.00911)
*Heng Zheng,Haochen You,Zijun Liu,Zijian Zhang,Lubin Gan,Hao Zhang,Wenjun Huang,Jin Huang*

Main category: cs.GR

TL;DR: 论文提出了一种名为G2rammar的双语法框架，用于显式编码文本属性图的结构和语义语法，以增强语言模型对图拓扑的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法将图结构线性化为标记序列，但忽略了语法在表达中的关键作用，这限制了语言模型对图拓扑的有效推理能力。

Method: G2rammar框架通过中心性和邻居模式编码结构语法，通过文本信息性捕捉语义语法，并采用两阶段学习（结构语法预训练和语义语法微调）。

Result: 在真实数据集上的广泛实验表明，G2rammar始终优于基线方法，为语言模型提供了理解图结构所需的语法上下文。

Conclusion: G2rammar通过引入语法框架，显著提升了语言模型对文本属性图中结构和语义关系的理解和推理能力。

Abstract: Text-attributed graphs require models to effectively integrate both
structural topology and semantic content. Recent approaches apply large
language models to graphs by linearizing structures into token sequences
through random walks. These methods create concise graph vocabularies to
replace verbose natural language descriptions. However, they overlook a
critical component that makes language expressive: grammar. In natural
language, grammar assigns syntactic roles to words and defines their functions
within sentences. Similarly, nodes in graphs play distinct structural roles as
hubs, bridges, or peripheral members. Current graph language methods provide
tokens without grammatical annotations to indicate these structural or semantic
roles. This absence limits language models' ability to reason about graph
topology effectively. We propose \textbf{G2rammar}, a bilingual grammar
framework that explicitly encodes both structural and semantic grammar for
text-attributed graphs. Structural grammar characterizes topological roles
through centrality and neighborhood patterns. Semantic grammar captures content
relationships through textual informativity. The framework implements two-stage
learning with structural grammar pre-training followed by semantic grammar
fine-tuning. Extensive experiments on real-world datasets demonstrate that
G2rammar consistently outperforms competitive baselines by providing language
models with the grammatical context needed to understand graph structures.

</details>


### [4] [An Adjoint Method for Differentiable Fluid Simulation on Flow Maps](https://arxiv.org/abs/2511.01259)
*Zhiqi Li,Jinjin He,Barnabás Börcsök,Taiyuan Zhang,Duowen Chen,Tao Du,Ming C. Lin,Greg Turk,Bo Zhu*

Main category: cs.GR

TL;DR: 本文提出了一种基于双向流映射的新型伴随求解器，用于可微分流体模拟，通过共享流映射提高梯度计算的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的伴随方法需要区分中间数值步骤或存储中间变量，而本文提出了一种新颖的伴随求解器，直接基于流映射求解伴随方程，从而提高计算效率和准确性。

Method: 引入了一种新型伴随求解器，直接在流映射上求解伴随方程，并提出了一种长时间-短时间内稀疏流映射表示方法，以减少内存使用。

Result: 该方法在分辨率192³时仅需6.53GB内存，同时保持了涡度跟踪的高精度，适用于需要精确识别、预测和控制涡动力学的可微分模拟任务。

Conclusion: 本研究展示了一种高效且准确的伴随求解器，为可微分流体模拟提供了新的可能性。

Abstract: This paper presents a novel adjoint solver for differentiable fluid
simulation based on bidirectional flow maps. Our key observation is that the
forward fluid solver and its corresponding backward, adjoint solver share the
same flow map as the forward simulation. In the forward pass, this map
transports fluid impulse variables from the initial frame to the current frame
to simulate vortical dynamics. In the backward pass, the same map propagates
adjoint variables from the current frame back to the initial frame to compute
gradients. This shared long-range map allows the accuracy of gradient
computation to benefit directly from improvements in flow map construction.
Building on this insight, we introduce a novel adjoint solver that solves the
adjoint equations directly on the flow map, enabling long-range and accurate
differentiation of incompressible flows without differentiating intermediate
numerical steps or storing intermediate variables, as required in conventional
adjoint methods. To further improve efficiency, we propose a long-short
time-sparse flow map representation for evolving adjoint variables. Our
approach has low memory usage, requiring only 6.53GB of data at a resolution of
$192^3$ while preserving high accuracy in tracking vorticity, enabling new
differentiable simulation tasks that require precise identification,
prediction, and control of vortex dynamics.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Equality Saturation Guided by Large Language Models](https://arxiv.org/abs/2511.00403)
*Wentao Peng,Ruyi Ji,Yingfei Xiong*

Main category: cs.PL

TL;DR: 论文提出了一种名为LGuess的方法，通过将e-graphs作为中间层，结合大型语言模型（LLMs）与重写系统，以解决LLMs在生成正确重写链方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）无法保证正确性，尤其是在生成可靠的重写链方面存在不足。论文旨在通过结合LLMs和e-graphs的技术，提升重写系统的可靠性。

Method: 论文提出了LGuess方法，利用e-graphs作为中间层，LLMs仅用于生成高层重写检查点，而e-graphs则负责提供这些检查点之间的低层重写链。通过从LLM学习概率模型来预测合适的检查点。

Result: 在多项式因式分解问题上，LGuess的表现显著优于直接使用等式饱和和直接查询LLM生成重写链的方法。

Conclusion: LGuess通过结合LLMs和e-graphs，有效弥补了LLMs在生成正确重写链方面的不足，为相关领域提供了新的解决方案。

Abstract: One critical issue with large language models (LLMs) is their inability to
guarantee correctness. Although this problem can be addressed by applying LLMs
to formal rewrite systems, current LLMs are still far from adequate to generate
sound rewrite chains. To bridge this gap, this paper proposes LLM-guided
equality saturation, dubbed LGuess, by incorporating e-graphs as an
intermediate layer between LLMs and rewrite systems. LGuess queries LLMs only
for high-level rewrite checkpoints and uses e-graphs to supply low-level
rewrite chains between these checkpoints. The key technical challenge in this
procedure lies in effectively extracting a suitable checkpoint from a saturated
e-graph, which LGuess addresses by learning a probabilistic model from the LLM.
The model predicts probable checkpoints while remaining simple enough for
effective extraction. We implement a prototype of LGuess and evaluate it on the
problem of factorizing multivariable polynomials. The results demonstrate a
significant advantage of LGuess compared to both straightforward equality
saturation and the approach that queries the LLM directly for the rewrite
chain.

</details>


### [6] [\texttt{ReMind}: Understanding Deductive Code Reasoning in LLMs](https://arxiv.org/abs/2511.00488)
*Jun Gao,Yun Peng,Xiaoxue Ren*

Main category: cs.PL

TL;DR: 提出多智能体框架ReMind，提升大型语言模型在演绎代码推理任务中的表现，解决了推理能力与生成能力的差距、代码源偏见和零次泛化弱等挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码相关任务中取得显著进展，但在演绎代码推理方面仍存在不足。论文旨在探索其根本原因并提出解决方案。

Method: 提出ReMind框架，包含Mutator、Executor和Inspector三个智能体，分别负责生成代码变体减少偏见、逐步跟踪变量状态暴露不一致性，以及识别问题推理步骤并提供控制流优化。

Result: 在两个基准测试和五种大型语言模型上的实验表明，ReMind在演绎代码推理任务中显著优于基线方法。

Conclusion: ReMind通过多智能体协作系统性地识别和优化推理缺陷，有效提升了模型的演绎代码推理能力和零次泛化能力。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in
code-related tasks. Despite their advancement, empirical evidence reveals that
they still struggle with \emph{deductive code reasoning}, the ability to reason
about the program execution process. While prior studies have recognized this
limitation, the underlying causes remain largely underexplored. In this paper,
we begin by presenting a comprehensive empirical study that reveals three key
challenges undermining deductive code reasoning: (1) an intrinsic gap between
generation and reasoning abilities, (2) a consistent bias towards code sources,
and (3) weak zero-shot generalization on complex benchmarks. In light of these
challenges, we propose \texttt{ReMind}, a multi-agent framework composed of
\texttt{Mutator}, \texttt{Executor}, and \texttt{Inspector}. The
\texttt{Mutator} generates code variants to mitigate bias towards code sources,
the \texttt{Executor} traces variable states step-by-step to expose
inconsistency, and the \texttt{Inspector} identifies problematic reasoning
steps and provides control-flow refinement to bridge the intrinsic reasoning
gap. Through their coordinated collaboration, \texttt{ReMind} systematically
identifies and refines reasoning flaws, achieving outstanding performance and
enabling robust zero-shot generalization. Extensive experiments on two
benchmarks with five LLMs demonstrate the superior advantages of
\texttt{ReMind} compared to baseline approaches in deductive code reasoning.

</details>


### [7] [Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization](https://arxiv.org/abs/2511.00592)
*Massinissa Merouani,Islem Kara Bernou,Riyadh Baghdadi*

Main category: cs.PL

TL;DR: 论文提出了一种新颖的代码优化方法ComPilot，利用大型语言模型（LLMs）与编译器通过闭环交互指导优化过程，无需任务特定微调，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现代硬件上的复杂循环嵌套代码优化是一个具有挑战性的问题，研究探索了利用通用大型语言模型（LLMs）作为交互式优化代理的可能性。

Method: ComPilot框架通过LLM与编译器的闭环交互实现优化：LLM提出循环嵌套的变换建议，编译器执行并反馈合法性和性能变化，LLM迭代优化策略。

Result: 在PolyBench基准测试中，ComPilot实现了单次运行2.66倍和最佳五次运行3.54倍的几何平均加速，优于现有Pluto多面体优化器。

Conclusion: 研究表明，通用LLMs在编译器反馈的指导下能有效优化代码，为AI代理在代码优化中的研究开辟了新方向。

Abstract: Automatic code optimization remains a difficult challenge, particularly for
complex loop nests on modern hardware. This paper investigates a novel approach
to code optimization where Large Language Models (LLMs) guide the process
through a closed-loop interaction with a compiler. We present ComPilot, an
experimental framework that leverages off-the-shelf LLMs, without any
task-specific fine-tuning, as interactive optimization agents. ComPilot
establishes a feedback loop where an LLM proposes transformations for a given
loop nest to a compiler. The compiler attempts the transformations, reporting
back legality status and measured speedup or slowdown. The LLM utilizes this
concrete feedback to iteratively refine its optimization strategy. Our
extensive evaluation across the PolyBench benchmark suite demonstrates the
effectiveness of this zero-shot approach. ComPilot achieves geometric mean
speedups of 2.66x (single run) and 3.54x (best-of-5 runs) over the original
code. Furthermore, ComPilot demonstrates competitive performance against the
state-of-the-art Pluto polyhedral optimizer, outperforming it in many cases.
This experimental study demonstrates that general-purpose LLMs can effectively
guide the code optimization process when grounded by compiler feedback, opening
promising research directions for agentic AI in code optimization.

</details>


### [8] [Typed Embedding of miniKanren for Functional Conversion](https://arxiv.org/abs/2511.00740)
*Igor Engel,Ekaterina Verbitskaia*

Main category: cs.PL

TL;DR: 本文提出了一种基于类型标签无终止嵌入的方法，将miniKanren嵌入Haskell，解决了之前功能转换中的性能开销问题，并减少了样板代码。


<details>
  <summary>Details</summary>
Motivation: 早期的功能转换方法虽然减少了性能开销，但存在类型忽视、确定性注解需求以及隐式生成器线程等问题，本文旨在解决这些问题。

Method: 采用类型标签无终止嵌入（typed tagless-final embedding）的方法，将miniKanren嵌入Haskell，优化了代码结构。

Result: 新方法显著减少了样板代码，同时保留甚至提升了之前的性能优化效果。

Conclusion: 通过类型标签无终止嵌入技术，本文提供了一种更优雅且高效的miniKanren实现方式。

Abstract: Relational programming enables program synthesis through a verifier-to-solver
approach. An earlier paper introduced a functional conversion that mitigated
some of the inherent performance overhead. However, the conversion was
inelegant: it was oblivious to types, demanded determinism annotations, and
implicit generator threading. In this paper, we address these issues by
providing a typed tagless-final embedding of miniKanren into Haskell. This
improvement significantly reduces boilerplate while preserving, and sometimes
enhancing, earlier speedups.

</details>


### [9] [Cobble: Compiling Block Encodings for Quantum Computational Linear Algebra](https://arxiv.org/abs/2511.01736)
*Charles Yuan*

Main category: cs.PL

TL;DR: Cobble是一种用于量子计算线性代数编程的语言，通过高级表示自动编译为正确的量子电路，显著提升量子算法的执行效率。


<details>
  <summary>Details</summary>
Motivation: 量子算法在计算线性代数中具有指数级加速潜力，但开发者在实现量子电路时面临复杂矩阵算术表达和优化挑战。

Method: Cobble语言允许开发者使用高级表示表达和操作矩阵的量子表示（块编码），并通过分析和优化技术（如量子奇异值变换）生成高效量子电路。

Result: 在模拟、回归和搜索等基准测试中，Cobble实现了2.6倍至25.4倍的加速，优于现有电路优化器。

Conclusion: Cobble为量子计算线性代数提供了一种高效的编程工具，解决了实现复杂量子算法的挑战。

Abstract: Quantum algorithms for computational linear algebra promise up to exponential
speedups for applications such as simulation and regression, making them prime
candidates for hardware realization. But these algorithms execute in a model
that cannot efficiently store matrices in memory like a classical algorithm
does, instead requiring developers to implement complex expressions for matrix
arithmetic in terms of correct and efficient quantum circuits. Among the
challenges for the developer is navigating a cost model in which conventional
optimizations for linear algebra, such as subexpression reuse, can be
inapplicable or unprofitable.
  In this work, we present Cobble, a language for programming with quantum
computational linear algebra. Cobble enables developers to express and
manipulate the quantum representations of matrices, known as block encodings,
using high-level notation that automatically compiles to correct quantum
circuits. Cobble features analyses that estimate leading factors in time and
space usage of programs, as well as optimizations that reduce overhead and
generate efficient circuits using leading techniques such as the quantum
singular value transformation. We evaluate Cobble on benchmark kernels for
simulation, regression, search, and other applications, showing 2.6x-25.4x
speedups not achieved by existing circuit optimizers on these benchmarks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [10] [Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure & Efficient Combinatorial Approach](https://arxiv.org/abs/2511.00835)
*Taikun Zhu,Kai Jin,Ruixi Luo,Song Cao*

Main category: cs.GT

TL;DR: 研究了在二元加法或子模估值下，将m个物品分配给n个代理人的最优社会福利分配问题，提出了稳定分配的概念及高效算法。


<details>
  <summary>Details</summary>
Motivation: 探讨在二元加法或子模型估值下，如何最优分配物品以实现社会福利的最大化，尤其是在常见的SPD对称准则下。

Method: 通过定义稳定分配概念，并设计了针对不可分物品和可分物品的高效算法，分别耗时O(m²n)和O(m²n⁵)。

Result: 证明了最优分配与稳定分配的重合性，并展示了不同最优分配之间的Chebyshev距离较小。

Conclusion: 研究提供了高效算法和理论支持，为二元加法或子模型估值下的社会福利分配问题提供了新的解决方案。

Abstract: We investigate optimal social welfare allocations of $m$ items to $n$ agents
with binary additive or submodular valuations. For binary additive valuations,
we prove that the set of optimal allocations coincides with the set of
so-called \emph{stable allocations}, as long as the employed criterion for
evaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many
common criteria are SPD and symmetric, such as Nash social welfare, leximax,
leximin, Gini index, entropy, and envy sum. We also design efficient algorithms
for finding a stable allocation, including an $O(m^2n)$ time algorithm for the
case of indivisible items, and an $O(m^2n^5)$ time one for the case of
divisible items. The first is faster than the existing algorithms or has a
simpler analysis. The latter is the first combinatorial algorithm for that
problem. It utilizes a hidden layer partition of items and agents admitted by
all stable allocations, and cleverly reduces the case of divisible items to the
case of indivisible items.
  In addition, we show that the profiles of different optimal allocations have
a small Chebyshev distance, which is 0 for the case of divisible items under
binary additive valuations, and is at most 1 for the case of indivisible items
under binary submodular valuations.

</details>


### [11] [Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers](https://arxiv.org/abs/2511.00847)
*Yuhan Cao,Yu Wang,Sitong Liu,Miao Li,Yixin Tao,Tianxing He*

Main category: cs.GT

TL;DR: 本文通过算法博弈论和机制设计研究了大型语言模型（LLM）API服务提供商的潜在不诚实行为，提出了一个形式化的经济模型，并证明了在连续策略空间中存在近似激励相容机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于应对LLM API服务提供商可能的操纵行为，例如秘密替换高性能模型或通过填充无意义标记增加计费。

Method: 采用算法博弈论和机制设计的方法，提出了一种形式化的经济模型，并在连续策略空间中证明了近似激励相容机制的存在性。

Result: 研究结果表明，该机制的近似比为O(T^{1-\epsilon}\log T)，并在模拟实验中验证了其有效性。

Conclusion: 本文证明了在连续策略空间中存在的近似激励相容机制的有效性，并指出任何机制都无法在用户效用上超越该机制。

Abstract: The widespread adoption of Large Language Models (LLMs) through Application
Programming Interfaces (APIs) induces a critical vulnerability: the potential
for dishonest manipulation by service providers. This manipulation can manifest
in various forms, such as secretly substituting a proclaimed high-performance
model with a low-cost alternative, or inflating responses with meaningless
tokens to increase billing. This work tackles the issue through the lens of
algorithmic game theory and mechanism design. We are the first to propose a
formal economic model for a realistic user-provider ecosystem, where a user can
iteratively delegate $T$ queries to multiple model providers, and providers can
engage in a range of strategic behaviors. As our central contribution, we prove
that for a continuous strategy space and any $\epsilon\in(0,\frac12)$, there
exists an approximate incentive-compatible mechanism with an additive
approximation ratio of $O(T^{1-\epsilon}\log T)$, and a guaranteed quasi-linear
second-best user utility. We also prove an impossibility result, stating that
no mechanism can guarantee an expected user utility that is asymptotically
better than our mechanism. Furthermore, we demonstrate the effectiveness of our
mechanism in simulation experiments with real-world API settings.

</details>


### [12] [Deliberation via Matching](https://arxiv.org/abs/2511.00986)
*Kamesh Munagala,Qilin Ye,Ian Zhang*

Main category: cs.GT

TL;DR: 研究了一种通过小群体讨论来优化选民偏好的社会选择协议，证明其失真度界限为3，突破了传统锦标赛规则的界限。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过小群体讨论（deliberation）来改进选民偏好的聚合过程，以提高集体决策的质量和准确性。

Method: 引入了一种简单的‘deliberation-via-matching’协议，通过匹配意见不一致的选民进行讨论，然后使用加权未覆盖集锦标赛规则进行偏好聚合。

Result: 该协议的失真度界限为3，突破了传统锦标赛规则3.11的下限，并证明了锦标赛规则在加入成对讨论后可与一般社会选择规则同样强大。

Conclusion: 通过双线性松弛方法证明了失真度界限，并提供了一个分析框架，可能对其他研究审议协议的失真度具有独立价值。

Abstract: We study deliberative social choice, where voters refine their preferences
through small-group discussions before collective aggregation. We introduce a
simple and easily implementable deliberation-via-matching protocol: for each
pair of candidates, we form an arbitrary maximum matching among voters who
disagree on that pair, and each matched pair deliberates. The resulting
preferences (individual and deliberative) are then appropriately weighted and
aggregated using the weighted uncovered set tournament rule.
  We show that our protocol has a tight distortion bound of $3$ within the
metric distortion framework. This breaks the previous lower bound of $3.11$ for
tournament rules without deliberation and matches the lower bound for
deterministic social choice rules without deliberation. Our result conceptually
shows that tournament rules are just as powerful as general social choice
rules, when the former are given the minimal added power of pairwise
deliberations. We prove our bounds via a novel bilinear relaxation of the
non-linear program capturing optimal distortion, whose vertices we can
explicitly enumerate, leading to an analytic proof. Loosely speaking, our key
technical insight is that the distortion objective, as a function of metric
distances to any three alternatives, is both supermodular and convex. We
believe this characterization provides a general analytical framework for
studying the distortion of other deliberative protocols, and may be of
independent interest.

</details>


### [13] [From Best Responses to Learning: Investment Efficiency in Dynamic Environment](https://arxiv.org/abs/2511.01157)
*Ce Li,Qianfan Zhang,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文研究了动态环境中学习型投资者的福利机制，分析了静态环境下近似分配算法的福利保证如何扩展到动态设置中。


<details>
  <summary>Details</summary>
Motivation: 现实中投资者由于信息不完全无法总是做出最佳响应，因此在动态环境中研究其学习行为对福利的影响具有重要意义。

Method: 通过分析投资者使用无遗憾在线学习算法选择投资的行为，研究了近似分配算法在动态学习环境中的性能表现。

Result: 静态环境的近似比在动态环境中保持不变，同时针对更强的时间变化基准提供了紧致的上下界。

Conclusion: 结合机制设计与在线学习理论，研究表明即使在复杂不确定环境中，投资者通过学习策略仍能保持稳健的福利保证。

Abstract: We study the welfare of a mechanism in a dynamic environment where a learning
investor can make a costly investment to change her value. In many real-world
problems, the common assumption that the investor always makes the best
responses, i.e., choosing her utility-maximizing investment option, is
unrealistic due to incomplete information in a dynamically evolving
environment. To address this, we consider an investor who uses a no-regret
online learning algorithm to adaptively select investments through repeated
interactions with the environment. We analyze how the welfare guarantees of
approximation allocation algorithms extend from static to dynamic settings when
the investor learns rather than best-responds, by studying the approximation
ratio for optimal welfare as a measurement of an algorithm's performance
against different benchmarks in the dynamic learning environment. First, we
show that the approximation ratio in the static environment remains unchanged
in the dynamic environment against the best-in-hindsight benchmark. Second, we
provide tight characterizations of the approximation upper and lower bounds
relative to a stronger time-varying benchmark. Bridging mechanism design with
online learning theory, our work shows how robust welfare guarantees can be
maintained even when an agent cannot make best responses but learns their
investment strategies in complex, uncertain environments.

</details>


### [14] [Designing Non-monetary Intersection Control Mechanisms for Efficient Selfish Routing](https://arxiv.org/abs/2511.01421)
*Yusuf Saltan,Jyun-Jhe Wang,Arda Kosay,Chung-Wei Lin,Muhammed O. Sayin*

Main category: cs.GT

TL;DR: 这篇论文提出了一种通过调整车辆通行时间戳的非货币机制来优化城市交通流量，以减少交通拥堵。


<details>
  <summary>Details</summary>
Motivation: 城市交通拥堵源于自利的路由决策与社会最优流量之间的不一致。交叉口作为关键瓶颈，放大了这种低效现象，因为现有控制方案通常忽略了司机的战略行为。

Method: 利用车辆到基础设施通信技术，提出了一种分层次架构：路边单元负责本地调度，中央规划者负责全网时间戳调整。通过离线双层优化程序实现均衡流量的唯一性。

Result: 在Sioux Falls网络上的实验显示，均衡流量与最优流量之间的效率差距最多可减少68%，证明了系统的可扩展性和有效性。

Conclusion: 论文证明了通过调整时间戳的非货币机制可以有效激励社会效率最优的路由决策，显著减少交通拥堵。

Abstract: Urban traffic congestion stems from the misalignment between self-interested
routing decisions and socially optimal flows. Intersections, as critical
bottlenecks, amplify these inefficiencies because existing control schemes
often neglect drivers' strategic behavior. Autonomous intersections, enabled by
vehicle-to-infrastructure communication, permit vehicle-level scheduling based
on individual requests. Leveraging this fine-grained control, we propose a
non-monetary mechanism that strategically adjusts request timestamps-delaying
or advancing passage times-to incentivize socially efficient routing. We
present a hierarchical architecture separating local scheduling by roadside
units from network-wide timestamp adjustments by a central planner. We
establish an experimentally validated analytical model, prove the existence and
essential uniqueness of equilibrium flows and formulate the planner's problem
as an offline bilevel optimization program solvable with standard tools.
Experiments on the Sioux Falls network show up to a 68% reduction in the
efficiency gap between equilibrium and optimal flows, demonstrating scalability
and effectiveness.

</details>


### [15] [Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games](https://arxiv.org/abs/2511.01852)
*Yang Cai,Constantinos Daskalakis,Haipeng Luo,Chen-Yu Wei,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文引入了基于邻近算子的新遗憾概念——邻近遗憾，填补了外部遗憾和交换遗憾之间的空白，并证明了在线梯度下降（GD）算法可以达到最优的$O(\sqrt{T})$邻近遗憾上界。


<details>
  <summary>Details</summary>
Motivation: 学习和计算均衡是算法博弈论中的核心问题。为了填补外部遗憾和交换遗憾之间的空白，并解释梯度下降在在线学习和博弈中的优越性能，作者提出了邻近遗憾的概念。

Method: 作者引入了邻近遗憾的概念，并通过理论分析证明了在线梯度下降（GD）算法和Mirror Descent在Bregman设置下以及Optimistic Gradient Descent的性能。

Result: 研究结果表明，GD算法可以在不修改的情况下最小化比外部遗憾更强的邻近遗憾概念，并且优化了$O(\sqrt{T})$的遗憾上界。此外，平滑凸博弈中Optimistic Gradient Descent具有更快的收敛速度。

Conclusion: 本文的框架统一了在线学习和博弈论中的多个新兴概念，并为梯度下降在实际应用中的优越性能提供了新的解释。

Abstract: Learning and computation of equilibria are central problems in algorithmic
game theory. In this work, we introduce proximal regret, a new notion of regret
based on proximal operators that lies strictly between external and swap
regret. When every player employs a no-proximal-regret algorithm in a general
convex game, the empirical distribution of play converges to proximal
correlated equilibria (PCE), a refinement of coarse correlated equilibria. Our
framework unifies several emerging notions in online learning and game theory
-- such as gradient equilibrium and semicoarse correlated equilibrium -- and
introduces new ones. Our main result shows that the classic Online Gradient
Descent (GD) algorithm achieves an optimal $O(\sqrt{T})$ bound on proximal
regret, revealing that GD, without modification, minimizes a stronger regret
notion than external regret. This provides a new explanation for the
empirically superior performance of gradient descent in online learning and
games. We further extend our analysis to Mirror Descent in the Bregman setting
and to Optimistic Gradient Descent, which yields faster convergence in smooth
convex games.

</details>
