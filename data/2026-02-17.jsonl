{"id": "2602.13422", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.13422", "abs": "https://arxiv.org/abs/2602.13422", "authors": ["Yuxi Liu", "Junqiang Peng", "Mingyu Xiao"], "title": "The Complexity of Tournament Fixing: Subset FAS Number and Acyclic Neighborhoods", "comment": null, "summary": "The \\textsc{Tournament Fixing Problem} (TFP) asks whether a knockout tournament can be scheduled to guarantee that a given player $v^*$ wins. Although TFP is NP-hard in general, it is known to be \\emph{fixed-parameter tractable} (FPT) when parameterized by the feedback arc/vertex set number, or the in/out-degree of $v^*$ (AAAI 17; IJCAI 18; AAAI 23; AAAI 26). However, it remained open whether TFP is FPT with respect to the \\emph{subset FAS number of $v^*$} -- the minimum number of arcs intersecting all cycles containing $v^*$ -- a parameter that is never larger than the aforementioned ones (AAAI 26). In this paper, we resolve this question negatively by proving that TFP stays NP-hard even when the subset FAS number of $v^*$ is constant $\\geq 1$ and either the subgraph induced by the in-neighbors $D[N_{\\mathrm{in}}(v^*)]$ or the out-neighbors $D[N_{\\mathrm{out}}(v^*)]$ is acyclic. Conversely, when both $D[N_{\\mathrm{in}}(v^*)]$ and $D[N_{\\mathrm{out}}(v^*)]$ are acyclic, we show that TFP becomes FPT parameterized by the subset FAS number of $v^*$. Furthermore, we provide sufficient conditions under which $v^*$ can win even when this parameter is unbounded."}
{"id": "2602.13451", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.13451", "abs": "https://arxiv.org/abs/2602.13451", "authors": ["Natalie Collina", "Surbhi Goel", "Aaron Roth", "Mirah Shi"], "title": "Personalization Aids Pluralistic Alignment Under Competition", "comment": null, "summary": "Can competition among misaligned AI providers yield aligned outcomes for a diverse population of users, and what role does model personalization play? We study a setting where multiple competing AI providers interact with multiple users who must make downstream decisions but differ in preferences. Providers have their own objectives over users' actions and strategically deploy AI models to advance them. We model the interaction as a Stackelberg game with multiple leaders (providers) and followers (users): providers commit to conversational policies, and users choose which model to use, how to converse, and how to act. With user-specific personalization, we show that under a Weak Market Alignment condition, every equilibrium gives each user outcomes comparable to those from a perfectly aligned common model -- so personalization can induce pluralistically aligned outcomes, even when providers are self-interested. In contrast, when providers must deploy a single anonymous policy, there exist equilibria with uninformative behavior under the same condition. We then give a stronger alignment condition that guarantees each user their optimal utility in the anonymous setting."}
{"id": "2602.13897", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.13897", "abs": "https://arxiv.org/abs/2602.13897", "authors": ["Bhaskar Ray Chaudhury", "Jugal Garg", "Eklavya Sharma", "Jiaxin Song"], "title": "Revenue-Optimal Pricing for Budget-Constrained Buyers in Data Markets", "comment": null, "summary": "We study revenue-optimal pricing in data markets with rational, budget-constrained buyers. Such a market offers multiple datasets for sale, and buyers aim to improve the accuracy of their prediction tasks by acquiring data bundles. For each dataset, the market sets a pricing function, which maps the number of records purchased from the dataset to a non-negative price. The market's objective is to set these pricing functions to maximize total revenue, considering that buyers with quasi-linear utilities choose their bundles optimally under budget constraints.\n  We analyze optimal pricing when each dataset's pricing function is only required to be monotone and lower-continuous. Surprisingly, even with this generality, optimal pricing has a highly structured form: it is piecewise linear and convex (PLC) and can be computed efficiently via an LP. Moreover, the total number of kinks across all pricing functions is bounded by the number of buyers. Thus, when datasets far outnumber buyers, most pricing functions are effectively linear.\n  This motivates studying linear pricing, where each record in a dataset is priced uniformly. Although competitive equilibrium gives revenue-optimal linear prices in rivalrous markets with quasi-linear buyers, we show that revenue maximization under linear pricing in data markets is APX-hard. Hence, a striking computational dichotomy emerges: fully general (nonlinear) pricing admits a polynomial-time algorithm, while the simpler linear scheme is APX-hard.\n  Despite the hardness, we design a 2-approximation algorithm when datasets arrive online, and a $(1-1/e)^{-1}$-approximation algorithm for the offline setting. Our framework lays the groundwork for exploring more general pricing schemes, richer utility models, and a deeper understanding of how market structure -- rivalrous versus non-rivalrous -- shapes revenue-optimal pricing."}
{"id": "2602.14076", "categories": ["cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14076", "abs": "https://arxiv.org/abs/2602.14076", "authors": ["Reshef Meir", "Jonathan Wagner", "Omer Ben-Porat"], "title": "Truthful Reporting of Competence with Minimal Verification", "comment": "Full version of a paper accepted to AAMAS 2026", "summary": "Suppose you run a home exam, where students should report their own scores but can cheat freely. You can, if needed, call a limited number of students to class and verify their actual performance against their reported score. We consider the class of mechanisms where truthful reporting is a dominant strategy, and truthful agents are never penalized -- even off-equilibrium.\n  How many students do we need to verify, in expectation, if we want to minimize the bias, i.e., the difference between agents' competence and their expected grade? When perfect verification is available, we characterize the best possible tradeoff between these requirements and provide a simple parametrized mechanism that is optimal in the class for any distribution of agents' types. When verification is noisy, the task becomes much more challenging. We show how proper scoring rules can be leveraged in different ways to construct truthful mechanisms with a good (though not necessarily optimal) tradeoff."}
{"id": "2602.14573", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.14573", "abs": "https://arxiv.org/abs/2602.14573", "authors": ["Marcel Moosbrugger", "Julian Müllner", "Ezio Bartocci", "Laura Kovács"], "title": "Polar: An Algebraic Analyzer for (Probabilistic) Loops", "comment": "Published in \"Principles of Verification: Cycling the Probabilistic Landscape\"", "summary": "We present the Polar framework for fully automating the analysis of classical and probabilistic loops using algebraic reasoning. The central theme in Polar comes with handling algebraic recurrences that precisely capture the loop semantics. To this end, our work implements a variety of techniques to compute exact closed-forms of recurrences over higher-order moments of variables, infer invariants, and derive loop sensitivities with respect to unknown parameters. Polar can analyze probabilistic loops containing if-statements, polynomial arithmetic, and common probability distributions. By translating loop analysis into linear recurrence solving, Polar uses the derived closed-forms of recurrences to compute the strongest polynomial invariant or to infer parameter sensitivity. Polar is both sound and complete within well-defined programming model restrictions. Lifting any of these restrictions results in significant hardness limits of computation. To overcome computational burdens for the sake of efficiency, Polar also provides incomplete but sound techniques to compute moments of combinations of variables."}
{"id": "2602.14120", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14120", "abs": "https://arxiv.org/abs/2602.14120", "authors": ["Juan Carlos Carbajal", "Ahuva Mualem"], "title": "Evaluating the Performance of Approximation Mechanisms under Budget Constraints", "comment": null, "summary": "We study revenue maximization in a buyer-seller setting where the seller has a single object and the buyer has both a private valuation and a private budget. The presence of private budgets complicates the classic single-product monopoly problem, making optimal mechanisms difficult to analyze. To overcome this, we evaluate the robust performance of approximation mechanisms relative to optimal mechanisms. We work with three measures of performance: the guaranteed fraction of optimal revenue (GFOR) for restricted classes of mechanisms, the maximal value of relaxation (MVR) for relaxed classes, and a revenue non-monotonicity gap for either relaxed or restricted classes. Our analysis reveals sharp contrasts. On the positive side, we show that for distributions with bounded support, simple mechanisms with poly-logarithmic menu size can approximate optimal revenue arbitrarily well, regardless of correlation between valuations and budgets. On the negative side, we establish strong impossibility results: for distributions with unbounded support, or even bounded distributions concentrated in the unit square, no simple mechanism - or indeed any mechanism with a finite or sublinear menu - can guarantee a positive fraction of the optimal revenue. We also demonstrate unbounded revenue gains from certain relaxations when valuations and budgets are negatively correlated, and highlight cases of revenue non-monotonicity. Taken together, our results underscore the fragility of approximation approaches in the presence of private budgets: except for a narrow set of conditions, approximation mechanisms incur large revenue losses, pointing to fundamental limits of simplicity and robustness in mechanism design. Our analysis highlights that approximation results are highly sensitive to details of the design environment."}
{"id": "2602.14717", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2602.14717", "abs": "https://arxiv.org/abs/2602.14717", "authors": ["Stephen Mell", "Steve Zdancewic", "Osbert Bastani"], "title": "Optimal Program Synthesis via Abstract Interpretation", "comment": null, "summary": "We consider the problem of synthesizing programs with numerical constants that optimize a quantitative objective, such as accuracy, over a set of input-output examples. We propose a general framework for optimal synthesis of such programs in a given domain specific language (DSL), with provable optimality guarantees. Our framework enumerates programs in a general search graph, where nodes represent subsets of concrete programs. To improve scalability, it uses A* search in conjunction with a search heuristic based on abstract interpretation; intuitively, this heuristic establishes upper bounds on the value of subtrees in the search graph, enabling the synthesizer to identify and prune subtrees that are provably suboptimal. In addition, we propose a natural strategy for constructing abstract transformers for monotonic semantics, which is a common property for components in DSLs for data classification. Finally, we implement our approach in the context of two such existing DSLs, demonstrating that our algorithm is more scalable than existing optimal synthesizers."}
{"id": "2602.14223", "categories": ["cs.GT", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.14223", "abs": "https://arxiv.org/abs/2602.14223", "authors": ["Tim J. Boonen", "Kenneth Tsz Hin Ng", "Tak Wa Ng", "Thai Nguyen"], "title": "Pareto and Bowley Reinsurance Games in Peer-to-Peer Insurance", "comment": null, "summary": "We propose a peer-to-peer (P2P) insurance scheme comprising a risk-sharing pool and a reinsurer. A plan manager determines how risks are allocated among members and ceded to the reinsurer, while the reinsurer sets the reinsurance loading. Our work focuses on the strategic interaction between the plan manager and the reinsurer, and this focus leads to two game-theoretic contract designs: a Pareto design and a Bowley design, for which we derive closed-form optimal contracts. In the Pareto design, cooperation between the reinsurer and the plan manager leads to multiple Pareto-optimal contracts, which are further refined by introducing the notion of coalitional stability. In contrast, the Bowley design yields a unique optimal contract through a leader-follower framework, and we provide a rigorous verification of the individual rationality constraints via pointwise comparisons of payoff vectors. Comparing the two designs, we prove that the Bowley-optimal contract is never Pareto optimal and typically yields lower total welfare. In our numerical examples, the presence of reinsurance improves welfare, especially with Pareto designs and a less risk-averse reinsurer. We further analyze the impact of the single-loading restriction, which disproportionately favors members with riskier losses."}
{"id": "2602.14278", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14278", "abs": "https://arxiv.org/abs/2602.14278", "authors": ["Mayank Kejriwal", "Shilpa Thomas", "Hongyu Li"], "title": "Characterizing Robustness of Strategies to Novelty in Zero-Sum Open Worlds", "comment": "25 pages, 10 tables, 15 figures", "summary": "In open-world environments, artificial agents must often contend with novel conditions that deviate from their training or design assumptions. This paper studies the robustness of fixed-strategy agents to such novelty within the setting of two-player zero-sum games. We present a general framework for characterizing the impact of environmental novelties, such as changes in payoff structure or action constraints, on agent performance in two distinct domains: Iterated Prisoner's Dilemma (IPD) and heads-up Texas Hold'em Poker. Novelty is operationalized as a perturbation of the game's rules or scoring mechanics, while agent behavior remains fixed. To measure the effects, we introduce two metrics: per-agent robustness, quantifying the relative performance shift of each strategy across novelties, and global impact, summarizing the population-wide disruption caused by a novelty. Our experiments, comprising 30 IPD agents across 20 payoff matrix novelties and 10 Poker agents across 5 rule-based novelties, reveal systematic patterns in robustness and highlight certain novelties that induce severe destabilization. The results offer insights into agent generalizability under perturbation and provide a quantitative basis for designing safer and more resilient autonomous systems in adversarial and dynamic environments."}
{"id": "2602.14321", "categories": ["cs.GT", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14321", "abs": "https://arxiv.org/abs/2602.14321", "authors": ["Saar Cohen"], "title": "Offline Learning of Nash Stable Coalition Structures with Possibly Overlapping Coalitions", "comment": "To Appear in the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2026", "summary": "Coalition formation concerns strategic collaborations of selfish agents that form coalitions based on their preferences. It is often assumed that coalitions are disjoint and preferences are fully known, which may not hold in practice. In this paper, we thus present a new model of coalition formation with possibly overlapping coalitions under partial information, where selfish agents may be part of multiple coalitions simultaneously and their full preferences are initially unknown. Instead, information about past interactions and associated utility feedback is stored in a fixed offline dataset, and we aim to efficiently infer the agents' preferences from this dataset. We analyze the impact of diverse dataset information constraints by studying two types of utility feedback that can be stored in the dataset: agent- and coalition-level utility feedback. For both feedback models, we identify assumptions under which the dataset covers sufficient information for an offline learning algorithm to infer preferences and use them to recover a partition that is (approximately) Nash stable, in which no agent can improve her utility by unilaterally deviating. Our additional goal is devising algorithms with low sample complexity, requiring only a small dataset to obtain a desired approximation to Nash stability. Under agent-level feedback, we provide a sample-efficient algorithm proven to obtain an approximately Nash stable partition under a sufficient and necessary assumption on the information covered by the dataset. However, under coalition-level feedback, we show that only under a stricter assumption is sufficient for sample-efficient learning. Still, in multiple cases, our algorithms' sample complexity bounds have optimality guarantees up to logarithmic factors. Finally, extensive experiments show that our algorithm converges to a low approximation level to Nash stability across diverse settings."}
{"id": "2602.14331", "categories": ["cs.GT", "cs.HC", "econ.TH"], "pdf": "https://arxiv.org/pdf/2602.14331", "abs": "https://arxiv.org/abs/2602.14331", "authors": ["Saurabh Amin", "Amine Bennouna", "Daniel Huttenlocher", "Dingwen Kong", "Liang Lyu", "Asuman Ozdaglar"], "title": "A Bayesian Framework for Human-AI Collaboration: Complementarity and Correlation Neglect", "comment": null, "summary": "We develop a decision-theoretic model of human-AI interaction to study when AI assistance improves or impairs human decision-making. A human decision-maker observes private information and receives a recommendation from an AI system, but may combine these signals imperfectly. We show that the effect of AI assistance decomposes into two main forces: the marginal informational value of the AI beyond what the human already knows, and a behavioral distortion arising from how the human uses the AI's recommendation. Central to our analysis is a micro-founded measure of informational overlap between human and AI knowledge. We study an empirically relevant form of imperfect decision-making -- correlation neglect -- whereby humans treat AI recommendations as independent of their own information despite shared evidence. Under this model, we characterize how overlap and AI capabilities shape the Human-AI interaction regime between augmentation, impairment, complementarity, and automation, and draw key insights."}
{"id": "2602.14476", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14476", "abs": "https://arxiv.org/abs/2602.14476", "authors": ["Pronoy Patra", "Sankarshan Damle", "Manisha Padala", "Sujit Gujar"], "title": "Truthful Reverse Auctions for Adaptive Selection via Contextual Multi-Armed Bandits", "comment": "20 pages, 6 figures", "summary": "We study the problem of selecting large language models (LLMs) for user queries in settings where multiple LLM providers submit the cost of solving a query. From the users' perspective, choosing an optimal model is a sequential, query-dependent decision problem: high-capacity models offer more reliable outputs but are costlier, while lightweight models are faster and cheaper. We formalize this interaction as a reverse auction design problem with contextual online learning, where the user adaptively discovers which model performs best while eliciting costs from competing LLM providers. Existing multi-armed bandit (MAB) mechanisms focus on forward auctions and social welfare, leaving open the challenges of reverse auctions, provider-optimal outcomes, and contextual adaptation. We address these gaps by designing a resampling-based procedure that generalizes truthful forward MAB mechanisms to reverse auctions and prove that any monotone allocation rule with this procedure is truthful. Using this, we propose a contextual MAB algorithm that learns query-dependent model quality with sublinear regret. Our framework unifies mechanism design and adaptive learning, enabling efficient, truthful, and query-aware LLM selection."}
{"id": "2602.14668", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14668", "abs": "https://arxiv.org/abs/2602.14668", "authors": ["Moshe Babaioff", "Gefen Frosh"], "title": "Near-Optimal Best-of-Both-Worlds Fairness for Few Agents", "comment": null, "summary": "We consider the problem of fair allocation of indivisible goods among agents with additive valuations, aiming for Best-of-Both-Worlds (BoBW) fairness: a distribution over allocations that is ex-ante fair, and additionally, it is supported only on deterministic allocations that are ex-post fair. We focus on BoBW for few agents, and our main result is the design of the first BoBW algorithms achieving near-optimal fairness for three agents. For three agents, we prove the existence of an ex-ante proportional distribution whose every allocation is Epistemic EFX (EEFX) and guarantees each agent at least $\\tfrac{9}{10}$ of her MMS. As MMS allocations do not exist for three additive agents, in every allocation at least one agent might not be getting her MMS. To compensate such an agent, we also guarantee that if an agent is not getting her MMS then she is EFX-satisfied - giving her the strongest achievable envy-based guarantee. Additionally, using an FPTAS for near-MMS partitions, we present an FPTAS to compute a BoBW distribution preserving all envy-based guarantees, and also preserving all value-based guarantees up to $(1-\\varepsilon)$. We further show that exact ex-ante proportionality can be restored when dropping EEFX. To do so, we first design, for two agents and any $\\varepsilon > 0$, a Fully Polynomial-Time Approximation Scheme (FPTAS) that outputs a distribution which is ex-ante envy-free (and thus proportional) and ex-post envy-free up to any good (EFX), while guaranteeing each agent at least a $(1-\\varepsilon)$-fraction of her maximin share (MMS). We then leverage this two-agent FPTAS algorithm as a subroutine to obtain, for three agents, the FPTAS guaranteeing exact ex-ante proportionality. We note that our result for two agents essentially matches the strongest fairness and efficiency guarantees achievable in polynomial time, and thus might be of independent interest."}
{"id": "2602.14815", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14815", "abs": "https://arxiv.org/abs/2602.14815", "authors": ["Ioannis Caragiannis", "Anders Bo Ipsen", "Stratis Skoulakis"], "title": "Revenue Guarantees in Autobidding Platforms", "comment": null, "summary": "Motivated by autobidding systems in online advertising, we study revenue maximization in markets with divisible goods and budget-constrained buyers with linear valuations. Our aim is to compute a single price for each good and an allocation that maximizes total revenue. We show that the First-Price Pacing Equilibrium (FPPE) guarantees at least half of the optimal revenue, even when compared to the maximal revenue of buyer-specific prices. This guarantee is particularly striking in light of our hardness result: we prove that revenue maximization under individual rationality and single-price-per-good constraints is APX-hard.\n  We further extend our analysis in two directions: first, we introduce an online analogue of FPPE and show that it achieves a constant-factor revenue guarantee, specifically a $1/4$-approximation; second, we consider buyers with concave valuation functions, characterizing an FPPE-type outcome as the solution to an Eisenberg-Gale-style convex program and showing that the revenue approximation degrades gracefully with the degree of nonlinearity of the valuations."}
{"id": "2602.14850", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14850", "abs": "https://arxiv.org/abs/2602.14850", "authors": ["Niclas Boehmer", "Luca Kreisel"], "title": "Fair Allocation with Initial Utilities", "comment": "34 pages. An extended abstract is scheduled to appear in the proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "The problem of allocating indivisible resources to agents arises in a wide range of domains, including treatment distribution and social support programs. An important goal in algorithm design for this problem is fairness, where the focus in previous work has been on ensuring that the computed allocation provides equal treatment to everyone. However, this perspective disregards that agents may start from unequal initial positions, which is crucial to consider in settings where fairness is understood as equality of outcome. In such settings, the goal is to create an equal final outcome for everyone by leveling initial inequalities through the allocated resources. To close this gap, focusing on agents with additive utilities, we extend the classic model by assigning each agent an initial utility and study the existence and computational complexity of several new fairness notions following the principle of equality of outcome. Among others, we show that complete allocations satisfying a direct analog of envy-freeness up to one resource (EF1) may fail to exist and are computationally hard to find, forming a contrast to the classic setting without initial utilities. We propose a new, always satisfiable fairness notion, called minimum-EF1-init and design a polynomial-time algorithm based on an extended round-robin procedure to compute complete allocations satisfying this notion."}
{"id": "2602.14858", "categories": ["cs.GT", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.14858", "abs": "https://arxiv.org/abs/2602.14858", "authors": ["Yuma Ichikawa"], "title": "Thermal Min-Max Games: Unifying Bounded Rationality and Typical-Case Equilibrium", "comment": "31 pages, 4 figures", "summary": "Strategic-form min-max game theory examines the existence, multiplicity, selection of equilibria, and the worst-case computational complexity under perfect rationality. However, in many applications, games are drawn from an ensemble, and players exhibit bounded rationality. We introduce thermal min-max games, a thermodynamic relaxation that unifies bounded and perfect rationality by assigning each player a temperature to regulate their rationality level. To analyze typical behavior in the large-strategy limit, we develop a nested replica framework for this relaxation. This theory provides tractable predictions for typical equilibrium values and mixed-strategy statistics as functions of rationality strength, strategy-count aspect ratio, and payoff randomness. Numerical experiments demonstrate that these asymptotic predictions accurately align with the equilibrium of finite games of moderate size."}
{"id": "2602.14961", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.14961", "abs": "https://arxiv.org/abs/2602.14961", "authors": ["Aris Filos-Ratsikas", "Georgios Kalantzis"], "title": "The Distortion of Stable Matching", "comment": null, "summary": "We initiate the study of distortion in stable matching. Concretely, we aim to design algorithms that have limited access to the agents' cardinal preferences and compute stable matchings of high quality with respect to some aggregate objective, e.g., the social welfare. Our first result is a strong impossibility: the classic Deferred Acceptance (DA) algorithm of Gale and Shapley [1962], as well as any deterministic algorithm that relies solely on ordinal information about the agents' preferences, has unbounded distortion.\n  To circumvent this impossibility, we consider algorithms that either (a) use randomization or (b) perform a small number of value queries to the agents' cardinal preferences. In the former case, we prove that a simple randomized version of the DA algorithm achieves a distortion of $2$, and that this is optimal among all randomized stable matching algorithms. For the latter case, we prove that the same bound of $2$ can be achieved with only $1$ query per agent, and improving upon this bound requires $Ω(\\log n)$ queries per agent. We further show that this query bound is asymptotically optimal for any constant approximation: for any $\\varepsilon >0$, there exists an algorithm which uses $O(\\log n /\\varepsilon^2)$ queries, and achieves a distortion of $1+\\varepsilon$. Moreover, under natural structural restrictions on the instances of the problem, we provide improved upper bounds on the number of queries required for a $(1+\\varepsilon)$-approximation.\n  We complement our main findings above with theoretical and empirical results on the average-case performance of stable matching algorithms, when the preferences of the agents are drawn i.i.d. from a given distribution."}
{"id": "2602.14966", "categories": ["cs.GT", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.14966", "abs": "https://arxiv.org/abs/2602.14966", "authors": ["Umang Bhaskar", "Juhi Chaudhary", "Sushmita Gupta", "Pallavi Jain", "Sanjay Seetharaman"], "title": "Robust Value Maximization in Challenge the Champ Tournaments with Probabilistic Outcomes", "comment": "28 pages; full version of the paper to appear in AAMAS 2026", "summary": "Challenge the Champ is a simple tournament format, where an ordering of the players -- called a seeding -- is decided. The first player in this order is the initial champ, and faces the next player. The outcome of each match decides the current champion, who faces the next player in the order. Each player also has a popularity, and the value of each match is the popularity of the winner. Value maximization in tournaments has been previously studied when each match has a deterministic outcome. However, match outcomes are often probabilistic, rather than deterministic. We study robust value maximization in Challenge the Champ tournaments, when the winner of a match may be probabilistic. That is, we seek to maximize the total value that is obtained, irrespective of the outcome of probabilistic matches. We show that even in simple binary settings, for non-adaptive algorithms, the optimal robust value -- which we term the \\textsc{VnaR}, or the value not at risk -- is hard to approximate. However, if we allow adaptive algorithms that determine the order of challengers based on the outcomes of previous matches, or restrict the matches with probabilistic outcomes, we can obtain good approximations to the optimal \\textsc{VnaR}."}
