{"id": "2507.02257", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.02257", "abs": "https://arxiv.org/abs/2507.02257", "authors": ["Stephen Pasch", "Joel K. Salzman", "Changxi Zheng"], "title": "Gbake: Baking 3D Gaussian Splats into Reflection Probes", "comment": "SIGGRAPH 2025 Posters", "summary": "The growing popularity of 3D Gaussian Splatting has created the need to\nintegrate traditional computer graphics techniques and assets in splatted\nenvironments. Since 3D Gaussian primitives encode lighting and geometry jointly\nas appearance, meshes are relit improperly when inserted directly in a mixture\nof 3D Gaussians and thus appear noticeably out of place. We introduce GBake, a\nspecialized tool for baking reflection probes from Gaussian-splatted scenes\nthat enables realistic reflection mapping of traditional 3D meshes in the Unity\ngame engine."}
{"id": "2507.02674", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.02674", "abs": "https://arxiv.org/abs/2507.02674", "authors": ["Tom Kneiphof", "Reinhard Klein"], "title": "Real-time Image-based Lighting of Glints", "comment": null, "summary": "Image-based lighting is a widely used technique to reproduce shading under\nreal-world lighting conditions, especially in real-time rendering applications.\nA particularly challenging scenario involves materials exhibiting a sparkling\nor glittering appearance, caused by discrete microfacets scattered across their\nsurface. In this paper, we propose an efficient approximation for image-based\nlighting of glints, enabling fully dynamic material properties and environment\nmaps. Our novel approach is grounded in real-time glint rendering under area\nlight illumination and employs standard environment map filtering techniques.\nCrucially, our environment map filtering process is sufficiently fast to be\nexecuted on a per-frame basis. Our method assumes that the environment map is\npartitioned into few homogeneous regions of constant radiance. By filtering the\ncorresponding indicator functions with the normal distribution function, we\nobtain the probabilities for individual microfacets to reflect light from each\nregion. During shading, these probabilities are utilized to hierarchically\nsample a multinomial distribution, facilitated by our novel dual-gated Gaussian\napproximation of binomial distributions. We validate that our real-time\napproximation is close to ground-truth renderings for a range of material\nproperties and lighting conditions, and demonstrate robust and stable\nperformance, with little overhead over rendering glints from a single\ndirectional light. Compared to rendering smooth materials without glints, our\napproach requires twice as much memory to store the prefiltered environment\nmap."}
{"id": "2507.02226", "categories": ["cs.PL", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02226", "abs": "https://arxiv.org/abs/2507.02226", "authors": ["Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "comment": "Accepted to the International Conference on Computer-Aided Design\n  (ICCAD 2025)", "summary": "As one of their many applications, large language models (LLMs) have recently\nshown promise in automating register transfer level (RTL) code generation.\nHowever, conventional LLM decoding strategies, originally designed for natural\nlanguage, often fail to meet the structural and semantic demands of RTL,\nleading to hallucinated, repetitive, or invalid code outputs. In this paper, we\nfirst investigate the root causes of these decoding failures through an\nempirical analysis of token-level entropy during RTL generation. Our findings\nreveal that LLMs exhibit low confidence in regions of structural ambiguity or\nsemantic complexity, showing that standard decoding strategies fail to\ndifferentiate between regions requiring determinism (syntax-critical regions)\nand those that benefit from creative exploratory variability (design-critical\nregions). Then, to overcome this, we introduce DecoRTL, a novel run-time\ndecoding strategy, that is both syntax-aware and contrastive for RTL code\ngeneration. DecoRTL integrates two complementary components: (i)\nself-consistency sampling, which generates multiple candidates and re-ranks\nthem based on token-level agreement to promote correctness while maintaining\ndiversity; and (ii) syntax-aware temperature adaptation, which classifies\ntokens by their syntactical and functional roles and adjusts the sampling\ntemperature accordingly, enforcing low temperature for syntax-critical tokens\nand higher temperature for exploratory ones. Our approach operates entirely at\ninference time without requiring any additional model fine-tuning. Through\nevaluations on multiple open-source LLMs using the VerilogEval benchmark, we\ndemonstrate significant improvements in syntactic validity, functional\ncorrectness, and output diversity, while the execution overhead (performance\noverhead) is imperceptible."}
{"id": "2507.02031", "categories": ["math.RT", "math.CT", "math.QA", "18D10 (primary), 14L15, 17B45, 18M05, 18M20 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.02031", "abs": "https://arxiv.org/abs/2507.02031", "authors": ["Dave Benson", "Julia Pevtsova"], "title": "Group schemes and their Lie algebras over a symmetric tensor category", "comment": null, "summary": "We investigate the theory of affine group schemes over a symmetric tensor\ncategory, with particular attention to the tangent space at the identity. We\nshow that this carries the structure of a restricted Lie algebra, and can be\nviewed as the degree one distributions on the group scheme, or as the right\ninvariant derivations on the coordinate ring. In the second half of the paper,\nwe illustrate the theory in the particular case of the symmetric tensor\ncategory $\\mathsf{Ver}_4^+$ in characteristic two."}
{"id": "2507.02008", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.02008", "abs": "https://arxiv.org/abs/2507.02008", "authors": ["Ziyi Yang", "Guangyu Hu", "Mingkai Miao", "Changyuan Yu", "Hongce Zhang"], "title": "SMT-Sweep: Word-Level Representation Unification for Hardware Verification", "comment": null, "summary": "SAT sweeping has long been a cornerstone technique in logic simplification\nand equivalence checking at the bit level, leveraging structural hashing,\nsimulation and SAT solving to prune redundant logic. However, with the growing\nadoption of word-level constructs in hardware verification, such as bit-vector\noperations, arithmetics and arrays, there lacks a counterpart of SAT sweeping\nat the word level. In this paper, we introduce SMT-Sweep, a novel extension of\nSAT sweeping into the word level, grounded in Satisfiability Modulo Theories\n(SMT). SMT-Sweep takes advantage of simulation and equivalence detection to\nhandle SMT terms with rich bit-vector operations and array semantics. Our\nframework incorporates both randomized and constraint-driven word-level\nsimulation tailored to symbolic expressions and operator semantics beyond pure\nBoolean logic. Experimental results show that SMT-Sweep achieves significant\nspeed-up compared to state-of-the-art bit-level SAT sweeping and word-level\nmonolithic SMT solving (averaging around 44x and 69x, respectively).To the best\nof our knowledge, this is the first work that brings sweeping techniques to\nSMT-based hardware verification. The implementation is open-sourced at:\nhttps://github.com/yangziyiiii/SMT-Sweep."}
{"id": "2507.02031", "categories": ["math.RT", "math.CT", "math.QA", "18D10 (primary), 14L15, 17B45, 18M05, 18M20 (secondary)"], "pdf": "https://arxiv.org/pdf/2507.02031", "abs": "https://arxiv.org/abs/2507.02031", "authors": ["Dave Benson", "Julia Pevtsova"], "title": "Group schemes and their Lie algebras over a symmetric tensor category", "comment": null, "summary": "We investigate the theory of affine group schemes over a symmetric tensor\ncategory, with particular attention to the tangent space at the identity. We\nshow that this carries the structure of a restricted Lie algebra, and can be\nviewed as the degree one distributions on the group scheme, or as the right\ninvariant derivations on the coordinate ring. In the second half of the paper,\nwe illustrate the theory in the particular case of the symmetric tensor\ncategory $\\mathsf{Ver}_4^+$ in characteristic two."}
{"id": "2507.02464", "categories": ["cs.GT", "cs.DC", "cs.FL", "cs.IR", "econ.GN", "q-fin.EC", "68M14, 91A05, 68Q85", "C.2.4; D.2.4; F.1.1"], "pdf": "https://arxiv.org/pdf/2507.02464", "abs": "https://arxiv.org/abs/2507.02464", "authors": ["Craig S Wright"], "title": "Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems", "comment": "51 pages 4 tables, includes formal proofs, automata construction, and\n  case study on Bitcoin Script", "summary": "The CAP theorem asserts a trilemma between consistency, availability, and\npartition tolerance. This paper introduces a rigorous automata-theoretic and\neconomically grounded framework that reframes the CAP trade-off as a constraint\noptimization problem. We model distributed systems as partition-aware state\nmachines and embed economic incentive layers to stabilize consensus behavior\nacross adversarially partitioned networks. By incorporating game-theoretic\nmechanisms into the global transition semantics, we define provable bounds on\nconvergence, liveness, and correctness. Our results demonstrate that\navailability and consistency can be simultaneously preserved within bounded\nepsilon margins, effectively extending the classical CAP limits through formal\neconomic control."}
{"id": "2507.02491", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2507.02491", "abs": "https://arxiv.org/abs/2507.02491", "authors": ["Alexandre Duret-Lutz", "Shufang Zhu", "Nir Piterman", "Giuseppe de Giacomo", "Moshe Y Vardi"], "title": "Engineering an LTLf Synthesis Tool", "comment": null, "summary": "The problem of LTLf reactive synthesis is to build a transducer, whose output\nis based on a history of inputs, such that, for every infinite sequence of\ninputs, the conjoint evolution of the inputs and outputs has a prefix that\nsatisfies a given LTLf specification. We describe the implementation of an LTLf\nsynthesizer that outperforms existing tools on our benchmark suite. This is\nbased on a new, direct translation from LTLf to a DFA represented as an array\nof Binary Decision Diagrams (MTBDDs) sharing their nodes. This MTBDD-based\nrepresentation can be interpreted directly as a reachability game that is\nsolved on-the-fly during its construction."}
{"id": "2507.02113", "categories": ["math.LO", "math.CA", "03D78, 26E10, 58C25, 54C20, 54C30"], "pdf": "https://arxiv.org/pdf/2507.02113", "abs": "https://arxiv.org/abs/2507.02113", "authors": ["Andrea Brun", "Guido Gherardi", "Alberto Marcone"], "title": "Computability of a Whitney Extension", "comment": "35 pages, 3 figures", "summary": "We prove the computability of a version of Whitney Extension, when the input\nis suitably represented. More specifically, if $F \\subseteq \\mathbb{R}^n$ is a\nclosed set represented so that the distance function $x \\mapsto d(x,F)$ can be\ncomputed, and $(f^{(\\bar{k})})_{|\\bar{k}| \\le m}$ is a Whitney jet of order $m$\non $F$, then we can compute $g \\in C^{m}(\\mathbb{R}^n)$ such that $g$ and its\npartial derivatives coincide on $F$ with the corresponding functions of\n$(f^{(\\bar{k})})_{|\\bar{k}| \\le m}$."}
{"id": "2507.02492", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.02492", "abs": "https://arxiv.org/abs/2507.02492", "authors": ["Arindam Banerjee", "Kanoy Kumar Das", "Ajeet Kumar", "Rakesh Kumar", "Subhamoy Maitra"], "title": "On Obtaining New MUBs by Finding Points on Complete Intersection Varieties over $\\mathbb{R}$", "comment": null, "summary": "Mutually Unbiased Bases (MUBs) are closely connected with quantum physics,\nand the structure has a rich mathematical background. We provide equivalent\ncriteria for extending a set of MUBs for $C^n$ by studying real points of a\ncertain affine algebraic variety. This variety comes from the relations that\ndetermine the extendability of a system of MUBs. Finally, we show that some\npart of this variety gives rise to complete intersection domains. Further, we\nshow that there is a one-to-one correspondence between MUBs and the maximal\ncommuting classes (bases) of orthogonal normal matrices in $\\mathcal\nM_n({\\mathbb{C}})$. It means that for $m$ MUBs in $C^n$, there are $m$\ncommuting classes, each consisting of $n$ commuting orthogonal normal matrices\nand the existence of maximal commuting basis for $\\mathcal M_n({\\mathbb{C}})$\nensures the complete set of MUBs in $\\mathcal M_n({\\mathbb{C}})$."}
{"id": "2507.02218", "categories": ["math.RT", "math.CO", "16G70 (Primary) 13F60, 16G20, 05E10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.02218", "abs": "https://arxiv.org/abs/2507.02218", "authors": ["Blake Jackson"], "title": "A geometric model for the non-$τ$-rigid modules of type $\\widetilde{D}_n$", "comment": "25 pages, 15 figures", "summary": "We give a geometric model for the non-$\\tau$-rigid modules over acyclic path\nalgebras of type $\\widetilde{D}_n$. Similar models have been provided for\nmodule categories over path algebras of types $A_n, D_n,$ and $\\widetilde{A}_n$\nas well as the $\\tau$-rigid modules of type $\\widetilde{D}_n$. A major draw of\nthese geometric models is the \"intersection-dimension formulas\" they often come\nwith. These formulas give an equality between the intersection number of the\ncurves representing the modules in the geometric model and the dimension of the\nextension spaces between the two modules. This formula allows us to calculate\nthe homological data between two modules combinatorially. Since there are\ninfinitely many distinct homogeneous stable tubes in the regular component of\nthe Auslander-Reiten quiver of type $\\widetilde{D}_n$, all of which are\ndisjoint, our geometric data requires an extra decoration on the admissible\nedges in our geometric model to prevent intersections between curves\ncorresponding to modules in distinct stable tubes of the Auslander-Reiten\nquiver."}
{"id": "2507.02742", "categories": ["cs.LO", "03B25, 26A06"], "pdf": "https://arxiv.org/pdf/2507.02742", "abs": "https://arxiv.org/abs/2507.02742", "authors": ["G. Buriola", "D. Cantone", "G. Cincotti", "E. G. Omodeo", "G. T. Spartà"], "title": "Decision algorithms for fragments of real analysis. III: A theory of differentiable functions with (semi-)open intervals", "comment": null, "summary": "This paper enriches preexisting satisfiability tests for unquantified\nlanguages, which in turn augment a fragment of Tarski's elementary algebra with\nunary real functions possessing a continuous first derivative.\n  Two sorts of individual variables are available, one ranging over real\nnumbers and the other one ranging over the functions of interest. Numerical\nterms are built from real variables through constructs designating the four\nbasic arithmetic operations and through the function-application constructs\n$f(t)$ and $D[\\,f\\,](t)$, where $f$ stands for a function variable, $t$ for a\nnumerical term, and $D[\\,\\sqdot\\,]$ designates the differentiation operator.\nComparison relators can be placed between numerical terms. An array of\npredicate symbols are also available, designating various relationships between\nfunctions, as well as function properties, that may hold over intervals of the\nreal line; those are: (pointwise) function comparisons, strict and nonstrict\nmonotonicity~/~convexity~/~concavity properties, comparisons between the\nderivative of a function and a real term--here, w.r.t.\\ earlier research, they\nare extended to (semi)-open intervals.\n  The decision method we propose consists in preprocessing the given formula\ninto an equisatisfiable quantifier-free formula of the elementary algebra of\nreal numbers, whose satisfiability can then be checked by means of Tarski's\ndecision method. No direct reference to functions will appear in the target\nformula, each function variable having been superseded by a collection of stub\nreal variables; hence, in order to prove that the proposed translation is\nsatisfiability-preserving, we must figure out a sufficiently flexible family of\ninterpolating $C^1$ functions that can accommodate a model for the source\nformula whenever the target formula turns out to be satisfiable."}
{"id": "2507.02675", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.02675", "abs": "https://arxiv.org/abs/2507.02675", "authors": ["Zhaoqilin Yang", "Xin Wang", "Ruichen Zhang", "Chanchan Li", "Youliang Tian"], "title": "TUC-PPO: Team Utility-Constrained Proximal Policy Optimization for Spatial Public Goods Games", "comment": null, "summary": "We introduce Team Utility-Constrained Proximal Policy Optimization (TUC-PPO),\na new deep reinforcement learning framework. It extends Proximal Policy\nOptimization (PPO) by integrating team welfare objectives specifically for\nspatial public goods games. Unlike conventional approaches where cooperation\nemerges indirectly from individual rewards, TUC-PPO instead optimizes a\nbi-level objective integrating policy gradients and team utility constraints.\nConsequently, all policy updates explicitly incorporate collective payoff\nthresholds. The framework preserves PPO's policy gradient core while\nincorporating constrained optimization through adaptive Lagrangian multipliers.\nTherefore, decentralized agents dynamically balance selfish and cooperative\nincentives. The comparative analysis demonstrates superior performance of this\nconstrained deep reinforcement learning approach compared to unmodified PPO and\nevolutionary game theory baselines. It achieves faster convergence to\ncooperative equilibria and greater stability against invasion by defectors. The\nframework formally integrates team objectives into policy updates. This work\nadvances multi-agent deep reinforcement learning for social dilemmas while\nproviding new computational tools for evolutionary game theory research."}
{"id": "2507.02464", "categories": ["cs.GT", "cs.DC", "cs.FL", "cs.IR", "econ.GN", "q-fin.EC", "68M14, 91A05, 68Q85", "C.2.4; D.2.4; F.1.1"], "pdf": "https://arxiv.org/pdf/2507.02464", "abs": "https://arxiv.org/abs/2507.02464", "authors": ["Craig S Wright"], "title": "Resolving CAP Through Automata-Theoretic Economic Design: A Unified Mathematical Framework for Real-Time Partition-Tolerant Systems", "comment": "51 pages 4 tables, includes formal proofs, automata construction, and\n  case study on Bitcoin Script", "summary": "The CAP theorem asserts a trilemma between consistency, availability, and\npartition tolerance. This paper introduces a rigorous automata-theoretic and\neconomically grounded framework that reframes the CAP trade-off as a constraint\noptimization problem. We model distributed systems as partition-aware state\nmachines and embed economic incentive layers to stabilize consensus behavior\nacross adversarially partitioned networks. By incorporating game-theoretic\nmechanisms into the global transition semantics, we define provable bounds on\nconvergence, liveness, and correctness. Our results demonstrate that\navailability and consistency can be simultaneously preserved within bounded\nepsilon margins, effectively extending the classical CAP limits through formal\neconomic control."}
{"id": "2507.02343", "categories": ["math.LO", "03C95, 03B22"], "pdf": "https://arxiv.org/pdf/2507.02343", "abs": "https://arxiv.org/abs/2507.02343", "authors": ["Sayantan Roy", "Sankha S. Basu", "Mihir K. Chakraborty"], "title": "Abstract Model Structures and Compactness Theorems", "comment": "33 pages. The final version of this article has been submitted for\n  publication", "summary": "The compactness theorem for a logic states, roughly, that the satisfiability\nof a set of well-formed formulas can be determined from the satisfiability of\nits finite subsets, and vice versa. Usually, proofs of this theorem depend on\nthe syntactic/semantic particularities of the corresponding logic. In this\npaper, using the notion of \\emph{abstract model structures}, we show that one\ncan develop a generalized notion of compactness that is independent of these.\nSeveral characterization theorems for a particular class of compact abstract\nmodel structures are also proved."}
{"id": "2507.02347", "categories": ["math.RT", "math.QA"], "pdf": "https://arxiv.org/pdf/2507.02347", "abs": "https://arxiv.org/abs/2507.02347", "authors": ["Marco Mackaay", "Vanessa Miemietz", "Pedro Vaz"], "title": "Induction for extended affine type A Soergel bimodules from a maximal parabolic", "comment": "91 pages, lots of pictures, comments welcome", "summary": "In this paper we take a first step towards the categorification of the\nZelevinsky tensor product of finite dimensional representations of extended\naffine type A Hecke algebras."}
{"id": "2507.02767", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.02767", "abs": "https://arxiv.org/abs/2507.02767", "authors": ["Tiziano Dalmonte", "Marianna Girlando"], "title": "A Proof-Theoretic View of Basic Intuitionistic Conditional Logic (Extended Version)", "comment": "Draft. A shorter version of this paper was accepted for presentation\n  at TABLEAUX 2025", "summary": "Intuitionistic conditional logic, studied by Weiss, Ciardelli and Liu, and\nOlkhovikov, aims at providing a constructive analysis of conditional reasoning.\nIn this framework, the would and the might conditional operators are no longer\ninterdefinable. The intuitionistic conditional logics considered in the\nliterature are defined by setting Chellas' conditional logic CK, whose\nsemantics is defined using selection functions, within the constructive and\nintuitionistic framework introduced for intuitionistic modal logics. This\noperation gives rise to a constructive and an intuitionistic variant of\n(might-free-) CK, which we call CCKbox and IntCK respectively. Building on the\nproof systems defined for CK and for intuitionistic modal logics, in this paper\nwe introduce a nested calculus for IntCK and a sequent calculus for CCKbox.\nBased on the sequent calculus, we define CCK, a conservative extension of\nWeiss' logic CCKbox with the might operator. We introduce a class of models and\nan axiomatization for CCK, and extend these result to several extensions of\nCCK."}
{"id": "2507.02801", "categories": ["cs.GT", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2507.02801", "abs": "https://arxiv.org/abs/2507.02801", "authors": ["Hu Fu", "Tao Lin"], "title": "Learning to Coordinate Bidders in Non-Truthful Auctions", "comment": null, "summary": "In non-truthful auctions such as first-price and all-pay auctions, the\nindependent strategic behaviors of bidders, with the corresponding equilibrium\nnotion -- Bayes Nash equilibria -- are notoriously difficult to characterize\nand can cause undesirable outcomes. An alternative approach to designing better\nauction systems is to coordinate the bidders: let a mediator make\nincentive-compatible recommendations of correlated bidding strategies to the\nbidders, namely, implementing a Bayes correlated equilibrium (BCE). The\nimplementation of BCE, however, requires knowledge of the distribution of\nbidders' private valuations, which is often unavailable. We initiate the study\nof the sample complexity of learning Bayes correlated equilibria in\nnon-truthful auctions. We prove that the BCEs in a large class of non-truthful\nauctions, including first-price and all-pay auctions, can be learned with a\npolynomial number $\\tilde O(\\frac{n}{\\varepsilon^2})$ of samples from the\nbidders' value distributions. Our technique is a reduction to the problem of\nestimating bidders' expected utility from samples, combined with an analysis of\nthe pseudo-dimension of the class of all monotone bidding strategies of\nbidders."}
{"id": "2507.02855", "categories": ["cs.LO", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.02855", "abs": "https://arxiv.org/abs/2507.02855", "authors": ["Colin Rothgang", "Florian Rabe"], "title": "Subtyping in DHOL -- Extended preprint", "comment": "16 pages main document, 44 pages of appendices, to be published in\n  FroCoS 2025", "summary": "The recently introduced dependent typed higher-order logic (DHOL) offers an\ninteresting compromise between expressiveness and automation support. It\nsacrifices the decidability of its type system in order to significantly extend\nits expressiveness over standard HOL. Yet it retains strong automated theorem\nproving support via a sound and complete translation to HOL.\n  We leverage this design to extend DHOL with refinement and quotient types.\nBoth of these are commonly requested by practitioners but rarely provided by\nautomated theorem provers. This is because they inherently require undecidable\ntyping and thus are very difficult to retrofit to decidable type systems. But\nwith DHOL already doing the heavy lifting, adding them is not only possible but\nelegant and simple.\n  Concretely, we add refinement and quotient types as special cases of\nsubtyping. This turns the associated canonical inclusion resp. projection maps\ninto identity maps and thus avoids costly changes in representation. We present\nthe syntax, semantics, and translation to HOL for the extended language,\nincluding the proofs of soundness and completeness."}
{"id": "2507.02553", "categories": ["math.RT", "17B10, 17B35, 17b65, 17b68"], "pdf": "https://arxiv.org/pdf/2507.02553", "abs": "https://arxiv.org/abs/2507.02553", "authors": ["Qiufan Chen", "Cong Guo"], "title": "Non-weight modules over the BMS-Kac-Moody algebra", "comment": null, "summary": "In this paper, we construct and classify a class of non-weight modules over\nthe BMS-Kac-Moody algebra, which are free modules of rank one when restricted\nto the universal enveloping algebra of the Cartan subalgebra (modulo center).\nWe give the classification of such modules. Moreover, the irreducibility and\nthe isomorphism classes of these modules are determined."}
{"id": "2507.02855", "categories": ["cs.LO", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.02855", "abs": "https://arxiv.org/abs/2507.02855", "authors": ["Colin Rothgang", "Florian Rabe"], "title": "Subtyping in DHOL -- Extended preprint", "comment": "16 pages main document, 44 pages of appendices, to be published in\n  FroCoS 2025", "summary": "The recently introduced dependent typed higher-order logic (DHOL) offers an\ninteresting compromise between expressiveness and automation support. It\nsacrifices the decidability of its type system in order to significantly extend\nits expressiveness over standard HOL. Yet it retains strong automated theorem\nproving support via a sound and complete translation to HOL.\n  We leverage this design to extend DHOL with refinement and quotient types.\nBoth of these are commonly requested by practitioners but rarely provided by\nautomated theorem provers. This is because they inherently require undecidable\ntyping and thus are very difficult to retrofit to decidable type systems. But\nwith DHOL already doing the heavy lifting, adding them is not only possible but\nelegant and simple.\n  Concretely, we add refinement and quotient types as special cases of\nsubtyping. This turns the associated canonical inclusion resp. projection maps\ninto identity maps and thus avoids costly changes in representation. We present\nthe syntax, semantics, and translation to HOL for the extended language,\nincluding the proofs of soundness and completeness."}
{"id": "2507.02061", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02061", "abs": "https://arxiv.org/abs/2507.02061", "authors": ["Liam Roditty", "Plia Trabelsi"], "title": "New algorithms for girth and cycle detection", "comment": null, "summary": "Let $G=(V,E)$ be an unweighted undirected graph with $n$ vertices and $m$\nedges. Let $g$ be the girth of $G$, that is, the length of a shortest cycle in\n$G$. We present a randomized algorithm with a running time of\n$\\tilde{O}\\big(\\ell \\cdot n^{1 + \\frac{1}{\\ell - \\varepsilon}}\\big)$ that\nreturns a cycle of length at most $ 2\\ell \\left\\lceil \\frac{g}{2} \\right\\rceil\n- 2 \\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil\n\\right\\rfloor, $ where $\\ell \\geq 2$ is an integer and $\\varepsilon \\in [0,1]$,\nfor every graph with $g = polylog(n)$.\n  Our algorithm generalizes an algorithm of Kadria \\etal{} [SODA'22] that\ncomputes a cycle of length at most $4\\left\\lceil \\frac{g}{2} \\right\\rceil -\n2\\left\\lfloor \\varepsilon \\left\\lceil \\frac{g}{2} \\right\\rceil \\right\\rfloor $\nin $\\tilde{O}\\big(n^{1 + \\frac{1}{2 - \\varepsilon}}\\big)$ time. Kadria \\etal{}\npresented also an algorithm that finds a cycle of length at most $ 2\\ell\n\\left\\lceil \\frac{g}{2} \\right\\rceil $ in $\\tilde{O}\\big(n^{1 +\n\\frac{1}{\\ell}}\\big)$ time, where $\\ell$ must be an integer. Our algorithm\ngeneralizes this algorithm, as well, by replacing the integer parameter $\\ell$\nin the running time exponent with a real-valued parameter $\\ell - \\varepsilon$,\nthereby offering greater flexibility in parameter selection and enabling a\nbroader spectrum of combinations between running times and cycle lengths.\n  We also show that for sparse graphs a better tradeoff is possible, by\npresenting an $\\tilde{O}(\\ell\\cdot m^{1+1/(\\ell-\\varepsilon)})$ time randomized\nalgorithm that returns a cycle of length at most $2\\ell(\\lfloor\n\\frac{g-1}{2}\\rfloor) - 2(\\lfloor \\varepsilon \\lfloor \\frac{g-1}{2}\\rfloor\n\\rfloor+1)$, where $\\ell\\geq 3$ is an integer and $\\varepsilon\\in [0,1)$, for\nevery graph with $g=polylog(n)$.\n  To obtain our algorithms we develop several techniques and introduce a formal\ndefinition of hybrid cycle detection algorithms. [...]"}
{"id": "2507.02722", "categories": ["math.RT"], "pdf": "https://arxiv.org/pdf/2507.02722", "abs": "https://arxiv.org/abs/2507.02722", "authors": ["Kevin Coulembier", "Johannes Flake"], "title": "A conjecture on the tensor ideal for an elementary p-group generated by the restriction of a Steinberg module", "comment": null, "summary": "In previous work (Coulembier--Flake 2024), the authors conjectured that the\ntensor product of an arbitrary finite-dimensional modular representation of an\nelementary abelian $p$-group with the biggest non-projective restricted\nSteinberg $SL_2$-module is a restricted tilting module. We showed that the\nvalidity of the conjecture would have interesting implications in the theory of\ntensor categories in positive characteristic, in particular, with respect to\nthe classification of incompressible symmetric tensor categories, which is the\nsubject of arguably the main open conjecture in the area. We present here some\nevidence for the conjecture to hold."}
{"id": "2507.02117", "categories": ["cs.DS", "I.2.8, E.1"], "pdf": "https://arxiv.org/pdf/2507.02117", "abs": "https://arxiv.org/abs/2507.02117", "authors": ["Dan Vanderkam"], "title": "A Computational Proof of the Highest-Scoring Boggle Board", "comment": "14 pages, 2 figures, code available at\n  https://github.com/danvk/hybrid-boggle/", "summary": "Finding all the words on a Boggle board is a classic computer programming\nproblem. With a fast Boggle solver, local optimization techniques such as\nhillclimbing and simulated annealing can be used to find particularly\nhigh-scoring boards. The sheer number of possible Boggle boards has\nhistorically prevented an exhaustive search for the global optimum board. We\napply Branch and Bound and a decision diagram-like data structure to perform\nthe first such search. We find that the highest-scoring boards found via\nhillclimbing are, in fact, the global optima."}
{"id": "2507.02394", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02394", "abs": "https://arxiv.org/abs/2507.02394", "authors": ["Yotam Kenneth-Mordoch", "Shay Sapir"], "title": "On the Adversarial Robustness of Online Importance Sampling", "comment": null, "summary": "This paper studies the adversarial-robustness of importance-sampling (aka\nsensitivity sampling); a useful algorithmic technique that samples elements\nwith probabilities proportional to some measure of their importance. A\nstreaming or online algorithm is called adversarially-robust if it succeeds\nwith high probability on input streams that may change adaptively depending on\nprevious algorithm outputs. Unfortunately, the dependence between stream\nelements breaks the analysis of most randomized algorithms, and in particular\nthat of importance-sampling algorithms. Previously, Braverman et al. [NeurIPS\n2021] suggested that streaming algorithms based on importance-sampling may be\nadversarially-robust; however, they proved it only for well-behaved inputs.\n  We focus on the adversarial-robustness of online importance-sampling, a\nnatural variant where sampling decisions are irrevocable and made as data\narrives. Our main technical result shows that, given as input an adaptive\nstream of elements $x_1,\\ldots,x_T\\in \\mathbb{R}_+$, online importance-sampling\nmaintains a $(1\\pm\\epsilon)$-approximation of their sum while matching (up to\nlower order terms) the storage guarantees of the oblivious (non-adaptive) case.\nWe then apply this result to develop adversarially-robust online algorithms for\ntwo fundamental problems: hypergraph cut sparsification and $\\ell_p$ subspace\nembedding."}
{"id": "2507.02433", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02433", "abs": "https://arxiv.org/abs/2507.02433", "authors": ["Yiping Liu", "Hoai-An Nguyen", "Junzhao Yang"], "title": "Numerical Linear Algebra in Linear Space", "comment": "52 pages, 0 figures", "summary": "We present a randomized linear-space solver for general linear systems\n$\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ with $\\mathbf{A} \\in \\mathbb{Z}^{n \\times\nn}$ and $\\mathbf{b} \\in \\mathbb{Z}^n$, without any assumption on the condition\nnumber of $\\mathbf{A}$. For matrices whose entries are bounded by\n$\\mathrm{poly}(n)$, the solver returns a $(1+\\epsilon)$-multiplicative\nentry-wise approximation to vector $\\mathbf{x} \\in \\mathbb{Q}^{n}$ using\n$\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ bit operations and $O(n\n\\log n)$ bits of working space (i.e., linear in the size of a vector), where\n$\\mathrm{nnz}$ denotes the number of nonzero entries. Our solver works for\nright-hand vector $\\mathbf{b}$ with entries up to $n^{O(n)}$. To our knowledge,\nthis is the first linear-space linear system solver over the rationals that\nruns in $\\widetilde{O}(n^2 \\cdot \\mathrm{nnz}(\\mathbf{A}))$ time.\n  We also present several applications of our solver to numerical linear\nalgebra problems, for which we provide algorithms with efficient polynomial\nrunning time and near-linear space. In particular, we present results for\nlinear regression, linear programming, eigenvalues and eigenvectors, and\nsingular value decomposition."}
{"id": "2507.02548", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02548", "abs": "https://arxiv.org/abs/2507.02548", "authors": ["Itai Boneh", "Egor Gorbachev", "Tomasz Kociumaka"], "title": "Bounded Weighted Edit Distance: Dynamic Algorithms and Matching Lower Bounds", "comment": "ESA 2025", "summary": "The edit distance $ed(X,Y)$ of two strings $X,Y\\in \\Sigma^*$ is the minimum\nnumber of character edits (insertions, deletions, and substitutions) needed to\ntransform $X$ into $Y$. Its weighted counterpart $ed^w(X,Y)$ minimizes the\ntotal cost of edits, which are specified using a function $w$, normalized so\nthat each edit costs at least one. The textbook dynamic-programming procedure,\ngiven strings $X,Y\\in \\Sigma^{\\le n}$ and oracle access to $w$, computes\n$ed^w(X,Y)$ in $O(n^2)$ time. Nevertheless, one can achieve better running\ntimes if the computed distance, denoted $k$, is small: $O(n+k^2)$ for unit\nweights [Landau and Vishkin; JCSS'88] and $\\tilde{O}(n+\\sqrt{nk^3})$ for\narbitrary weights [Cassis, Kociumaka, Wellnitz; FOCS'23].\n  In this paper, we study the dynamic version of the weighted edit distance\nproblem, where the goal is to maintain $ed^w(X,Y)$ for strings $X,Y\\in\n\\Sigma^{\\le n}$ that change over time, with each update specified as an edit in\n$X$ or $Y$. Very recently, Gorbachev and Kociumaka [STOC'25] showed that the\nunweighted distance $ed(X,Y)$ can be maintained in $\\tilde{O}(k)$ time per\nupdate after $\\tilde{O}(n+k^2)$-time preprocessing; here, $k$ denotes the\ncurrent value of $ed(X,Y)$. Their algorithm generalizes to small integer\nweights, but the underlying approach is incompatible with large weights.\n  Our main result is a dynamic algorithm that maintains $ed^w(X,Y)$ in\n$\\tilde{O}(k^{3-\\gamma})$ time per update after $\\tilde{O}(nk^\\gamma)$-time\npreprocessing. Here, $\\gamma\\in [0,1]$ is a real trade-off parameter and $k\\ge\n1$ is an integer threshold fixed at preprocessing time, with $\\infty$ returned\nwhenever $ed^w(X,Y)>k$. We complement our algorithm with conditional lower\nbounds showing fine-grained optimality of our trade-off for $\\gamma \\in\n[0.5,1)$ and justifying our choice to fix $k$."}
{"id": "2507.02657", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02657", "abs": "https://arxiv.org/abs/2507.02657", "authors": ["Jens Schlöter"], "title": "On the Complexity of Knapsack under Explorable Uncertainty: Hardness and Algorithms", "comment": null, "summary": "In the knapsack problem under explorable uncertainty, we are given a knapsack\ninstance with uncertain item profits. Instead of having access to the precise\nprofits, we are only given uncertainty intervals that are guaranteed to contain\nthe corresponding profits. The actual item profit can be obtained via a query.\nThe goal of the problem is to adaptively query item profits until the revealed\ninformation suffices to compute an optimal (or approximate) solution to the\nunderlying knapsack instance. Since queries are costly, the objective is to\nminimize the number of queries.\n  In the offline variant of this problem, we assume knowledge of the precise\nprofits and the task is to compute a query set of minimum cardinality that a\nthird party without access to the profits could use to identify an optimal (or\napproximate) knapsack solution. We show that this offline variant is complete\nfor the second-level of the polynomial hierarchy, i.e., $\\Sigma_2^p$-complete,\nand cannot be approximated within a non-trivial factor unless $\\Sigma_2^p =\n\\Delta_2^p$. Motivated by these strong hardness results, we consider a\nresource-augmented variant of the problem where the requirements on the query\nset computed by an algorithm are less strict than the requirements on the\noptimal solution we compare against. More precisely, a query set computed by\nthe algorithm must reveal sufficient information to identify an approximate\nknapsack solution, while the optimal query set we compare against has to reveal\nsufficient information to identify an optimal solution. We show that this\nresource-augmented setting allows interesting non-trivial algorithmic results."}
{"id": "2507.02701", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02701", "abs": "https://arxiv.org/abs/2507.02701", "authors": ["Tomasz Kociumaka", "Ali Shahali"], "title": "Faster Algorithm for Bounded Tree Edit Distance in the Low-Distance Regime", "comment": "Accepted to ESA 2025", "summary": "The tree edit distance is a natural dissimilarity measure between rooted\nordered trees whose nodes are labeled over an alphabet $\\Sigma$. It is defined\nas the minimum number of node edits (insertions, deletions, and relabelings)\nrequired to transform one tree into the other. In the weighted variant, the\nedits have associated costs (depending on the involved node labels) normalized\nso that each cost is at least one, and the goal is to minimize the total cost\nof edits.\n  The unweighted tree edit distance between two trees of total size $n$ can be\ncomputed in $O(n^{2.6857})$ time; in contrast, determining the weighted tree\nedit distance is fine-grained equivalent to the All-Pairs Shortest Paths\nproblem and requires $n^3/2^{\\Omega(\\sqrt{\\log n})}$ time [Nogler et al.;\nSTOC'25]. These super-quadratic running times are unattractive for large but\nvery similar trees, which motivates the bounded version of the problem, where\nthe runtime is parameterized by the computed distance $k$, potentially yielding\nfaster algorithms for $k\\ll n$.\n  Previous best algorithms for the bounded unweighted setting run in\n$O(nk^2\\log n)$ time [Akmal & Jin; ICALP'21] and $O(n + k^7\\log k)$ time [Das\net al.; STOC'23]. For the weighted variant, the only known running time has\nbeen $O(n + k^{15})$.\n  We present an $O(n + k^6\\log k)$-time algorithm for computing the bounded\ntree edit distance in both the weighted and unweighted settings. Our approach\nbegins with an alternative $O(nk^2\\log n)$-time algorithm that handles weights\nand is significantly easier to analyze than the existing counterpart. We then\nintroduce a novel optimization that leverages periodic structures within the\ninput trees. To utilize it, we modify the $O(k^5)$-size $O(n)$-time universal\nkernel, the central component of the prior $O(n + k^{O(1)})$-time algorithms,\nso that it produces instances containing these periodic structures."}
{"id": "2507.02728", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02728", "abs": "https://arxiv.org/abs/2507.02728", "authors": ["Lorenzo Carfagna", "Carlo Tosoni"], "title": "Indexing Tries within Entropy-Bounded Space", "comment": "14 pages, 1 figure, submitted to SPIRE 2025", "summary": "We study the problem of indexing and compressing tries using a BWT-based\napproach. Specifically, we consider a succinct and compressed representation of\nthe XBWT of Ferragina et al.\\ [FOCS '05, JACM '09] corresponding to the\nanalogous of the FM-index [FOCS '00, JACM '05] for tries. This representation\nallows to efficiently count the number of nodes reached by a given string\npattern. To analyze the space complexity of the above trie index, we propose a\nproof for the combinatorial problem of counting the number of tries with a\ngiven symbol distribution. We use this formula to define a worst-case entropy\nmeasure for tries, as well as a notion of k-th order empirical entropy. In\nparticular, we show that the relationships between these two entropy measures\nare similar to those between the corresponding well-known measures for strings.\nWe use these measures to prove that the XBWT of a trie can be encoded within a\nspace bounded by our k-th order empirical entropy plus a o(n) term, with n\nbeing the number of nodes in the trie. Notably, as happens for strings, this\nspace bound can be reached for every sufficiently small k simultaneously.\nFinally, we compare the space complexity of the above index with that of the\nr-index for tries proposed by Prezza [SODA '21] and we prove that in some cases\nthe FM-index for tries is asymptotically smaller."}
{"id": "2507.02774", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02774", "abs": "https://arxiv.org/abs/2507.02774", "authors": ["Jan Eube", "Kelin Luo", "Dorian Reineccius", "Heiko Röglin", "Melanie Schmidt"], "title": "Connected k-Median with Disjoint and Non-disjoint Clusters", "comment": "To appear in ESA 2025", "summary": "The connected $k$-median problem is a constrained clustering problem that\ncombines distance-based $k$-clustering with connectivity information. The\nproblem allows to input a metric space and an unweighted undirected\nconnectivity graph that is completely unrelated to the metric space. The goal\nis to compute $k$ centers and corresponding clusters such that each cluster\nforms a connected subgraph of $G$, and such that the $k$-median cost is\nminimized.\n  The problem has applications in very different fields like geodesy\n(particularly districting), social network analysis (especially community\ndetection), or bioinformatics. We study a version with overlapping clusters\nwhere points can be part of multiple clusters which is natural for the use case\nof community detection. This problem variant is $\\Omega(\\log n)$-hard to\napproximate, and our main result is an $\\mathcal{O}(k^2 \\log n)$-approximation\nalgorithm for the problem. We complement it with an\n$\\Omega(n^{1-\\epsilon})$-hardness result for the case of disjoint clusters\nwithout overlap with general connectivity graphs, as well as an exact algorithm\nin this setting if the connectivity graph is a tree."}
{"id": "2507.02842", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.02842", "abs": "https://arxiv.org/abs/2507.02842", "authors": ["Anders Aamand", "Maryam Aliakbarpour", "Justin Y. Chen", "Shyam Narayanan", "Sandeep Silwal"], "title": "On the Structure of Replicable Hypothesis Testers", "comment": "Abstract abridged to meet arxiv requirements", "summary": "A hypothesis testing algorithm is replicable if, when run on two different\nsamples from the same distribution, it produces the same output with high\nprobability. This notion, defined by by Impagliazzo, Lei, Pitassi, and Sorell\n[STOC'22], can increase trust in testing procedures and is deeply related to\nalgorithmic stability, generalization, and privacy. We build general tools to\nprove lower and upper bounds on the sample complexity of replicable testers,\nunifying and quantitatively improving upon existing results.\n  We identify a set of canonical properties, and prove that any replicable\ntesting algorithm can be modified to satisfy these properties without worsening\naccuracy or sample complexity. A canonical replicable algorithm computes a\ndeterministic function of its input (i.e., a test statistic) and thresholds\nagainst a uniformly random value in $[0,1]$. It is invariant to the order in\nwhich the samples are received, and, if the testing problem is ``symmetric,''\nthen the algorithm is also invariant to the labeling of the domain elements,\nresolving an open question by Liu and Ye [NeurIPS'24]. We prove new lower\nbounds for uniformity, identity, and closeness testing by reducing to the case\nwhere the replicable algorithm satisfies these canonical properties.\n  We systematize and improve upon a common strategy for replicable algorithm\ndesign based on test statistics with known expectation and bounded variance.\nOur framework allow testers which have been extensively analyzed in the\nnon-replicable setting to be made replicable with minimal overhead. As direct\napplications of our framework, we obtain constant-factor optimal bounds for\ncoin testing and closeness testing and get replicability for free in a large\nparameter regime for uniformity testing.\n  We also give state-of-the-art bounds for replicable Gaussian mean testing,\nand, unlike prior work, our algorithm runs in polynomial time."}
