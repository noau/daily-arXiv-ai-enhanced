<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature](https://arxiv.org/abs/2601.03319)
*Eldad Matmon,Amit Bracha,Noam Rotstein,Ron Kimmel*

Main category: cs.GR

TL;DR: 介绍了一种逼真且可控的3D人脸卡通化框架，结合3D高斯抛光和局部编辑技术，实现了高质量且实时可控的卡通化效果。


<details>
  <summary>Details</summary>
Motivation: 传统基于高斯曲率的表面夸张技术结合纹理渲染时，往往导致过度平滑的结果。为了解决这一问题，研究人员采用了3D高斯抛光（3DGS）技术。

Method: 通过从多视角序列中提取FLAME网格，求解曲率加权的泊松方程，并通过局部仿射变换生成伪真实卡通图像。训练方案交替使用真实和合成的监督信号，实现了自然和夸张化身的统一表示。

Result: 定量和定性评估表明，该方法优于现有工作，提供了逼真且几何可控的卡通化身，并支持实时变形和局部编辑。

Conclusion: 该框架不仅提升了卡通化的保真度，还实现了对夸张强度的连续控制，为实时3D人脸卡通化提供了一种高效的解决方案。

Abstract: A photorealistic and controllable 3D caricaturization framework for faces is introduced. We start with an intrinsic Gaussian curvature-based surface exaggeration technique, which, when coupled with texture, tends to produce over-smoothed renders. To address this, we resort to 3D Gaussian Splatting (3DGS), which has recently been shown to produce realistic free-viewpoint avatars. Given a multiview sequence, we extract a FLAME mesh, solve a curvature-weighted Poisson equation, and obtain its exaggerated form. However, directly deforming the Gaussians yields poor results, necessitating the synthesis of pseudo-ground-truth caricature images by warping each frame to its exaggerated 2D representation using local affine transformations. We then devise a training scheme that alternates real and synthesized supervision, enabling a single Gaussian collection to represent both natural and exaggerated avatars. This scheme improves fidelity, supports local edits, and allows continuous control over the intensity of the caricature. In order to achieve real-time deformations, an efficient interpolation between the original and exaggerated surfaces is introduced. We further analyze and show that it has a bounded deviation from closed-form solutions. In both quantitative and qualitative evaluations, our results outperform prior work, delivering photorealistic, geometry-controlled caricature avatars.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [MHRC-Bench: A Multilingual Hardware Repository-Level Code Completion benchmark](https://arxiv.org/abs/2601.03708)
*Qingyun Zou,Jiahao Cui,Nuo Chen,Bingsheng He,Weng-Fai Wong*

Main category: cs.PL

TL;DR: MHRC-Bench是首个针对多语言硬件代码在仓库级别补全任务的基准，包括训练集MHRC-Bench-Train和评估集MHRC-Bench-Eval，填补了现有基准在硬件描述语言上的空白。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在通用编程语言的代码补全任务中表现优异，但现有仓库级代码补全基准主要关注软件代码，忽视了硬件描述语言。因此，研究团队提出了MHRC-Bench，作为首个专注于硬件代码补全的基准。

Method: MHRC-Bench包括训练集MHRC-Bench-Train和评估集MHRC-Bench-Eval，覆盖三种主要硬件设计编码风格。每个补全目标通过具体语法树分析获得代码结构级和硬件导向的语义标签。

Result: 在MHRC-Bench-Eval上的全面评估表明，MHRC-Bench在硬件代码补全任务中表现出色，验证了其有效性。

Conclusion: MHRC-Bench填补了硬件描述语言在仓库级代码补全基准中的空白，并通过评估验证了其作为硬件代码补全基准的有效性。

Abstract: Large language models (LLMs) have achieved strong performance on code completion tasks in general-purpose programming languages. However, existing repository-level code completion benchmarks focus almost exclusively on software code and largely overlook hardware description languages. In this work, we present \textbf{MHRC-Bench}, consisting of \textbf{MHRC-Bench-Train} and \textbf{MHRC-Bench-Eval}, the first benchmark designed for multilingual hardware code completion at the repository level. Our benchmark targets completion tasks and covers three major hardware design coding styles. Each completion target is annotated with code-structure-level and hardware-oriented semantic labels derived from concrete syntax tree analysis. We conduct a comprehensive evaluation of models on MHRC-Bench-Eval. Comprehensive evaluation results and analysis demonstrate the effectiveness of MHRC-Bench.

</details>


### [3] [Agentic Proof Automation: A Case Study](https://arxiv.org/abs/2601.03768)
*Yichen Xu,Martin Odersky*

Main category: cs.PL

TL;DR: 本文提出了一种基于大型语言模型（LLM）的代理式证明自动化方案，通过代理完成大部分证明工程工作，人类仅需提供数学洞察。研究以系统Capless的语义类型安全性为例，展示了代理的高效性和局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的证明工程劳动强度大，而大型语言模型（LLM）的发展为证明自动化提供了新的可能性。本文旨在探索如何利用LLM代理在人类指导下完成证明工程，以提高效率。

Method: 通过一个案例研究，使用现成的LLM代理和轻量级的证明检查工具，在Lean 4中机械化系统Capless的语义类型安全性。人类提供定义、定理和证明策略，代理负责具体的证明开发工作。

Result: 代理完成了189个证明工程任务，成功率为87%，仅16%的任务需要人类干预。研究表明，代理能够显著提高生产力，但在创造性推理方面仍存在不足。

Conclusion: 代理式证明自动化能够有效提升证明工程的效率，但仍需人类在创造性任务中提供指导。研究为未来的自动化证明工作提供了实践基础和开源资源。

Abstract: Proof engineering is notoriously labor-intensive: proofs that are straightforward on paper often require lengthy scripts in theorem provers. Recent advances in large language models (LLMs) create new opportunities for proof automation: modern LLMs not only generate proof scripts, but also support agentic behavior, exploring codebases and iteratively refining their outputs against prover feedback. These advances enable an emerging scheme where LLM-based agents undertake most proof engineering under human guidance. Humans provide mathematical insight (definitions, theorems, proof strategies); agents handle the mechanical work of proof development. We call this scheme agentic proof automation. We present this scheme through a case study: mechanizing the semantic type soundness of a sophisticated formal system, System Capless, in Lean 4, comprising over 14,000 lines of code. Using off-the-shelf LLM agents with a single lightweight proof-checking tool, the agents completed 189 proof engineering tasks with an 87% success rate, only 16% requiring human intervention. The case study demonstrates that agents are capable proof engineers that substantially boost productivity, though they fall short in creative reasoning and still require human guidance in certain cases. We release an interactive explorer where readers can examine all agent interactions; the mechanization is open-sourced for experiments and extensions.

</details>


### [4] [Logic Programming with Extensible Types](https://arxiv.org/abs/2601.03836)
*Ivan Perez,Angel Herranz*

Main category: cs.PL

TL;DR: 本文提出了一种新颖的方法，在类型化函数式编程语言中融入逻辑编程，结合宿主语言的类型系统，实现了逻辑变量的动态扩展和统一化算法，并通过领域特定语言展示其实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管逻辑编程语言在声明性和简洁性方面具有明显优势，但其理念在其他编程社区中被抵制，未被其他范式和语言广泛采纳。因此，本文旨在探索如何在不牺牲静态类型的情况下，将逻辑编程融入现有代码库。

Method: 本文通过三种技术实现逻辑编程的融合：1) 使用可扩展类型技术使宿主语言的值包含逻辑变量；2) 实现适用于支持特定操作的数据结构的统一化算法；3) 引入领域特定语言以定义和查询谓词。

Result: 通过在Haskell语言中的实现，证明了该方法的可行性和实用性，并通过一系列示例展示了其成功应用。

Conclusion: 本文的方法不仅技术上可行，且在实际应用中表现良好，为逻辑编程在其他编程范式中的集成提供了新的思路。

Abstract: Logic programming languages present clear advantages in terms of declarativeness and conciseness. However, the ideas of logic programming have been met with resistance in other programming communities, and have not generally been adopted by other paradigms and languages. This paper proposes a novel way to incorporate logic programming in an existing codebase in a typed functional programming language. Our approach integrates with the host language without sacrificing static typing, and leverages strengths of typed functional programming such as polymorphism and higher-order. We do so by combining three ideas. First, we use the extensible types technique to allow values of the host language to contain logic variables. Second, we implement a unification algorithm that works for any data structure that supports certain operations.Third, we introduce a domain-specific language to define and query predicates. We demonstrate our proposal via a series of examples, and provide aids to make the notation convenient for users, showing that the proposed approach is not just technically possible but also practical. Our ideas have been implemented in the language Haskell with very good results.

</details>


### [5] [Inductive First-Order Formula Synthesis by ASP: A Case Study in Invariant Inference](https://arxiv.org/abs/2601.03854)
*Ziyi Yang,George Pîrlea,Ilya Sergey*

Main category: cs.PL

TL;DR: 本文提出了一个从示例中合成一阶逻辑（FOL）公式的框架，统一并改进了现有推理过渡系统不变量的最先进方法。


<details>
  <summary>Details</summary>
Motivation: 通过研究和分类现有方法及其基于答案集编程（ASP）的公式合成技术，提出了一种新的公式枚举技术——正交切片。

Method: 提出了正交切片技术，将搜索空间划分为可管理的块，实现了两种增量候选剪枝方法。结合现有的一阶不变式合成技术，在框架FORCE中实现了这一技术。

Result: 显著加速了分布式系统不变量推理的最先进算法，并展示了该方法促进了不同不变量推理框架的组合，实现了新的优化。

Conclusion: 该方法不仅加速了算法性能，还促进了框架间的组合优化，为一阶逻辑公式合成提供了更高效的解决方案。

Abstract: We present a framework for synthesising formulas in first-order logic (FOL) from examples, which unifies and advances state-of-the-art approaches for inference of transition system invariants. To do so, we study and categorise the existing methodologies, encoding techniques in their formula synthesis via answer set programming (ASP). Based on the derived categorisation, we propose orthogonal slices, a new technique for formula enumeration that partitions the search space into manageable chunks, enabling two approaches for incremental candidate pruning. Using a combination of existing techniques for first-order (FO) invariant synthesis and the orthogonal slices implemented in our framework FORCE, we significantly accelerate a state-of-the-art algorithm for distributed system invariant inference. We also show that our approach facilitates composition of different invariant inference frameworks, allowing for novel optimisations.

</details>


### [6] [Implementing Binary Search Trees in GP 2 (Extended Abstract)](https://arxiv.org/abs/2601.03897)
*Ziad Ismaili Alaoui,Detlef Plump*

Main category: cs.PL

TL;DR: 本文提出了在基于规则的图形编程语言GP 2中实现二叉搜索树的方法，支持插入、删除和查询操作，并分析了其时间复杂性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何在非传统的规则型图形编程语言GP 2中高效实现二叉搜索树，以匹配传统命令式语言中的时间复杂性。

Method: 利用GP 2的根图转换规则来实现二叉搜索树的操作（插入、删除、查询），并确保算法的高效性。

Result: 每个操作的最坏情况下时间复杂性为O(n)，平均情况下为O(log(n))，与传统命令式语言中的实现相当。

Conclusion: 该研究表明，在GP 2中可以实现高效且时间复杂性匹配传统语言的二叉搜索树操作。

Abstract: We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.

</details>


### [7] [CSSG: Measuring Code Similarity with Semantic Graphs](https://arxiv.org/abs/2601.04085)
*Jingwen Xu,Yiyang Lu,Changze Lv,Zisu Huang,Zhengkang Guo,Zhengyuan Wang,Muzhao Tian,Xuanjing Huang,Xiaoqing Zheng*

Main category: cs.PL

TL;DR: CSSG是一种利用程序依赖图显式建模控制依赖和变量交互的新型代码相似性度量方法，相比传统方法，它能更好地捕捉代码间的深层语义关系。


<details>
  <summary>Details</summary>
Motivation: 现有代码相似性度量（如BLEU、CodeBLEU和TSED）主要依赖表面字符串重叠或抽象语法树结构，往往无法捕捉程序间的深层语义关系。

Method: CSSG通过程序依赖图显式建模控制依赖和变量交互，提供语义感知的代码表示。

Result: 在CodeContests+数据集上的实验表明，CSSG在单语言和跨语言场景下均显著优于现有度量方法。

Conclusion: 依赖感知的图表示提供了一种比表面或基于语法的相似性度量更有效的替代方案。

Abstract: Existing code similarity metrics, such as BLEU, CodeBLEU, and TSED, largely rely on surface-level string overlap or abstract syntax tree structures, and often fail to capture deeper semantic relationships between programs.We propose CSSG (Code Similarity using Semantic Graphs), a novel metric that leverages program dependence graphs to explicitly model control dependencies and variable interactions, providing a semantics-aware representation of code.Experiments on the CodeContests+ dataset show that CSSG consistently outperforms existing metrics in distinguishing more similar code from less similar code under both monolingual and cross-lingual settings, demonstrating that dependency-aware graph representations offer a more effective alternative to surface-level or syntax-based similarity measures.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [8] [Algorithm and Strategy Construction for Sure-Almost-Sure Stochastic Parity Games](https://arxiv.org/abs/2601.03381)
*Laurent Doyen,Shibashis Guha*

Main category: cs.GT

TL;DR: 本文研究了一种结合了确定性和概率性条件的双玩家随机游戏，提出了递归算法来解决获胜策略问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决在最坏情况下结合硬性和软性要求的合成框架中的核心问题，即确定获胜策略的存在性。

Method: 方法基于递归算法，通过对获胜区域的特性描述，深入剖析问题并构建获胜策略。

Result: 结果表明，递归算法能有效构建获胜策略，并为特殊类别的复杂性及内存需求提供了新的界限。

Conclusion: 结论指出该方法不仅提供了对问题的深入理解，还提出了针对特定类别的优化方案。

Abstract: We consider turn-based stochastic two-player games with a combination of a parity condition that must hold surely, that is in all possible outcomes, and of a parity condition that must hold almost-surely, that is with probability 1. The problem of deciding the existence of a winning strategy in such games is central in the framework of synthesis beyond worst-case where a hard requirement that must hold surely is combined with a softer requirement. Recent works showed that the problem is coNP-complete, and infinite-memory strategies are necessary in general, even in one-player games (i.e., Markov decision processes). However, memoryless strategies are sufficient for the opponent player. Despite these comprehensive results, the known algorithmic solution enumerates all memoryless strategies of the opponent, which is exponential in all cases, and does not construct a winning strategy when one exists.
  We present a recursive algorithm, based on a characterisation of the winning region, that gives a deeper insight into the problem. In particular, we show how to construct a winning strategy to achieve the combination of sure and almost-sure parity, and we derive new complexity and memory bounds for special classes of the problem, defined by fixing the index of either of the two parity conditions.

</details>


### [9] [EFX and PO Allocation Exists for Two Types of Goods](https://arxiv.org/abs/2601.03438)
*Vladimir Davidiuk,Yuriy Dementiev,Artur Ignatiev,Danil Sagunov*

Main category: cs.GT

TL;DR: 研究如何在具有加法估值的代理之间公平且高效地分配不可分割物品，重点关注EFX（任何物品的无嫉妒分配）公平性。


<details>
  <summary>Details</summary>
Motivation: 解决EFX分配是否始终存在的核心问题，并在已有研究的基础上扩展，证明在两种类型物品的情况下，EFX与帕累托最优性可以同时满足。

Method: 提出一种简单高效的算法，证明在两种类型物品且估值均为正的情况下，可以计算满足EFX和帕累托最优性的分配。

Result: 证明了在两种类型物品的情况下，EFX与帕累托最优性的分配始终存在，并且可以在准线性时间内计算。

Conclusion: 研究结果强化了已有工作，展示了EFX与帕累托最优性可以同时实现的简单高效算法。

Abstract: We study the problem of fairly and efficiently allocating indivisible goods among agents with additive valuations. We focus on envy-freeness up to any good (EFX) -- an important fairness notion in fair division of indivisible goods. A central open question in this field is whether EFX allocations always exist for any number of agents. While prior work has established EFX existence for settings with at most three distinct valuations (Prakash HV et al. 2025) and for two types of goods (Gorantla, Marwaha, and Velusamy 2023), the general case remains unresolved.
  In this paper, we extend the existent knowledge by proving that EFX allocations satisfying Pareto optimality (PO) always exist and can be computed in quasiliniear time when there are two types of goods, given that the valuations are positive. This result strengthens the existing work of (Gorantla, Marwaha, and Velusamy 2023), which only guarantees the existence of EFX allocations without ensuring Pareto optimality. Our findings demonstrate a fairly simple and efficient algorithm constructing an EFX+PO allocation.

</details>


### [10] [From No-Regret to Strategically Robust Learning in Repeated Auctions](https://arxiv.org/abs/2601.03853)
*Junyao Zhao*

Main category: cs.GT

TL;DR: 本文证明，在贝叶斯单物品拍卖中，任何无遗憾学习算法在满足分配单调性和自愿参与的条件下，都能实现战略稳健性，而不仅限于敏捷在线梯度下降或第一价格拍卖。


<details>
  <summary>Details</summary>
Motivation: 研究的目标是验证在贝叶斯单物品拍卖中，战略稳健性是否仅限于特定学习算法或拍卖形式。

Method: 通过量化表示和梯度反馈，使用无遗憾学习算法（如MWU）进行分析。

Result: 结果显示，任何无遗憾学习算法都能实现战略稳健性，且MWU同时达到最优遗憾保证和最佳战略稳健性。

Conclusion: 研究发现可以将标准遗憾保证转化为特定博弈的战略稳健性，无需显式最小化交换遗憾。

Abstract: In Bayesian single-item auctions, a monotone bidding strategy--one that prescribes a higher bid for a higher value type--can be equivalently represented as a partition of the quantile space into consecutive intervals corresponding to increasing bids. Kumar et al. (2024) prove that agile online gradient descent (OGD), when used to update a monotone bidding strategy through its quantile representation, is strategically robust in repeated first-price auctions: when all bidders employ agile OGD in this way, the auctioneer's average revenue per round is at most the revenue of Myerson's optimal auction, regardless of how she adjusts the reserve price over time.
  In this work, we show that this strategic robustness guarantee is not unique to agile OGD or to the first-price auction: any no-regret learning algorithm, when fed gradient feedback with respect to the quantile representation, is strategically robust, even if the auction format changes every round, provided the format satisfies allocation monotonicity and voluntary participation. In particular, the multiplicative weights update (MWU) algorithm simultaneously achieves the optimal regret guarantee and the best-known strategic robustness guarantee. At a technical level, our results are established via a simple relation that bridges Myerson's auction theory and standard no-regret learning theory. This showcases the potential of translating standard regret guarantees into strategic robustness guarantees for specific games, without explicitly minimizing any form of swap regret.

</details>
