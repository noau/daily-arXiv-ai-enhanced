{"id": "2508.13228", "categories": ["cs.GR", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.13228", "abs": "https://arxiv.org/abs/2508.13228", "authors": ["Yuyan Ye", "Hang Xu", "Yanghang Huang", "Jiali Huang", "Qian Weng"], "title": "PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism", "comment": "2025 International Joint Conference on Neural Networks (IJCNN 2025)", "summary": "This paper proposes PreSem-Surf, an optimized method based on the Neural\nRadiance Field (NeRF) framework, capable of reconstructing high-quality scene\nsurfaces from RGB-D sequences in a short time. The method integrates RGB,\ndepth, and semantic information to improve reconstruction performance.\nSpecifically, a novel SG-MLP sampling structure combined with PR-MLP\n(Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering,\nallowing the model to capture scene-related information earlier and better\ndistinguish noise from local details. Furthermore, progressive semantic\nmodeling is adopted to extract semantic information at increasing levels of\nprecision, reducing training time while enhancing scene understanding.\nExperiments on seven synthetic scenes with six evaluation metrics show that\nPreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while\nmaintaining competitive results in NC, Accuracy, and Completeness,\ndemonstrating its effectiveness and practical applicability.", "AI": {"tldr": "PreSem-Surf\u662f\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u6846\u67b6\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u4eceRGB-D\u5e8f\u5217\u4e2d\u5feb\u901f\u91cd\u5efa\u9ad8\u8d28\u91cf\u573a\u666f\u8868\u9762\u3002", "motivation": "\u8be5\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u6574\u5408RGB\u3001\u6df1\u5ea6\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u63d0\u5347\u573a\u666f\u91cd\u5efa\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528SG-MLP\u91c7\u6837\u7ed3\u6784\u548cPR-MLP\uff08\u9884\u6761\u4ef6\u591a\u5c42\u611f\u77e5\u5668\uff09\u8fdb\u884c\u4f53\u7d20\u9884\u6e32\u67d3\uff0c\u5e76\u7ed3\u5408\u6e10\u8fdb\u5f0f\u8bed\u4e49\u5efa\u6a21\u63d0\u53d6\u7cbe\u786e\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5728\u4e03\u4e2a\u5408\u6210\u573a\u666f\u548c\u516d\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPreSem-Surf\u5728C-L1\u3001F-score\u548cIoU\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u540c\u65f6\u5728NC\u3001Accuracy\u548cCompleteness\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "PreSem-Surf\u5c55\u793a\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u9002\u7528\u4e8e\u9ad8\u8d28\u91cf\u573a\u666f\u91cd\u5efa\u4efb\u52a1\u3002"}}
{"id": "2508.13386", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.13386", "abs": "https://arxiv.org/abs/2508.13386", "authors": ["Ty Trusty", "David I. W. Levin", "Danny M. Kaufman"], "title": "Sparse, Geometry- and Material-Aware Bases for Multilevel Elastodynamic Simulation", "comment": "15 pages,22 figures", "summary": "We present a multi-level elastodynamics timestep solver for accelerating\nincremental potential contact (IPC) simulations. Our method retains the\nrobustness of gold standard IPC in the face of intricate geometry, complex\nheterogeneous material distributions and high resolution input data without\nsacrificing visual fidelity (per-timestep relative displacement error of\n$\\approx1\\%$). The success of our method is enabled by a novel, sparse,\ngeometry- and material-aware basis construction method which allows for the use\nof fast preconditioned conjugate gradient solvers (in place of a sparse direct\nsolver), but without suffering convergence issues due to stiff or heterogeneous\nmaterials. The end result is a solver that produces results visually\nindistinguishable and quantitatively very close to gold-standard IPC methods\nbut up to $13\\times$ faster on identical hardware.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ea7\u5f39\u6027\u52a8\u529b\u5b66\u65f6\u95f4\u6b65\u6c42\u89e3\u5668\uff0c\u7528\u4e8e\u52a0\u901f\u589e\u91cf\u6f5c\u5728\u63a5\u89e6\uff08IPC\uff09\u6a21\u62df\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u89c6\u89c9\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u4fdd\u7559\u4e86IPC\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u901f\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u5728\u590d\u6742\u51e0\u4f55\u5f62\u72b6\u3001\u590d\u6742\u975e\u5747\u8d28\u6750\u6599\u5206\u5e03\u548c\u9ad8\u5206\u8fa8\u7387\u8f93\u5165\u6570\u636e\u7684\u573a\u666f\u4e0b\uff0c\u4fdd\u6301IPC\u6a21\u62df\u7684\u9c81\u68d2\u6027\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7a00\u758f\u3001\u51e0\u4f55\u548c\u6750\u6599\u611f\u77e5\u7684\u57fa\u6784\u5efa\u65b9\u6cd5\uff0c\u7ed3\u5408\u5feb\u901f\u9884\u6761\u4ef6\u5171\u8f6d\u68af\u5ea6\u6c42\u89e3\u5668\u66ff\u4ee3\u7a00\u758f\u76f4\u63a5\u6c42\u89e3\u5668\uff0c\u907f\u514d\u4e86\u6536\u655b\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u548c\u6570\u503c\u4e0a\u4e0eIPC\u9ec4\u91d1\u6807\u51c6\u65b9\u6cd5\u51e0\u4e4e\u65e0\u5dee\u522b\uff0c\u4f46\u5728\u76f8\u540c\u786c\u4ef6\u4e0a\u53ef\u63d0\u5347\u8ba1\u7b97\u901f\u5ea6\u9ad8\u8fbe13\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u7ea7\u5f39\u6027\u52a8\u529b\u5b66\u65f6\u95f4\u6b65\u6c42\u89e3\u5668\u5728\u4fdd\u6301IPC\u6a21\u62df\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2508.13738", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2508.13738", "abs": "https://arxiv.org/abs/2508.13738", "authors": ["Shidong Wang", "Renato Pajarola"], "title": "Eliminating Rasterization: Direct Vector Floor Plan Generation with DiffPlanner", "comment": "accepted to IEEE Transactions on Visualization and Computer Graphics", "summary": "The boundary-constrained floor plan generation problem aims to generate the\ntopological and geometric properties of a set of rooms within a given boundary.\nRecently, learning-based methods have made significant progress in generating\nrealistic floor plans. However, these methods involve a workflow of converting\nvector data into raster images, using image-based generative models, and then\nconverting the results back into vector data. This process is complex and\nredundant, often resulting in information loss. Raster images, unlike vector\ndata, cannot scale without losing detail and precision. To address these\nissues, we propose a novel deep learning framework called DiffPlanner for\nboundary-constrained floor plan generation, which operates entirely in vector\nspace. Our framework is a Transformer-based conditional diffusion model that\nintegrates an alignment mechanism in training, aligning the optimization\ntrajectory of the model with the iterative design processes of designers. This\nenables our model to handle complex vector data, better fit the distribution of\nthe predicted targets, accomplish the challenging task of floor plan layout\ndesign, and achieve user-controllable generation. We conduct quantitative\ncomparisons, qualitative evaluations, ablation experiments, and perceptual\nstudies to evaluate our method. Extensive experiments demonstrate that\nDiffPlanner surpasses existing state-of-the-art methods in generating floor\nplans and bubble diagrams in the creative stages, offering more controllability\nto users and producing higher-quality results that closely match the ground\ntruths.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiffPlanner\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u76f4\u63a5\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u5904\u7406\u8fb9\u754c\u7ea6\u675f\u7684\u5e73\u9762\u56fe\u751f\u6210\u95ee\u9898\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u53ef\u63a7\u6027\u548c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u5e73\u9762\u56fe\u751f\u6210\u65b9\u6cd5\u9700\u8981\u901a\u8fc7\u590d\u6742\u7684\u6d41\u7a0b\u5c06\u77e2\u91cf\u6570\u636e\u8f6c\u6362\u4e3a\u6805\u683c\u56fe\u50cf\uff0c\u518d\u8f6c\u6362\u56de\u77e2\u91cf\u6570\u636e\uff0c\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u548c\u5197\u4f59\u3002DiffPlanner\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u76f4\u63a5\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u548c\u7528\u6237\u53ef\u63a7\u6027\u3002", "method": "DiffPlanner\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u8bad\u7ec3\u4e2d\u7684\u5bf9\u9f50\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u77e2\u91cf\u6570\u636e\uff0c\u5e76\u66f4\u597d\u5730\u62df\u5408\u9884\u6d4b\u76ee\u6807\u7684\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDiffPlanner\u5728\u751f\u6210\u5e73\u9762\u56fe\u548c\u6c14\u6ce1\u56fe\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u53ef\u63a7\u6027\u548c\u66f4\u63a5\u8fd1\u771f\u5b9e\u7ed3\u679c\u7684\u8d28\u91cf\u3002", "conclusion": "DiffPlanner\u901a\u8fc7\u5728\u5411\u91cf\u7a7a\u95f4\u4e2d\u76f4\u63a5\u64cd\u4f5c\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e73\u9762\u56fe\u751f\u6210\u7684\u8d28\u91cf\u548c\u7528\u6237\u53ef\u63a7\u6027\u3002"}}
{"id": "2508.13797", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.13797", "abs": "https://arxiv.org/abs/2508.13797", "authors": ["Feng-Lin Liu", "Shi-Yang Li", "Yan-Pei Cao", "Hongbo Fu", "Lin Gao"], "title": "Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing", "comment": "SIGGRAPH 2025", "summary": "Recent video editing methods achieve attractive results in style transfer or\nappearance modification. However, editing the structural content of 3D scenes\nin videos remains challenging, particularly when dealing with significant\nviewpoint changes, such as large camera rotations or zooms. Key challenges\ninclude generating novel view content that remains consistent with the original\nvideo, preserving unedited regions, and translating sparse 2D inputs into\nrealistic 3D video outputs. To address these issues, we propose Sketch3DVE, a\nsketch-based 3D-aware video editing method to enable detailed local\nmanipulation of videos with significant viewpoint changes. To solve the\nchallenge posed by sparse inputs, we employ image editing methods to generate\nedited results for the first frame, which are then propagated to the remaining\nframes of the video. We utilize sketching as an interaction tool for precise\ngeometry control, while other mask-based image editing methods are also\nsupported. To handle viewpoint changes, we perform a detailed analysis and\nmanipulation of the 3D information in the video. Specifically, we utilize a\ndense stereo method to estimate a point cloud and the camera parameters of the\ninput video. We then propose a point cloud editing approach that uses depth\nmaps to represent the 3D geometry of newly edited components, aligning them\neffectively with the original 3D scene. To seamlessly merge the newly edited\ncontent with the original video while preserving the features of unedited\nregions, we introduce a 3D-aware mask propagation strategy and employ a video\ndiffusion model to produce realistic edited videos. Extensive experiments\ndemonstrate the superiority of Sketch3DVE in video editing. Homepage and code:\nhttp://http://geometrylearning.com/Sketch3DVE/", "AI": {"tldr": "Sketch3DVE\u662f\u4e00\u79cd\u57fa\u4e8e\u8349\u56fe\u76843D\u611f\u77e5\u89c6\u9891\u7f16\u8f91\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u89c6\u89d2\u53d8\u5316\u663e\u8457\u7684\u89c6\u9891\uff0c\u901a\u8fc7\u70b9\u4e91\u7f16\u8f91\u548c\u6df1\u5ea6\u56fe\u6280\u672f\u5b9e\u73b0\u5c40\u90e8\u8be6\u7ec6\u64cd\u4f5c\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u7f16\u8f91\u65b9\u6cd5\u5728\u98ce\u683c\u8f6c\u79fb\u6216\u5916\u89c2\u4fee\u6539\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u74063D\u573a\u666f\u7ed3\u6784\u5185\u5bb9\u7f16\u8f91\u65f6\uff0c\u5c24\u5176\u662f\u9762\u5bf9\u5927\u5e45\u89c6\u89d2\u53d8\u5316\u65f6\uff0c\u4ecd\u5b58\u5728\u6311\u6218\u3002", "method": "\u5229\u7528\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u751f\u6210\u9996\u5e27\u7f16\u8f91\u7ed3\u679c\uff0c\u5e76\u901a\u8fc73D\u70b9\u4e91\u548c\u6df1\u5ea6\u56fe\u6280\u672f\u5b9e\u73b0\u51e0\u4f55\u63a7\u5236\uff0c\u7ed3\u54083D\u611f\u77e5\u63a9\u7801\u4f20\u64ad\u7b56\u7565\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u751f\u6210\u903c\u771f\u7684\u7f16\u8f91\u89c6\u9891\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSketch3DVE\u5728\u89c6\u9891\u7f16\u8f91\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u89c6\u89d2\u53d8\u5316\u5e76\u4fdd\u6301\u672a\u7f16\u8f91\u533a\u57df\u7684\u5b8c\u6574\u6027\u3002", "conclusion": "Sketch3DVE\u901a\u8fc7\u7ed3\u54083D\u6280\u672f\u548c\u7528\u6237\u53cb\u597d\u7684\u8349\u56fe\u4ea4\u4e92\uff0c\u4e3a\u5927\u5e45\u89c6\u89d2\u53d8\u5316\u7684\u89c6\u9891\u7f16\u8f91\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u903c\u771f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.13432", "categories": ["cs.GT", "cs.DM", "F.2.2; G.2.1"], "pdf": "https://arxiv.org/pdf/2508.13432", "abs": "https://arxiv.org/abs/2508.13432", "authors": ["Paul G\u00f6lz", "Hannane Yaghoubizade"], "title": "Fair Division Among Couples and Small Groups", "comment": null, "summary": "We study the fair allocation of indivisible goods across groups of agents,\nwhere each agent fully enjoys all goods allocated to their group. We focus on\ngroups of two (couples) and other groups of small size. For two couples, an EF1\nallocation -- one in which all agents find their group's bundle no worse than\nthe other group's, up to one good -- always exists and can be found\nefficiently. For three or more couples, EF1 allocations need not exist.\n  Turning to proportionality, we show that, whenever groups have size at most\n$k$, a PROP$k$ allocation exists and can be found efficiently. In fact, our\nalgorithm additionally guarantees (fractional) Pareto optimality, and PROP1 to\nthe first agent in each group, PROP2 to the second, etc., for an arbitrary\nagent ordering. In special cases, we show that there are PROP1 allocations for\nany number of couples.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5728\u5c0f\u7ec4\u95f4\u516c\u5e73\u5206\u914d\u7684\u95ee\u9898\uff0c\u91cd\u70b9\u662f\u5c0f\u7ec4\u6210\u5458\uff08\u5982\u4e24\u4eba\u5c0f\u7ec4\uff09\u3002\u5bf9\u4e8e\u4e24\u4eba\u5c0f\u7ec4\uff0cEF1\u5206\u914d\u603b\u662f\u5b58\u5728\u5e76\u53ef\u9ad8\u6548\u627e\u5230\uff1b\u5bf9\u4e8e\u4e09\u4eba\u53ca\u4ee5\u4e0a\u5c0f\u7ec4\uff0cEF1\u5206\u914d\u4e0d\u4e00\u5b9a\u5b58\u5728\u3002\u540c\u65f6\uff0c\u8bc1\u660e\u4e86PROPk\u5206\u914d\u5728\u5c0f\u7ec4\u6210\u5458\u4e0d\u8d85\u8fc7k\u65f6\u603b\u662f\u5b58\u5728\u5e76\u53ef\u9ad8\u6548\u5b9e\u73b0\u3002", "motivation": "\u63a2\u8ba8\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5728\u5c0f\u7ec4\u6210\u5458\u95f4\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5c0f\u7ec4\u89c4\u6a21\u8f83\u5c0f\u7684\u60c5\u51b5\uff0c\u4ee5\u89e3\u51b3\u5b9e\u9645\u751f\u6d3b\u4e2d\u7684\u5408\u4f5c\u4e0e\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e24\u4eba\u5c0f\u7ec4\uff08\u5982\u592b\u59bb\uff09\u53ca\u7a0d\u5927\u7ec4\uff08\u5982\u4e09\u4eba\u5c0f\u7ec4\uff09\u7684\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51faEF1\u548cPROPk\u7684\u6982\u5ff5\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u5b9e\u73b0\u8fd9\u4e9b\u5206\u914d\u65b9\u5f0f\u3002", "result": "\u5bf9\u4e8e\u4e24\u4eba\u5c0f\u7ec4\uff0c\u8bc1\u660eEF1\u5206\u914d\u603b\u662f\u5b58\u5728\u4e14\u53ef\u9ad8\u6548\u627e\u5230\uff1b\u5bf9\u4e8e\u4e09\u4eba\u53ca\u4ee5\u4e0a\u5c0f\u7ec4\uff0cEF1\u5206\u914d\u53ef\u80fd\u4e0d\u5b58\u5728\u3002\u540c\u65f6\uff0c\u8bc1\u660ePROPk\u5206\u914d\u5728\u5c0f\u7ec4\u6210\u5458\u4e0d\u8d85\u8fc7k\u65f6\u603b\u662f\u5b58\u5728\u5e76\u53ef\u9ad8\u6548\u5b9e\u73b0\uff0c\u4e14\u7b97\u6cd5\u5177\u6709Pareto\u6700\u4f18\u6027\u3002", "conclusion": "\u5728\u5c0f\u7ec4\u6210\u5458\u8f83\u5c11\u7684\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u5206\u914d\u4e2d\uff0cEF1\u548cPROPk\u5206\u914d\u662f\u53ef\u884c\u7684\u516c\u5e73\u65b9\u6848\uff0c\u4f46\u968f\u5c0f\u7ec4\u89c4\u6a21\u589e\u5927\uff0cEF1\u5206\u914d\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u800cPROPk\u5206\u914d\u4ecd\u9002\u7528\u3002"}}
{"id": "2508.13610", "categories": ["cs.PL", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.13610", "abs": "https://arxiv.org/abs/2508.13610", "authors": ["Basile Pesin", "Celia Picard", "Cyril Allignol"], "title": "Reactive Semantics for User Interface Description Languages", "comment": "In Proceedings ICE 2025, arXiv:2508.12308", "summary": "User Interface Description Languages (UIDLs) are high-level languages that\nfacilitate the development of Human-Machine Interfaces, such as Graphical User\nInterface (GUI) applications. They usually provide first-class primitives to\nspecify how the program reacts to an external event (user input, network\nmessage), and how data flows through the program. Although these\ndomain-specific languages are now widely used to implement safety-critical\nGUIs, little work has been invested in their formalization and verification.\n  In this paper, we propose a denotational semantic model for a core reactive\nUIDL, Smalite, which we argue is expressive enough to encode constructs from\nmore realistic languages. This preliminary work may be used as a stepping stone\nto produce a formally verified compiler for UIDLs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSmalite\u7684\u6838\u5fc3\u53cd\u5e94\u5f0f\u7528\u6237\u754c\u9762\u63cf\u8ff0\u8bed\u8a00\uff08UIDL\uff09\u7684\u6307\u79f0\u8bed\u4e49\u6a21\u578b\uff0c\u65e8\u5728\u4e3aUIDL\u7684\u5f62\u5f0f\u5316\u4e0e\u9a8c\u8bc1\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u5e7f\u6cdb\u7528\u4e8e\u5b89\u5168\u5173\u952e\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u5f00\u53d1\u7684UIDL\u7f3a\u4e4f\u5f62\u5f0f\u5316\u548c\u9a8c\u8bc1\u65b9\u9762\u7684\u7814\u7a76\uff0c\u8fd9\u6210\u4e3a\u7814\u7a76\u7684\u52a8\u673a\u3002", "method": "\u901a\u8fc7\u6784\u5efaSmalite\u7684\u6307\u79f0\u8bed\u4e49\u6a21\u578b\uff0c\u7814\u7a76\u5176\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u7f16\u7801\u66f4\u590d\u6742\u8bed\u8a00\u7ed3\u6784\u65b9\u9762\u7684\u6f5c\u529b\u3002", "result": "\u63d0\u51fa\u7684Smalite\u6a21\u578b\u5177\u5907\u8db3\u591f\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u591f\u7f16\u7801\u66f4\u590d\u6742\u8bed\u8a00\u7684\u7ed3\u6784\uff0c\u4e3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7f16\u8bd1\u5668\u5f00\u53d1\u63d0\u4f9b\u53ef\u80fd\u3002", "conclusion": "Smalite\u7684\u6307\u79f0\u8bed\u4e49\u6a21\u578b\u4e3aUIDL\u7684\u5f62\u5f0f\u5316\u4e0e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u521d\u6b65\u57fa\u7840\uff0c\u672a\u6765\u6709\u671b\u63a8\u52a8\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7f16\u8bd1\u5668\u7684\u5f00\u53d1\u3002"}}
{"id": "2508.13808", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.13808", "abs": "https://arxiv.org/abs/2508.13808", "authors": ["Nan Luo", "Chenglin Ye", "Jiaxu Li", "Gang Liu", "Bo Wan", "Di Wang", "Lupeng Liu", "Jun Xiao"], "title": "Is-NeRF: In-scattering Neural Radiance Field for Blurred Images", "comment": null, "summary": "Neural Radiance Fields (NeRF) has gained significant attention for its\nprominent implicit 3D representation and realistic novel view synthesis\ncapabilities. Available works unexceptionally employ straight-line volume\nrendering, which struggles to handle sophisticated lightpath scenarios and\nintroduces geometric ambiguities during training, particularly evident when\nprocessing motion-blurred images. To address these challenges, this work\nproposes a novel deblur neural radiance field, Is-NeRF, featuring explicit\nlightpath modeling in real-world environments. By unifying six common light\npropagation phenomena through an in-scattering representation, we establish a\nnew scattering-aware volume rendering pipeline adaptable to complex lightpaths.\nAdditionally, we introduce an adaptive learning strategy that enables\nautonomous determining of scattering directions and sampling intervals to\ncapture finer object details. The proposed network jointly optimizes NeRF\nparameters, scattering parameters, and camera motions to recover fine-grained\nscene representations from blurry images. Comprehensive evaluations demonstrate\nthat it effectively handles complex real-world scenarios, outperforming\nstate-of-the-art approaches in generating high-fidelity images with accurate\ngeometric details.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53bb\u6a21\u7cca\u795e\u7ecf\u8f90\u5c04\u573a\uff08Is-NeRF\uff09\uff0c\u901a\u8fc7\u663e\u5f0f\u7684\u5149\u8def\u5efa\u6a21\u548c\u6563\u5c04\u611f\u77e5\u7684\u4f53\u79ef\u6e32\u67d3\u7ba1\u7ebf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u5728\u5904\u7406\u590d\u6742\u5149\u8def\u548c\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfNeRF\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u5149\u8def\u548c\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u65f6\u5b58\u5728\u51e0\u4f55\u6a21\u7cca\u548c\u8bad\u7ec3\u6311\u6218\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u7cbe\u7ec6\u5149\u4f20\u64ad\u73b0\u8c61\u3002", "method": "\u63d0\u51faIs-NeRF\uff0c\u901a\u8fc7\u663e\u5f0f\u5149\u8def\u5efa\u6a21\u548c\u6563\u5c04\u611f\u77e5\u7684\u4f53\u79ef\u6e32\u67d3\u7ba1\u7ebf\uff0c\u7edf\u4e00\u516d\u79cd\u5e38\u89c1\u5149\u4f20\u64ad\u73b0\u8c61\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u6563\u5c04\u65b9\u5411\u548c\u91c7\u6837\u95f4\u9694\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIs-NeRF\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u56fe\u50cf\u5e76\u6062\u590d\u7cbe\u786e\u51e0\u4f55\u7ec6\u8282\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Is-NeRF\u901a\u8fc7\u5149\u8def\u5efa\u6a21\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86NeRF\u5728\u5904\u7406\u590d\u6742\u5149\u8def\u548c\u53bb\u6a21\u7cca\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2508.13473", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.13473", "abs": "https://arxiv.org/abs/2508.13473", "authors": ["Atefeh Mollabagher", "Parinaz Naghizadeh"], "title": "Reactive Users vs. Recommendation Systems: An Adaptive Policy to Manage Opinion Drifts", "comment": null, "summary": "Recommendation systems are used in a range of platforms to maximize user\nengagement through personalization and the promotion of popular content. It has\nbeen found that such recommendations may shape users' opinions over time. In\nthis paper, we ask whether reactive users, who are cognizant of the influence\nof the content they consume, can prevent such changes by adaptively adjusting\ntheir content consumption choices. To this end, we study users' opinion\ndynamics under two types of stochastic policies: a passive policy where the\nprobability of clicking on recommended content is fixed and a reactive policy\nwhere clicking probability adaptively decreases following large opinion drifts.\nWe analytically derive the expected opinion and user utility under these\npolicies. We show that the adaptive policy can help users prevent opinion\ndrifts and that when a user prioritizes opinion preservation, the expected\nutility of the adaptive policy outperforms the fixed policy. We validate our\ntheoretical findings through numerical simulations. These findings help better\nunderstand how user-level strategies can challenge the biases induced by\nrecommendation systems.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u53cd\u5e94\u7b56\u7565\u5982\u4f55\u9632\u6b62\u610f\u89c1\u6f02\u79fb\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u81ea\u9002\u5e94\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u901a\u8fc7\u4e2a\u6027\u5316\u5185\u5bb9\u63a8\u5e7f\u53ef\u80fd\u4f1a\u5f71\u54cd\u7528\u6237\u7684\u610f\u89c1\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u7528\u6237\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u5185\u5bb9\u6d88\u8d39\u7b56\u7565\u6765\u9632\u6b62\u8fd9\u79cd\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e24\u79cd\u968f\u673a\u7b56\u7565\uff1a\u56fa\u5b9a\u70b9\u51fb\u6982\u7387\u7684\u88ab\u52a8\u7b56\u7565\u548c\u6839\u636e\u610f\u89c1\u6f02\u79fb\u8c03\u6574\u70b9\u51fb\u6982\u7387\u7684\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u81ea\u9002\u5e94\u7b56\u7565\u80fd\u5e2e\u52a9\u7528\u6237\u9632\u6b62\u610f\u89c1\u6f02\u79fb\uff0c\u4e14\u5728\u7528\u6237\u4f18\u5148\u8003\u8651\u610f\u89c1\u4fdd\u6301\u65f6\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u56fa\u5b9a\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u7528\u6237\u5c42\u9762\u7684\u7b56\u7565\u53ef\u4ee5\u6311\u6218\u63a8\u8350\u7cfb\u7edf\u5f15\u53d1\u7684\u504f\u89c1\uff0c\u4e3a\u7406\u89e3\u7528\u6237\u5982\u4f55\u5e94\u5bf9\u63a8\u8350\u7cfb\u7edf\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.13611", "categories": ["cs.PL", "cs.LO", "D.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2508.13611", "abs": "https://arxiv.org/abs/2508.13611", "authors": ["Clemens Grabmayer", "Maurizio Murgia"], "title": "Bisimilarity and Simulatability of Processes Parameterized by Join Interactions", "comment": "In Proceedings ICE 2025, arXiv:2508.12308", "summary": "Departing from Larsen's concept of parameterized bisimilarity of processes\nwith respect to interaction with environments, we start an exploration of its\nnatural weakening: bisimilarity of unrestricted join interactions with\nenvironments. Parameterized bisimilarity relates processes p and q with respect\nto an environment e if p and q behave bi-similarly while joining --\nrespectively the same -- transitions from e. The weakened variant relates\nprocesses p and q with respect to environment e if the join-interaction\nprocesses p & e and q & e of p and q with e are bisimilar. (Hereby join\ninteractions r & f facilitate a step with label a to r' & f' if and only if r\nand f permit a-steps to r' and f' , respectively.) Join-interaction\nparameterized (ji-parameterized) bisimilarity coincides with parameterized\nbisimilarity for deterministic environments, but that it is a coarser\nequivalence in general. We explain how Larsen's concept can be recovered from\nji-parameterized bisimilarity by 'determinizing' interactions. We show that by\nadaptation to simulatability (simulation preorder) the same concept arises:\nparameterized simulatability coincides with ji-parameterized simulatability.\nFor the discrimination preorder of (ji-)parameterized simulatability on\nenvironments we obtain the same result as Larsen did for parameterized\nbisimilarity. Also, we give a modal-logic characterization of\n(ji-)parameterized simulatability. Finally we gather open problems, and provide\nan outlook on our current related work.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u53c2\u6570\u5316\u4e92\u6a21\u62df\u7684\u81ea\u7136\u5f31\u5316\u7248\u672c\uff0c\u5373\u65e0\u9650\u5236\u8fde\u63a5\u4ea4\u4e92\u4e92\u6a21\u62df\uff0c\u5c55\u793a\u4e86\u5176\u5728\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u4e0e\u53c2\u6570\u5316\u4e92\u6a21\u62df\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u66f4\u5e7f\u6cdb\u60c5\u51b5\u4e0b\u7684\u9002\u7528\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u5bf9Larsen\u7684\u53c2\u6570\u5316\u4e92\u6a21\u62df\u6982\u5ff5\u7684\u62d3\u5c55\uff0c\u63a2\u8ba8\u5176\u5728\u66f4\u5e7f\u6cdb\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5f15\u5165\u65e0\u9650\u5236\u8fde\u63a5\u4ea4\u4e92\u6765\u5f31\u5316\u539f\u6709\u5b9a\u4e49\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5b9a\u4e49\u5e76\u6bd4\u8f83\u53c2\u6570\u5316\u4e92\u6a21\u62df\u53ca\u5176\u5f31\u5316\u7248\u672c\uff08ji-\u53c2\u6570\u5316\u4e92\u6a21\u62df\uff09\uff0c\u5e76\u901a\u8fc7\u786e\u5b9a\u6027\u5316\u4ea4\u4e92\u6062\u590d\u539f\u6709\u6982\u5ff5\uff1b\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u9002\u5e94\u6027\u6a21\u62df\u7684\u524d\u5e8f\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u663e\u793aji-\u53c2\u6570\u5316\u4e92\u6a21\u62df\u5728\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u4e0e\u53c2\u6570\u5316\u4e92\u6a21\u62df\u7b49\u4ef7\uff0c\u4f46\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u662f\u4e00\u4e2a\u66f4\u7c97\u7cd9\u7684\u7b49\u4ef7\u5173\u7cfb\uff1b\u540c\u65f6\u8bc1\u660e\u4e86\u53c2\u6570\u5316\u6a21\u62df\u4e0eji-\u53c2\u6570\u5316\u6a21\u62df\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u5316\u4ea4\u4e92\u53ef\u4ee5\u6062\u590dLarsen\u7684\u6982\u5ff5\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u6a21\u6001\u903b\u8f91\u5bf9(ji-)\u53c2\u6570\u5316\u6a21\u62df\u7684\u8868\u5f81\u3002"}}
{"id": "2508.13841", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.13841", "abs": "https://arxiv.org/abs/2508.13841", "authors": ["Colin Cleveland", "Bart de Keijzer", "Maria Polukarov"], "title": "Optimal Candidate Positioning in Multi-Issue Elections", "comment": "18 pages, 3 figures, Ecai 25", "summary": "We study strategic candidate positioning in multidimensional spatial-voting\nelections. Voters and candidates are represented as points in $\\mathbb{R}^d$,\nand each voter supports the candidate that is closest under a distance induced\nby an $\\ell_p$-norm. We prove that computing an optimal location for a new\ncandidate is NP-hard already against a single opponent, whereas for a constant\nnumber of issues the problem is tractable: an $O(n^{d+1})$\nhyperplane-enumeration algorithm and an $O(n \\log n)$ radial-sweep routine for\n$d=2$ solve the task exactly. We further derive the first approximation\nguarantees for the general multi-candidate case and show how our geometric\napproach extends seamlessly to positional-scoring rules such as $k$-approval\nand Borda. These results clarify the algorithmic landscape of multidimensional\nspatial elections and provide practically implementable tools for campaign\nstrategy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u7ef4\u7a7a\u95f4\u9009\u4e3e\u4e2d\u5019\u9009\u4eba\u7684\u7b56\u7565\u5b9a\u4f4d\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u5355\u4e00\u5bf9\u624b\u60c5\u51b5\u4e0b\u8ba1\u7b97\u6700\u4f73\u65b0\u5019\u9009\u4eba\u4f4d\u7f6e\u662fNP\u96be\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8e\u56fa\u5b9a\u6570\u91cf\u7684\u8bae\u9898\uff0c\u95ee\u9898\u53ef\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u4f55\u65b9\u6cd5\u548c\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e3a\u4e86\u89e3\u51b3\u591a\u7ef4\u7a7a\u95f4\u9009\u4e3e\u4e2d\u5019\u9009\u4eba\u5982\u4f55\u7b56\u7565\u6027\u5730\u5b9a\u4f4d\u81ea\u5df1\u4ee5\u83b7\u5f97\u6700\u591a\u9009\u6c11\u652f\u6301\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u590d\u6742\u7684\u9009\u6c11\u548c\u5bf9\u624b\u5206\u5e03\u65f6\u3002", "method": "\u8bba\u6587\u4f7f\u7528\u4e86\u57fa\u4e8e$\\(\backslash ell_p\\)-\u8303\u6570\u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u901a\u8fc7\u8d85\u5e73\u9762\u679a\u4e3e\u7b97\u6cd5\u548c\u5f84\u5411\u626b\u63cf\u65b9\u6cd5\uff08\u5bf9\u4e8e\u4e8c\u7ef4\u60c5\u51b5\uff09\u6765\u89e3\u51b3\u5019\u9009\u4eba\u5b9a\u4f4d\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u5230\u591a\u5019\u9009\u4eba\u548c\u4f4d\u7f6e\u8bc4\u5206\u89c4\u5219\uff08\u5982$k$-Approval\u548cBorda\uff09\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8ba1\u7b97\u65b0\u5019\u9009\u4eba\u7684\u6700\u4f18\u4f4d\u7f6e\u5728\u5355\u4e00\u5bf9\u624b\u60c5\u51b5\u4e0b\u662fNP\u96be\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8e\u56fa\u5b9a\u6570\u91cf\u7684\u8bae\u9898\u53ef\u89e3\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u51e0\u4f55\u65b9\u6cd5\u548c\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u4e3a\u7ade\u9009\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u660e\u786e\u4e86\u591a\u7ef4\u7a7a\u95f4\u9009\u4e3e\u7684\u7b97\u6cd5\u590d\u6742\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u5b9e\u73b0\u7684\u51e0\u4f55\u5de5\u5177\uff0c\u4e3a\u7ade\u9009\u7b56\u7565\u8bbe\u8ba1\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2508.13868", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2508.13868", "abs": "https://arxiv.org/abs/2508.13868", "authors": ["Joanna Kaczmarek", "J\u00f6rg Rothe"], "title": "Control by Deleting Players from Weighted Voting Games Is NP^PP-Complete for the Penrose-Banzhaf Power Index", "comment": "To appear in Proceedings of ECAI 2025", "summary": "Weighted voting games are a popular class of coalitional games that are\nwidely used to model real-life situations of decision-making. They can be\napplied, for instance, to analyze legislative processes in parliaments or\nvoting in corporate structures. Various ways of tampering with these games have\nbeen studied, among them merging or splitting players, fiddling with the quota,\nand controlling weighted voting games by adding or deleting players. While the\ncomplexity of control by adding players to such games so as to change or\nmaintain a given player's power has been recently settled, the complexity of\ncontrol by deleting players from such games (with the same goals) remained\nopen. We show that when the players' power is measured by the probabilistic\nPenrose-Banzhaf index, some of these problems are complete for NP^PP -- the\nclass of problems solvable by NP machines equipped with a PP (\"probabilistic\npolynomial time\") oracle. Our results optimally improve the currently known\nlower bounds of hardness for much smaller complexity classes, thus providing\nprotection against SAT-solving techniques in practical applications.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u52a0\u6743\u6295\u7968\u6e38\u620f\u4e2d\u901a\u8fc7\u5220\u9664\u73a9\u5bb6\u6765\u63a7\u5236\u73a9\u5bb6\u6743\u529b\u7684\u590d\u6742\u6027\uff0c\u53d1\u73b0\u67d0\u4e9b\u95ee\u9898\u5728\u6982\u7387Penrose-Banzhaf\u6307\u6570\u4e0b\u5bf9NP^PP\u7c7b\u662f\u5b8c\u5907\u7684\u3002", "motivation": "\u52a0\u6743\u6295\u7968\u6e38\u620f\u5e7f\u6cdb\u7528\u4e8e\u6a21\u62df\u73b0\u5b9e\u51b3\u7b56\u573a\u666f\uff0c\u4f46\u5176\u901a\u8fc7\u5220\u9664\u73a9\u5bb6\u6765\u63a7\u5236\u73a9\u5bb6\u6743\u529b\u7684\u590d\u6742\u6027\u5c1a\u672a\u89e3\u51b3\u3002", "method": "\u4f7f\u7528\u6982\u7387Penrose-Banzhaf\u6307\u6570\u4f5c\u4e3a\u8861\u91cf\u73a9\u5bb6\u6743\u529b\u7684\u6807\u51c6\uff0c\u5206\u6790\u5220\u9664\u73a9\u5bb6\u7684\u63a7\u5236\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u8fd9\u4e9b\u95ee\u9898\u5bf9NP^PP\u7c7b\u662f\u5b8c\u5907\u7684\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f53\u524d\u5df2\u77e5\u7684\u590d\u6742\u6027\u4e0b\u754c\u3002", "conclusion": "\u7ed3\u679c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u4fdd\u62a4\u52a0\u6743\u6295\u7968\u6e38\u620f\u514d\u53d7SAT\u6c42\u89e3\u6280\u672f\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2508.13960", "categories": ["cs.GT", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.13960", "abs": "https://arxiv.org/abs/2508.13960", "authors": ["Bj\u00f6rn Filter", "Ralf M\u00f6ller", "\u00d6zg\u00fcr L\u00fctf\u00fc \u00d6z\u00e7ep"], "title": "A Mechanism for Mutual Fairness in Cooperative Games with Replicable Resources -- Extended Version", "comment": "This paper is the extended version of a paper accepted at the\n  European Conference on Artificial Intelligence 2025 (ECAI 2025), providing\n  the proof of the main theorem in the appendix", "summary": "The latest developments in AI focus on agentic systems where artificial and\nhuman agents cooperate to realize global goals. An example is collaborative\nlearning, which aims to train a global model based on data from individual\nagents. A major challenge in designing such systems is to guarantee safety and\nalignment with human values, particularly a fair distribution of rewards upon\nachieving the global goal. Cooperative game theory offers useful abstractions\nof cooperating agents via value functions, which assign value to each\ncoalition, and via reward functions. With these, the idea of fair allocation\ncan be formalized by specifying fairness axioms and designing concrete\nmechanisms. Classical cooperative game theory, exemplified by the Shapley\nvalue, does not fully capture scenarios like collaborative learning, as it\nassumes nonreplicable resources, whereas data and models can be replicated.\nInfinite replicability requires a generalized notion of fairness, formalized\nthrough new axioms and mechanisms. These must address imbalances in reciprocal\nbenefits among participants, which can lead to strategic exploitation and\nunfair allocations. The main contribution of this paper is a mechanism and a\nproof that it fulfills the property of mutual fairness, formalized by the\nBalanced Reciprocity Axiom. It ensures that, for every pair of players, each\nbenefits equally from the participation of the other.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6ee1\u8db3\u4e92\u60e0\u516c\u5e73\u6027\uff08Balanced Reciprocity Axiom\uff09\u7684\u65b0\u673a\u5236\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u4f5c\u5b66\u4e60\u4e2d\u6570\u636e\u53ef\u590d\u5236\u5bfc\u81f4\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\u3002", "motivation": "\u534f\u4f5c\u5b66\u4e60\u4e2d\u6570\u636e\u548c\u6a21\u578b\u7684\u53ef\u590d\u5236\u6027\u5e26\u6765\u4e86\u516c\u5e73\u5206\u914d\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7684\u5408\u4f5c\u535a\u5f08\u8bba\uff08\u5982Shapley\u503c\uff09\u65e0\u6cd5\u5b8c\u5168\u9002\u7528\u3002\u8bba\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u673a\u5236\uff0c\u786e\u4fdd\u53c2\u4e0e\u8005\u4e4b\u95f4\u7684\u4e92\u60e0\u516c\u5e73\u6027\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5e7f\u4e49\u7684\u516c\u5e73\u6027\u516c\u7406\uff08Balanced Reciprocity Axiom\uff09\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u673a\u5236\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6ee1\u8db3\u4e92\u60e0\u516c\u5e73\u6027\uff0c\u5373\u6bcf\u5bf9\u53c2\u4e0e\u8005\u80fd\u5e73\u7b49\u53d7\u76ca\u4e8e\u5bf9\u65b9\u7684\u53c2\u4e0e\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u7684\u673a\u5236\u6210\u529f\u6ee1\u8db3\u4e86Balanced Reciprocity Axiom\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u548c\u6a21\u578b\u53ef\u590d\u5236\u6027\u5e26\u6765\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u907f\u514d\u4e86\u7b56\u7565\u6027\u5265\u524a\u548c\u4e0d\u516c\u5e73\u5206\u914d\u3002", "conclusion": "\u901a\u8fc7\u5e7f\u4e49\u516c\u5e73\u6027\u516c\u7406\u548c\u65b0\u673a\u5236\u7684\u8bbe\u8ba1\uff0c\u8bba\u6587\u4e3a\u534f\u4f5c\u5b66\u4e60\u4e2d\u6570\u636e\u548c\u6a21\u578b\u53ef\u590d\u5236\u6027\u5e26\u6765\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u4e86\u53c2\u4e0e\u8005\u4e4b\u95f4\u7684\u4e92\u60e0\u516c\u5e73\u6027\u3002"}}
