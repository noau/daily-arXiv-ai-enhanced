<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 5]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Deep Inverse Shading: Consistent Albedo and Surface Detail Recovery via Generative Refinement](https://arxiv.org/abs/2511.08079)
*Jiacheng Wu,Ruiqi Zhang,Jie Chen*

Main category: cs.GR

TL;DR: DIS（深度逆向着色）是一个统一的框架，通过结合生成先验和表面表示，实现高保真、可重光照的虚拟形象重建。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖体表示或表面表示，存在速度慢或分辨率受限问题，且生成先验与物理建模的结合尚未充分探索。

Method: DIS采用基于网格的模型，通过法线转换模块将多视角2D生成法线预测融合到中央网格中，并引入去着色模块优化材质属性。

Result: DIS实现了高质量的几何和材质重建，支持精确重光照，并在实验中表现出渲染效率高、内存消耗低和表面细节丰富等优势。

Conclusion: DIS通过联合优化几何和材质，提供了一种高效且高质量的虚拟形象重建方法，适用于实际应用。

Abstract: Reconstructing human avatars using generative priors is essential for achieving versatile and realistic avatar models. Traditional approaches often rely on volumetric representations guided by generative models, but these methods require extensive volumetric rendering queries, leading to slow training. Alternatively, surface-based representations offer faster optimization through differentiable rasterization, yet they are typically limited by vertex count, restricting mesh resolution and scalability when combined with generative priors. Moreover, integrating generative priors into physically based human avatar modeling remains largely unexplored. To address these challenges, we introduce DIS (Deep Inverse Shading), a unified framework for high-fidelity, relightable avatar reconstruction that incorporates generative priors into a coherent surface representation. DIS centers on a mesh-based model that serves as the target for optimizing both surface and material details. The framework fuses multi-view 2D generative surface normal predictions, rich in detail but often inconsistent, into the central mesh using a normal conversion module. This module converts generative normal outputs into per-triangle surface offsets via differentiable rasterization, enabling the capture of fine geometric details beyond sparse vertex limitations. Additionally, DIS integrates a de-shading module to recover accurate material properties. This module refines albedo predictions by removing baked-in shading and back-propagates reconstruction errors to optimize the geometry. Through joint optimization of geometry and material appearance, DIS achieves physically consistent, high-quality reconstructions suitable for accurate relighting. Our experiments show that DIS delivers SOTA relighting quality, enhanced rendering efficiency, lower memory consumption, and detailed surface reconstruction.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Dynamic Stability of LLM-Generated Code](https://arxiv.org/abs/2511.07463)
*Prateek Rajput,Abdoul Aziz Bonkoungou,Yewei Song,Abdoul Kader Kabore,Iyiola E. Olatunji,Jacques Klein,Tegewende Bissyande*

Main category: cs.PL

TL;DR: 论文提出了一个新的评估框架，用于衡量大语言模型（LLM）生成代码的动态稳定性，关注算法复杂性和运行时行为的多样性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码生成的评估方法过于关注功能性正确性，忽略了算法复杂性和性能差异的重要性，例如O(n^2)和O(n logn)排序算法的不同性能表现。

Method: 提出了基于操作码分布的两个指标：静态规范跟踪差异（SCTD）和动态规范跟踪差异（DCTD），以及它们的比值行为表达因子（BEF），用于诊断运行时行为稳定性。

Result: 实验结果表明，即使功能正确的LLM输出也存在显著的算法多样性，且提高采样温度会提高正确率但降低稳定性，揭示了正确性与行为一致性之间的矛盾。

Conclusion: 研究呼吁在代码生成中引入稳定性目标，并开发包含渐进性测试用例的新基准，以实现对LLM的全面评估。

Abstract: Current evaluations of LLMs for code generation emphasize functional correctness, overlooking the fact that functionally correct solutions can differ significantly in algorithmic complexity. For instance, an $(O(n^2))$ versus $(O(n \log n))$ sorting algorithm may yield similar output but incur vastly different performance costs in production. This discrepancy reveals a critical limitation in current evaluation methods: they fail to capture the behavioral and performance diversity among correct solutions. To address this, we introduce a principled framework for evaluating the dynamic stability of generated code. We propose two metrics derived from opcode distributions: Static Canonical Trace Divergence (SCTD), which captures algorithmic structure diversity across generated solutions, and Dynamic Canonical Trace Divergence (DCTD), which quantifies runtime behavioral variance. Their ratio, the Behavioral Expression Factor (BEF), serves as a diagnostic signal: it indicates critical runtime instability when BEF $\ll$ 1 and functional redundancy when BEF $\gg$ 1. Empirical results on BigOBench and CodeContests show that state-of-the-art LLMs exhibit significant algorithmic variance even among functionally correct outputs. Notably, increasing sampling temperature improves pass@1 rates but degrades stability, revealing an unrecognized trade-off: searching for correct solutions in diverse output spaces introduces a "penalty of instability" between correctness and behavioral consistency. Our findings call for stability-aware objectives in code generation and new benchmarks with asymptotic test cases for robust, real-world LLM evaluation.

</details>


### [3] [Streaming Tensor Program: A streaming abstraction for dynamic parallelism](https://arxiv.org/abs/2511.07776)
*Gina Sohn,Genghan Zhang,Konstantin Hossfeld,Jungwoo Kim,Nathan Sobotka,Nathan Zhang,Olivia Hsu,Kunle Olukotun*

Main category: cs.PL

TL;DR: STeP是一种新的流式抽象，用于在空间数据流加速器上高效运行动态张量工作负载，通过灵活的路由操作符、显式内存层次结构和符号形状语义，优化动态行为。


<details>
  <summary>Details</summary>
Motivation: 由于现有编程抽象在表达动态行为方面的局限性，无法高效处理动态张量工作负载，因此提出了STeP以解决这些挑战。

Method: STeP引入了灵活的路由操作符、显式内存层次结构和符号形状语义，支持动态数据率和张量维度，并解锁了动态分块、动态并行化和配置时分复用等优化技术。

Result: 通过对典型LLM层的模拟测试，动态分块减少片上内存需求2.18倍，动态并行化提高延迟1.5倍，配置时分复用提高计算利用率2.57倍。

Conclusion: STeP能够高效处理动态张量工作负载，并在性能和资源利用方面显著优于现有抽象。

Abstract: Dynamic behaviors are becoming prevalent in many tensor applications. In machine learning, for example, the input tensors are dynamically shaped or ragged, and data-dependent control flow is widely used in many models. However, the limited expressiveness of prior programming abstractions for spatial dataflow accelerators forces the dynamic behaviors to be implemented statically or lacks the visibility for performance-critical decisions. To address these challenges, we present the Streaming Tensor Program (STeP), a new streaming abstraction that enables dynamic tensor workloads to run efficiently on spatial dataflow accelerators. STeP introduces flexible routing operators, an explicit memory hierarchy, and symbolic shape semantics that expose dynamic data rates and tensor dimensions. These capabilities unlock new optimizations-dynamic tiling, dynamic parallelization, and configuration time-multiplexing-that adapt to dynamic behaviors while preserving dataflow efficiency. Using a cycle-approximate simulator on representative LLM layers with real-world traces, dynamic tiling reduces on-chip memory requirement by 2.18x, dynamic parallelization improves latency by 1.5x, and configuration time-multiplexing improves compute utilization by 2.57x over implementations available in prior abstractions.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Reliable and Private Utility Signaling for Data Markets](https://arxiv.org/abs/2511.07975)
*Li Peng,Jiayao Zhang,Yihang Wu,Weiran Liu,Jinfei Liu,Zheng Yan,Kui Ren,Lei Zhang,Lin Qu*

Main category: cs.GT

TL;DR: 本文提出了一种非TCP基础的信号机制，利用恶意安全的多方计算（MPC）确保隐私和可靠性，同时优化了MPC基础的KNN-Shapley方法以提高效率。


<details>
  <summary>Details</summary>
Motivation: 数据市场的爆炸性增长凸显了数据共享和高品质数据集访问的重要性。然而，数据的自由复制特性导致现有信号机制在隐私和可靠性之间存在矛盾，影响了决策效果。

Method: 本文提出了一种非TCP基础的信号机制，通过恶意安全的多方计算（MPC）确保信号计算的隐私和鲁棒性，并引入了基于MPC的哈希验证方案以确保输入可靠性。在多卖家场景中，进一步优化了MPC-based KNN-Shapley方法以提高效率。

Result: 严格的实验证明了该方法的效率和实用性。

Conclusion: 本研究不仅定义了理想的信号机制，还通过MPC技术和优化方法实现了隐私与可靠性的平衡，为数据市场的有效交易提供了支持。

Abstract: The explosive growth of data has highlighted its critical role in driving economic growth through data marketplaces, which enable extensive data sharing and access to high-quality datasets. To support effective trading, signaling mechanisms provide participants with information about data products before transactions, enabling informed decisions and facilitating trading. However, due to the inherent free-duplication nature of data, commonly practiced signaling methods face a dilemma between privacy and reliability, undermining the effectiveness of signals in guiding decision-making.
  To address this, this paper explores the benefits and develops a non-TCP-based construction for a desirable signaling mechanism that simultaneously ensures privacy and reliability. We begin by formally defining the desirable utility signaling mechanism and proving its ability to prevent suboptimal decisions for both participants and facilitate informed data trading. To design a protocol to realize its functionality, we propose leveraging maliciously secure multi-party computation (MPC) to ensure the privacy and robustness of signal computation and introduce an MPC-based hash verification scheme to ensure input reliability. In multi-seller scenarios requiring fair data valuation, we further explore the design and optimization of the MPC-based KNN-Shapley method with improved efficiency. Rigorous experiments demonstrate the efficiency and practicality of our approach.

</details>


### [5] [Centralized Group Equitability and Individual Envy-Freeness in the Allocation of Indivisible Items](https://arxiv.org/abs/2511.07984)
*Ying Wang,Jiaqian Li,Tianze Wei,Hau Chan,Minming Li*

Main category: cs.GT

TL;DR: 论文研究了不可分割物品在代理群组中的公平分配问题，引入了集中化群组公平性（CGEQ）和代理嫉妒自由（EF）的概念，并证明了满足EF1和CGEQ1的分配总是存在且可高效计算。


<details>
  <summary>Details</summary>
Motivation: 研究动机来自现实场景中集中分配者对群组间和代理间公平性的需求，例如学校资源分配和城市住房分配。

Method: 通过定义集中化群组公平性（CGEQ）和嫉妒自由（EF）的放松版本EF1和CGEQ1，分析了不同估值函数类别下的公平分配问题。

Result: 证明了对特定的代理和分配者估值函数，满足EF1和CGEQ1的分配总是存在，并设计了高效的计算算法。

Conclusion: 研究提供了在集中分配场景下实现代理和群组双重公平性的实用方法与理论支持。

Abstract: We study the fair allocation of indivisible items for groups of agents from the perspectives of the agents and a centralized allocator. In our setting, the centralized allocator is interested in ensuring the allocation is fair among the groups and between agents. This setting applies to many real-world scenarios, including when a school administrator wants to allocate resources (e.g., office spaces and supplies) to staff members in departments and when a city council allocates limited housing units to various families in need across different communities. To ensure fair allocation between agents, we consider the classical envy-freeness (EF) notion. To ensure fairness among the groups, we define the notion of centralized group equitability (CGEQ) to capture the fairness for the groups from the allocator's perspective. Because an EF or CGEQ allocation does not always exist in general, we consider their corresponding natural relaxations of envy-freeness to one item (EF1) and centralized group equitability up to one item (CGEQ1). For different classes of valuation functions of the agents and the centralized allocator, we show that allocations satisfying both EF1 and CGEQ1 always exist and design efficient algorithms to compute these allocations. We also consider the centralized group maximin share (CGMMS) from the centralized allocator's perspective as a group-level fairness objective with EF1 for agents and present several results.

</details>


### [6] [Nash-equilibrium Seeking Algorithm for Power-Allocation Games on Networks of International Relations](https://arxiv.org/abs/2511.08033)
*Chuanzhe Zhang,Yuke Li,Wenjun Mei*

Main category: cs.GT

TL;DR: 本文改进了国际安全中的战略互动模型，通过调整偏好公理和提出新算法，验证了纯策略纳什均衡的存在，并使用历史数据验证模型。


<details>
  <summary>Details</summary>
Motivation: 国际安全中战略互动的网络化研究尚不完善，现有框架未能充分捕捉复杂场景，需要更细致的分析和验证。

Method: 修改偏好公理以更细致描述国家行为（自保、盟友防御、敌对进攻），并提出新算法证明纯策略纳什均衡的存在。

Result: 模型通过了1940年历史数据的验证，成功预测了国家的生存能力，扩展了原框架的实用性。

Conclusion: 研究填补了国际安全战略互动模型的空白，提供了更全面的网络化安全环境分析方法。

Abstract: In the field of international security, understanding the strategic interactions between countries within a networked context is crucial. Our previous research has introduced a ``games-on-signed graphs'' framework~\cite{LiMorse2022} to analyze these interactions. While the framework is intended to be basic and general, there is much left to be explored, particularly in capturing the complexity of strategic scenarios in international relations. Our paper aims to fill this gap in two key ways. First, we modify the existing preference axioms to allow for a more nuanced understanding of how countries pursue self-survival, defense of allies, and offense toward adversaries. Second, we introduce a novel algorithm that proves the existence of a pure-strategy Nash equilibrium for these revised games. To validate our model, we employ historical data from the year 1940 as the game input and predict countries' survivability. Our contributions thus extend the real-world applicability of the original framework, offering a more comprehensive view of strategic interactions in a networked security environment.

</details>


### [7] [Dividing Indivisible Items for the Benefit of All: It is Hard to Be Fair Without Social Awareness](https://arxiv.org/abs/2511.08160)
*Argyris Deligkas,Eduard Eiben,Tiger-Lily Goldsmith,Dušan Knop,Šimon Schierreich*

Main category: cs.GT

TL;DR: 研究公平分配不可分割物品的问题，同时最大化社会影响。结果表明，问题的复杂性取决于代理是否具有社会意识。


<details>
  <summary>Details</summary>
Motivation: 在标准公平分配模型中，代理通常是自私的，但在许多情况下，资源分配直接影响整个群体或社会，因此需要同时考虑公平性和社会影响。

Method: 模型中将每个代理与两个加法函数关联，分别定义其对物品的价值和社会影响。目标是分配物品以最大化社会影响并保持一定的公平性。

Result: 对于不具备社会意识的代理，问题在多种公平性概念下是NP难的；具备社会意识的代理则可以多项式时间内计算公平分配。

Conclusion: 社会意识的引入使得公平性与社会影响的平衡成为可能，但问题的复杂性随社会意识定义的放宽而增加。

Abstract: In standard fair division models, we assume that all agents are selfish. However, in many scenarios, division of resources has a direct impact on the whole group or even society. Therefore, we study fair allocations of indivisible items that, at the same time, maximize social impact. In this model, each agent is associated with two additive functions that define their value and social impact for each item. The goal is to allocate items so that the social impact is maximized while maintaining some fairness criterion. We reveal that the complexity of the problem heavily depends on whether the agents are socially aware, i.e., they take into consideration the social impact functions. For socially unaware agents, we prove that the problem is NP-hard for a variety of fairness notions, and that it is tractable only for very restricted cases, e.g., if, for every agent, the valuation equals social impact and it is binary. On the other hand, social awareness allows for fair allocations that maximize social impact, and such allocations can be computed in polynomial time. Interestingly, the problem becomes again intractable as soon as the definition of social awareness is relaxed.

</details>


### [8] [Classification in Equilibrium: Structure of Optimal Decision Rules](https://arxiv.org/abs/2511.08347)
*Elizabeth Maggie Penn,John W. Patty*

Main category: cs.GT

TL;DR: 这篇论文刻画了个体对分类规则做出行为调整时的最优分类问题，提出了一个斯塔克尔伯格博弈模型，设计者在预期个体行为基础上选择分类规则。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解设计者在个体行为调整的情况下如何选择最优的分类规则，尤其是在个体可能通过合规、欺骗或放弃来影响分类结果的情境下。

Method: 方法上采用了斯塔克尔伯格博弈模型，设计者在个体行为调整的预期下选择分类规则，并在标准的单调似然比假设下进行分析。

Result: 研究发现，最优分类规则属于一个简单且可解释的类别（单阈值和双截断规则），这些规则可能与传统设计相悖，例如故意奖励较低的似然比或在中间段集中奖励/惩罚以提高信息质量。

Conclusion: 结论表明，最优分类规则的设计可能与先前研究结果截然不同，强调了在个体行为调整背景下重新思考分类规则的必要性。

Abstract: This paper characterizes optimal classification when individuals adjust their behavior in response to the classification rule. We model the interaction between a designer and a population as a Stackelberg game: the designer selects a classification rule anticipating how individuals will comply, cheat, or abstain in order to obtain a favorable classification. Under standard monotone likelihood ratio assumptions, optimal rules belong to a small and interpretable family (single-threshold and two-cut rules) that encompass both conventional and counterintuitive designs. Our results depart sharply from prior findings that optimal classifiers reward higher signals: in equilibrium, the designer may deliberately reward those with lower likelihood ratios or concentrate rewards/penalties in a middle band to improve informational quality.

</details>
