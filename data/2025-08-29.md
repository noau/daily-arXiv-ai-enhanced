<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Mixture of Contexts for Long Video Generation](https://arxiv.org/abs/2508.21058)
*Shengqu Cai,Ceyuan Yang,Lvmin Zhang,Yuwei Guo,Junfei Xiao,Ziyan Yang,Yinghao Xu,Zhenheng Yang,Alan Yuille,Leonidas Guibas,Maneesh Agrawala,Lu Jiang,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 为了解决长视频生成中上下文记忆的挑战，论文提出了一种可学习的稀疏注意力路由模块（Mixture of Contexts，MoC），通过动态选择信息块和必须的锚点（如标题和局部窗口）来优化长序列生成的计算效率。


<details>
  <summary>Details</summary>
Motivation: 长视频生成的核心挑战在于如何高效处理长上下文记忆问题，避免模型在处理长序列时因自我注意力的平方成本而导致内存和计算资源不可行。

Method: 论文提出了一种称为Mixture of Contexts（MoC）的稀疏注意力路由模块，通过动态选择少量信息块和必须的锚点（如标题和局部窗口），并通过因果路由防止环路闭合，从而优化长序列生成的计算效率。

Result: 实验表明，MoC模块能够显著提升长视频生成的效率（接近线性扩展），并在数据和路由逐渐稀疏的情况下，模型能够专注于关键历史信息，保持内容的一致性。

Conclusion: 通过MoC模块，论文成功解决了长上下文记忆的挑战，实现了高效的长视频生成，并且在计算效率和内容一致性方面取得了显著进展。

Abstract: Long video generation is fundamentally a long context memory problem: models
must retain and retrieve salient events across a long range without collapsing
or drifting. However, scaling diffusion transformers to generate long-context
videos is fundamentally limited by the quadratic cost of self-attention, which
makes memory and computation intractable and difficult to optimize for long
sequences. We recast long-context video generation as an internal information
retrieval task and propose a simple, learnable sparse attention routing module,
Mixture of Contexts (MoC), as an effective long-term memory retrieval engine.
In MoC, each query dynamically selects a few informative chunks plus mandatory
anchors (caption, local windows) to attend to, with causal routing that
prevents loop closures. As we scale the data and gradually sparsify the
routing, the model allocates compute to salient history, preserving identities,
actions, and scenes over minutes of content. Efficiency follows as a byproduct
of retrieval (near-linear scaling), which enables practical training and
synthesis, and the emergence of memory and consistency at the scale of minutes.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Solvable Tuple Patterns and Their Applications to Program Verification](https://arxiv.org/abs/2508.20365)
*Naoki Kobayashi,Ryosuke Sato,Ayumi Shinohara,Ryo Yoshinaka*

Main category: cs.PL

TL;DR: 本文提出了一种名为可解决元组模式（STPs）的新概念，用于表达递归数据结构之间的不变量。STPs可以通过少量正样本高效推断，无需负样本。结合SMT求解器和STP推断算法，支持列表类数据结构的CHC求解器在ADT-LIN类别中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管程序验证技术最近取得了进展，但全自动验证递归数据结构的程序仍然是一个挑战。因此，作者提出了STPs来解决这一问题。

Method: 作者引入了可解决元组模式（STPs）的概念，并展示了如何从少量正样本中高效推断STPs。STPs的验证可以通过支持序列理论的SMT求解器完成。此外，文章还提出了一个基本的STP推断算法，并将其整合到一个支持列表类数据结构的CHC求解器中。

Result: 整合了STP推断的CHC求解器在CHC-COMP 2025的ADT-LIN类别中以显著优势获胜，证明了方法的有效性。

Conclusion: 通过引入STPs并将其整合到CHC求解器中，本文提供了一种高效、自动化的方法来验证递归数据结构的程序。这一成果为程序验证工具提供了统一的、实用的后端支持。

Abstract: Despite the recent progress of automated program verification techniques,
fully automated verification of programs manipulating recursive data structures
remains a challenge. We introduce the notion of solvable tuple patterns (STPs)
to express invariants between list-like recursive data structures. A
distinguishing feature of STPs is that they can be efficiently inferred from
only a small number of positive samples; no negative samples are required. An
SMT solver that supports the sequence theory can be used to check that an
inferred STP is indeed an inductive invariant. After presenting basic
properties of STPs and an STP inference algorithm, we show how to incorporate
the STP inference into a CHC (Constrained Horn Clauses) solver supporting
list-like data structures, which serves as a uniform backend for automated
program verification tools. A CHC solver incorporating the STP inference has
won the ADT-LIN category of CHC-COMP 2025 by a big margin.

</details>


### [3] [Static Factorisation of Probabilistic Programs With User-Labelled Sample Statements and While Loops](https://arxiv.org/abs/2508.20922)
*Markus Böck,Jürgen Cito*

Main category: cs.PL

TL;DR: 该论文解决了概率程序（特别是带有用户标记的样本语句和循环结构的程序）如何用图形表示的问题，并提出了一种静态分析方法来近似程序的依赖结构，从而实现了对概率程序密度的新型图形表示。


<details>
  <summary>Details</summary>
Motivation: 当前的贝叶斯网络可以轻松转换为概率程序，但反向转换并不明确。论文的目的是探索带有用户标记样本语句和循环结构的概率程序如何用图形表示。

Method: 论文扩展了现有的操作语义以支持这些语言特性，通过将程序转换为控制流图，定义了一种静态分析方法来近似随机变量的依赖结构，从而实现了程序密度的静态分解。

Result: 研究结果是一种新型图形表示，适用于定义无限随机变量的程序，并提出了一种程序切片技术，以静态启用三种优化：降低变分推断中梯度估计的方差，并加速单点Metropolis Hastings和序列蒙特卡洛方法。

Conclusion: 论文提出的优化被证明是有效的，并在实证研究中表现优于现有技术。

Abstract: It is commonly known that any Bayesian network can be implemented as a
probabilistic program, but the reverse direction is not so clear. In this work,
we address the open question to what extent a probabilistic program with
user-labelled sample statements and while loops - features found in languages
like Gen, Turing, and Pyro - can be represented graphically. To this end, we
extend existing operational semantics to support these language features. By
translating a program to its control-flow graph, we define a sound static
analysis that approximates the dependency structure of the random variables in
the program. As a result, we obtain a static factorisation of the implicitly
defined program density, which is equivalent to the known Bayesian network
factorisation for programs without loops and constant labels, but constitutes a
novel graphical representation for programs that define an unbounded number of
random variables via loops or dynamic labels. We further develop a sound
program slicing technique to leverage this structure to statically enable three
well-known optimisations for the considered program class: we reduce the
variance of gradient estimates in variational inference and we speed up both
single-site Metropolis Hastings and sequential Monte Carlo. These optimisations
are proven correct and empirically shown to match or outperform existing
techniques.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Collaborating with GenAI: Incentives and Replacements](https://arxiv.org/abs/2508.20213)
*Boaz Taitler,Omer Ben-Porat*

Main category: cs.GT

TL;DR: 生成式AI（GenAI）的出现正在改变员工在共享项目中的贡献方式。研究表明，GenAI可能导致员工不再付出努力，即使GenAI几乎无效，同时管理者的优化问题具有NP复杂度。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI如何影响团队协作，尤其是在管理者和员工之间可能产生的动态变化，例如生产力提升或员工被替代的风险。

Method: 通过理论模型分析GenAI对团队协作的影响，包括管理者选择团队和GenAI替代部分员工的机制，以及员工努力程度的决策。

Result: 研究表明，GenAI可能导致员工完全不努力，即使GenAI效果有限；同时，管理者的优化问题被证明是NP完全的，并提供了近似线性情况下的高效算法。

Conclusion: 低价值员工可能在维持整体产出中起到关键作用，排除他们可能引发连锁反应。通过大量仿真验证了理论结果。

Abstract: The rise of Generative AI (GenAI) is reshaping how workers contribute to
shared projects. While workers can use GenAI to boost productivity or reduce
effort, managers may use it to replace some workers entirely. We present a
theoretical framework to analyze how GenAI affects collaboration in such
settings. In our model, the manager selects a team to work on a shared task,
with GenAI substituting for unselected workers. Each worker selects how much
effort to exert, and incurs a cost that increases with the level of effort. We
show that GenAI can lead workers to exert no effort, even if GenAI is almost
ineffective. We further show that the manager's optimization problem is
NP-complete, and provide an efficient algorithm for the special class of
(almost-) linear instances. Our analysis shows that even workers with low
individual value may play a critical role in sustaining overall output, and
excluding such workers can trigger a cascade. Finally, we conduct extensive
simulations to illustrate our theoretical findings.

</details>


### [5] [Balancing Profit and Traveller Acceptance in Ride-Pooling Personalised Fares](https://arxiv.org/abs/2508.20723)
*Michal Bujak,Rafal Kucharski*

Main category: cs.GT

TL;DR: 论文提出了一种自适应定价策略，通过学习乘客的接受价格，实现个性化定价，从而提高乘客效用和运营利润。


<details>
  <summary>Details</summary>
Motivation: 由于乘客对价值的感知存在异质性，运营者难以知道每位乘客的可接受价格，因此需要一种方法来学习和优化个性化定价。

Method: 采用自适应定价策略，每天运营者根据乘客行为逐步调整报价，以吸引更多需求并满足乘客期望。

Result: 实验结果显示，运营者在10天内对拼车乘客的学习准确率超过90%，能够显著提升乘客效用和运营利润，并优化拼车组合效率。

Conclusion: 通过学习乘客行为特征，运营者可以实现个性化定价，从而改善乘客体验并提高自身利润，同时优化拼车服务的效率。

Abstract: Ride-pooling systems, to succeed, must provide an attractive service, namely
compensate perceived costs with an appealing price. However, because of a
strong heterogeneity in a value-of-time, each traveller has his own acceptable
price, unknown to the operator. Here, we show that individual acceptance levels
can be learned by the operator (over $90\%$ accuracy for pooled travellers in
$10$ days) to optimise personalised fares. We propose an adaptive pricing
policy, where every day the operator constructs an offer that progressively
meets travellers' expectations and attracts a growing demand. Our results
suggest that operators, by learning behavioural traits of individual
travellers, may improve performance not only for travellers (increased utility)
but also for themselves (increased profit). Moreover, such knowledge allows the
operator to remove inefficient pooled rides and focus on attractive and
profitable combinations.

</details>
