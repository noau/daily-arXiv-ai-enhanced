<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [LGCC: Enhancing Flow Matching Based Text-Guided Image Editing with Local Gaussian Coupling and Context Consistency](https://arxiv.org/abs/2511.01894)
*Fangbing Liu,Pengfei Duan,Wen Li,Yi He*

Main category: cs.GR

TL;DR: LGCC是一种新型框架，通过局部高斯噪声耦合（LGNC）和内容一致性损失（CCL）解决了现有MLLMs在图像编辑中的细节退化、内容不一致和效率低下的问题，显著提升了编辑速度和细节保留。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流匹配的多模态大语言模型（MLLMs）在图像编辑中存在细节退化、内容不一致和效率低下的问题，LGCC旨在解决这些问题。

Method: LGCC框架包含两个关键组件：局部高斯噪声耦合（LGNC）和内容一致性损失（CCL），并通过课程学习集成到BAGEL预训练模型中。

Result: LGCC在I2EBench上提升了局部细节分数1.60%和总分0.53%，并实现了3倍到5倍的编辑速度提升，推理时间仅为BAGEL或Flux的40%-50%。

Conclusion: LGCC显著提升了图像编辑的效率和质量，提供了一种成本高效的解决方案，同时保持了编辑质量的完整性。

Abstract: Recent advancements have demonstrated the great potential of flow
matching-based Multimodal Large Language Models (MLLMs) in image editing.
However, state-of-the-art works like BAGEL face limitations, including detail
degradation, content inconsistency, and inefficiency due to their reliance on
random noise initialization. To address these issues, we propose LGCC, a novel
framework with two key components: Local Gaussian Noise Coupling (LGNC) and
Content Consistency Loss (CCL). LGNC preserves spatial details by modeling
target image embeddings and their locally perturbed counterparts as coupled
pairs, while CCL ensures semantic alignment between edit instructions and image
modifications, preventing unintended content removal. By integrating LGCC with
the BAGEL pre-trained model via curriculum learning, we significantly reduce
inference steps, improving local detail scores on I2EBench by 1.60% and overall
scores by 0.53%. LGCC achieves 3x -- 5x speedup for lightweight editing and 2x
for universal editing, requiring only 40% -- 50% of the inference time of BAGEL
or Flux. These results demonstrate LGCC's ability to preserve detail, maintain
contextual integrity, and enhance inference speed, offering a cost-efficient
solution without compromising editing quality.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [Oriented Metrics for Bottom-Up Enumerative Synthesis](https://arxiv.org/abs/2511.02491)
*Roland Meyer,Jakob Tepe*

Main category: cs.PL

TL;DR: 该论文提出了一种称为定向度量的结构，用于减少语法引导合成中的搜索空间，并在字符串和位向量域中开发了几种新的定向度量，通过四种技术显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 减少语法引导合成中庞大的搜索空间是该领域的挑战之一，作者观察到搜索空间可以通过定向度量结构化，从而优化搜索效率。

Method: 开发了针对字符串和位向量域的定向度量，并提出了四种技术：修剪搜索空间、因子化搜索空间、抽象和细化定向度量、以及改进枚举顺序。

Result: 通过实验验证，新合成的算法在字符串和位向量域中将性能提升了超过一个数量级。

Conclusion: 定向度量的引入及其相关技术显著提高了语法引导合成的效率，新算法在实验中表现优越。

Abstract: In syntax-guided synthesis, one of the challenges is to reduce the enormous
size of the search space. We observe that most search spaces are not just flat
sets of programs, but can be endowed with a structure that we call an oriented
metric. Oriented metrics measure the distance between programs, like ordinary
metrics do, but are designed for settings in which operations have an
orientation. Our focus is on the string and the bitvector domains, where
operations like concatenation and bitwise conjunction transform an input into
an output in a way that is not symmetric. We develop several new oriented
metrics for these domains. Oriented metrics are designed for search space
reduction, and we present four techniques: (i) pruning the search space to a
ball around the ground truth, (ii) factorizing the search space by an
equivalence that is induced by the oriented metric, (iii) abstracting the
oriented metric (and hence the equivalence) and refining it, and (iv) improving
the enumeration order by learning from abstract information. We acknowledge
that these techniques are inspired by developments in the literature. By
understanding their roots in oriented metrics, we can substantially increase
their applicability and efficiency. We have integrated these techniques into a
new synthesis algorithm and implemented the algorithm in a new solver. Notably,
our solver is generic in the oriented metric over which it computes. We
conducted experiments in the string and the bitvector domains, and consistently
improve the performance over the state-of-the-art by more than an order of
magnitude.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [3] [Near Optimal Convergence to Coarse Correlated Equilibrium in General-Sum Markov Games](https://arxiv.org/abs/2511.02157)
*Asrin Efe Yorulmaz,Tamer Başar*

Main category: cs.GT

TL;DR: 本文通过改进自适应步长技术，将马尔可夫博弈中粗相关均衡（CCE）的收敛速率从$ackslashmathcal{O}(ackslashlog^5 T / T)$提高到$ackslashmathcal{O}(ackslashlog T / T)$，并改善了动作集大小的依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是提升马尔可夫博弈中粗相关均衡（CCE）和关联均衡（CE）的无悔学习动态的收敛速率，以解决高维设置下的效率问题。

Method: 方法基于自适应步长技术，扩展了其对马尔可夫环境的适用性，通过阶段性的学习率调整和乐观跟随正则化领导者（OFTRL）框架，定制了基于值迭代学习的策略更新。

Result: 结果显示，该方法将CCE的收敛速率提高到$ackslashmathcal{O}(ackslashlog T / T)$，并在动作集大小上实现多项式到对数函数的改进，适用于高维设置。

Conclusion: 结论表明，该自对抗算法在马尔可夫博弈中实现了迄今最快的CCE收敛速率，为高维环境下的博弈理论提供了更高效的解决方案。

Abstract: No-regret learning dynamics play a central role in game theory, enabling
decentralized convergence to equilibrium for concepts such as Coarse Correlated
Equilibrium (CCE) or Correlated Equilibrium (CE). In this work, we improve the
convergence rate to CCE in general-sum Markov games, reducing it from the
previously best-known rate of $\mathcal{O}(\log^5 T / T)$ to a sharper
$\mathcal{O}(\log T / T)$. This matches the best known convergence rate for CE
in terms of $T$, number of iterations, while also improving the dependence on
the action set size from polynomial to polylogarithmic-yielding exponential
gains in high-dimensional settings. Our approach builds on recent advances in
adaptive step-size techniques for no-regret algorithms in normal-form games,
and extends them to the Markovian setting via a stage-wise scheme that adjusts
learning rates based on real-time feedback. We frame policy updates as an
instance of Optimistic Follow-the-Regularized-Leader (OFTRL), customized for
value-iteration-based learning. The resulting self-play algorithm achieves, to
our knowledge, the fastest known convergence rate to CCE in Markov games.

</details>


### [4] [Human-AI Collaboration with Misaligned Preferences](https://arxiv.org/abs/2511.02746)
*Jiaxin Song,Parnian Shahkar,Kate Donahue,Bhaskar Ray Chaudhury*

Main category: cs.GT

TL;DR: 本文研究了算法作为助手在人类决策中的作用，发现人类在与不完全对齐的算法合作时，可能比与完全对齐的算法合作获得更多效用。


<details>
  <summary>Details</summary>
Motivation: 现实中，算法常作为助手帮助人类从众多选项中筛选出子集供人类决策。然而，人类的偏好可能不完全明确或不一致，算法也可能不完全了解人类的具体偏好。本文旨在探讨这种情境下人类如何从与算法合作中受益。

Method: 通过建模和理论分析，研究了人类与不完全对齐的算法合作的场景，探讨了算法在不同偏好下的效用差异。

Result: 研究发现，人类在与不完全对齐的算法合作时，可能比与完全对齐的算法获得更高的效用。进一步分析了算法如何最大化人类福利。

Conclusion: 研究结果为算法工具的设计者及政策制定者提供了重要启示，强调了不完全对齐算法的潜在优势。

Abstract: In many real-life settings, algorithms play the role of assistants, while
humans ultimately make the final decision. Often, algorithms specifically act
as curators, narrowing down a wide range of options into a smaller subset that
the human picks between: consider content recommendation or chatbot responses
to questions with multiple valid answers. Crucially, humans may not know their
own preferences perfectly either, but instead may only have access to a noisy
sampling over preferences. Algorithms can assist humans by curating a smaller
subset of items, but must also face the challenge of misalignment: humans may
have different preferences from each other (and from the algorithm), and the
algorithm may not know the exact preferences of the human they are facing at
any point in time. In this paper, we model and theoretically study such a
setting. Specifically, we show instances where humans benefit by collaborating
with a misaligned algorithm. Surprisingly, we show that humans gain more
utility from a misaligned algorithm (which makes different mistakes) than from
an aligned algorithm. Next, we build on this result by studying what properties
of algorithms maximize human welfare when the goals could be either utilitarian
welfare or ensuring all humans benefit. We conclude by discussing implications
for designers of algorithmic tools and policymakers.

</details>
