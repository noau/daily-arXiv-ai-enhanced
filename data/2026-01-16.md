<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 1]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Extrinsic Vector Field Processing](https://arxiv.org/abs/2601.10621)
*Hongyi Liu,Oded Stein,Amir Vaxman,Mirela Ben-Chen,Misha Kazhdan*

Main category: cs.GR

TL;DR: 提出了一种针对三角网格的切向量场的新离散化方法，通过Phong映射和Rodrigues旋转定义连续且弱可微的切向量场，从而支持协变导数和标准算子的定义。


<details>
  <summary>Details</summary>
Motivation: 为了在三角网格上高效且准确地处理切向量场，需要一种新的离散化方法，支持连续性和弱可微性，以实现协变导数和相关算子的定义。

Method: 基于Phong映射定义连续切向量场，利用Rodrigues旋转将顶点切向量扩展到三角形内部，从而构建连续且弱可微的向量场。

Result: 该方法能够定义协变导数场及其分解形式，支持Hodge Laplacian能量、Connection Laplacian能量、Killing能量等标准算子的定义，同时还能定义Lie括号。

Conclusion: 所提出的离散化方法在三角网格上实现了连续且弱可微的切向量场，为向量场处理提供了高效且灵活的数学工具。

Abstract: We propose a novel discretization of tangent vector fields for triangle meshes. Starting with a Phong map continuously assigning normals to all points on the mesh, we define an extrinsic bases for continuous tangent vector fields by using the Rodrigues rotation to transport tangent vectors assigned to vertices to tangent vectors in the interiors of the triangles. As our vector fields are continuous and weakly differentiable, we can use them to define a covariant derivative field that is evaluatable almost-everywhere on the mesh. Decomposing the covariant derivative in terms of diagonal multiple of the identity, anti-symmetric, and trace-less symmetric components, we can define the standard operators used for vector field processing including the Hodge Laplacian energy, Connection Laplacian energy, and Killing energy. Additionally, the ability to perform point-wise evaluation of the covariant derivative also makes it possible for us to define the Lie bracket.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [2] [From Dynamic to Lexical: A Comparative Exploration of Scoping Rules in SAS and R](https://arxiv.org/abs/2601.09808)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 本文对比了SAS的动态作用域和R的词法作用域，分析了它们在变量访问方式和代码行为上的差异，并提供了调试和优化的实用方法。


<details>
  <summary>Details</summary>
Motivation: 探讨SAS和R中的作用域规则差异，帮助程序员更好地管理和优化变量，提升代码效率和可靠性。

Method: 通过符号表和环境的概念，分别分析SAS的动态作用域和R的词法作用域，并结合实例展示其行为差异。

Result: 研究表明，SAS的动态作用域在运行时解析变量，而R的词法作用域基于函数定义结构解析变量，两者对代码行为有显著影响。

Conclusion: 对比分析为程序员提供了关键见解，使其能在SAS和R中更有效地控制变量作用域，从而优化代码管理和编程实践。

Abstract: Variable scoping dictates how and where variables are accessible within programming languages, playing a crucial role in code efficiency and organization. This paper examines the distinct scoping rules in SAS and R, focusing on SAS's dynamic scoping and R's lexical scoping. In SAS, dynamic scoping utilizes symbol tables, resolving variables at runtime by dynamically searching through active macro layers. R, in contrast, employs lexical scoping, using environments to resolve variables based on the structure in which functions are defined. Illustrative examples highlight the differences between these scoping strategies, showcasing their impact on code behavior. Additionally, the paper outlines methods for inspecting variables in SAS's symbol tables and R's environments, offering practical insights for debugging and optimization. Strategies for controlling variable scope in both languages are discussed, enhancing code precision and reliability. This exploration equips programmers with critical understanding to optimize variable management, improving their programming practices in SAS and R.

</details>


### [3] [Lazy Evaluation: A Comparative Analysis of SAS MACROs and R Functions](https://arxiv.org/abs/2601.09839)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 论文比较了R和SAS在惰性求值机制上的差异，重点分析了它们的实现原理和对编程效率的影响，为程序员提供了优化代码的指导。


<details>
  <summary>Details</summary>
Motivation: 惰性求值是一种优化代码执行效率的技术，但在SAS中的应用尚未得到广泛探讨。随着制药行业从SAS转向R的现象增多，理解这两种语言的惰性求值机制变得尤为重要。

Method: 论文通过比较R和SAS MACROs的惰性求值机制，分析了R的Promise数据结构和SAS的符号表在惰性求值中的应用及其差异。

Result: 研究发现，R通过Promise数据结构采用按需调用策略，而SAS通过符号表采用按名调用策略，这些差异显著影响了编程效率和内存使用。

Conclusion: 论文揭示了惰性求值在不同编程语言中的实现原理及其对效率的影响，为程序员在SAS和R中优化代码提供了实用指导。

Abstract: Lazy evaluation is a powerful technique that can optimize code execution by deferring evaluations until their results are required, thus enhancing efficiency. In most modern programming languages, like R, lazy evaluation is commonly applied to function arguments. However, the application of lazy evaluation in SAS has not been extensively explored. This paper focuses on the mechanisms of lazy evaluation in SAS MACROs and R functions, offering a comparative analysis of the underlying principles that drive these processes.
  R's lazy evaluation is driven by a data structure called Promise, which postpones evaluation and does not occupy memory until the value is needed, utilizing a call-by-need strategy. SAS, on the other hand, achieves lazy evaluation through its symbol tables, employing memory to store parameters, and operates on a call-by-name basis. These discrepancies in lazy evaluation strategies can notably impact the results of R functions and SAS MACROs. By examining these distinct approaches, the paper illuminates the impact of lazy evaluation on programming efficiency, supported by illustrative examples. As the shift from SAS to R becomes increasingly prevalent in the pharmaceutical industry, understanding these techniques enables programmers to optimize their code for greater efficacy. This exploration serves as a guide to enhance programming capabilities and performance in both languages.

</details>


### [4] [Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT](https://arxiv.org/abs/2601.09986)
*Cheng Zhang,Qiancheng Fu,Hang Ji,Ines Santacruz Del Valle,Alexandra Silva,Marco Gaboardi*

Main category: cs.PL

TL;DR: 本文提出了几种高效的GKAT自动机迹等价决策程序，利用SAT求解器实现了即时符号技术。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发高效的算法来解决GKAT自动机的迹等价问题，并通过CF-GKAT系统验证控制流转换的实际应用。

Method: 方法包括使用SAT求解器的符号技术设计符号导数，并在Rust中实现算法，同时在随机生成的基准测试和实际控制流转换中进行评估。

Result: 结果显示在KAT和CF-GKAT上实现了数量级的性能提升，并发现了行业标准反编译器Ghidra中的一个错误。

Conclusion: 结论是我们的算法不仅在理论上高效，而且在实际应用中表现出色，证明了其在验证控制流转换中的实用性。

Abstract: This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [5] [A Control Theoretic Approach to Decentralized AI Economy Stabilization via Dynamic Buyback-and-Burn Mechanisms](https://arxiv.org/abs/2601.09961)
*Zehua Cheng,Wei Dai,Zhipeng Wang,Rui Sun,Nick Wen,Jiahao Sun*

Main category: cs.GT

TL;DR: 论文提出了一种名为动态控制回购机制（DCBM）的控制理论框架，通过PID控制器和严格的偿付能力约束来稳定去中心化AI网络的通证经济，显著降低了价格波动和运营商流失率。


<details>
  <summary>Details</summary>
Motivation: 当前的通证经济模型主要依赖静态或阈值回购策略，无法有效应对复杂系统动态，常常加剧市场波动，因此亟需一种动态稳定的经济机制来确保去中心化AI网络的长期可持续性。

Method: 作者提出了动态控制回购机制（DCBM），采用比例-积分-微分（PID）控制器，并结合严格的偿付能力约束，将通证经济作为动态系统进行调节。通过基于跳跃扩散过程的代理模拟验证了该方法的有效性。

Result: 结果显示，DCBM显著优于静态基线，在高波动性情境下，通证价格波动降低了约66%，运营商流失率从19.5%降至8.1%。

Conclusion: 研究表明，将通证经济从静态规则转化为连续的、结构化的控制回路是实现安全且可持续的去中心化智能网络的必要条件。

Abstract: The democratization of artificial intelligence through decentralized networks represents a paradigm shift in computational provisioning, yet the long-term viability of these ecosystems is critically endangered by the extreme volatility of their native economic layers. Current tokenomic models, which predominantly rely on static or threshold-based buyback heuristics, are ill-equipped to handle complex system dynamics and often function pro-cyclically, exacerbating instability during market downturns. To bridge this gap, we propose the Dynamic-Control Buyback Mechanism (DCBM), a formalized control-theoretic framework that utilizes a Proportional-Integral-Derivative (PID) controller with strict solvency constraints to regulate the token economy as a dynamical system. Extensive agent-based simulations utilizing Jump-Diffusion processes demonstrate that DCBM fundamentally outperforms static baselines, reducing token price volatility by approximately 66% and lowering operator churn from 19.5% to 8.1% in high-volatility regimes. These findings establish that converting tokenomics from static rules into continuous, structurally constrained control loops is a necessary condition for secure and sustainable decentralized intelligence networks.

</details>


### [6] [Inverse Learning in $2\times2$ Games: From Synthetic Interactions to Traffic Simulation](https://arxiv.org/abs/2601.10367)
*Daniela Aguirre Salazar,Firas Moatemri,Tatiana Tatarenko*

Main category: cs.GT

TL;DR: 该论文研究了从有限行为数据中理解多智能体系统的战略交互问题，提出了两种互补的反向博弈论学习方法，并在合成游戏和交通场景中进行了评估。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过有限行为数据建模多智能体系统的战略交互，为交通、机器人等领域提供理论基础和方法支持。

Method: 提出了两种方法：(i)针对2×2游戏的闭式相关均衡最大似然估计器(CE-ML)；(ii)通过随机响应过程捕捉长期适应动态的Logit最佳响应最大似然估计器(LBR-ML)。

Result: 在合成“胆小鬼”游戏和SUMO模拟的交通交互场景中进行了评估，揭示了模型在可解释性、计算易处理性和行为表现力之间的权衡。

Conclusion: 结论是两种方法在静态均衡一致性和动态行为真实性之间提供了互补视角，为理解和设计多智能体交互提供了实用工具。

Abstract: Understanding how agents coordinate or compete from limited behavioral data is central to modeling strategic interactions in traffic, robotics, and other multi-agent systems. In this work, we investigate the following complementary formulations of inverse game-theoretic learning: (i) a Closed-form Correlated Equilibrium Maximum-Likelihood estimator (CE-ML) specialized for $2\times2$ games; and (ii) a Logit Best Response Maximum-Likelihood estimator (LBR-ML) that captures long-run adaptation dynamics via stochastic response processes. Together, these approaches span the spectrum between static equilibrium consistency and dynamic behavioral realism. We evaluate them on synthetic "chicken-dare" games and traffic-interaction scenarios simulated in SUMO, comparing parameter recovery and distributional fit. Results reveal clear trade-offs between interpretability, computational tractability, and behavioral expressiveness across models.

</details>
