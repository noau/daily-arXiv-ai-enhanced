<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 6]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 6]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [The Last Mile to Production Readiness: Physics-Based Motion Refinement for Video-Based Capture](https://arxiv.org/abs/2601.19036)
*Tianxin Tao,Han Liu,Hung Yu Ling*

Main category: cs.GR

TL;DR: 论文提出了一种基于物理的运动优化框架，旨在解决视觉运动捕捉在物理真实性和制作准备性上的不足，减少人工清理的工作量并提升视觉效果。


<details>
  <summary>Details</summary>
Motivation: 视觉运动捕捉工具在游戏、电影、XR和机器人领域取得了显著进展，但在物理真实性和制作准备性上仍存在不足，导致需要大量人工清理。

Method: 通过案例研究和专业动画师的反馈总结关键问题，提出了一种基于物理的运动优化框架，支持单人和多人序列，并可集成到动画师的工作流程中。

Result: 框架能够减少人工清理的工作量，提升视觉效果和物理真实性，并支持进一步的风格化调整。

Conclusion: 该框架为运动清理的未来研究奠定了基础，并通过物理优化填补了现有工具的不足。

Abstract: High-quality motion data underpins games, film, XR, and robotics. Vision-based motion capture tools have made significant progress, offering accessible and visually convincing results, yet often fall short in the final stretch -- the last mile -- when it comes to physical realism and production readiness, due to various artifacts introduced during capture. In this paper, we summarize key issues through case studies and feedback from professional animators to set a stepping stone for future research in motion cleanup. We then present a physics-based motion refinement framework to bridge the gap, with the goal of reducing labor-intensive manual cleanup and enhancing visual quality and physical realism. Our framework supports both single- and multi-character sequences and can be integrated into animator workflows for further refinement, such as stylizing motions via keyframe editing.

</details>


### [2] [UniMGS: Unifying Mesh and 3D Gaussian Splatting with Single-Pass Rasterization and Proxy-Based Deformation](https://arxiv.org/abs/2601.19233)
*Zeyu Xiao,Mingyang Sun,Yimin Cong,Lintao Wang,Dongliang Kou,Zhenyi Wu,Dingkang Yang,Peng Zhai,Zeyu Wang,Lihua Zhang*

Main category: cs.GR

TL;DR: UniMGS是一个统一框架，旨在单次抗锯齿渲染中同时处理网格和3D高斯溅射（3DGS），通过创新的绑定策略解决变形中的视觉伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法分别渲染网格和3DGS，难以准确处理遮挡和透明性，且变形后的3DGS因对代理网格拓扑质量的敏感性而产生视觉伪影。UniMGS旨在解决这些问题。

Method: UniMGS通过单次抗锯齿α-blending混合三角形和高斯碎片的颜色，并使用基于代理网格的高斯中心绑定策略，显著减少变形3DGS的视觉伪影。

Result: UniMGS实现了视觉一致的渲染效果，精确处理了遮挡和透明性，为网格和3DGS的统一可视化与操作提供了新可能性。

Conclusion: UniMGS为网格和3DGS的统一处理提供了新框架，支持其在AI、虚拟现实和游戏中的广泛应用，未来将开源代码以促进研究。

Abstract: Joint rendering and deformation of mesh and 3D Gaussian Splatting (3DGS) have significant value as both representa tions offer complementary advantages for graphics applica tions. However, due to differences in representation and ren dering pipelines, existing studies render meshes and 3DGS separately, making it difficult to accurately handle occlusions and transparency. Moreover, the deformed 3DGS still suffers from visual artifacts due to the sensitivity to the topology quality of the proxy mesh. These issues pose serious obsta cles to the joint use of 3DGS and meshes, making it diffi cult to adapt 3DGS to conventional mesh-oriented graphics pipelines. We propose UniMGS, the first unified framework for rasterizing mesh and 3DGS in a single-pass anti-aliased manner, with a novel binding strategy for 3DGS deformation based on proxy mesh. Our key insight is to blend the col ors of both triangle and Gaussian fragments by anti-aliased α-blending in a single pass, achieving visually coherent re sults with precise handling of occlusion and transparency. To improve the visual appearance of the deformed 3DGS, our Gaussian-centric binding strategy employs a proxy mesh and spatially associates Gaussians with the mesh faces, signifi cantly reducing rendering artifacts. With these two compo nents, UniMGS enables the visualization and manipulation of 3D objects represented by mesh or 3DGS within a unified framework, opening up new possibilities in embodied AI, vir tual reality, and gaming. We will release our source code to facilitate future research.

</details>


### [3] [Words have Weight: Comparing the use of pressure and weight as a metaphor in a User Interface in Virtual Reality](https://arxiv.org/abs/2601.19294)
*Joffrey Guilmet,Suzanne Sorli,Diego Vilela Monteiro*

Main category: cs.GR

TL;DR: 本研究探讨了重量和压力如何作为触觉隐喻支持虚拟现实中的用户界面通知，发现压力增强了重量的感知，但并未提高通知的紧急感。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索未充分研究的重量和压力结合在虚拟现实用户界面通知中的作用。

Method: 开发了一种可穿戴触觉设备，通过在手背柔性容器中注入液体和空气独立控制重量和压力。

Result: 结果表明压力增强了重量的感知，但这种增强的重量并未提高通知的紧急感。

Conclusion: 结论是压力增强的重量可以丰富虚拟现实中的触觉渲染，但其在传达紧急感方面的作用还需进一步研究。

Abstract: This work investigates how weight and pressure can function as haptic metaphors to support user interface notifications in Virtual Reality (VR). While prior research has explored ungrounded weight simulation and pneumatic feedback, their combined role in conveying information through UI elements remains underexplored. We developed a wearable haptic device that transfers liquid and air into flexible containers mounted on the back of the user's hand, allowing us to independently manipulate weight and pressure. Through an initial evaluation using three conditions-no feedback, weight only, and weight combined with pressure-we examined how these signals affect perceived heaviness, coherence with visual cues, and the perceived urgency of notifications. Our results validate that pressure amplifies the perception of weight, but this increased heaviness does not translate into higher perceived urgency. These findings suggest that while pressure___enhanced weight can enrich haptic rendering of UI elements in VR, its contribution to communicating urgency may require further investigation, alternative pressure profiles, or different types of notifications.

</details>


### [4] [ClipGS-VR: Immersive and Interactive Cinematic Visualization of Volumetric Medical Data in Mobile Virtual Reality](https://arxiv.org/abs/2601.19310)
*Yuqi Tong,Ruiyang Li,Chengkun Li,Qixuan Liu,Shi Qiu,Pheng-Ann Heng*

Main category: cs.GR

TL;DR: ClipGS-VR通过重新结构化ClipGS的神经推理，实现了在移动虚拟现实(VR)上的高保真医学可视化，并支持任意角度切片。


<details>
  <summary>Details</summary>
Motivation: 移动VR上的高保真医学可视化仍然具有挑战性，ClipGS虽然支持截面探索，但缺乏在消费级VR头盔上的任意角度切片功能。

Method: 通过将ClipGS的神经推理整合为一个统一的数据集，结合梯度不透明度调制技术，实现任意角度切片和视觉连贯的渲染。

Result: 评估证实，该方法在视觉保真度上与离线结果相当，同时提供更高的可用性和交互效率。

Conclusion: ClipGS-VR成功实现了移动VR上的高保真医学可视化，支持任意角度切片，提升了用户体验。

Abstract: High-fidelity cinematic medical visualization on mobile virtual reality (VR) remains challenging. Although ClipGS enables cross-sectional exploration via 3D Gaussian Splatting, it lacks arbitrary-angle slicing on consumer-grade VR headsets. To achieve real-time interactive performance, we introduce ClipGS-VR and restructure ClipGS's neural inference into a consolidated dataset, integrating high-fidelity layers from multiple pre-computed slicing states into a unified rendering structure. Our framework further supports arbitrary-angle slicing via gradient-based opacity modulation for smooth, visually coherent rendering. Evaluations confirm our approach maintains visual fidelity comparable to offline results while offering superior usability and interaction efficiency.

</details>


### [5] [It's Not Just a Phase: Creating Phase-Aligned Peripheral Metamers](https://arxiv.org/abs/2601.19425)
*Sophie Kergaßner,Piotr Didyk*

Main category: cs.GR

TL;DR: 该论文提出了一种基于图像统计的高效生成图像信号的方法，通过局部图像统计的推断和合成，替代高频率细节的渲染，显著降低了精确渲染的内容量。


<details>
  <summary>Details</summary>
Motivation: 新型显示技术能为用户提供沉浸式体验，但全视野高质量渲染成本高昂。人类在视野周边区域的视觉感知不同于中心区域，因此需要利用视觉感知的局限来优化渲染效率。

Method: 方法从图像统计中发现，保留适当的局部统计对感知图像质量至关重要。基于此，论文从中心区域内容推断局部图像统计到高频范围，利用丰富的统计信息合成信号并添加到初始渲染中，提升感知质量。重点关注相位信息的空间和频率对齐。

Result: 与现有策略相比，该方法显著减少了需要精确渲染的内容，且合成额外信号的额外成本较低。

Conclusion: 通过合成替代精确渲染高频率细节的方法，可以在降低计算成本的同时保持感知质量，为高效渲染提供了新方向。

Abstract: Novel display technologies can deliver high-quality images across a wide field of view, creating immersive experiences. While rendering for such devices is expensive, most of the content falls into peripheral vision, where human perception differs from that in the fovea. Consequently, it is critical to understand and leverage the limitations of visual perception to enable efficient rendering. A standard approach is to exploit the reduced sensitivity to spatial details in the periphery by reducing rendering resolution, so-called foveated rendering. While this strategy avoids rendering part of the content altogether, an alternative promising direction is to replace accurate and expensive rendering with inexpensive synthesis of content that is perceptually indistinguishable from the ground-truth image. In this paper, we propose such a method for the efficient generation of an image signal that substitutes the rendering of high-frequency details. The method is grounded in findings from image statistics, which show that preserving appropriate local statistics is critical for perceived image quality. Based on this insight, we extrapolate several local image statistics from foveated content into higher spatial frequency ranges that are attenuated or omitted in the rendering process. This rich set of statistics is later used to synthesize a signal that is added to the initial rendering, boosting its perceived quality. We focus on phase information, demonstrating the importance of its alignment across space and frequencies. We calibrate and compare our method with state-of-the-art strategies, showing a significant reduction in the content that must be accurately rendered at a relatively small extra cost for synthesizing the additional signal.

</details>


### [6] [Graphical X Splatting (GraphiXS): A Graphical Model for 4D Gaussian Splatting under Uncertainty](https://arxiv.org/abs/2601.19843)
*Doga Yilmaz,Jialin Zhu,Deshan Gong,He Wang*

Main category: cs.GR

TL;DR: 论文提出了GraphiXS框架，系统地将数据不确定性引入高斯泼溅（Gaussian Splatting）中，填补了这一领域的空白。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅作为一种新兴的神经渲染范式，已在多个应用中展开研究，但数据不确定性（如视图稀疏性、帧缺失、相机不同步等）的研究尚未深入。

Method: 论文提出GraphiXS，一个概率框架，支持多种数据不确定性类型，并可扩展为多种基础模型（如高斯分布、Student's-t分布）。

Result: 实验证明，GraphiXS能系统性建模数据不确定性，在数据缺失或污染的情况下优于现有方法。

Conclusion: GraphiXS是对当前4D高斯泼溅研究的重大推广，为数据不确定性提供了全面的解决方案。

Abstract: We propose a new framework to systematically incorporate data uncertainty in Gaussian Splatting. Being the new paradigm of neural rendering, Gaussian Splatting has been investigated in many applications, with the main effort in extending its representation, improving its optimization process, and accelerating its speed. However, one orthogonal, much needed, but under-explored area is data uncertainty. In standard 4D Gaussian Splatting, data uncertainty can manifest as view sparsity, missing frames, camera asynchronization, etc. So far, there has been little research to holistically incorporating various types of data uncertainty under a single framework. To this end, we propose Graphical X Splatting, or GraphiXS, a new probabilistic framework that considers multiple types of data uncertainty, aiming for a fundamental augmentation of the current 4D Gaussian Splatting paradigm into a probabilistic setting. GraphiXS is general and can be instantiated with a range of primitives, e.g. Gaussians, Student's-t. Furthermore, GraphiXS can be used to `upgrade' existing methods to accommodate data uncertainty. Through exhaustive evaluation and comparison, we demonstrate that GraphiXS can systematically model various uncertainties in data, outperform existing methods in many settings where data are missing or polluted in space and time, and therefore is a major generalization of the current 4D Gaussian Splatting research.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs](https://arxiv.org/abs/2601.19207)
*Matthew Britton,Sasha Pak,Alex Potanin*

Main category: cs.PL

TL;DR: REM2.0是一个基于rust-analyzer的Rust代码重构工具链，专注于提取函数功能，并通过自动修复生命周期和签名问题，以及可选的验证管道，提供低延迟的重构和机器检查的行为保留。


<details>
  <summary>Details</summary>
Motivation: Rust的所有权、借用和高级类型特性使得自动化提取函数重构变得困难。现有工具要么依赖缓慢的编译器分析，要么仅支持受限的语言片段，或仅提供基本的编译保证。REM2.0旨在解决这些问题，为Rust提供快速且功能丰富的重构工具。

Method: REM2.0基于rust-analyzer作为持久守护进程运行，提供低延迟重构功能。它包括一个自动修复器，用于调整生命周期和签名问题，以及一个可选的验证管道，连接到CHARON和AENEAS，生成Coq等价证明。

Result: REM2.0在三个基准测试中表现优异：在原始REM测试中兼容性达到100%，延迟从1000ms降至个位数毫秒；在40个来自GitHub的高星仓库示例中，处理了异步/等待、泛型等复杂场景；在20个验证基准中，CHARON/AENEAS管道成功生成了端到端的等价证明。

Conclusion: REM2.0证明了基于rust-analyzer的设计可以为实际Rust程序提供快速且功能丰富的提取函数重构，同时通过可选验证实现了机器检查的行为保留。

Abstract: Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond "it still compiles." This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.

</details>


### [8] [For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426)
*Samy Avrillon,Ambrus Kaposi,Ambroise Lafont,Niyousha Najmaei,Johann Rosain*

Main category: cs.PL

TL;DR: 本文展示了如何将具有多排序的广义代数理论（GATs）简化为仅含两排序的GATs，并在模型间建立了严格的核心反射关系。


<details>
  <summary>Details</summary>
Motivation: 广义代数理论（GATs）通常包含多排序的复杂结构（如范畴论或Martin-L{ö}f类型论），但其复杂性限制了理论应用和实现。本文旨在简化GATs的结构，使其更易于处理和实现。

Method: 通过语义方法，将多排序的GATs简化为仅含两排序的GATs，并建立模型间的严格核心反射关系。该方法不依赖于语法描述，而是基于Uemura对GATs的初始代数特性分类。

Result: 简化后的GATs避免了排序等式和交错的排序与操作，使得其在实现上更为简洁。此外，该方法还为Cubical Agda中无法实现的QIITs提供了一种新的实现途径。

Conclusion: 本文提出的简化方法不仅减少了GATs的复杂性，还扩展了其应用范围，特别是在类型论及其实现中具有重要的理论和实践意义。

Abstract: Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity.
  The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [Fog of War Chess](https://arxiv.org/abs/2601.18813)
*Matthias Gehnen,Julius Stannat*

Main category: cs.GT

TL;DR: 本研究首次对迷雾象棋（Fog of War chess）残局进行了理论分析，重点研究了王和后对王、王和车对王、王和双车对王的局面。


<details>
  <summary>Details</summary>
Motivation: 迷雾象棋是国际象棋的一种变体，玩家只能部分了解对方棋子的位置。然而，目前缺乏对该游戏残局的理论分析，本研究旨在填补这一空白。

Method: 研究分析了三种残局局面：王和后对王、王和车对王、王和双车对王，通过理论推导探讨了这些局面中是否存在必胜策略。

Result: 研究发现，在王和后对王的局面中，玩家可以确保必胜；而在王和车对王的局面中，玩家无法确保必胜；然而，增加一名车后可确保必胜。

Conclusion: 本研究揭示了迷雾象棋残局中的必胜条件，为迷雾象棋的理论分析提供了重要基础。

Abstract: Fog of War chess is a popular variant of classical chess, in which both players have only partial information about the position of the opponent's pieces. This study provides the first theoretical analysis of endgames in Fog of War chess. In particular, we analyze the setups king and queen versus king, king and rook versus king, and king and two rooks versus king. We show that a king and queen can always guarantee a win against a lone king. In contrast to classical chess, a king and a rook cannot guarantee a win against a lone king. However, adding one more rook guarantees a win.

</details>


### [10] [Differential Voting: Loss Functions For Axiomatically Diverse Aggregation of Heterogeneous Preferences](https://arxiv.org/abs/2601.18824)
*Zhiyu An,Duaa Nakshbandi,Wan Du*

Main category: cs.GT

TL;DR: 研究提出了一个名为Differential Voting的统一框架，用于在RLHF中实现多样化的偏好聚合，使其成为一种可控的设计选择。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF方法通常依赖于单一偏好聚合原则（如BTL模型），这限制了学习奖励的公理性质并掩盖了优化中的规范性假设。为了解决这一问题，研究提出了一个更灵活的框架。

Method: 通过构建实例化的、可微分损失函数，Differential Voting框架实现了基于多数票、Copeland和Kemeny规则的不同偏好聚合方法。

Result: 研究证明了每种损失函数与对应社会选择规则的一致性，并分析了它们的校准特性、梯度场和平滑参数消失时的极限行为。

Conclusion: Differential Voting为RLHF中的偏好聚合提供了一种显式且可控的设计选择，使公理保证与优化稳定性之间的权衡更加原则化。

Abstract: Reinforcement learning from human feedback (RLHF) implicitly aggregates heterogeneous human preferences into a single utility function, even though the underlying utilities of the participants are in practice diverse. Hence, RLHF can be viewed as a form of voting, where the aggregation mechanism is defined by the loss function. Although Arrow's Impossibility Theorem suggests that different mechanisms satisfy different sets of desirable axioms, most existing methods rely on a single aggregation principle, typically the Bradley-Terry-Luce (BTL) model, which corresponds to Borda count voting. This restricts the axiomatic properties of the learned reward and obscures the normative assumptions embedded in optimization. In this work, we introduce Differential Voting, a unifying framework that constructs instance-wise, differentiable loss functions whose population-level optima provably correspond to distinct classical voting rules. We develop differentiable surrogates for majority-based aggregation (BTL), Copeland, and Kemeny rules, and formally analyze their calibration properties, gradient fields, and limiting behavior as smoothing parameters vanish. For each loss, we establish consistency with the corresponding social choice rule and characterize the axioms it satisfies or violates. Our analysis shows how design choices in loss geometry-such as margin sensitivity and boundary concentration-directly translate into normative aggregation behavior. Differential Voting makes preference aggregation an explicit and controllable design choice in RLHF, enabling principled trade-offs between axiomatic guarantees and optimization stability. Code to reproduce our experiments is open-sourced.

</details>


### [11] [Ad Insertion in LLM-Generated Responses](https://arxiv.org/abs/2601.19435)
*Shengwei Xu,Zhaohua Chen,Xiaotie Deng,Zhiyi Huang,Grant Schoenebeck*

Main category: cs.GT

TL;DR: 提出了一种解决大型语言模型可持续货币化挑战的框架，通过解耦广告插入与响应生成，并使用语义簇作为代理，实现高效、隐私保护的广告投放。


<details>
  <summary>Details</summary>
Motivation: 传统搜索广告无法捕捉对话流中短暂、依赖上下文的用户意图，且现有方法难以同时满足上下文连贯性、计算效率和伦理要求。

Method: 提出双解耦策略：广告插入与响应生成解耦以避免延迟和隐私问题；使用语义簇代替具体查询进行竞价以减少计算负担。

Result: 实验表明，该框架在激励相容性、社会福利优化和上下文连贯性评估上表现优异，且计算效率高。

Conclusion: 该框架有效解决了LLM广告的多重挑战，为可持续货币化提供了可行的解决方案。

Abstract: Sustainable monetization of Large Language Models (LLMs) remains a critical open challenge. Traditional search advertising, which relies on static keywords, fails to capture the fleeting, context-dependent user intents--the specific information, goods, or services a user seeks--embedded in conversational flows. Beyond the standard goal of social welfare maximization, effective LLM advertising imposes additional requirements on contextual coherence (ensuring ads align semantically with transient user intents) and computational efficiency (avoiding user interaction latency), as well as adherence to ethical and regulatory standards, including preserving privacy and ensuring explicit ad disclosure. Although various recent solutions have explored bidding on token-level and query-level, both categories of approaches generally fail to holistically satisfy this multifaceted set of constraints.
  We propose a practical framework that resolves these tensions through two decoupling strategies. First, we decouple ad insertion from response generation to ensure safety and explicit disclosure. Second, we decouple bidding from specific user queries by using ``genres'' (high-level semantic clusters) as a proxy. This allows advertisers to bid on stable categories rather than sensitive real-time response, reducing computational burden and privacy risks. We demonstrate that applying the VCG auction mechanism to this genre-based framework yields approximately dominant strategy incentive compatibility (DSIC) and individual rationality (IR), as well as approximately optimal social welfare, while maintaining high computational efficiency. Finally, we introduce an "LLM-as-a-Judge" metric to estimate contextual coherence. Our experiments show that this metric correlates strongly with human ratings (Spearman's $ρ\approx 0.66$), outperforming 80% of individual human evaluators.

</details>


### [12] [Single-Winner Voting on Matchings](https://arxiv.org/abs/2601.19653)
*Niclas Boehmer,Jessica Dierking*

Main category: cs.GT

TL;DR: 本文研究了在图匹配投票问题中，选民如何从可行匹配中选择最优匹配，并探讨了计算可行性的复杂性。结果表明，不同的效用模型或解决方案可能会导致计算复杂性的显著变化。


<details>
  <summary>Details</summary>
Motivation: 传统的匹配问题中，选民通常是图的一部分，而本文探讨的场景中选民对整个匹配有偏好，这种新颖视角下的计算复杂性尚未被充分研究。

Method: 研究采用了社会福利最大化、帕累托最优结果构建与验证、以及康多塞赢家存在性与验证等方法，分析了一种线性效用模型和两种基于认可的效用模型。

Result: 研究结果表明，计算可行性取决于效用模型或解决方案的微妙变化，部分情况下可以恢复计算可行性，而其他情况下则存在计算复杂性障碍。

Conclusion: 本文揭示了在图匹配投票问题中，不同效用模型和解决方案之间的复杂性边界，为未来的研究和实际应用提供了理论基础。

Abstract: We introduce a single-winner perspective on voting on matchings, in which voters have preferences over possible matchings in a graph, and the goal is to select a single collectively desirable matching. Unlike in classical matching problems, voters in our model are not part of the graph; instead, they have preferences over the entire matching. In the resulting election, the candidate space consists of all feasible matchings, whose exponential size renders standard algorithms for identifying socially desirable outcomes computationally infeasible. We study whether the computational tractability of finding such outcomes can be regained by exploiting the matching structure of the candidate space. Specifically, we provide a complete complexity landscape for questions concerning the maximization of social welfare, the construction and verification of Pareto optimal outcomes, and the existence and verification of Condorcet winners under one affine and two approval-based utility models. Our results consist of a mix of algorithmic and intractability results, revealing sharp boundaries between tractable and intractable cases, with complexity jumps arising from subtle changes in the utility model or solution concept.

</details>


### [13] [Robustness of Approval-Based Multiwinner Voting Rules](https://arxiv.org/abs/2601.19706)
*Piotr Faliszewski,Grzegorz Gawron,Bartosz Kusek*

Main category: cs.GT

TL;DR: 研究基于批准的多赢家投票规则在投票出现小扰动时的鲁棒性，包括添加/删除/交换一个批准对委员会的影响及其计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 探讨投票规则在现实中的稳定性，尤其是在面临选民行为微小变化时的表现。

Method: 通过分析添加/删除/交换一个批准对委员会的潜在影响，并研究相关问题的计算复杂性及其计数变体。

Result: 揭示了变更委员会所需的操作次数及其计算复杂性，同时计算了随机扰动导致选举结果变化的概率。

Conclusion: 该研究为理解投票规则在小扰动下的稳定性提供了理论基础，并在计算复杂性方面提出了新的研究问题。

Abstract: We investigate how robust approval-based multiwinner voting rules are to small perturbations in the votes. In particular, we consider the extent to which a committee can change after we add/remove/swap one approval, and we consider the computational complexity of deciding how many such operations are necessary to change the set of winning committees. We also consider the counting variants of our problems, which can be interpreted as computing the probability that the result of an election changes after a given number of random perturbations of the given election.

</details>


### [14] [How Similar Are Two Elections?](https://arxiv.org/abs/2601.19716)
*Piotr Faliszewski,Piotr Skowron,Arkadii Slinko,Krzysztof Sornat,Stanisław Szufa,Nimrod Talmon*

Main category: cs.GT

TL;DR: 这篇论文研究了一种基于同构距离的选举分析方法，提出了一种能够保持候选人及选民名称不变的距离度量，并探讨了其计算复杂性和近似难度。


<details>
  <summary>Details</summary>
Motivation: 为了解决选举分析中如何度量两个选举之间的相似性，同时避免名称变动带来的影响，论文提出了同构距离的概念。

Method: 论文通过扩展偏好顺序之间的距离d，定义了选举之间的同构距离d-ID，并通过统一候选人名称和匹配选民投票来计算最小总距离。

Result: 研究发现，选举同构测试可以在多项式时间内完成，但某些自然同构距离的计算是NP完全的且难以近似；同时，论文提供了若干参数化的FPT算法以缓解计算复杂性。

Conclusion: 论文证实了选举同构距离的计算在某些情况下是可行的，但也揭示了其计算复杂性的挑战，并提出了一些参数化解决方案。

Abstract: We introduce and study isomorphic distances between ordinal
  elections (with the same numbers of candidates and voters). The main
  feature of these distances is that they are invariant to renaming
  the candidates and voters, and two elections are at distance zero if
  and only if they are isomorphic. Specifically, we consider
  isomorphic extensions of distances between preference orders: Given
  such a distance d, we extend it to distance d-ID between
  elections by unifying candidate names and finding a matching between
  the votes, so that the sum of the d-distances between the matched
  votes is as small as possible.
  We show that testing isomorphism of two elections can be done in
  polynomial time so, in principle, such distances can be tractable.
  Yet, we show that two very natural isomorphic distances are
  NP-complete and hard to approximate. We attempt to rectify the
  situation by showing FPT algorithms for several natural
  parameterizations.

</details>
