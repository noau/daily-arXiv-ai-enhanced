{"id": "2602.09110", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.09110", "abs": "https://arxiv.org/abs/2602.09110", "authors": ["Ioannis Anagnostides", "Ian Gemp", "Georgios Piliouras", "Kelly Spendlove"], "title": "Tight Inapproximability for Welfare-Maximizing Autobidding Equilibria", "comment": null, "summary": "We examine the complexity of computing welfare- and revenue-maximizing equilibria in autobidding second-price auctions subject to return-on-spend (RoS) constraints. We show that computing an autobidding equilibrium that approximates the welfare-optimal one within a factor of $2 - ε$ is NP-hard for any constant $ε> 0$. Moreover, deciding whether there exists an autobidding equilibrium that attains a $1/2 + ε$ fraction of the optimal welfare -- unfettered by equilibrium constraints -- is NP-hard for any constant $ε> 0$. This hardness result is tight in view of the fact that the price of anarchy (PoA) is at most $2$, and shows that deciding whether a non-trivial autobidding equilibrium exists -- one that is even marginally better than the worst-case guarantee -- is intractable. For revenue, we establish a stronger logarithmic inapproximability, while under the projection games conjecture, our reduction rules out even a polynomial approximation factor. These results significantly strengthen the APX-hardness of Li and Tang (AAAI '24). Furthermore, we refine our reduction in the presence of ML advice concerning the buyers' valuations, revealing again a close connection between the inapproximability threshold and PoA bounds. Finally, we examine relaxed notions of equilibrium attained by simple learning algorithms, establishing constant inapproximability for both revenue and welfare."}
{"id": "2602.09118", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.09118", "abs": "https://arxiv.org/abs/2602.09118", "authors": ["Ioannis Anagnostides", "Ian Gemp", "Georgios Piliouras", "Kelly Spendlove"], "title": "Chaos in Autobidding Auctions", "comment": null, "summary": "As autobidding systems increasingly dominate online advertising auctions, characterizing their long-term dynamical behavior is brought to the fore. In this paper, we examine the dynamics of autobidders who optimize value subject to a return-on-spend (RoS) constraint under uniform bid scaling. Our main set of results show that simple autobidding dynamics can exhibit formally chaotic behavior. This significantly strengthens the recent results of Leme, Piliouras, Schneider, Spendlove, and Zuo (EC '24) that went as far as quasiperiodicity. Our proof proceeds by establishing that autobidding dynamics can simulate -- up to an arbitrarily small error -- a broad class of continuous-time nonlinear dynamical systems. This class contains as a special case Chua's circuit, a classic chaotic system renowned for its iconic double scroll attractor. Our reduction develops several modular gadgets, which we anticipate will find other applications going forward. Moreover, in discrete time, we show that different incarnations of mirror descent can exhibit Li-Yorke chaos, topological transitivity, and sensitivity to initial conditions, connecting along the way those dynamics to classic dynamical systems such as the logistic map and the Ricker population model. Taken together, our results reveal that the long-term behavior of ostensibly simple second-price autobidding auctions can be inherently unpredictable and complex."}
{"id": "2602.09357", "categories": ["cs.GT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.09357", "abs": "https://arxiv.org/abs/2602.09357", "authors": ["Raef Bassily", "Kate Donahue", "Diptangshu Sen", "Annuo Zhao", "Juba Ziani"], "title": "Data Sharing with Endogenous Choices over Differential Privacy Levels", "comment": "40 pages", "summary": "We study coalition formation for data sharing under differential privacy when agents have heterogeneous privacy costs. Each agent holds a sensitive data point and decides whether to participate in a data-sharing coalition and how much noise to add to their data. Privacy choices induce a fundamental trade-off: higher privacy reduces individual data-sharing costs but degrades data utility and statistical accuracy for the coalition. These choices generate externalities across agents, making both participation and privacy levels strategic. Our goal is to understand which coalitions are stable, how privacy choices shape equilibrium outcomes, and how decentralized data sharing compares to a centralized, socially optimal benchmark.\n  We provide a comprehensive equilibrium analysis across a broad range of privacy-cost regimes, from decreasing costs (e.g., privacy amplification from pooling data) to increasing costs (e.g., greater exposure to privacy attacks in larger coalitions). We first characterize Nash equilibrium coalitions with endogenous privacy levels and show that equilibria may fail to exist and can be non-monotonic in problem parameters. We also introduce a weaker equilibrium notion called robust equilibrium (that allows more widespread equilibrium existence by equipping existing players in the coalition with the power to prevent or veto external players from joining) and fully characterize such equilibria. Finally, we analyze, for both Nash and robust equilibria, the efficiency relative to the social optimum in terms of social welfare and estimator accuracy. We derive bounds that depend sharply on the number of players, properties of the cost profile and how privacy costs scale with coalition size."}
{"id": "2602.09455", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09455", "abs": "https://arxiv.org/abs/2602.09455", "authors": ["Haoran Sun", "Xuanzhi Xia", "Xu Chu", "Xiaotie Deng"], "title": "Enhancing Affine Maximizer Auctions with Correlation-Aware Payment", "comment": "22 pages. Work in progress", "summary": "Affine Maximizer Auctions (AMAs), a generalized mechanism family from VCG, are widely used in automated mechanism design due to their inherent dominant-strategy incentive compatibility (DSIC) and individual rationality (IR). However, as the payment form is fixed, AMA's expressiveness is restricted, especially in distributions where bidders' valuations are correlated. In this paper, we propose Correlation-Aware AMA (CA-AMA), a novel framework that augments AMA with a new correlation-aware payment. We show that any CA-AMA preserves the DSIC property and formalize finding optimal CA-AMA as a constraint optimization problem subject to the IR constraint. Then, we theoretically characterize scenarios where classic AMAs can perform arbitrarily poorly compared to the optimal revenue, while the CA-AMA can reach the optimal revenue. For optimizing CA-AMA, we design a practical two-stage training algorithm. We derive that the target function's continuity and the generalization bound on the degree of deviation from strict IR. Finally, extensive experiments showcase that our algorithm can find an approximate optimal CA-AMA in various distributions with improved revenue and a low degree of violation of IR."}
{"id": "2602.09902", "categories": ["cs.GT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09902", "abs": "https://arxiv.org/abs/2602.09902", "authors": ["Rafid Mahmood"], "title": "Routing, Cascades, and User Choice for LLMs", "comment": "23 pages, accepted in ICLR 2026", "summary": "To mitigate the trade-offs between performance and costs, LLM providers route user tasks to different models based on task difficulty and latency. We study the effect of LLM routing with respect to user behavior. We propose a game between an LLM provider with two models (standard and reasoning) and a user who can re-prompt or abandon tasks if the routed model cannot solve them. The user's goal is to maximize their utility minus the delay from using the model, while the provider minimizes the cost of servicing the user. We solve this Stackelberg game by fully characterizing the user best response and simplifying the provider problem. We observe that in nearly all cases, the optimal routing policy involves a static policy with no cascading that depends on the expected utility of the models to the user. Furthermore, we reveal a misalignment gap between the provider-optimal and user-preferred routes when the user's and provider's rankings of the models with respect to utility and cost differ. Finally, we demonstrate conditions for extreme misalignment where providers are incentivized to throttle the latency of the models to minimize their costs, consequently depressing user utility. The results yield simple threshold rules for single-provider, single-user interactions and clarify when routing, cascading, and throttling help or harm."}
{"id": "2602.10053", "categories": ["cs.GT", "econ.TH"], "pdf": "https://arxiv.org/pdf/2602.10053", "abs": "https://arxiv.org/abs/2602.10053", "authors": ["Raman Ebrahimi", "Sepehr Ilami", "Babak Heydari", "Isabel Trevino", "Massimo Franceschetti"], "title": "The Architecture of Illusion: Network Opacity and Strategic Escalation", "comment": "34 pages, 6 figures", "summary": "Standard models of bounded rationality typically assume agents either possess accurate knowledge of the population's reasoning abilities (Cognitive Hierarchy) or hold dogmatic, degenerate beliefs (Level-$k$). We introduce the ``Connected Minds'' model, which unifies these frameworks by integrating iterative reasoning with a parameterized network bias. We posit that agents do not observe the global population; rather, they observe a sample biased by their network position, governed by a locality parameter $p$ representing algorithmic ranking, social homophily, or information disclosure. We show that this parameter acts as a continuous bridge: the model collapses to the myopic Level-$k$ recursion as networks become opaque ($p \\to 0$) and recovers the standard Cognitive Hierarchy model under full transparency ($p=1$). Theoretically, we establish that network opacity induces a \\emph{Sophisticated Bias}, causing agents to systematically overestimate the cognitive depth of their opponents while preserving the log-concavity of belief distributions. This makes $p$ an actionable lever: a planner or platform can tune transparency -- globally or by segment (a personalized $p_k$) -- to shape equilibrium behavior. From a mechanism design perspective, we derive the \\emph{Escalation Principle}: in games of strategic complements, restricting information can maximize aggregate effort by trapping agents in echo chambers where they compete against hallucinated, high-sophistication peers. Conversely, we identify a \\emph{Transparency Reversal} for coordination games, where maximizing network visibility is required to minimize variance and stabilize outcomes. Our results suggest that network topology functions as a cognitive zoom lens, determining whether agents behave as local imitators or global optimizers."}
{"id": "2602.10083", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.10083", "abs": "https://arxiv.org/abs/2602.10083", "authors": ["Daria Boratyn", "Dariusz Stolicki"], "title": "Allocation Proportionality of OWA--Based Committee Scoring Rules", "comment": "17 pages, 4 figures", "summary": "While proportionality is frequently named as a desirable property of voting rules, its interpretation in multiwinner voting differs significantly from that in apportionment. We aim to bridge these two distinct notions of proportionality by introducing the concept of allocation proportionality, founded upon the framework of party elections, where each candidate in a multiwinner election is assigned to a party. A voting rule is allocation proportional if each party's share of elected candidates equals that party's aggregate score. Recognizing that no committee scoring rule can universally satisfy allocation proportionality in practice, we introduce a new measure of allocation proportionality degree and discuss how it relates to other quantitative measures of proportionality. This measure allows us to compare OWA-based committee scoring rules according to how much they diverge from the ideal of allocation proportionality. We present experimental results for several common rules: SNTV, $k$-Borda, Chamberlin-Courant, Harmonic Borda, Proportional $k$-Approval Voting, and Bloc Voting."}
{"id": "2602.10096", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2602.10096", "abs": "https://arxiv.org/abs/2602.10096", "authors": ["Brian Hu Zhang", "Ioannis Anagnostides", "Kiriaki Fragkia", "Maria-Florina Balcan", "Tuomas Sandholm"], "title": "The Complexity of Proper Equilibrium in Extensive-Form and Polytope Games", "comment": "This paper contains and extends results that were originally in a prior version of arXiv:2511.03968", "summary": "The proper equilibrium, introduced by Myerson (1978), is a classic refinement of the Nash equilibrium that has been referred to as the \"mother of all refinements.\" For normal-form games, computing a proper equilibrium is known to be PPAD-complete for two-player games and FIXP$_a$-complete for games with at least three players. However, the complexity beyond normal-form games -- in particular, for extensive-form games (EFGs) -- was a long-standing open problem first highlighted by Miltersen and Sørensen (SODA '08). In this paper, we resolve this problem by establishing PPAD- and FIXP$_a$-membership (and hence completeness) of normal-form proper equilibria in two-player and multi-player EFGs respectively. Our main ingredient is a technique for computing a perturbed (proper) best response that can be computed efficiently in EFGs. This is despite the fact that, as we show, computing a best response using the classic perturbation of Kohlberg and Mertens based on the permutahedron is #P-hard even in Bayesian games. In stark contrast, we show that computing a proper equilibrium in polytope games is NP-hard. This marks the first natural class in which the complexity of computing equilibrium refinements does not collapse to that of Nash equilibria, and the first problem in which equilibrium computation in polytope games is strictly harder -- unless there is a collapse in the complexity hierarchy -- relative to extensive-form games."}
