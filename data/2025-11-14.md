<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Cyclotron: Compilation of Recurrences to Distributed and Systolic Architectures](https://arxiv.org/abs/2511.09987)
*Shiv Sundram,Akhilesh Balasingam,Nathan Zhang,Kunle Olukotun,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: Cyclotron是一个用于通过递归方程表达流式数据流算法的框架和编译器，可便携地编译成分布式拓扑结构的互联处理器。其优化机制使得内存交互仅限于迭代空间边界，提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的流式数据流算法实现通常缺乏便携性和优化能力，尤其是在分布式环境中。Cyclotron旨在提供一个统一的框架和编译器，以解决这些问题。

Method: Cyclotron采用递归方程表达算法，并通过多级中间语言将其转换为处理器的特定操作。优化后的IR使内存交互仅限于迭代空间边界，内部数据访问则完全本地化。此外，提供调度语言以实现数据流的定义和执行管线的优化。

Result: Cyclotron展示了其便携性，可编译到可重构的模拟器和分布式CPU集群。在模拟环境中支持硬件设计空间探索；在CPU集群中高效实现了多种矩阵运算（如Cannon、SUMMA）和解算器（如三角解和Cholesky），性能与ScaLAPACK相当。

Conclusion: Cyclotron通过递归方程和优化的中间表示，实现了高性能和便携的分布式流式数据流算法编译。其方法在多种硬件平台上表现优异，为分布式计算提供了灵活且高效的解决方案。

Abstract: We present Cyclotron, a framework and compiler for using recurrence equations to express streaming dataflow algorithms, which then get portably compiled to distributed topologies of interlinked processors. Our framework provides an input language of recurrences over logical tensors, which then gets lowered into an intermediate language of recurrences over logical iteration spaces, and finally into programs of send, receive, and computation operations specific to each individual processor. In Cyclotron's IR, programs are optimized such that external memory interactions are confined to the boundaries of the iteration space. Within inner iteration spaces, all data accesses become local: data accesses target values residing in local fast memory or on neighboring processing units, avoiding costly memory movement. We provide a scheduling language allowing users to define how data gets streamed and broadcasted between processors, enabling pipelined execution of computation kernels over distributed topologies of processing elements. We demonstrate the portability of our approach by compiling our IR to a reconfigurable simulator of systolic arrays and chiplet style distributed hardware, as well as to distributed-memory CPU clusters. In the simulated reconfigurable setting, we use our compiler for hardware design space exploration in which link costs and latencies can be specified. In the distributed CPU setting, we show how to use recurrences and our scheduling language to express various matrix multiplication routines (Cannon, SUMMA, PUMMA, weight stationary) and solvers (Triangular solve and Cholesky). For matrix multiplication and the triangular solve, we generate distributed implementations competitive with ScaLAPACK.

</details>


### [2] [Omnidirectional type inference for ML: principality any way](https://arxiv.org/abs/2511.10343)
*Alistair O'Brien,Didier Rémy,Gabriel Scherer*

Main category: cs.PL

TL;DR: 提出了一种名为“全向类型推断”的方法，通过动态处理类型信息流，解决了ML类型系统扩展中的主推断性问题，增强了表达力。


<details>
  <summary>Details</summary>
Motivation: ML类型系统的主推断性在许多扩展（如GADTs、高阶多态性和静态重载）中受到威胁，导致类型推断变得脆弱且不灵活。现有方法通过固定的推断顺序处理这些问题，但可能导致原本有效的程序被拒绝。

Method: 提出了“全向类型推断”方法，允许类型信息以动态顺序流动，并使用“挂起匹配约束”解决类型约束。通过“增量实例化”技术，克服了let-generalization的挑战。

Result: 该方法成功应用于OCaml的两个不同特性（记录标签和数据类型构造器的静态重载、半显式一级多态），实现了更具表达力的主类型推断算法。

Conclusion: 全向类型推断提供了一种通用框架，能够在不牺牲主推断性的基础上支持脆弱的语言特性，增强了类型系统的灵活性和表达力。

Abstract: The Damas-Hindley-Milner (ML) type system owes its success to principality, the property that every well-typed expression has a unique most general type. This makes inference predictable and efficient. Unfortunately, many extensions of ML (GADTs, higher-rank polymorphism, and static overloading) endanger princpality by introducing _fragile_ constructs that resist principal inference. Existing approaches recover principality through directional inference algorithms, which propagate _known_ type information in a fixed (or static) order (e.g. as in bidirectional typing) to disambiguate such constructs. However, the rigidity of a static inference order often causes otherwise well-typed programs to be rejected.
  We propose _omnidirectional_ type inference, where type information flows in a dynamic order. Typing constraints may be solved in any order, suspending when progress requires known type information and resuming once it becomes available, using _suspended match constraints_. This approach is straightforward for simply typed systems, but extending it to ML is challenging due to let-generalization. Existing ML inference algorithms type let-bindings (let x = e1 in e2) in a fixed order: type e1, generalize its type, and then type e2. To overcome this, we introduce _incremental instantiation_, allowing partially solved type schemes containing suspended constraints to be instantiated, with a mechanism to incrementally update instances as the scheme is refined.
  Omnidirectionality provides a general framework for restoring principality in the presence of fragile features. We demonstrate its versatility on two fundamentally different features of OCaml: static overloading of record labels and datatype constructors and semi-explicit first-class polymorphism. In both cases, we obtain a principal type inference algorithm that is more expressive than OCaml's current typechecker.

</details>


### [3] [Lazy Linearity for a Core Functional Language](https://arxiv.org/abs/2511.10361)
*Rodrigo Mesquita,Bernardo Toninho*

Main category: cs.PL

TL;DR: 线性核心（Linear Core）是一种新的系统，适用于惰性语言如GHC的核心中间语言，它通过接受线性性的惰性语义，确保线性资源使用的正确性。


<details>
  <summary>Details</summary>
Motivation: 传统线性类型语言中，线性资源的消耗与其在程序中的语法出现直接相关，但在非严格求值环境下，线性性可以从语义层面理解。Haskell的优化编译器会重写源代码，破坏语法线性性但保留语义，这一问题亟待解决。

Method: 提出了线性核心（Linear Core）系统，该系统静态接受线性性的惰性语义，并通过编译器插件实现。

Result: 证明了线性核心的正确性，确保了线性资源的使用，同时展示了多个优化转换在线性核心中保持线性性而在传统核心中失败。

Conclusion: 线性核心为惰性语言提供了一种有效的线性资源管理方法，且通过实验验证了其在线性资源密集型库中的实用性。

Abstract: Traditionally, in linearly typed languages, consuming a linear resource is synonymous with its syntactic occurrence in the program. However, under the lens of non-strict evaluation, linearity can be further understood semantically, where a syntactic occurrence of a resource does not necessarily entail using that resource when the program is executed. While this distinction has been largely unexplored, it turns out to be inescapable in Haskell's optimising compiler, which heavily rewrites the source program in ways that break syntactic linearity but preserve the program's semantics. We introduce Linear Core, a novel system which accepts the lazy semantics of linearity statically and is suitable for lazy languages such as the Core intermediate language of the Glasgow Haskell Compiler. We prove that Linear Core is sound, guaranteeing linear resource usage, and that multiple optimising transformations preserve linearity in Linear Core while failing to do so in Core. We have implemented Linear Core as a compiler plugin to validate the system against linearity-heavy libraries, including linear-base.

</details>


### [4] [Modeling Layout Abstractions Using Integer Set Relations](https://arxiv.org/abs/2511.10374)
*Somashekaracharya G Bhaskaracharya,Aravind Acharya,Bastian Hagedorn,Vinod Grover*

Main category: cs.PL

TL;DR: 本文提出了一种利用整数集库（ISL）的新方法，通过整数集关系为CuTe布局和Triton线性布局创建统一的数学表示，支持形式化分析和跨系统优化。


<details>
  <summary>Details</summary>
Motivation: 现有的CuTe布局和Triton线性布局系统因其不同的数学基础而无法进行统一的形式化分析和跨系统推理。

Method: 使用整数集关系分别建模CuTe布局（基于跨步计算的坐标到索引转换）和Triton线性布局（基于有限域F_2规则的二进制向量空间变换），并通过ISL实现布局操作算法。

Result: 实验表明，该系统能够处理从简单标识变换到复杂多维度张量排列的全频谱布局问题，验证了数学模型的有效性。

Conclusion: 提出的方法成功地为不同布局系统提供了统一的数学基础，支持形式化验证并为未来的跨系统优化奠定了基础。

Abstract: Modern deep learning compilers rely on layout abstractions to manage the complex mapping between logical tensor structures and physical memory arrangements. CuTe layouts and Triton linear layouts are widely adopted industry standards. However, these layout systems operate independently with distinct mathematical underpinnings, preventing unified formal analysis and cross-system reasoning. We bridge this gap by introducing a novel approach that leverages the Integer Set Library (ISL) to create a unified mathematical representation for both layout systems through integer set relations, thereby enabling rigorous formal analysis, correctness verification, and the foundation for future cross-system optimization strategies. Our approach models CuTe layouts through integer set relations that encode the transformation from multi-dimensional coordinates to linear indices using stride-based calculations, including sophisticated swizzle operations that perform bit-level manipulations for enhanced memory access patterns. For Triton linear layouts, we construct integer set relations that model the binary vector space transformations where arithmetic operations follow finite field F_2 rules. We implement a complete suite of layout manipulation algorithms for composition, inversion, complement using built-in operations in ISL to ensure mathematical correctness and preserve layout semantics. Experimental evaluation shows that the system handles the full spectrum of layout complexity, from elementary identity transformations to sophisticated multi-dimensional tensor arrangements with complex stride configurations and swizzle patterns, validating the mathematical modeling approach across different layout paradigms.

</details>


### [5] [zkStruDul: Programming zkSNARKs with Structural Duality](https://arxiv.org/abs/2511.10565)
*Rahul Krishnan,Ashley Samuelson,Emily Yao,Ethan Cecchetti*

Main category: cs.PL

TL;DR: zkStruDul是一种语言，将输入转换和谓词定义统一为一个抽象，避免了重复逻辑和安全漏洞，同时支持递归证明等功能。


<details>
  <summary>Details</summary>
Motivation: 现有工具专注于定义需要证明的谓词，但在实际应用中，优化谓词定义以最小化证明生成开销时，需要相应转换谓词输入。分开实现这两个步骤会导致逻辑重复和安全漏洞的风险。

Method: 提出了zkStruDul语言，将输入转换和谓词定义统一为一个抽象，编译器可以从该抽象中生成两个过程，消除了代码重复和不匹配问题。

Result: zkStruDul不仅提供了一种高层次的抽象方法，还支持递归证明等重要功能，并通过证明其源级语义与投影语义一致确保了标准推理的简便性。

Conclusion: zkStruDul解决了现有工具在处理优化谓词定义时的逻辑重复和安全漏洞问题，为NIZK技术提供了一个高效且安全的解决方案。

Abstract: Non-Interactive Zero Knowledge (NIZK) proofs, such as zkSNARKS, let one prove knowledge of private data without revealing it or interacting with a verifier. While existing tooling focuses on specifying the predicate to be proven, real-world applications optimize predicate definitions to minimize proof generation overhead, but must correspondingly transform predicate inputs. Implementing these two steps separately duplicates logic that must precisely match to avoid catastrophic security flaws. We address this shortcoming with zkStruDul, a language that unifies input transformations and predicate definitions into a single combined abstraction from which a compiler can project both procedures, eliminating duplicate code and problematic mismatches. zkStruDul provides a high-level abstraction to layer on top of existing NIZK technology and supports important features like recursive proofs. We provide a source-level semantics and prove its behavior is identical to the projected semantics, allowing straightforward standard reasoning.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [6] [Truth, Justice, and Secrecy: Cake Cutting Under Privacy Constraints](https://arxiv.org/abs/2511.09882)
*Yaron Salman,Tamir Tassa,Omer Lev,Roie Zivan*

Main category: cs.GT

TL;DR: 本文扩展了Chen等人的策略证明算法，引入了隐私保护维度，提出了首个隐私保护的蛋糕切割协议，该协议同时具有嫉妒自由和策略证明性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有蛋糕切割算法在公平性和策略证明性方面取得进展，但代理可能因隐私问题不愿透露真实偏好。本文旨在解决这一问题。

Method: 采用加密技术替代集中式计算，确保隐私保护同时不损害公平性或策略证明性。

Result: 提出了首个隐私保护、嫉妒自由和策略证明的蛋糕切割协议。

Conclusion: 新协议不仅能防止代理撒谎的动机，还能保护其隐私，从而鼓励真实偏好报告。

Abstract: Cake-cutting algorithms, which aim to fairly allocate a continuous resource based on individual agent preferences, have seen significant progress over the past two decades. Much of the research has concentrated on fairness, with comparatively less attention given to other important aspects. Chen et al. (2010) introduced an algorithm that, in addition to ensuring fairness, was strategyproof -- meaning agents had no incentive to misreport their valuations. However, even in the absence of strategic incentives to misreport, agents may still hesitate to reveal their true preferences due to privacy concerns (e.g., when allocating advertising time between firms, revealing preferences could inadvertently expose planned marketing strategies or product launch timelines). In this work, we extend the strategyproof algorithm of Chen et al. by introducing a privacy-preserving dimension. To the best of our knowledge, we present the first private cake-cutting protocol, and, in addition, this protocol is also envy-free and strategyproof. Our approach replaces the algorithm's centralized computation with a novel adaptation of cryptographic techniques, enabling privacy without compromising fairness or strategyproofness. Thus, our protocol encourages agents to report their true preferences not only because they are not incentivized to lie, but also because they are protected from having their preferences exposed.

</details>


### [7] [Robust Resource Allocation via Competitive Subsidies](https://arxiv.org/abs/2511.09934)
*David X. Lin,Giannis Fikioris,Siddhartha Banerjee,Éva Tardos*

Main category: cs.GT

TL;DR: 本文提出了一种新的0.625-鲁棒性机制，打破了之前0.6的限制，主要通过简单的拍卖方式实现。


<details>
  <summary>Details</summary>
Motivation: 现有的拍卖机制在非货币在线资源分配中，最多只能达到0.6的鲁棒性，无法接近非战略情况下的0.63上限。本文旨在打破这一限制。

Method: 提出了一种简单的拍卖机制：每轮投标者决定是否请求项目，然后随机分配给请求者之一，并引入竞争补贴概念调整中标者的信用支付。

Result: 新机制实现了0.625的鲁棒性，接近非战略上限0.63，并通过改进达到均衡策略下的0.61鲁棒性。

Conclusion: 本文的机制在拍卖类别中提供了最优的鲁棒性界限，填补了理论与实际之间的差距。

Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.

</details>


### [8] [Facility Location for Congesting Commuters and Generalizing the Cost-Distance Problem](https://arxiv.org/abs/2511.10228)
*Thanasis Lianeas,Marios Mertzanidis,Aikaterini Nikolidaki*

Main category: cs.GT

TL;DR: 本文介绍了一种新颖的设施选址问题，即面向拥堵（自私）通勤者的设施选址问题，基于拥堵依赖的连接成本，提出了针对非递减和非递增成本函数的近似解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的设施选址问题假设连接成本固定，但实际中通勤者的拥堵会影响连接成本。本文旨在解决这一现实问题，研究如何在拥堵依赖的成本下优化设施选址。

Method: 对于非递减成本函数，本文创新地应用了近似Caratheodory定理来推导问题的近似解；对于非递增成本函数，问题被推广为成本距离问题，并提出了一种算法，确保相同的近似保证。

Result: 本文证明了在拥堵依赖的连接成本下，设施选址问题的不可近似性，并通过提出的方法为不同成本函数提供了有效的近似解。

Conclusion: 本文为解决拥堵环境下的设施选址问题提供了理论和方法支持，扩展了传统设施选址问题的适用范围，并为实际应用提供了可行的解决方案。

Abstract: In Facility Location problems there are agents that should be connected to facilities and locations where facilities may be opened so that agents can connect to them. We depart from Uncapacitated Facility Location and by assuming that the connection costs of agents to facilities are congestion dependent, we define a novel problem, namely, Facility Location for Congesting (Selfish) Commuters. The connection costs of agents to facilities come as a result of how the agents commute to reach the facilities in an underlying network with cost functions on the edges. Inapproximability results follow from the related literature and thus approximate solutions is all we can hope for. For when the cost functions are nondecreasing we employ in a novel way an approximate version of Caratheodory's Theorem [5] to show how approximate solutions for different versions of the problem can be derived. For when the cost functions are nonincreasing we show how this problem generalizes the Cost-Distance problem [38] and provide an algorithm that for this more general case achieves the same approximation guarantees.

</details>
