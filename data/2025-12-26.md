<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 3]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Efficient Computation of Integer-constrained Cones for Conformal Parameterizations](https://arxiv.org/abs/2512.20904)
*Wei Du,Qing Fang,Ligang Liu,Xiao-Ming Fu*

Main category: cs.GR

TL;DR: 提出一种高效计算整数约束锥奇异点集的方法，实现低失真且旋转无缝的共形参数化。


<details>
  <summary>Details</summary>
Motivation: 为了解决高曲面数据处理中的共形参数化问题，需要一种高效且低失真的方法。

Method: 交替优化顶点约束位置、整数约束角度和锥数量三种离散变量，引入显式构造算法和新导数公式。

Result: 在大规模测试数据集上实现了旋转无缝且低失真的参数化，速度比现有方法快30倍。

Conclusion: 该方法在锥数量和参数化失真之间实现了良好的平衡，具有高效性和实用性。

Abstract: We propose an efficient method to compute a small set of integer-constrained cone singularities, which induce a rotationally seamless conformal parameterization with low distortion. Since the problem only involves discrete variables, i.e., vertex-constrained positions, integer-constrained angles, and the number of cones, we alternately optimize these three types of variables to achieve tractable convergence. Central to high efficiency is an explicit construction algorithm that reduces the optimization problem scale to be slightly greater than the number of integer variables for determining the optimal angles with fixed positions and numbers, even for high-genus surfaces. In addition, we derive a new derivative formula that allows us to move the cones, effectively reducing distortion until convergence. Combined with other strategies, including repositioning and adding cones to decrease distortion, adaptively selecting a constrained number of integer variables for efficient optimization, and pairing cones to reduce the number, we quickly achieve a favorable tradeoff between the number of cones and the parameterization distortion. We demonstrate the effectiveness and practicability of our cones by using them to generate rotationally seamless and low-distortion parameterizations on a massive test data set. Our method demonstrates an order-of-magnitude speedup (30$\times$ faster on average) compared to state-of-the-art approaches while maintaining comparable cone numbers and parameterization distortion.

</details>


### [2] [AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences](https://arxiv.org/abs/2512.20943)
*Zhe Wang,Jinghang Li,Yifei Zhu*

Main category: cs.GR

TL;DR: AirGS是一个优化的4D高斯溅射框架，通过重新设计训练和交付流程，提升了自由视点视频的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的4D高斯溅射方法在长序列中质量下降，带宽和存储开销大，限制了实时和大规模应用。

Method: AirGS将高斯视频流转换为多通道2D格式，智能识别关键帧，并结合时间相干性和膨胀损失优化训练和传输效率。

Result: 实验表明，AirGS在场景变化时PSNR偏差减少20%以上，训练加速6倍，传输大小减少50%。

Conclusion: AirGS显著提升了自由视点视频的质量和效率，适用于实时和大规模部署。

Abstract: Free-viewpoint video (FVV) enables immersive viewing experiences by allowing users to view scenes from arbitrary perspectives. As a prominent reconstruction technique for FVV generation, 4D Gaussian Splatting (4DGS) models dynamic scenes with time-varying 3D Gaussian ellipsoids and achieves high-quality rendering via fast rasterization. However, existing 4DGS approaches suffer from quality degradation over long sequences and impose substantial bandwidth and storage overhead, limiting their applicability in real-time and wide-scale deployments. Therefore, we present AirGS, a streaming-optimized 4DGS framework that rearchitects the training and delivery pipeline to enable high-quality, low-latency FVV experiences. AirGS converts Gaussian video streams into multi-channel 2D formats and intelligently identifies keyframes to enhance frame reconstruction quality. It further combines temporal coherence with inflation loss to reduce training time and representation size. To support communication-efficient transmission, AirGS models 4DGS delivery as an integer linear programming problem and design a lightweight pruning level selection algorithm to adaptively prune the Gaussian updates to be transmitted, balancing reconstruction quality and bandwidth consumption. Extensive experiments demonstrate that AirGS reduces quality deviation in PSNR by more than 20% when scene changes, maintains frame-level PSNR consistently above 30, accelerates training by 6 times, reduces per-frame transmission size by nearly 50% compared to the SOTA 4DGS approaches.

</details>


### [3] [TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars](https://arxiv.org/abs/2512.21099)
*Jaeseong Lee,Junyeong Ahn,Taewoong Kang,Jaegul Choo*

Main category: cs.GR

TL;DR: TexAvatars是一种混合型3D头像表示方法，结合了分析绑定的几何基础和纹理空间的空间连续性，提升了极端姿势和表情下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有3D头像构建方法在极端重演场景中泛化能力有限，且几何一致性和复杂变形外推能力不足。TexAvatars旨在解决这些问题。

Method: TexAvatars结合CNN预测UV空间的局部几何属性，并通过网格感知的雅可比矩阵驱动3D变形，实现平滑且语义清晰的三角形边界过渡。

Result: TexAvatars在极端姿势和表情变化下表现优异，能够高保真地捕捉肌肉引起的皱纹、眉间纹和口腔几何等细节。

Conclusion: TexAvatars通过分离语义建模和几何控制，提升了泛化能力、可解释性和稳定性，在挑战性头像重演场景中达到最优性能。

Abstract: Constructing drivable and photorealistic 3D head avatars has become a central task in AR/XR, enabling immersive and expressive user experiences. With the emergence of high-fidelity and efficient representations such as 3D Gaussians, recent works have pushed toward ultra-detailed head avatars. Existing approaches typically fall into two categories: rule-based analytic rigging or neural network-based deformation fields. While effective in constrained settings, both approaches often fail to generalize to unseen expressions and poses, particularly in extreme reenactment scenarios. Other methods constrain Gaussians to the global texel space of 3DMMs to reduce rendering complexity. However, these texel-based avatars tend to underutilize the underlying mesh structure. They apply minimal analytic deformation and rely heavily on neural regressors and heuristic regularization in UV space, which weakens geometric consistency and limits extrapolation to complex, out-of-distribution deformations. To address these limitations, we introduce TexAvatars, a hybrid avatar representation that combines the explicit geometric grounding of analytic rigging with the spatial continuity of texel space. Our approach predicts local geometric attributes in UV space via CNNs, but drives 3D deformation through mesh-aware Jacobians, enabling smooth and semantically meaningful transitions across triangle boundaries. This hybrid design separates semantic modeling from geometric control, resulting in improved generalization, interpretability, and stability. Furthermore, TexAvatars captures fine-grained expression effects, including muscle-induced wrinkles, glabellar lines, and realistic mouth cavity geometry, with high fidelity. Our method achieves state-of-the-art performance under extreme pose and expression variations, demonstrating strong generalization in challenging head reenactment settings.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [4] [Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems](https://arxiv.org/abs/2512.20688)
*Stefano Grassi*

Main category: cs.GT

TL;DR: 这篇论文提出了机制基础智能（MBI）范式，通过可微分价格机制（DPM）解决多智能体系统中的信息分散和激励对齐问题，提供了一种高效且可扩展的协调方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在解决信息分散（Hayekian问题）和激励对齐（Hurwiczian问题）时表现脆弱，导致协调计算复杂。研究发现传统的单一大脑智能模式难以应对这些挑战，因此需要新的范式。

Method: 论文引入了机制基础智能（MBI）范式，其核心是可微分价格机制（DPM），通过计算动态的VCG等效激励信号来保证激励兼容性和全局最优收敛。贝叶斯扩展进一步确保了在信息不对称条件下的激励兼容性（BIC）。

Result: 该方法在智能体数量上具有线性复杂度（O(N)），比无模型强化学习快50倍，能够高效解决Dec-POMDP的组合复杂性。实验结果验证了其高效性和可扩展性。

Conclusion: MBI通过将智能体自利与集体目标结构对齐，提供了一种基于经济学原理的可证明高效、可审计且通用的多智能体智能协调方法。

Abstract: Autonomous multi-agent systems are fundamentally fragile: they struggle to solve the Hayekian Information problem (eliciting dispersed private knowledge) and the Hurwiczian Incentive problem (aligning local actions with global objectives), making coordination computationally intractable. I introduce Mechanism-Based Intelligence (MBI), a paradigm that reconceptualizes intelligence as emergent from the coordination of multiple "brains", rather than a single one. At its core, the Differentiable Price Mechanism (DPM) computes the exact loss gradient $$ \mathbf{G}_i = - \frac{\partial \mathcal{L}}{\partial \mathbf{x}_i} $$ as a dynamic, VCG-equivalent incentive signal, guaranteeing Dominant Strategy Incentive Compatibility (DSIC) and convergence to the global optimum. A Bayesian extension ensures incentive compatibility under asymmetric information (BIC). The framework scales linearly ($\mathcal{O}(N)$) with the number of agents, bypassing the combinatorial complexity of Dec-POMDPs and is empirically 50x faster than Model-Free Reinforcement Learning. By structurally aligning agent self-interest with collective objectives, it provides a provably efficient, auditable and generalizable approach to coordinated, trustworthy and scalable multi-agent intelligence grounded in economic principles.

</details>


### [5] [(Im)possibility of Incentive Design for Challenge-based Blockchain Protocols](https://arxiv.org/abs/2512.20864)
*Suhyeon Lee,Dieu-Huyen Nguyen,Donghwan Lee*

Main category: cs.GT

TL;DR: 区块链通过去中心化和安全执行环境支持加密货币，但状态复制模型导致链上计算成本高。Truebit和乐观汇总等技术通过挑战协议将计算移出链外，仅在受挑战时调用链，降低正常情况成本并能防止欺诈。本文研究在存在少数串通者和异构成本的情况下，是否能同时实现诚实无损失和欺诈威慑的目标。


<details>
  <summary>Details</summary>
Motivation: 研究挑战协议在诚实挑战者激励和不诚实提议者受损方面的有效性，特别是在最坏情况下。

Method: 构建了一个模型，包括少数串通者、异构成本和三种排序模式，探讨是否能在单赢家设计中实现诚实无损失和欺诈威慑的双重目标。

Result: 单赢家设计中激励设计不可能或规模受限，而在多赢家设计中能通过简单明确的条件下实现双重目标。

Conclusion: 多赢家设计优于单赢家设计，能更有效地满足诚实无损失和欺诈威慑的目标。

Abstract: Blockchains offer a decentralized and secure execution environment strong enough to host cryptocurrencies, but the state-replication model makes on-chain computation expensive. To avoid heavy on-chain workloads, systems like Truebit and optimistic rollups use challenge-based protocols, performing computations off-chain and invoking the chain only when challenged. This keeps normal-case costs low and, if at least one honest challenger exists, can catch fraud. What has been less clear is whether honest challengers are actually incentivized and a dishonest proposer is properly damaged under the worst case environment. We build a model with a colluding minority, heterogeneous costs, and three ordering modes. We then ask whether two goals can be met together: honest non-loss and fraud deterrence. Our results are clear: in single-winner designs, the incentive design is impossible or limited in scale. By contrast, in multi-winner designs, we obtain simple, explicit conditions under which both goals hold.

</details>


### [6] [Policy-Conditioned Policies for Multi-Agent Task Solving](https://arxiv.org/abs/2512.21024)
*Yue Lin,Shuhui Zhu,Wenhao Li,Ang Li,Dan Qiao,Pascal Poupart,Hongyuan Zha,Baoxiang Wang*

Main category: cs.GT

TL;DR: 论文提出了一种将策略表示为人类可读源代码的范式转变，利用大型语言模型（LLMs）作为近似解释器，以解决多智能体任务中的动态策略适应挑战。


<details>
  <summary>Details</summary>
Motivation: 在多智能体任务中，动态策略适应的核心挑战在于神经策略的高维性和不透明性，导致无法直接条件化对手策略。

Method: 通过将策略表示为源代码，并利用LLMs在程序化策略空间中进行优化，提出了一种基于文本梯度的程序化迭代最佳响应（PIBR）算法。

Result: 该方法成功解决了多个标准协调矩阵游戏和一个合作性基于等级的觅食环境问题。

Conclusion: 研究表明，程序化表示与LLMs的结合为解决多智能体任务中的策略适应问题提供了有效途径。

Abstract: In multi-agent tasks, the central challenge lies in the dynamic adaptation of strategies. However, directly conditioning on opponents' strategies is intractable in the prevalent deep reinforcement learning paradigm due to a fundamental ``representational bottleneck'': neural policies are opaque, high-dimensional parameter vectors that are incomprehensible to other agents. In this work, we propose a paradigm shift that bridges this gap by representing policies as human-interpretable source code and utilizing Large Language Models (LLMs) as approximate interpreters. This programmatic representation allows us to operationalize the game-theoretic concept of \textit{Program Equilibrium}. We reformulate the learning problem by utilizing LLMs to perform optimization directly in the space of programmatic policies. The LLM functions as a point-wise best-response operator that iteratively synthesizes and refines the ego agent's policy code to respond to the opponent's strategy. We formalize this process as \textit{Programmatic Iterated Best Response (PIBR)}, an algorithm where the policy code is optimized by textual gradients, using structured feedback derived from game utility and runtime unit tests. We demonstrate that this approach effectively solves several standard coordination matrix games and a cooperative Level-Based Foraging environment.

</details>
