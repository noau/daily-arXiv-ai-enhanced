{"id": "2509.11418", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.11418", "abs": "https://arxiv.org/abs/2509.11418", "authors": ["Runming Li", "Yue Yao", "Robert Harper"], "title": "Mechanizing Synthetic Tait Computability in Istari", "comment": null, "summary": "Categorical gluing is a powerful technique for proving meta-theorems of type\ntheories such as canonicity and normalization. Synthetic Tait Computability\n(STC) provides an abstract treatment of the complex gluing models by\ninternalizing the gluing category into a modal dependent type theory with a\nphase distinction. This work presents a mechanization of STC in the Istari\nproof assistant. Istari is a Martin-L\\\"{o}f-style extensional type theory with\nequality reflection. Equality reflection eliminates the nuisance of transport\nreasoning typically found in intensional proof assistants. This work develops a\nreusable library for synthetic phase distinction, including modalities,\nextension types, and strict glue types, and applies it to two case studies: (1)\na canonicity model for dependent type theory with dependent products and\nbooleans with large elimination, and (2) a Kripke canonicity model for the\ncost-aware logical framework. Our results demonstrate that the core STC\nconstructions can be formalized essentially verbatim in Istari, preserving the\nelegance of the on-paper arguments while ensuring machine-checked correctness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Istari\u8bc1\u660e\u52a9\u624b\u4e2d\u673a\u68b0\u5316\u7684STC\uff08\u5408\u6210Tait\u53ef\u8ba1\u7b97\u6027\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u73b0\u7c7b\u578b\u7406\u8bba\u7684\u5143\u5b9a\u7406\u8bc1\u660e\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u901a\u8fc7\u5408\u6210Tait\u53ef\u8ba1\u7b97\u6027\uff08STC\uff09\u8fd9\u4e00\u62bd\u8c61\u65b9\u6cd5\uff0c\u7b80\u5316\u590d\u6742\u7684\u80f6\u5408\u6a21\u578b\uff0c\u5e76\u5728Martin-L\\\"{o}f\u98ce\u683c\u7684\u6269\u5c55\u7c7b\u578b\u7406\u8bba\u4e2d\u673a\u68b0\u5316\u4e3a\u53ef\u590d\u7528\u7684\u5e93\u3002", "method": "\u5728Istari\u8bc1\u660e\u52a9\u624b\u4e2d\u5b9e\u73b0STC\uff0c\u5f00\u53d1\u5305\u542b\u6a21\u6001\u3001\u6269\u5c55\u7c7b\u578b\u548c\u4e25\u683c\u80f6\u5408\u7c7b\u578b\u7684\u5408\u6210\u76f8\u533a\u5206\u5e93\uff0c\u5e76\u5e94\u7528\u4e8e\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86STC\u6838\u5fc3\u6784\u9020\u5728Istari\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4fdd\u7559\u4e86\u7eb8\u9762\u8bba\u8bc1\u7684\u4f18\u96c5\u540c\u65f6\u786e\u4fdd\u4e86\u673a\u5668\u68c0\u67e5\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86STC\u5728Istari\u4e2d\u7684\u673a\u68b0\u5316\u5b9e\u73b0\uff0c\u4e3a\u7c7b\u578b\u7406\u8bba\u7684\u5143\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2509.11901", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2509.11901", "abs": "https://arxiv.org/abs/2509.11901", "authors": ["Kentaro Kobayashi", "Yukiyoshi Kameyama"], "title": "Expressive Power of One-Shot Control Operators and Coroutines", "comment": "Full version of the paper accepted at APLAS 2025. Includes appendices\n  with proofs. 59 pages", "summary": "Control operators, such as exceptions and effect handlers, provide a means of\nrepresenting computational effects in programs abstractly and modularly. While\nmost theoretical studies have focused on multi-shot control operators, one-shot\ncontrol operators -- which restrict the use of captured continuations to at\nmost once -- are gaining attention for their balance between expressiveness and\nefficiency. This study aims to fill the gap. We present a mathematically\nrigorous comparison of the expressive power among one-shot control operators,\nincluding effect handlers, delimited continuations, and even asymmetric\ncoroutines. Following previous studies on multi-shot control operators, we\nadopt Felleisen's macro-expressiveness as our measure of expressiveness. We\nverify the folklore that one-shot effect handlers and one-shot\ndelimited-control operators can be macro-expressed by asymmetric coroutines,\nbut not vice versa. We explain why a previous informal argument fails, and how\nto revise it to make a valid macro-translation.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e00\u62cd\u63a7\u5236\u8fd0\u7b97\u7b26\uff08\u5982\u5f02\u5e38\u548c\u6548\u679c\u5904\u7406\u7a0b\u5e8f\uff09\u7684\u8868\u8fbe\u529b\uff0c\u8bc1\u5b9e\u4e86\u4e0d\u5bf9\u79f0\u534f\u7a0b\u53ef\u4ee5\u5b8f\u8868\u8fbe\u4e00\u62cd\u6548\u679c\u5904\u7406\u7a0b\u5e8f\u548c\u4e00\u62cd\u5b9a\u754c\u63a7\u5236\u8fd0\u7b97\u7b26\uff0c\u4f46\u53cd\u4e4b\u4e0d\u6210\u7acb\u3002", "motivation": "\u4e00\u62cd\u63a7\u5236\u8fd0\u7b97\u7b26\u5728\u8868\u8fbe\u529b\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4f46\u76ee\u524d\u5bf9\u5176\u8868\u8fbe\u529b\u7684\u7406\u8bba\u6bd4\u8f83\u4ecd\u5b58\u5728\u7a7a\u767d\u3002", "method": "\u91c7\u7528Felleisen\u7684\u5b8f\u8868\u8fbe\u529b\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\uff0c\u5bf9\u4e00\u62cd\u6548\u679c\u5904\u7406\u7a0b\u5e8f\u3001\u5b9a\u754c\u63a7\u5236\u8fd0\u7b97\u7b26\u548c\u4e0d\u5bf9\u79f0\u534f\u7a0b\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u6570\u5b66\u6bd4\u8f83\u3002", "result": "\u9a8c\u8bc1\u4e86\u4e00\u62cd\u6548\u679c\u5904\u7406\u7a0b\u5e8f\u548c\u5b9a\u754c\u63a7\u5236\u8fd0\u7b97\u7b26\u53ef\u4ee5\u88ab\u4e0d\u5bf9\u79f0\u534f\u7a0b\u5b8f\u8868\u8fbe\uff0c\u4f46\u53cd\u4e4b\u4e0d\u6210\u7acb\uff0c\u5e76\u4fee\u6b63\u4e86\u5148\u524d\u7684\u975e\u6b63\u5f0f\u8bba\u8bc1\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u4e00\u62cd\u63a7\u5236\u8fd0\u7b97\u7b26\u7684\u8868\u8fbe\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u89e3\u3002"}}
{"id": "2509.10983", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2509.10983", "abs": "https://arxiv.org/abs/2509.10983", "authors": ["Mai Pham", "Vikrant Vaze", "Peter Chin"], "title": "Strategic Cyber Defense via Reinforcement Learning-Guided Combinatorial Auctions", "comment": "IEEE HPEC'25", "summary": "Cyber defense operations increasingly require long-term strategic planning\nunder uncertainty and resource constraints. We propose a new use of\ncombinatorial auctions for allocating defensive action bundles in a realistic\ncyber environment, using host-specific valuations derived from reinforcement\nlearning (RL) Q-values. These Q-values encode long-term expected utility,\nallowing upstream planning. We train CAFormer, a differentiable\nTransformer-based auction mechanism, to produce allocations that are\napproximately incentive-compatible under misreporting. Rather than benchmarking\nagainst existing agents, we explore the qualitative and strategic properties of\nthe learned mechanisms. Compared to oracle and heuristic allocations, our\nmethod achieves competitive revenue while offering robustness to misreporting.\nIn addition, we find that allocation patterns correlate with adversarial and\ndefensive activity, suggesting implicit alignment with operational priorities.\nOur results demonstrate the viability of auction-based planning in cyber\ndefense and highlight the interpretability benefits of RL-derived value\nstructures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ec4\u5408\u62cd\u5356\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7f51\u7edc\u9632\u5fa1\u8d44\u6e90\u914d\u7f6e\u65b9\u6cd5CAFormer\uff0c\u5176\u5728\u9762\u5bf9\u8bef\u62a5\u65f6\u5177\u6709\u8fd1\u4f3c\u6fc0\u52b1\u76f8\u5bb9\u6027\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u5c55\u73b0\u51fa\u4e0e\u64cd\u4f5c\u4f18\u5148\u7ea7\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u7f51\u7edc\u9632\u5fa1\u64cd\u4f5c\u9700\u8981\u957f\u671f\u6218\u7565\u89c4\u5212\uff0c\u4e14\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u548c\u8d44\u6e90\u9650\u5236\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60Q\u503c\u751f\u6210\u4e3b\u673a\u7279\u5b9a\u4f30\u503c\uff0c\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u53ef\u5fae\u5206\u62cd\u5356\u673a\u5236CAFormer\uff0c\u5b9e\u73b0\u8fd1\u4f3c\u6fc0\u52b1\u76f8\u5bb9\u7684\u8d44\u6e90\u5206\u914d\u3002", "result": "\u76f8\u6bd4\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0cCAFormer\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u6536\u5165\u7684\u540c\u65f6\uff0c\u5177\u5907\u4e86\u8bef\u62a5\u9c81\u68d2\u6027\uff0c\u4e14\u5206\u914d\u6a21\u5f0f\u4e0e\u653b\u9632\u6d3b\u52a8\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u62cd\u5356\u7684\u89c4\u5212\u65b9\u6cd5\u5728\u7f51\u7edc\u9632\u5fa1\u4e2d\u5177\u6709\u53ef\u884c\u6027\uff0c\u4e14\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u7684\u4ef7\u503c\u7ed3\u6784\u5177\u6709\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\u3002"}}
{"id": "2509.10599", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.10599", "abs": "https://arxiv.org/abs/2509.10599", "authors": ["Yongxue Chen", "Tao Liu", "Yuming Huang", "Weiming Wang", "Tianyu Zhang", "Kun Qian", "Zikang Shi", "Charlie C. L. Wang"], "title": "Can any model be fabricated? Inverse operation based planning for hybrid additive-subtractive manufacturing", "comment": null, "summary": "This paper presents a method for computing interleaved additive and\nsubtractive manufacturing operations to fabricate models of arbitrary shapes.\nWe solve the manufacturing planning problem by searching a sequence of inverse\noperations that progressively transform a target model into a null shape. Each\ninverse operation corresponds to either an additive or a subtractive step,\nensuring both manufacturability and structural stability of intermediate shapes\nthroughout the process. We theoretically prove that any model can be fabricated\nexactly using a sequence generated by our approach. To demonstrate the\neffectiveness of this method, we adopt a voxel-based implementation and develop\na scalable algorithm that works on models represented by a large number of\nvoxels. Our approach has been tested across a range of digital models and\nfurther validated through physical fabrication on a hybrid manufacturing system\nwith automatic tool switching.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u589e\u6750\u4e0e\u51cf\u6750\u5236\u9020\u64cd\u4f5c\u6765\u5236\u9020\u4efb\u610f\u5f62\u72b6\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u5236\u9020\u53ef\u884c\u6027\u548c\u7ed3\u6784\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5236\u9020\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u590d\u6742\u6a21\u578b\u7684\u5236\u9020\u53ef\u884c\u6027\u548c\u7ed3\u6784\u7a33\u5b9a\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u4ea4\u66ff\u8fdb\u884c\u589e\u6750\u4e0e\u51cf\u6750\u64cd\u4f5c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u641c\u7d22\u4ece\u76ee\u6807\u6a21\u578b\u9010\u6b65\u53d8\u5f62\u4e3a\u7a7a\u5f62\u72b6\u7684\u9006\u5411\u64cd\u4f5c\u5e8f\u5217\uff0c\u6bcf\u4e00\u6b65\u5bf9\u5e94\u589e\u6750\u6216\u51cf\u6750\u64cd\u4f5c\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u4f53\u7d20\u7684\u5b9e\u73b0\u65b9\u6cd5\u5f00\u53d1\u53ef\u6269\u5c55\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4efb\u4f55\u6a21\u578b\u5747\u53ef\u901a\u8fc7\u8be5\u65b9\u6cd5\u7cbe\u786e\u5236\u9020\uff0c\u5e76\u901a\u8fc7\u6570\u5b57\u6a21\u578b\u548c\u7269\u7406\u5236\u9020\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u6a21\u578b\u7684\u5236\u9020\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u4f53\u7d20\u6a21\u578b\uff0c\u5e76\u5728\u6df7\u5408\u5236\u9020\u7cfb\u7edf\u4e2d\u5f97\u5230\u4e86\u5b9e\u9645\u9a8c\u8bc1\u3002"}}
{"id": "2509.10989", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2509.10989", "abs": "https://arxiv.org/abs/2509.10989", "authors": ["Zhenlong Fang", "Aryan Deshwal", "Yue Yu"], "title": "Actively Learning to Coordinate in Convex Games via Approximate Correlated Equilibrium", "comment": null, "summary": "Correlated equilibrium generalizes Nash equilibrium by allowing a central\ncoordinator to guide players' actions through shared recommendations, similar\nto how routing apps guide drivers. We investigate how a coordinator can learn a\ncorrelated equilibrium in convex games where each player minimizes a convex\ncost function that depends on other players' actions, subject to convex\nconstraints without knowledge of the players' cost functions. We propose a\nlearning framework that learns an approximate correlated equilibrium by\nactively querying players' regrets, \\emph{i.e.}, the cost saved by deviating\nfrom the coordinator's recommendations. We first show that a correlated\nequilibrium in convex games corresponds to a joint action distribution over an\ninfinite joint action space that minimizes all players' regrets. To make the\nlearning problem tractable, we introduce a heuristic that selects finitely many\nrepresentative joint actions by maximizing their pairwise differences. We then\napply Bayesian optimization to learn a probability distribution over the\nselected joint actions by querying all players' regrets. The learned\ndistribution approximates a correlated equilibrium by minimizing players'\nregrets. We demonstrate the proposed approach via numerical experiments on\nmulti-user traffic assignment games in a shared transportation network.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u51f8\u6e38\u620f\u4e2d\u901a\u8fc7\u4e3b\u52a8\u67e5\u8be2\u73a9\u5bb6\u7684\u540e\u6094\u503c\u6765\u5b66\u4e60\u8fd1\u4f3c\u76f8\u5173\u5747\u8861\u7684\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u73a9\u5bb6\u6210\u672c\u51fd\u6570\u672a\u77e5\u7684\u51f8\u6e38\u620f\u4e2d\uff0c\u901a\u8fc7\u4e2d\u592e\u534f\u8c03\u5458\u7684\u5b66\u4e60\u6846\u67b6\u8fbe\u6210\u76f8\u5173\u5747\u8861\uff0c\u7c7b\u4f3c\u4e8e\u8def\u7531\u5e94\u7528\u6307\u5bfc\u53f8\u673a\u7684\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u8054\u5408\u884c\u52a8\u7684\u6210\u5bf9\u5dee\u5f02\u9009\u62e9\u6709\u9650\u4ee3\u8868\u884c\u52a8\uff0c\u5e76\u5e94\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u5b66\u4e60\u8fd9\u4e9b\u884c\u52a8\u4e0a\u7684\u6982\u7387\u5206\u5e03\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u5728\u591a\u7528\u6237\u4ea4\u901a\u5206\u914d\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u5206\u5e03\u8fd1\u4f3c\u76f8\u5173\u5747\u8861\uff0c\u6700\u5c0f\u5316\u73a9\u5bb6\u7684\u540e\u6094\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6709\u9650\u67e5\u8be2\u548c\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u6210\u529f\u5728\u51f8\u6e38\u620f\u4e2d\u5b9e\u73b0\u4e86\u8fd1\u4f3c\u76f8\u5173\u5747\u8861\uff0c\u5c55\u793a\u4e86\u5728\u5171\u4eab\u4ea4\u901a\u7f51\u7edc\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.10678", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.10678", "abs": "https://arxiv.org/abs/2509.10678", "authors": ["Jiahao Luo", "Chaoyang Wang", "Michael Vasilkovsky", "Vladislav Shakhrai", "Di Liu", "Peiye Zhuang", "Sergey Tulyakov", "Peter Wonka", "Hsin-Ying Lee", "James Davis", "Jian Wang"], "title": "T2Bs: Text-to-Character Blendshapes via Video Generation", "comment": null, "summary": "We present T2Bs, a framework for generating high-quality, animatable\ncharacter head morphable models from text by combining static text-to-3D\ngeneration with video diffusion. Text-to-3D models produce detailed static\ngeometry but lack motion synthesis, while video diffusion models generate\nmotion with temporal and multi-view geometric inconsistencies. T2Bs bridges\nthis gap by leveraging deformable 3D Gaussian splatting to align static 3D\nassets with video outputs. By constraining motion with static geometry and\nemploying a view-dependent deformation MLP, T2Bs (i) outperforms existing 4D\ngeneration methods in accuracy and expressiveness while reducing video\nartifacts and view inconsistencies, and (ii) reconstructs smooth, coherent,\nfully registered 3D geometries designed to scale for building morphable models\nwith diverse, realistic facial motions. This enables synthesizing expressive,\nanimatable character heads that surpass current 4D generation techniques.", "AI": {"tldr": "T2Bs\u662f\u4e00\u4e2a\u7ed3\u5408\u9759\u6001\u6587\u672c\u52303D\u751f\u6210\u4e0e\u89c6\u9891\u6269\u6563\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u52a8\u753b\u5316\u7684\u89d2\u8272\u5934\u90e8\u53ef\u53d8\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u52303D\u6a21\u578b\u867d\u80fd\u751f\u6210\u8be6\u7ec6\u9759\u6001\u51e0\u4f55\u4f46\u7f3a\u4e4f\u8fd0\u52a8\u5408\u6210\uff0c\u800c\u89c6\u9891\u6269\u6563\u6a21\u578b\u867d\u80fd\u751f\u6210\u8fd0\u52a8\u4f46\u5b58\u5728\u65f6\u95f4\u548c\u591a\u89c6\u89d2\u51e0\u4f55\u4e0d\u4e00\u81f4\u95ee\u9898\u3002T2Bs\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5229\u7528\u53ef\u53d8\u5f62\u76843D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u5c06\u9759\u60013D\u8d44\u4ea7\u4e0e\u89c6\u9891\u8f93\u51fa\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u9759\u6001\u51e0\u4f55\u7ea6\u675f\u8fd0\u52a8\u548c\u4f9d\u8d56\u89c6\u89d2\u7684\u53d8\u5f62MLP\u3002", "result": "T2Bs\u5728\u51c6\u786e\u6027\u548c\u8868\u73b0\u529b\u4e0a\u8d85\u8d8a\u73b0\u67094D\u751f\u6210\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u5c11\u89c6\u9891\u4f2a\u5f71\u548c\u89c6\u89d2\u4e0d\u4e00\u81f4\uff0c\u5e76\u91cd\u5efa\u5e73\u6ed1\u3001\u8fde\u8d2f\u3001\u5b8c\u5168\u6ce8\u518c\u76843D\u51e0\u4f55\u3002", "conclusion": "T2Bs\u80fd\u591f\u5408\u6210\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u53ef\u52a8\u753b\u5316\u89d2\u8272\u5934\u90e8\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d4D\u751f\u6210\u6280\u672f\u3002"}}
{"id": "2509.11261", "categories": ["cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.11261", "abs": "https://arxiv.org/abs/2509.11261", "authors": ["Piotr Faliszewski", "Lukasz Janeczko", "Grzegorz Lisowski", "Kristyna Pekarkova", "Ildiko Schlotter"], "title": "Identifying Imperfect Clones in Elections", "comment": null, "summary": "A perfect clone in an ordinal election (i.e., an election where the voters\nrank the candidates in a strict linear order) is a set of candidates that each\nvoter ranks consecutively. We consider different relaxations of this notion:\nindependent or subelection clones are sets of candidates that only some of the\nvoters recognize as a perfect clone, whereas approximate clones are sets of\ncandidates such that every voter ranks their members close to each other, but\nnot necessarily consecutively. We establish the complexity of identifying such\nimperfect clones, and of partitioning the candidates into families of imperfect\nclones. We also study the parameterized complexity of these problems with\nrespect to a set of natural parameters such as the number of voters, the size\nor the number of imperfect clones we are searching for, or their level of\nimperfection.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5e8f\u6570\u9009\u4e3e\u4e2d\u7684\u4e0d\u5b8c\u5168\u514b\u9686\u5019\u9009\u4eba\u7684\u8bc6\u522b\u548c\u5212\u5206\u95ee\u9898\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u677e\u5f1b\u5b9a\u4e49\u4e0b\u7684\u514b\u9686\u6027\u8d28\u53ca\u5176\u7b97\u6cd5\u590d\u6742\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5e8f\u6570\u9009\u4e3e\u4e2d\u514b\u9686\u5019\u9009\u4eba\u7684\u4e0d\u540c\u677e\u5f1b\u5b9a\u4e49\u53ca\u5176\u5bf9\u9009\u4e3e\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5982\u4f55\u8bc6\u522b\u548c\u5212\u5206\u8fd9\u4e9b\u4e0d\u5b8c\u5168\u514b\u9686\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u590d\u6742\u6027\u5206\u6790\u548c\u53c2\u6570\u5316\u590d\u6742\u6027\u7684\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86\u72ec\u7acb\u514b\u9686\u3001\u5b50\u9009\u4e3e\u514b\u9686\u548c\u8fd1\u4f3c\u514b\u9686\u7684\u5b9a\u4e49\u53ca\u5176\u76f8\u5173\u95ee\u9898\u7684\u8ba1\u7b97\u96be\u5ea6\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u8bc6\u522b\u548c\u5212\u5206\u4e0d\u5b8c\u5168\u514b\u9686\u5019\u9009\u4eba\u7684\u8ba1\u7b97\u590d\u6742\u6027\u7ed3\u679c\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u53c2\u6570\u5316\u590d\u6742\u6027\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\u8bc6\u522b\u4e0d\u5b8c\u5168\u514b\u9686\u5019\u9009\u4eba\u5728\u8ba1\u7b97\u4e0a\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u7684\u677e\u5f1b\u5b9a\u4e49\u4e0b\uff0c\u53c2\u6570\u5316\u5206\u6790\u4e3a\u89e3\u51b3\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2509.11003", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.11003", "abs": "https://arxiv.org/abs/2509.11003", "authors": ["Gurutva Patle", "Nilay Girgaonkar", "Nagabhushan Somraj", "Rajiv Soundararajan"], "title": "AD-GS: Alternating Densification for Sparse-Input 3D Gaussian Splatting", "comment": "SIGGRAPH Asia 2025", "summary": "3D Gaussian Splatting (3DGS) has shown impressive results in real-time novel\nview synthesis. However, it often struggles under sparse-view settings,\nproducing undesirable artifacts such as floaters, inaccurate geometry, and\noverfitting due to limited observations. We find that a key contributing factor\nis uncontrolled densification, where adding Gaussian primitives rapidly without\nguidance can harm geometry and cause artifacts. We propose AD-GS, a novel\nalternating densification framework that interleaves high and low densification\nphases. During high densification, the model densifies aggressively, followed\nby photometric loss based training to capture fine-grained scene details. Low\ndensification then primarily involves aggressive opacity pruning of Gaussians\nfollowed by regularizing their geometry through pseudo-view consistency and\nedge-aware depth smoothness. This alternating approach helps reduce overfitting\nby carefully controlling model capacity growth while progressively refining the\nscene representation. Extensive experiments on challenging datasets demonstrate\nthat AD-GS significantly improves rendering quality and geometric consistency\ncompared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4ea4\u66ff\u7a20\u5bc6\u5316\u6846\u67b6AD-GS\uff0c\u901a\u8fc7\u9ad8\u4f4e\u7a20\u5bc6\u5316\u9636\u6bb5\u7684\u4ea4\u66ff\u4f18\u5316\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u6cfc\u6e85\u5728\u7a00\u758f\u89c6\u89d2\u4e0b\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6e32\u67d3\u8d28\u91cf\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002", "motivation": "3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5728\u7a00\u758f\u89c6\u89d2\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u51fa\u73b0\u6d6e\u52a8\u7269\u4f53\u3001\u51e0\u4f55\u4e0d\u51c6\u786e\u548c\u8fc7\u62df\u5408\u7b49\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u63a7\u5236\u7684\u7a20\u5bc6\u5316\u662f\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u3002", "method": "\u63d0\u51fa\u4e86AD-GS\u6846\u67b6\uff0c\u4ea4\u66ff\u8fdb\u884c\u9ad8\u7a20\u5bc6\u5316\u548c\u4f4e\u7a20\u5bc6\u5316\u9636\u6bb5\u3002\u9ad8\u7a20\u5bc6\u5316\u9636\u6bb5\u901a\u8fc7\u5149\u5ea6\u635f\u5931\u8bad\u7ec3\u6355\u83b7\u573a\u666f\u7ec6\u8282\uff0c\u4f4e\u7a20\u5bc6\u5316\u9636\u6bb5\u901a\u8fc7\u4f2a\u89c6\u89d2\u4e00\u81f4\u6027\u548c\u8fb9\u7f18\u611f\u77e5\u6df1\u5ea6\u5e73\u6ed1\u6027\u8fdb\u884c\u51e0\u4f55\u6b63\u5219\u5316\u548c\u900f\u660e\u5ea6\u4fee\u526a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAD-GS\u5728\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6e32\u67d3\u8d28\u91cf\u548c\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AD-GS\u901a\u8fc7\u4ea4\u66ff\u7a20\u5bc6\u5316\u6846\u67b6\u6709\u6548\u51cf\u5c11\u4e86\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u4f18\u5316\u4e86\u573a\u666f\u8868\u793a\uff0c\u4e3a\u7a00\u758f\u89c6\u89d2\u4e0b\u76843D\u6e32\u67d3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.11294", "categories": ["cs.GT", "cs.ET", "cs.IR", "cs.IT", "math.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2509.11294", "abs": "https://arxiv.org/abs/2509.11294", "authors": ["Sina Aeeneh", "Nikola Zlatanov", "Jiangshan Yu"], "title": "An Incentive-Compatible Reward Sharing Mechanism for Mitigating Mirroring Attacks in Decentralized Data-Feed Systems", "comment": null, "summary": "Decentralized data-feed systems enable blockchain-based smart contracts to\naccess off-chain information by aggregating values from multiple oracles. To\nimprove accuracy, these systems typically use an aggregation function, such as\nmajority voting, to consolidate the inputs they receive from oracles and make a\ndecision. Depending on the final decision and the values reported by the\noracles, the participating oracles are compensated through shared rewards.\nHowever, such incentive mechanisms are vulnerable to mirroring attacks, where a\nsingle user controls multiple oracles to bias the decision of the aggregation\nfunction and maximize rewards. This paper analyzes the impact of mirroring\nattacks on the reliability and dependability of majority voting-based data-feed\nsystems. We demonstrate how existing incentive mechanisms can unintentionally\nencourage rational users to implement such attacks. To address this, we propose\na new incentive mechanism that discourages Sybil behavior. We prove that the\nproposed mechanism leads to a Nash Equilibrium in which each user operates only\none oracle. Finally, we discuss the practical implementation of the proposed\nincentive mechanism and provide numerical examples to demonstrate its\neffectiveness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u955c\u50cf\u653b\u51fb\u5bf9\u57fa\u4e8e\u591a\u6570\u6295\u7968\u7684\u6570\u636e\u9988\u9001\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6fc0\u52b1\u673a\u5236\u6765\u6291\u5236\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u7684\u6fc0\u52b1\u673a\u5236\u53ef\u80fd\u4f1a\u65e0\u610f\u4e2d\u9f13\u52b1\u7528\u6237\u53d1\u8d77\u955c\u50cf\u653b\u51fb\uff0c\u4ece\u800c\u5f71\u54cd\u6570\u636e\u9988\u9001\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u4f9d\u8d56\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u65e8\u5728\u6291\u5236Sybil\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u8be5\u673a\u5236\u80fd\u591f\u5728\u7eb3\u4ec0\u5747\u8861\u72b6\u6001\u4e0b\u786e\u4fdd\u6bcf\u4e2a\u7528\u6237\u4ec5\u64cd\u4f5c\u4e00\u4e2a\u9884\u8a00\u673a\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u65b0\u673a\u5236\u80fd\u591f\u6709\u6548\u6291\u5236\u955c\u50cf\u653b\u51fb\uff0c\u5e76\u4fdd\u8bc1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u901a\u8fc7\u65b0\u7684\u6fc0\u52b1\u673a\u5236\uff0c\u8bba\u6587\u6210\u529f\u89e3\u51b3\u4e86\u955c\u50cf\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u57fa\u4e8e\u591a\u6570\u6295\u7968\u7684\u6570\u636e\u9988\u9001\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.11087", "categories": ["cs.GR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.11087", "abs": "https://arxiv.org/abs/2509.11087", "authors": ["Omkar Shailendra Vengurlekar", "Adithya Pediredla", "Suren Jayasuriya"], "title": "SH-SAS: An Implicit Neural Representation for Complex Spherical-Harmonic Scattering Fields for 3D Synthetic Aperture Sonar", "comment": null, "summary": "Synthetic aperture sonar (SAS) reconstruction requires recovering both the\nspatial distribution of acoustic scatterers and their direction-dependent\nresponse. Time-domain backprojection is the most common 3D SAS reconstruction\nalgorithm, but it does not model directionality and can suffer from sampling\nlimitations, aliasing, and occlusion. Prior neural volumetric methods applied\nto synthetic aperture sonar treat each voxel as an isotropic scattering\ndensity, not modeling anisotropic returns. We introduce SH-SAS, an implicit\nneural representation that expresses the complex acoustic scattering field as a\nset of spherical harmonic (SH) coefficients. A multi-resolution hash encoder\nfeeds a lightweight MLP that outputs complex SH coefficients up to a specified\ndegree L. The zeroth-order coefficient acts as an isotropic scattering field,\nwhich also serves as the density term, while higher orders compactly capture\ndirectional scattering with minimal parameter overhead. Because the model\npredicts the complex amplitude for any transmit-receive baseline, training is\nperformed directly from 1-D time-of-flight signals without the need to beamform\nintermediate images for supervision. Across synthetic and real SAS (both in-air\nand underwater) benchmarks, results show that SH-SAS performs better in terms\nof 3D reconstruction quality and geometric metrics than previous methods.", "AI": {"tldr": "SH-SAS\u662f\u4e00\u79cd\u57fa\u4e8e\u7403\u8c10\u7cfb\u6570\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u6210\u5b54\u5f84\u58f0\u7eb3(SAS)\u76843D\u91cd\u5efa\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u65b9\u5411\u6027\u6563\u5c04\u5e76\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u65f6\u57df\u53cd\u6295\u5f71\u65b9\u6cd5\u5728SAS\u91cd\u5efa\u4e2d\u672a\u8003\u8651\u65b9\u5411\u6027\uff0c\u4e14\u5b58\u5728\u91c7\u6837\u9650\u5236\u3001\u6df7\u53e0\u548c\u906e\u6321\u7b49\u95ee\u9898\u3002\u73b0\u6709\u795e\u7ecf\u4f53\u79ef\u65b9\u6cd5\u5c06\u6bcf\u4e2a\u4f53\u7d20\u89c6\u4e3a\u5404\u5411\u540c\u6027\u6563\u5c04\u5bc6\u5ea6\uff0c\u65e0\u6cd5\u5efa\u6a21\u5404\u5411\u5f02\u6027\u6563\u5c04\u3002", "method": "SH-SAS\u901a\u8fc7\u7403\u8c10(SH)\u7cfb\u6570\u8868\u793a\u590d\u6742\u7684\u58f0\u5b66\u6563\u5c04\u573a\uff0c\u4f7f\u7528\u591a\u5206\u8fa8\u7387\u54c8\u5e0c\u7f16\u7801\u5668\u548c\u8f7b\u91cf\u7ea7MLP\u8f93\u51fa\u590d\u6570SH\u7cfb\u6570\u3002\u96f6\u9636\u7cfb\u6570\u8868\u793a\u5404\u5411\u540c\u6027\u6563\u5c04\u573a\uff0c\u9ad8\u9636\u7cfb\u6570\u7d27\u51d1\u5730\u6355\u83b7\u65b9\u5411\u6027\u6563\u5c04\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9eSAS\uff08\u5305\u62ec\u7a7a\u4e2d\u548c\u6c34\u4e0b\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSH-SAS\u57283D\u91cd\u5efa\u8d28\u91cf\u548c\u51e0\u4f55\u6307\u6807\u4e0a\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "SH-SAS\u80fd\u591f\u76f4\u63a5\u4ece1-D\u65f6\u95f4\u98de\u884c\u4fe1\u53f7\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u4e2d\u95f4\u6ce2\u675f\u6210\u5f62\u56fe\u50cf\u76d1\u7763\uff0c\u663e\u8457\u63d0\u5347\u4e86SAS\u91cd\u5efa\u7684\u7cbe\u5ea6\u548c\u6548\u7387\u3002"}}
{"id": "2509.11377", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.11377", "abs": "https://arxiv.org/abs/2509.11377", "authors": ["Isha Sharma", "Dieter Schmalstieg"], "title": "3D Gaussian Modeling and Ray Marching of OpenVDB datasets for Scientific Visualization", "comment": null, "summary": "3D Gaussians are currently being heavily investigated for their scene\nmodeling and compression abilities. In 3D volumes, their use is being explored\nfor representing dense volumes as sparsely as possible. However, most of these\nmethods begin with a memory inefficient data format. Specially in Scientific\nVisualization(SciVis), where most popular formats are dense-grid data\nstructures that store every grid cell, irrespective of its contribution.\nOpenVDB library and data format were introduced for representing sparse\nvolumetric data specifically for visual effects use cases such as clouds, fire,\nfluids etc. It avoids storing empty cells by masking them during storage. It\npresents an opportunity for use in SciVis, specifically as a modeling framework\nfor conversion to 3D Gaussian particles for further compression and for a\nunified modeling approach for different scientific volume types. This\ncompression head-start is non-trivial and this paper would like to present this\nwith a rendering algorithm based on line integration implemented in OptiX8.1\nfor calculating 3D Gaussians contribution along a ray for optical-depth\naccumulation. For comparing the rendering results of our ray marching Gaussians\nrenderer, we also implement a SciVis style primary-ray only NanoVDB HDDA based\nray marcher for OpenVDB voxel grids. Finally, this paper also explores\napplication of this Gaussian model to formats of volumes other than regular\ngrids, such as AMR volumes and point clouds, using internal representation of\nOpenVDB grid class types for data hierarchy and subdivision structure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528OpenVDB\u7a00\u758f\u4f53\u79ef\u6570\u636e\u683c\u5f0f\u4f18\u53163D\u9ad8\u65af\u7c92\u5b50\u7684\u5efa\u6a21\u4e0e\u538b\u7f29\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ebf\u79ef\u5206\u7684\u6e32\u67d3\u7b97\u6cd5\u3002", "motivation": "\u79d1\u5b66\u53ef\u89c6\u5316\u4e2d\u5e38\u7528\u7684\u5bc6\u96c6\u7f51\u683c\u6570\u636e\u683c\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0cOpenVDB\u7a00\u758f\u4f53\u79ef\u6570\u636e\u683c\u5f0f\u4e3a\u4f18\u5316\u5b58\u50a8\u548c\u5efa\u6a21\u63d0\u4f9b\u4e86\u6f5c\u529b\uff0c\u7279\u522b\u662f\u7528\u4e8e3D\u9ad8\u65af\u7c92\u5b50\u7684\u8f6c\u6362\u4e0e\u538b\u7f29\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eOptiX8.1\u7684\u7ebf\u79ef\u5206\u6e32\u67d3\u7b97\u6cd5\uff0c\u5c063D\u9ad8\u65af\u7c92\u5b50\u6cbf\u5149\u7ebf\u8d21\u732e\u8ba1\u7b97\u4e3a\u5149\u5b66\u6df1\u5ea6\u7d2f\u79ef\uff0c\u5e76\u4e0eOpenVDB\u4f53\u7d20\u7f51\u683c\u7684\u4f20\u7edf\u6e32\u67d3\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u901a\u8fc7\u5b9e\u73b0\u4e24\u79cd\u6e32\u67d3\u5668\u5e76\u6bd4\u8f83\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e3D\u9ad8\u65af\u7c92\u5b50\u7684\u65b9\u6cd5\u5728\u538b\u7f29\u548c\u5efa\u6a21\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u81f3\u975e\u89c4\u5219\u7f51\u683c\u4f53\u79ef\u683c\u5f0f\uff08\u5982AMR\u548c\u70b9\u4e91\uff09\u3002", "conclusion": "OpenVDB\u7a00\u758f\u6570\u636e\u683c\u5f0f\u7ed3\u54083D\u9ad8\u65af\u7c92\u5b50\u6a21\u578b\u4e3a\u79d1\u5b66\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u538b\u7f29\u548c\u7edf\u4e00\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u4f53\u79ef\u6570\u636e\u683c\u5f0f\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2509.11410", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2509.11410", "abs": "https://arxiv.org/abs/2509.11410", "authors": ["Roberta C. R. Mota", "Allan Rocha", "Julio Daniel Silva", "Usman Alim", "Ehud Sharlin"], "title": "3De Interactive Lenses for Visualization in Virtual Environments", "comment": null, "summary": "We present 3De lens, a technique for focus+context visualization of\nmulti-geometry data. It fuses two categories of lenses (3D and Decal) to become\na versatile lens for seamlessly working on multiple geometric representations\nthat commonly coexist in 3D visualizations. In addition, we incorporate our\nlens into virtual reality as it enables a natural style of direct spatial\nmanipulation for exploratory 3D data analysis. To demonstrate its potential\nuse, we discuss two domain examples in which our lens technique creates\ncustomized visualizations of both surfaces and streamlines.", "AI": {"tldr": "3De lens \u6280\u672f\u878d\u5408\u4e863D\u548c\u8d34\u82b1\u4e24\u79cd\u955c\u5934\uff0c\u7528\u4e8e\u591a\u51e0\u4f55\u6570\u636e\u7684\u7126\u70b9+\u4e0a\u4e0b\u6587\u53ef\u89c6\u5316\uff0c\u652f\u6301\u865a\u62df\u73b0\u5b9e\u4e2d\u7684\u76f4\u63a5\u7a7a\u95f4\u64cd\u4f5c\u3002", "motivation": "\u9488\u5bf9\u591a\u51e0\u4f55\u6570\u636e\u5171\u5b58\u76843D\u53ef\u89c6\u5316\u9700\u6c42\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u65e0\u7f1d\u5904\u7406\u591a\u79cd\u51e0\u4f55\u8868\u793a\u7684\u955c\u5934\u6280\u672f\u3002", "method": "\u7ed3\u54083D\u548c\u8d34\u82b1\u955c\u5934\u6280\u672f\uff0c\u5f62\u62103De lens\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u865a\u62df\u73b0\u5b9e\u73af\u5883\u4e2d\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u9886\u57df\u6848\u4f8b\u5c55\u793a\u4e863De lens\u5728\u8868\u9762\u548c\u6d41\u7ebf\u5b9a\u5236\u53ef\u89c6\u5316\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "3De lens\u662f\u4e00\u79cd\u591a\u529f\u80fd\u955c\u5934\u6280\u672f\uff0c\u9002\u7528\u4e8e\u865a\u62df\u73b0\u5b9e\u4e2d\u7684\u591a\u51e0\u4f55\u6570\u636e\u63a2\u7d22\u6027\u5206\u6790\u3002"}}
