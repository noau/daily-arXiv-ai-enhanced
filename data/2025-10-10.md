<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 9]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation](https://arxiv.org/abs/2510.07340)
*Yongzhi Li,Saining Zhang,Yibing Chen,Boying Li,Yanxin Zhang,Xiaoyu Du*

Main category: cs.GR

TL;DR: SpotDiff是一种新颖的学习方法，通过分离干扰特征实现个性化图像生成，在高效性和鲁棒性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 个性化图像生成需要在保留参考对象身份的同时适应多样化文本提示，现有方法在效率或特征分离上存在不足。

Method: SpotDiff利用预训练的CLIP图像编码器和专家网络，通过正交约束分离主体特征，并引入SpotDiff10k数据集进行训练。

Result: 实验表明，SpotDiff在保留主体身份和控制编辑方面优于现有方法，仅需10k训练样本即可实现竞争性能。

Conclusion: SpotDiff以高效性和鲁棒性解决了个性化图像生成的问题，为未来研究提供了新的方向。

Abstract: Personalized image generation aims to faithfully preserve a reference
subject's identity while adapting to diverse text prompts. Existing
optimization-based methods ensure high fidelity but are computationally
expensive, while learning-based approaches offer efficiency at the cost of
entangled representations influenced by nuisance factors. We introduce
SpotDiff, a novel learning-based method that extracts subject-specific features
by spotting and disentangling interference. Leveraging a pre-trained CLIP image
encoder and specialized expert networks for pose and background, SpotDiff
isolates subject identity through orthogonality constraints in the feature
space. To enable principled training, we introduce SpotDiff10k, a curated
dataset with consistent pose and background variations. Experiments demonstrate
that SpotDiff achieves more robust subject preservation and controllable
editing than prior methods, while attaining competitive performance with only
10k training samples.

</details>


### [2] [Local MAP Sampling for Diffusion Models](https://arxiv.org/abs/2510.07343)
*Shaorong Zhang,Rob Brekelmans,Greg Ver Steeg*

Main category: cs.GR

TL;DR: 提出了局部最大后验概率采样（LMAPS）框架，通过迭代解决扩散轨迹上的局部MAP子问题，为基于优化的扩散求解器提供了统一的概率解释，并在多个图像恢复和科学任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散后验采样（DPS）方法虽然提供了贝叶斯框架，但在解决逆问题时，目标更倾向于恢复最准确的重建，而基于优化的扩散求解器在此类任务中表现优异却缺乏清晰的概率基础。本文旨在填补这一空白。

Method: 引入了局部最大后验概率采样（LMAPS）框架，通过迭代解决扩散轨迹上的局部MAP子问题，提供了一个统一的概率解释，并开发了具有概率解释的协方差近似、重新制定的稳定目标以及非可微分算子的梯度近似算法。

Result: 在广泛的图像恢复和科学任务中，LMAPS实现了最先进的性能，包括在运动去模糊、JPEG恢复和量化任务中取得≥2 dB的增益，在逆散射基准测试中提升>1.5 dB。

Conclusion: LMAPS不仅为基于优化的扩散求解器提供了统一的概率解释，还显著提升了多种逆问题求解的性能，展示了其在理论和实践中的重要价值。

Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to
inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the
goal of inverse problem solving is not to cover the posterior but to recover
the most accurate reconstruction, where optimization-based diffusion solvers
often excel despite lacking a clear probabilistic foundation. We introduce
Local MAP Sampling (LMAPS), a new inference framework that iteratively solving
local MAP subproblems along the diffusion trajectory. This perspective
clarifies their connection to global MAP estimation and DPS, offering a unified
probabilistic interpretation for optimization-based methods. Building on this
foundation, we develop practical algorithms with a probabilistically
interpretable covariance approximation, a reformulated objective for stability
and interpretability, and a gradient approximation for non-differentiable
operators. Across a broad set of image restoration and scientific tasks, LMAPS
achieves state-of-the-art performance, including $\geq 2$ dB gains on motion
deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on
inverse scattering benchmarks.

</details>


### [3] [Differentiable Variable Fonts](https://arxiv.org/abs/2510.07638)
*Kinjal Parikh,Danny M. Kaufman,David I. W. Levin,Alec Jacobson*

Main category: cs.GR

TL;DR: 论文提出了一种基于可微分可变字体的自动化字体设计和动画工作流程，解决了传统手动调节字体参数的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统字体设计和动画需要艺术家手动调节参数，耗时且复杂。可变字体虽提供了参数化设计空间，但仍需手动操作，限制了其应用。

Method: 研究将可变字体规范转化为紧凑的数学形式，建立了可微分框架，支持基于梯度的优化，应用于字形和图像的能量优化。

Result: 通过四种应用展示了框架的实用性：直接形状操作、重叠感知建模、基于物理的文本动画和自动化字体设计优化。

Conclusion: 可微分可变字体框架为现代设计优化技术提供了新途径，简化了字体设计和动画工作流程。

Abstract: Editing and animating text appearance for graphic designs, commercials, etc.
remain highly skilled tasks requiring detailed, hands on efforts from artists.
Automating these manual workflows requires balancing the competing goals of
maintaining legibility and aesthetics of text, while enabling creative
expression. Variable fonts, recent parametric extensions to traditional fonts,
offer the promise of new ways to ease and automate typographic design and
animation. Variable fonts provide custom constructed parameters along which
fonts can be smoothly varied. These parameterizations could then potentially
serve as high value continuous design spaces, opening the door to automated
design optimization tools. However, currently variable fonts are underutilized
in creative applications, because artists so far still need to manually tune
font parameters. Our work opens the door to intuitive and automated font design
and animation workflows with differentiable variable fonts. To do so we distill
the current variable font specification to a compact mathematical formulation
that differentiably connects the highly non linear, non invertible mapping of
variable font parameters to the underlying vector graphics representing the
text. This enables us to construct a differentiable framework, with respect to
variable font parameters, allowing us to perform gradient based optimization of
energies defined on vector graphics control points, and on target rasterized
images. We demonstrate the utility of this framework with four applications:
direct shape manipulation, overlap aware modeling, physics based text
animation, and automated font design optimization. Our work now enables
leveraging the carefully designed affordances of variable fonts with
differentiability to use modern design optimization technologies, opening new
possibilities for easy and intuitive typographic design workflows.

</details>


### [4] [NRRS: Neural Russian Roulette and Splitting](https://arxiv.org/abs/2510.07868)
*Haojie Jin,Jierui Ren,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出了一种针对波前路径追踪的俄罗斯轮盘与分裂（RRS）框架，解决了传统RRS方法与波前架构的内存与调度不兼容问题，并通过神经网络学习RRS因子，显著提升了渲染质量和性能。


<details>
  <summary>Details</summary>
Motivation: 传统RRS方法在波前路径追踪中由于不可预测的路径计数与预分配内存和调度要求不兼容，因此需要一种新的方法来解决这一问题。

Method: 提出了一个规范化的RRS框架，并引入两种神经网络模型（NRRS和AID-NRRS）来学习RRS因子，同时设计了Mix-Depth机制以平衡计算成本与推断准确性。

Result: 实验表明，该方法在多种复杂场景中均优于传统启发式方法和近期RRS技术，表现出更高的渲染质量与性能。

Conclusion: 本文提出的方法成功解决了波前路径追踪中RRS的不兼容问题，并通过神经网络和自适应机制显著提升了效率和渲染效果。

Abstract: We propose a novel framework for Russian Roulette and Splitting (RRS)
tailored to wavefront path tracing, a highly parallel rendering architecture
that processes path states in batched, stage-wise execution for efficient GPU
utilization. Traditional RRS methods, with unpredictable path counts, are
fundamentally incompatible with wavefront's preallocated memory and scheduling
requirements. To resolve this, we introduce a normalized RRS formulation with a
bounded path count, enabling stable and memory-efficient execution.
  Furthermore, we pioneer the use of neural networks to learn RRS factors,
presenting two models: NRRS and AID-NRRS. At a high level, both feature a
carefully designed RRSNet that explicitly incorporates RRS normalization, with
only subtle differences in their implementation. To balance computational cost
and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism
that adaptively regulates neural evaluation, further improving efficiency.
  Extensive experiments demonstrate that our method outperforms traditional
heuristics and recent RRS techniques in both rendering quality and performance
across a variety of complex scenes.

</details>


### [5] [Variable-Rate Texture Compression: Real-Time Rendering with JPEG](https://arxiv.org/abs/2510.08166)
*Elias Kristmann,Markus Schütz,Michael Wimmer*

Main category: cs.GR

TL;DR: 研究了在现代GPU上使用JPEG格式实现可变速率纹理压缩的可行性，并与固定速率压缩方法BC1和ASTC进行了比较。结果表明JPEG在质量和压缩率上优于BC1，有时能与ASTC媲美。


<details>
  <summary>Details</summary>
Motivation: 可变速率压缩图像格式（如JPEG）尚未在实时渲染中广泛应用，主要因为需要随机访问单个纹理像素的特殊需求。本文探究了在现代GPU上使用JPEG实现可变速率纹理压缩的可能性。

Method: 采用延迟渲染管道，识别出每帧所需的子块，解码并着色帧缓冲区的像素。尽管需要额外的每像素0.17比特，JPEG仍能保持良好的质量和压缩率。

Result: JPEG在质量和压缩率上显著优于BC1，且在特定图像类型中与ASTC表现相当或更优。在RTX 4090上，JPEG渲染管道的渲染时间仅增加不到0.3毫秒。

Conclusion: 研究表明，复杂的可变速率压缩方案在现代GPU上是可行的，即使在VR应用中也能胜任。源代码和数据集已公开。

Abstract: Although variable-rate compressed image formats such as JPEG are widely used
to efficiently encode images, they have not found their way into real-time
rendering due to special requirements such as random access to individual
texels. In this paper, we investigate the feasibility of variable-rate texture
compression on modern GPUs using the JPEG format, and how it compares to the
GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred
rendering pipeline, we are able to identify the subset of blocks that are
needed for a given frame, decode these, and colorize the framebuffer's pixels.
Despite the additional $\sim$0.17 bit per pixel that we require for our
approach, JPEG maintains significantly better quality and compression rates
compared to BC1, and depending on the type of image, outperforms or competes
with ASTC. The JPEG rendering pipeline increases rendering duration by less
than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate
compression schemes are feasible on modern GPUs, even in VR. Source code and
data sets are available at: https://github.com/elias1518693/jpeg_textures

</details>


### [6] [SViM3D: Stable Video Material Diffusion for Single Image 3D Generation](https://arxiv.org/abs/2510.08271)
*Andreas Engelhardt,Mark Boss,Vikram Voletti,Chun-Han Yao,Hendrik P. A. Lensch,Varun Jampani*

Main category: cs.GR

TL;DR: SViM3D是一个基于单图像预测多视角一致物理渲染（PBR）材料的框架，结合视频扩散模型实现了高质量的3D资产重光照和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在从单图像重建3D对象时效率高，但其反射率仍需通过简单材料模型或多步骤估计，限制了重光照和外观编辑的控制能力。

Method: 扩展了潜在视频扩散模型，使其基于显式相机控制输出空间变化的PBR参数和表面法线，并在此流程中引入多种机制以提升质量。

Result: 在多个以对象为中心的数据集上，该方法展示了最先进的重光照和新视角合成性能，并能泛化到多样化的输入。

Conclusion: SViM3D方法能够生成可用于AR/VR、电影、游戏等视觉媒体的可重光照3D资产，表现出良好的通用性和实用性。

Abstract: We present Stable Video Materials 3D (SViM3D), a framework to predict
multi-view consistent physically based rendering (PBR) materials, given a
single image. Recently, video diffusion models have been successfully used to
reconstruct 3D objects from a single image efficiently. However, reflectance is
still represented by simple material models or needs to be estimated in
additional steps to enable relighting and controlled appearance edits. We
extend a latent video diffusion model to output spatially varying PBR
parameters and surface normals jointly with each generated view based on
explicit camera control. This unique setup allows for relighting and generating
a 3D asset using our model as neural prior. We introduce various mechanisms to
this pipeline that improve quality in this ill-posed setting. We show
state-of-the-art relighting and novel view synthesis performance on multiple
object-centric datasets. Our method generalizes to diverse inputs, enabling the
generation of relightable 3D assets useful in AR/VR, movies, games and other
visual media.

</details>


### [7] [Spectral Prefiltering of Neural Fields](https://arxiv.org/abs/2510.08394)
*Mustafa B. Yaldiz,Ishit Mehta,Nithin Raghavan,Andreas Meuleman,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出了一种优化神经场的新方法，通过单次前向传递实现预滤波，支持多种滤波器类型，并在训练和推理中表现高效。


<details>
  <summary>Details</summary>
Motivation: 神经场通常在固定分辨率下运行，限制了其灵活性和适应性。为此，研究提出了一种能够在单次前向传递中实现预滤波的方法。

Method: 方法包括在输入域中进行卷积滤波，通过傅里叶特征嵌入与滤波器频率响应的分析缩放；支持高斯以外的其他参数滤波器；使用单样本蒙特卡罗估计训练神经场。

Result: 该方法在训练和推理中速度快，对网络架构无额外约束，定量和定性均优于现有神经场滤波方法。

Conclusion: 该方法为神经场的滤波提供了高效且灵活的解决方案，支持多种滤波器类型，显著提升了性能。

Abstract: Neural fields excel at representing continuous visual signals but typically
operate at a single, fixed resolution. We present a simple yet powerful method
to optimize neural fields that can be prefiltered in a single forward pass. Key
innovations and features include: (1) We perform convolutional filtering in the
input domain by analytically scaling Fourier feature embeddings with the
filter's frequency response. (2) This closed-form modulation generalizes beyond
Gaussian filtering and supports other parametric filters (Box and Lanczos) that
are unseen at training time. (3) We train the neural field using single-sample
Monte Carlo estimates of the filtered signal. Our method is fast during both
training and inference, and imposes no additional constraints on the network
architecture. We show quantitative and qualitative improvements over existing
methods for neural-field filtering.

</details>


### [8] [Splat the Net: Radiance Fields with Splattable Neural Primitives](https://arxiv.org/abs/2510.08491)
*Xilong Zhou,Bao-Huy Nguyen,Loïc Magne,Vladislav Golyanik,Thomas Leimkühler,Christian Theobalt*

Main category: cs.GR

TL;DR: 该论文提出了一种新的体积表示方法——可压缩神经基元，结合了神经模型的表达能力和基于基元的喷射方法的高效性，实现了高质量和快速的场景渲染。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景外观建模中，神经辐射场表达能力强但渲染成本高，而基于基元的喷射方法（如3D高斯喷射）效率高但表达能力有限。本文旨在结合两者的优势。

Method: 引入可压缩神经基元作为新的体积表示方法，每个基元通过浅层神经网络编码有界的神经密度场，并通过解析解法高效计算透视准确的喷射核。

Result: 在新视角合成基准测试中，该方法与3D高斯喷射的质量和速度相当，但使用的基元数量和参数数量分别减少了10倍和6倍。

Conclusion: 该方法通过结合神经模型的表达能力和基于基元的喷射效率，实现了高效且高质量的3D场景渲染，且不依赖复杂的控制或适配框架。

Abstract: Radiance fields have emerged as a predominant representation for modeling 3D
scene appearance. Neural formulations such as Neural Radiance Fields provide
high expressivity but require costly ray marching for rendering, whereas
primitive-based methods such as 3D Gaussian Splatting offer real-time
efficiency through splatting, yet at the expense of representational power.
Inspired by advances in both these directions, we introduce splattable neural
primitives, a new volumetric representation that reconciles the expressivity of
neural models with the efficiency of primitive-based splatting. Each primitive
encodes a bounded neural density field parameterized by a shallow neural
network. Our formulation admits an exact analytical solution for line
integrals, enabling efficient computation of perspectively accurate splatting
kernels. As a result, our representation supports integration along view rays
without the need for costly ray marching. The primitives flexibly adapt to
scene geometry and, being larger than prior analytic primitives, reduce the
number required per scene. On novel-view synthesis benchmarks, our approach
matches the quality and speed of 3D Gaussian Splatting while using $10\times$
fewer primitives and $6\times$ fewer parameters. These advantages arise
directly from the representation itself, without reliance on complex control or
adaptation frameworks. The project page is
https://vcai.mpi-inf.mpg.de/projects/SplatNet/.

</details>


### [9] [X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](https://arxiv.org/abs/2510.08530)
*Zhitong Huang,Mohan Zhang,Renhan Wang,Rui Tang,Hao Zhu,Jing Liao*

Main category: cs.GR

TL;DR: X2Video是首个基于内在通道（如反照率、法线、粗糙度、金属度和辐照度）的光照真实视频扩散模型，支持通过参考图像和文本提示进行多模态控制。


<details>
  <summary>Details</summary>
Motivation: 传统的视频生成方法难以准确控制颜色、材质、几何和光照等内在属性，同时缺乏多模态控制的灵活性。X2Video旨在解决这些问题，提供更准确且直观的视频生成工具。

Method: X2Video通过Hybrid Self-Attention技术扩展了XRGB模型以支持视频生成，确保时间一致性并提升参考图像的保真度。此外，Masked Cross-Attention用于解耦全局和局部文本提示，Recursive Sampling方法则用于生成长视频。

Result: 实验证明，X2Video能够生成长时间、时间一致且光照真实的视频，同时支持多模态控制和参数化编辑。

Conclusion: X2Video是一种高效且灵活的扩散模型，能够通过内在属性和多模态控制生成高质量视频，为视频编辑和生成领域提供了新的工具。

Abstract: We present X2Video, the first diffusion model for rendering photorealistic
videos guided by intrinsic channels including albedo, normal, roughness,
metallicity, and irradiance, while supporting intuitive multi-modal controls
with reference images and text prompts for both global and local regions. The
intrinsic guidance allows accurate manipulation of color, material, geometry,
and lighting, while reference images and text prompts provide intuitive
adjustments in the absence of intrinsic information. To enable these
functionalities, we extend the intrinsic-guided image generation model XRGB to
video generation by employing a novel and efficient Hybrid Self-Attention,
which ensures temporal consistency across video frames and also enhances
fidelity to reference images. We further develop a Masked Cross-Attention to
disentangle global and local text prompts, applying them effectively onto
respective local and global regions. For generating long videos, our novel
Recursive Sampling method incorporates progressive frame sampling, combining
keyframe prediction and frame interpolation to maintain long-range temporal
consistency while preventing error accumulation. To support the training of
X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154
rooms from 295 interior scenes, complete with reliable ground-truth intrinsic
channel sequences and smooth camera trajectories. Both qualitative and
quantitative evaluations demonstrate that X2Video can produce long, temporally
consistent, and photorealistic videos guided by intrinsic conditions.
Additionally, X2Video effectively accommodates multi-modal controls with
reference images, global and local text prompts, and simultaneously supports
editing on color, material, geometry, and lighting through parametric tuning.
Project page: https://luckyhzt.github.io/x2video

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [10] [Type, Ability, and Effect Systems: Perspectives on Purity, Semantics, and Expressiveness](https://arxiv.org/abs/2510.07582)
*Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 本文提出了一种基于语义的纯度定义，并比较了不同类型的效果和能力系统在表达能力上的优劣，最终提出了一种综合方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如单子、类型-效果系统和能力系统）在强制分离纯计算与副作用之间存在精度与可用性的矛盾，本文旨在提高对这些系统的评估标准。

Method: 提出基于上下文等价的语义纯度定义，并通过完整性衡量表达能力，重点分析最小有意义的效果和能力系统。

Result: 研究发现效果和能力系统在表达能力上不可比较，进而提出了一种结合三者优点的综合方案。

Conclusion: 本文展示了类型、能力和效果系统的综合优势，为多种效果类型系统提供了形式化模型和纯度证明工具。

Abstract: Programming benefits from a clear separation between pure, mathematical
computation and impure, effectful interaction with the world. Existing
approaches to enforce this separation include monads, type-and-effect systems,
and capability systems. All share a tension between precision and usability,
and each one has non-obvious strengths and weaknesses.
  This paper aims to raise the bar in assessing such systems. First, we propose
a semantic definition of purity, inspired by contextual equivalence, as a
baseline independent of any specific typing discipline. Second, we propose that
expressiveness should be measured by the degree of completeness, i.e., how many
semantically pure terms can be typed as pure. Using this measure, we focus on
minimal meaningful effect and capability systems and show that they are
incomparable, i.e., neither subsumes the other in terms of expressiveness.
  Based on this result, we propose a synthesis and show that type, ability, and
effect systems combine their respective strengths while avoiding their
weaknesses. As part of our formal model, we provide a logical relation to
facilitate proofs of purity and other properties for a variety of effect typing
disciplines.

</details>


### [11] [The Functional Machine Calculus III: Control](https://arxiv.org/abs/2510.07851)
*Willem Heijltjes*

Main category: cs.PL

TL;DR: 功能机器演算（FMC）是一种新方法，统一了命令式和函数式编程范式。它扩展了λ演算，支持并发归约和类型化终止，并嵌入计算效果、评估策略和控制流操作。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在统一命令式和函数式编程范式，通过扩展λ演算模型，使其能够支持更复杂的控制流操作（如分支和循环），同时保留并发归约和类型化终止的关键特性。

Method: 论文提出了一种基于Krivine机器的操作语义，通过多重操作堆栈和延续堆栈来建模效果和控制流。该方法支持分支、循环和异常处理，并提供了简单的类型系统。

Result: 结果显示功能机器演算具有并发归约关系和类型系统，保证了机器的终止性和强归一化（在无迭代的情况下）。这些特性可直接应用于嵌入的命令式语言。

Conclusion: 功能机器演算提供了一个统一的函数式-命令式计算模型，支持简单类型、直观的操作语义和并发归约语义。

Abstract: The Functional Machine Calculus (Heijltjes 2022) is a new approach to
unifying the imperative and functional programming paradigms. It extends the
lambda-calculus, preserving the key features of confluent reduction and typed
termination, to embed computational effects, evaluation strategies, and control
flow operations. The first instalment modelled sequential higher-order
computation with global store, input/output, probabilities, and
non-determinism, and embedded both the call-by-name and call-by-value
lambda-calculus, as well as Moggi's computational metalanguage and Levy's
call-by-push-value. The present paper extends the calculus from sequential to
branching and looping control flow. This allows the faithful embedding of a
minimal but complete imperative language, including conditionals, exception
handling, and iteration, as well as constants and algebraic data types.
  The calculus is defined through a simple operational semantics, extending the
(simplified) Krivine machine for the lambda-calculus with multiple operand
stacks to model effects and a continuation stack to model sequential,
branching, and looping computation. It features a confluent reduction relation
and a system of simple types that guarantees termination of the machine and
strong normalization of reduction (in the absence of iteration). These
properties carry over to the embedded imperative language, providing a unified
functional-imperative model of computation that supports simple types, a direct
and intuitive operational semantics, and a confluent reduction semantics.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [12] [BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats](https://arxiv.org/abs/2510.07430)
*Yang Jiao,Guanpu Chen,Yiguang Hong*

Main category: cs.GT

TL;DR: 本文提出了一种贝叶斯游戏框架BG-FlipIn，用于研究具有不同偏好的内部人员的APT攻击，并探讨了防御者的决策指导。


<details>
  <summary>Details</summary>
Motivation: 研究高级持续性威胁（APT）中具有不同偏好的内部人员的角色，解决内部人员偏好的不确定性。

Method: 提出了BG-FlipIn框架，计算了封闭形式的贝叶斯纳什均衡表达式，并分析了三种确定性内部人员的纳什均衡表达式。

Result: 发现了与防御者行动率和成本以及内部人员偏好相关的APT现象，并提供了不同参数条件下的防御决策指导。

Conclusion: BG-FlipIn框架使防御者能够一致地做出决策，避免频繁检测内部人员具体偏好或调整策略，并通过两个应用验证了其有效性。

Abstract: In this paper, we study advanced persistent threats (APT) with an insider who
has different preferences. To address the uncertainty of the insider's
preference, we propose the BG-FlipIn: a Bayesian game framework for
FlipIt-insider models with an investigation on malicious, inadvertent, or
corrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium
expression and further obtain three edge cases with deterministic insiders
corresponding to their Nash Equilibrium expressions. On this basis, we further
discover several phenomena in APT related to the defender's move rate and cost,
as well as the insider's preferences. We then provide decision-making guidance
for the defender, given different parametric conditions. Two applications
validate that our BG-FlipIn framework enables the defender to make decisions
consistently, avoiding detecting the insider's concrete preference or adjusting
its strategy frequently.

</details>


### [13] [Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices](https://arxiv.org/abs/2510.07572)
*Jesse D Wei,Guo Wei*

Main category: cs.GT

TL;DR: 该论文研究了在网络设备连接问题中，通过确定性算法高效近似Shapley值的方法，避免了传统方法的指数复杂度或蒙特卡罗采样的不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统计算Shapley值的方法具有指数复杂度或依赖蒙特卡罗采样，性能不稳定。本研究旨在设计确定性算法，高效且准确地近似Shapley值。

Method: 提出基于非齐次伯努利试验的确定性算法，通过线性或二次时间近似Shapley值，并进行了严格的误差分析。

Result: 实现了在合理时间内高效近似Shapley值的目标，并通过定积分和组合分析补充了Shapley原始证明的不足。

Conclusion: 确定性算法显著提升了Shapley值计算的效率与准确性，填补了原始证明的空白，为实际应用提供了可靠工具。

Abstract: Suppose that $n$ computer devices are to be connected to a network via
inhomogeneous Bernoulli trials. The Shapley value of a device quantifies how
much the network's value increases due to the participation of that device.
Characteristic functions of such games are naturally taken as the belief
function (containment function) and Choquet capacity (hitting probability) of a
random set (random network of devices).
  Traditionally, the Shapley value is either calculated as the expected
marginal contribution over all possible coalitions (subnetworks), which results
in exponential computational complexity, or approximated by the Monte Carlo
sampling technique, where the performance is highly dependent on the stochastic
sampling process.
  The purpose of this study is to design deterministic algorithms for games
formulated via inhomogeneous Bernoulli trials that approximate the Shapley
value in linear or quadratic time, with rigorous error analysis (Sections 3 and
4). Additionally, we provide a review of relevant literature on existing
calculation methods in Remark 3.1 and Appendix I.
  A further goal is to supplement Shapley's original proof by deriving the
Shapley value formula using a rigorous approach based on definite integrals and
combinatorial analysis. This method explicitly highlights the roles of the
Binomial Theorem and the Beta function in the proof, addressing a gap in
Shapley's work (Appendix II).

</details>


### [14] [Extending Games beyond the Finite Horizon](https://arxiv.org/abs/2510.08453)
*Kiri Sakahara,Takashi Sato*

Main category: cs.GT

TL;DR: 本文提出了一种基于替代集合理论（AST）的新框架，解决有限视野悖论中标准数系统在模拟无限认知时的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于标准数系统在建模人类对无限的认知时出现的矛盾，例如有限视野悖论，这些问题导致博弈论与直觉不符。

Method: 方法是通过AST构建新框架，利用不同拓扑结构表示对长历史事件的认知视角，并定义一个不可区分性等价关系来处理巨大且无法区分的数量。

Result: 结果表明，该框架能够提供依赖标准的解决方案，揭示了新的直觉子博弈完美均衡，其特性取决于选择的时间视角和收益评估。

Conclusion: 结论是，通过将数学基础建立在人类认知的不同模式上，该研究扩展了博弈论在长期情景中的解释能力。

Abstract: This paper argues that the finite horizon paradox, where game theory
contradicts intuition, stems from the limitations of standard number systems in
modelling the cognitive perception of infinity. To address this issue, we
propose a new framework based on Alternative Set Theory (AST). This framework
represents different cognitive perspectives on a long history of events using
distinct topologies. These topologies define an indiscernibility equivalence
that formally treats huge, indistinguishable quantities as equivalent. This
offers criterion-dependent resolutions to long-standing paradoxes, such as
Selten's chain store paradox and Rosenthal's centipede game. Our framework
reveals new intuitive subgame perfect equilibria, the characteristics of which
depend on the chosen temporal perspective and payoff evaluation. Ultimately, by
grounding its mathematical foundation in different modes of human cognition,
our work expands the explanatory power of game theory for long-horizon
scenarios.

</details>
