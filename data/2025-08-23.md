<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 8]
- [cs.GT](#cs.GT) [Total: 4]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Hybrelighter: Combining Deep Anisotropic Diffusion and Scene Reconstruction for On-device Real-time Relighting in Mixed Reality](https://arxiv.org/abs/2508.14930)
*Hanwen Zhao,John Akers,Baback Elmieh,Ira Kemelmacher-Shlizerman*

Main category: cs.GR

TL;DR: 本文提出了一种新颖的混合现实场景重光照方法，通过结合图像分割和各向异性扩散的光照传播技术，解决了现有方法在实时性和准确性上的不足，实现了在边缘设备上实时运行的高质量重光照效果。


<details>
  <summary>Details</summary>
Motivation: 混合现实场景重光照在多种应用中具有潜力，如房地产中的房间光照可视化。然而，现有深度学习方法难以满足实时性要求，场景理解方法因扫描限制导致结果不准确，而简单的2D图像滤镜方法无法处理复杂几何和阴影。

Method: 提出了一种新方法，结合图像分割、基于各向异性扩散的光照传播技术，以及简单的滤镜方法，以此纠正设备扫描的误差，并在边缘设备上实现实时运行。

Result: 该方法在边缘设备上能够以高达100帧每秒的速度运行，并提供视觉上吸引人且准确的重光照效果。通过与行业标准的直接对比及相关房地产示例的实践演示，验证了其有效性。

Conclusion: 本文提出的方法在实时性和准确性上优于现有技术，为混合现实场景重光照提供了一种实用的解决方案。

Abstract: Mixed Reality scene relighting, where virtual changes to lighting conditions
realistically interact with physical objects, producing authentic illumination
and shadows, can be used in a variety of applications. One such application in
real estate could be visualizing a room at different times of day and placing
virtual light fixtures. Existing deep learning-based relighting techniques
typically exceed the real-time performance capabilities of current MR devices.
On the other hand, scene understanding methods, such as on-device scene
reconstruction, often yield inaccurate results due to scanning limitations, in
turn affecting relighting quality. Finally, simpler 2D image filter-based
approaches cannot represent complex geometry and shadows. We introduce a novel
method to integrate image segmentation, with lighting propagation via
anisotropic diffusion on top of basic scene understanding, and the
computational simplicity of filter-based techniques. Our approach corrects
on-device scanning inaccuracies, delivering visually appealing and accurate
relighting effects in real-time on edge devices, achieving speeds as high as
100 fps. We show a direct comparison between our method and the industry
standard, and present a practical demonstration of our method in the
aforementioned real estate example.

</details>


### [2] [Inference Time Debiasing Concepts in Diffusion Models](https://arxiv.org/abs/2508.14933)
*Lucas S. Kupssinskü,Marco N. Bochernitsan,Jordan Kopper,Otávio Parraga,Rodrigo C. Barros*

Main category: cs.GR

TL;DR: DeCoDi是一种用于基于扩散的文本到图像生成模型的去偏方法，通过改变推理过程而非训练过程，有效减少偏见概念，同时保持图像质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 针对基于扩散的文本到图像生成模型中存在的偏见问题，DeCoDi通过改变推理过程而非复杂的训练干预，提供了一种更易广泛使用的去偏方法。

Method: DeCoDi通过调整扩散过程，避免潜在维度中的偏见概念区域，实现去偏。该方法仅改变推理过程，无需复杂的计算或干预。

Result: 人工评估1200张生成图像显示，DeCoDi在性别、种族和年龄等偏见维度上表现有效。自动评估与人工评估结果一致，证明了方法的有效性。

Conclusion: DeCoDi通过简单的推理调整，显著提升了基于扩散的文本到图像生成模型生成图像的多样性，具有广泛应用潜力。

Abstract: We propose DeCoDi, a debiasing procedure for text-to-image diffusion-based
models that changes the inference procedure, does not significantly change
image quality, has negligible compute overhead, and can be applied in any
diffusion-based image generation model. DeCoDi changes the diffusion process to
avoid latent dimension regions of biased concepts. While most deep learning
debiasing methods require complex or compute-intensive interventions, our
method is designed to change only the inference procedure. Therefore, it is
more accessible to a wide range of practitioners. We show the effectiveness of
the method by debiasing for gender, ethnicity, and age for the concepts of
nurse, firefighter, and CEO. Two distinct human evaluators manually inspect
1,200 generated images. Their evaluation results provide evidence that our
method is effective in mitigating biases based on gender, ethnicity, and age.
We also show that an automatic bias evaluation performed by the GPT4o is not
significantly statistically distinct from a human evaluation. Our evaluation
shows promising results, with reliable levels of agreement between evaluators
and more coverage of protected attributes. Our method has the potential to
significantly improve the diversity of images it generates by diffusion-based
text-to-image generative models.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Homomorphism Calculus for User-Defined Aggregations](https://arxiv.org/abs/2508.15109)
*Ziteng Wang,Ruijie Fang,Linus Zheng,Dixin Tang,Isil Dillig*

Main category: cs.PL

TL;DR: 本文提出了一种新型的同态演算方法，用于验证和反驳用户定义聚合函数（UDAF）是否满足同态性质，并构造相应的合并运算符，以支持增量计算和并行执行。


<details>
  <summary>Details</summary>
Motivation: 现有的数据处理框架（如Apache Spark和Flink）需要用户定义的聚合函数满足同态性质才能支持高效执行，但是目前缺乏一种系统性的方法来验证和构造这种性质。

Method: 本文提出了一种同态演算方法，用于验证UDAF是否满足同态性质，并构造合并运算符以实现增量计算和并行执行。

Result: 基于该演算实现的算法在真实世界的UDAF上进行了评估，结果显示其性能显著优于两种领先的综合器。

Conclusion: 本文提出的同态演算方法不仅能够验证和反驳UDAF的同态性质，还能构造高效的合并运算符，为数据处理框架的优化提供了有力支持。

Abstract: Data processing frameworks like Apache Spark and Flink provide built-in
support for user-defined aggregation functions (UDAFs), enabling the
integration of domain-specific logic. However, for these frameworks to support
\emph{efficient} UDAF execution, the function needs to satisfy a
\emph{homomorphism property}, which ensures that partial results from
independent computations can be merged correctly. Motivated by this problem,
this paper introduces a novel \emph{homomorphism calculus} that can both verify
and refute whether a UDAF is a dataframe homomorphism. If so, our calculus also
enables the construction of a corresponding merge operator which can be used
for incremental computation and parallel execution. We have implemented an
algorithm based on our proposed calculus and evaluate it on real-world UDAFs,
demonstrating that our approach significantly outperforms two leading
synthesizers.

</details>


### [4] [Software Model Checking via Summary-Guided Search (Extended Version)](https://arxiv.org/abs/2508.15137)
*Ruijie Fang,Zachary Kincaid,Thomas Reps*

Main category: cs.PL

TL;DR: GPS是一种新的软件模型检查算法，通过结合静态分析和测试生成，高效地寻找程序中的漏洞和安全证明，并在性能上优于现有的模型检查工具。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统模型检查方法在处理依赖输入的长错误路径程序时的效率问题，GPS通过结合静态分析和测试生成技术，提出了一种高效的算法。

Method: GPS采用了一种基于组合静态分析的摘要技术，通过剪除不可行路径和生成测试用例来探索新状态，并引入了两层搜索策略和插装技术以保证完备性。

Result: GPS在多个基准测试（包括SV-COMP和现有文献中的程序）中表现优异，解决了更多问题且运行时间更短，优于当前最先进的软件模型检查工具。

Conclusion: 通过引入GPS算法，证明了其在高效性、完备性以及性能上的优势，为软件模型检查领域提供了新的解决方案。

Abstract: In this work, we describe a new software model-checking algorithm called GPS.
GPS treats the task of model checking a program as a directed search of the
program states, guided by a compositional, summary-based static analysis. The
summaries produced by static analysis are used both to prune away infeasible
paths and to drive test generation to reach new, unexplored program states. GPS
can find both proofs of safety and counter-examples to safety (i.e., inputs
that trigger bugs), and features a novel two-layered search strategy that
renders it particularly efficient at finding bugs in programs featuring long,
input-dependent error paths. To make GPS refutationally complete (in the sense
that it will find an error if one exists, if it is allotted enough time), we
introduce an instrumentation technique and show that it helps GPS achieve
refutation-completeness without sacrificing overall performance. We benchmarked
GPS on a suite of benchmarks including both programs from the Software
Verification Competition (SV-COMP) and from prior literature, and found that
our implementation of GPS outperforms state-of-the-art software model checkers
(including the top performers in SV-COMP ReachSafety-Loops category), both in
terms of the number of benchmarks solved and in terms of running time.

</details>


### [5] [Big-Stop Semantics: A Simple Way to Get the Benefits of Small-Step Semantics in a Big-Step Judgment](https://arxiv.org/abs/2508.15157)
*David M Kahn,Jan Hoffmann,Runming Li*

Main category: cs.PL

TL;DR: 该论文提出了一种扩展的大步语义（big-stop语义），通过引入归纳定义来捕捉发散计算，解决了传统大步语义无法描述程序发散行为的问题，同时保持了语义的简洁性。


<details>
  <summary>Details</summary>
Motivation: 传统的大步语义虽然简洁且易于使用，但无法描述程序的发散行为（如无限循环），这使得其在某些场景下表现不足。本文旨在通过扩展大步语义的方法，弥补这一不足。

Method: 作者提出了一种称为\"big-stop语义\"的扩展大步语义，通过引入少量额外的推理规则，定义了一个评估判断，该判断等价于小步语义的自反传递闭包。这一方法避免了其他解决方案中引入复杂规则或全局状态的缺点。

Result: 论文展示了big-stop语义在类型化、非类型化和带效应的PCF语言以及基于while循环的命令式语言中的应用。结果表明，该方法能够在不引入错误状态的情况下捕捉发散计算。

Conclusion: big-stop语义通过简单的扩展，成功地捕捉了程序的发散行为，同时保持了传统大步语义的简洁性和易用性，为程序语义描述提供了一种新的有效工具。

Abstract: As evident in the programming language literature, many practitioners favor
specifying dynamic program behavior using big-step over small-step semantics.
Unlike small-step semantics, which must dwell on every intermediate program
state, big-step semantics conveniently jump directly to the ever-important
result of the computation. Big-step semantics also typically involve fewer
inference rules than their small-step counterparts. However, in exchange for
ergonomics, big-step semantics give up power: Small-step semantics describes
program behaviors that are outside the grasp of big-step semantics, notably
divergence. This work presents a little-known extension of big-step semantics
with inductive definitions that captures diverging computations without
introducing error states. This big-stop semantics is illustrated for typed,
untyped, and effectful variants of PCF, as well as a while-loop-based
imperative language. Big-stop semantics extends the standard big-step inference
rules with a few additional rules to define an evaluation judgment that is
equivalent to the reflexive-transitive closure of small-step transitions. This
simple extension contrasts with other solutions in the literature which
sacrifice ergonomics by introducing many additional inference rules, global
state, and/or less-commonly-understood reasoning principles like coinduction.

</details>


### [6] [Probabilistic Inference for Datalog with Correlated Inputs](https://arxiv.org/abs/2508.15166)
*Jingbo Wang,Shashin Halalingaiah,Weiyi Chen,Chao Wang,Isil Dillig*

Main category: cs.PL

TL;DR: 本文介绍了一种名为Praline的新型Datalog扩展，用于在存在输入相关性时进行精确的概率推理，并提出了一种高效的δ-精确推理算法。


<details>
  <summary>Details</summary>
Motivation: 现有的概率逻辑编程语言（如ProbLog）未考虑输入事实之间的统计相关性，限制了推理的精确性。

Method: 通过将推理任务建模为约束优化问题，结合静态分析和迭代优化，提出了一种高效的δ-精确推理算法。

Result: 实验证明，该方法不仅能有效扩展到大型程序，还能提供紧密的概率界限。

Conclusion: Praline方法在处理输入相关性时表现出高效性和精确性，适用于实际应用场景（如侧信道分析）。

Abstract: Probabilistic extensions of logic programming languages, such as ProbLog,
integrate logical reasoning with probabilistic inference to evaluate
probabilities of output relations; however, prior work does not account for
potential statistical correlations among input facts. This paper introduces
Praline, a new extension to Datalog designed for precise probabilistic
inference in the presence of (partially known) input correlations. We formulate
the inference task as a constrained optimization problem, where the solution
yields sound and precise probability bounds for output facts. However, due to
the complexity of the resulting optimization problem, this approach alone often
does not scale to large programs. To address scalability, we propose a more
efficient $\delta$-exact inference algorithm that leverages constraint solving,
static analysis, and iterative refinement. Our empirical evaluation on
challenging real-world benchmarks, including side-channel analysis,
demonstrates that our method not only scales effectively but also delivers
tight probability bounds.

</details>


### [7] [Exploring the Theory and Practice of Concurrency in the Entity-Component-System Pattern](https://arxiv.org/abs/2508.15264)
*Patrick Redmond,Jonathan Castello,José Manuel Calderón Trilla,Lindsey Kuper*

Main category: cs.PL

TL;DR: 该论文提出了一种形式化模型Core ECS，以抽象化ECS（实体-组件-系统）模式的具体实现，揭示其本质，并发现了一类无论调度如何都能确定性执行的Core ECS程序。


<details>
  <summary>Details</summary>
Motivation: ECS模式虽然在游戏开发中广泛应用，但其在少数领域外并不为人熟知，且现有解释多局限于具体框架或不精确的比喻。论文旨在通过形式化模型Core ECS，提供对ECS模式的严格理解。

Method: 设计了一个形式化模型Core ECS，抽象化具体实现细节，并识别了一类无论调度如何都能确定性执行的Core ECS程序。

Result: 研究发现，现有ECS框架均未能充分利用确定性并发的机会，指出了新的ECS实现技术的潜在空间。

Conclusion: 通过Core ECS模型，论文揭示了ECS模式作为确定性并发编程模型的潜力，并指出了未来框架设计中可以进一步优化的方向。

Abstract: The Entity-Component-System (ECS) software design pattern, long used in game
development, encourages a clean separation of identity (entities), data
properties (components), and computational behaviors (systems). Programs
written using the ECS pattern are naturally concurrent, and the pattern offers
modularity, flexibility, and performance benefits that have led to a
proliferation of ECS frameworks. Nevertheless, the ECS pattern is little-known
and not well understood outside of a few domains. Existing explanations of the
ECS pattern tend to be mired in the concrete details of particular ECS
frameworks, or they explain the pattern in terms of imperfect metaphors or in
terms of what it is not. We seek a rigorous understanding of the ECS pattern
via the design of a formal model, Core ECS, that abstracts away the details of
specific implementations to reveal the essence of software using the ECS
pattern. We identify a class of Core ECS programs that behave deterministically
regardless of scheduling, enabling use of the ECS pattern as a
deterministic-by-construction concurrent programming model. With Core ECS as a
point of comparison, we then survey several real-world ECS frameworks and find
that they all leave opportunities for deterministic concurrency unexploited.
Our findings point out a space for new ECS implementation techniques that
better leverage such opportunities.

</details>


### [8] [Fair Termination for Resource-Aware Active Objects](https://arxiv.org/abs/2508.15333)
*Francesco Dagnino,Paola Giannini,Violet Ka I Pun,Ulises Torrella*

Main category: cs.PL

TL;DR: 开发了一种资源感知的主动对象核心演算和类型系统，确保良好类型的程序可以公平终止。


<details>
  <summary>Details</summary>
Motivation: 主动对象系统是分布式计算的一种模型，用于建模分布式系统和业务流程工作流。这一领域本质上是并发和资源感知的，因此需要开发资源感知的主动对象模型。

Method: 结合了用于顺序程序的分级语义和类型系统技术，以及为同步会话开发的公平终止技术。

Result: 研究成果包括一种核心演算和类型系统，确保良好类型的程序可以公平终止。

Conclusion: 通过结合分级语义和公平终止技术，成功开发了一种资源感知的主动对象模型，并验证了其有效性。

Abstract: Active object systems are a model of distributed computation that has been
adopted for modelling distributed systems and business process workflows. This
field of modelling is, in essence, concurrent and resource-aware, motivating
the development of resource-aware formalisations on the active object model.
The contributions of this work are the development of a core calculus for
resource-aware active objects together with a type system ensuring that
well-typed programs are fairly terminating, i.e., they can always eventually
terminate. To achieve this, we combine techniques from graded semantics and
type systems, which are quite well understood for sequential programs, with
those for fair termination, which have been developed for synchronous~sessions.

</details>


### [9] [Compositional Symbolic Execution for the Next 700 Memory Models (Extended Version)](https://arxiv.org/abs/2508.15576)
*Andreas Lööw,Seung Hoon Park,Daniele Nantes-Sobrinho,Sacha-Élie Ayoun,Opale Sjöstedt,Philippa Gardner*

Main category: cs.PL

TL;DR: 该论文提出了一种新的形式化基础，用于支持内存模型参数化的组合符号执行（CSE）平台，提升了现有技术的灵活性和适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的组合符号执行工具和平台缺乏对内存模型参数化的形式化基础，限制了其在支持多种编程语言分析和性能优化方面的灵活性。

Method: 论文通过Rocq交互式定理证明器机械化其形式化基础，并将其实例化为包括C和CHERI在内的多种内存模型，同时覆盖了SL和ISL分析。

Result: 该形式化基础不仅支持多种内存模型，还扩展了SL和ISL分析的能力，并基于SL和ISL的标准定义确保了与其他工具的互操作性。

Conclusion: 该论文为内存模型参数化的CSE平台提供了坚实的形式化基础，进一步推动了组合符号执行技术的发展和应用。

Abstract: Multiple successful compositional symbolic execution (CSE) tools and
platforms exploit separation logic (SL) for compositional verification and/or
incorrectness separation logic (ISL) for compositional bug-finding, including
VeriFast, Viper, Gillian, CN, and Infer-Pulse. Previous work on the Gillian
platform, the only CSE platform that is parametric on the memory model, meaning
that it can be instantiated to different memory models, suggests that the
ability to use custom memory models allows for more flexibility in supporting
analysis of a wide range of programming languages, for implementing custom
automation, and for improving performance. However, the literature lacks a
satisfactory formal foundation for memory-model-parametric CSE platforms.
  In this paper, inspired by Gillian, we provide a new formal foundation for
memory-model-parametric CSE platforms. Our foundation advances the state of the
art in four ways. First, we mechanise our foundation (in the interactive
theorem prover Rocq). Second, we validate our foundation by instantiating it to
a broad range of memory models, including models for C and CHERI. Third,
whereas previous memory-model-parametric work has only covered SL analyses, we
cover both SL and ISL analyses. Fourth, our foundation is based on standard
definitions of SL and ISL (including definitions of function specification
validity, to ensure sound interoperation with other tools and platforms also
based on standard definitions).

</details>


### [10] [Active Learning for Neurosymbolic Program Synthesis](https://arxiv.org/abs/2508.15750)
*Celeste Barnaby,Qiaochu Chen,Ramya Ramalingam,Osbert Bastani,Isil Dillig*

Main category: cs.PL

TL;DR: 本文提出了一种新的主动学习方法，用于解决神经符号程序合成中神经网络误预测的问题，通过约束符合评估（CCE）提高精度，实验表明其有效性显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的主动学习方法在神经符号程序合成中因神经网络误预测而失效，需要一种能够处理此类误预测的新方法。

Method: 提出基于约束符合评估（CCE）的主动学习技术，通过用户反馈迭代优化CCE，确保剩余程序在观测上等价。

Result: 实验显示，SmartLabel工具在98%的基准测试中成功识别真实程序，平均仅需不到5轮用户交互，而传统方法最多仅能处理65%。

Conclusion: 本文的CCE方法显著提升了神经符号程序合成中的主动学习效果，为相关领域提供了可靠的技术支持。

Abstract: The goal of active learning for program synthesis is to synthesize the
desired program by asking targeted questions that minimize user interaction.
While prior work has explored active learning in the purely symbolic setting,
such techniques are inadequate for the increasingly popular paradigm of
neurosymbolic program synthesis, where the synthesized program incorporates
neural components. When applied to the neurosymbolic setting, such techniques
can -- and, in practice, do -- return an unintended program due to
mispredictions of neural components. This paper proposes a new active learning
technique that can handle the unique challenges posed by neural network
mispredictions. Our approach is based upon a new evaluation strategy called
constrained conformal evaluation (CCE), which accounts for neural
mispredictions while taking into account user-provided feedback. Our proposed
method iteratively makes CCE more precise until all remaining programs are
guaranteed to be observationally equivalent. We have implemented this method in
a tool called SmartLabel and experimentally evaluated it on three neurosymbolic
domains. Our results demonstrate that SmartLabel identifies the ground truth
program for 98% of the benchmarks, requiring under 5 rounds of user interaction
on average. In contrast, prior techniques for active learning are only able to
converge to the ground truth program for at most 65% of the benchmarks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [11] [AI Testing Should Account for Sophisticated Strategic Behaviour](https://arxiv.org/abs/2508.14927)
*Vojtech Kovarik,Eric Olav Chen,Sami Petersen,Alexis Ghersengorin,Vincent Conitzer*

Main category: cs.GT

TL;DR: 该立场论文主张AI测试和评估需要考虑系统战略推理能力，并提出博弈论分析可优化评估设计。


<details>
  <summary>Details</summary>
Motivation: AI系统可能具备理解和战略推理能力，而现有的评估方法未能充分考虑这一点，导致评估结果无法准确预测实际部署行为。

Method: 通过分析现有AI系统的案例、综述相关研究，以及对一个简化评估场景进行形式化战略分析，支持论文的两个主张。

Result: 研究表明，AI系统的战略推理能力会影响评估的准确性，博弈论分析有助于设计更有效的评估方法。

Conclusion: 论文提出需要将战略推理纳入AI评估范畴，并通过博弈论分析改进评估设计，同时指出了未来的研究方向。

Abstract: This position paper argues for two claims regarding AI testing and
evaluation. First, to remain informative about deployment behaviour,
evaluations need account for the possibility that AI systems understand their
circumstances and reason strategically. Second, game-theoretic analysis can
inform evaluation design by formalising and scrutinising the reasoning in
evaluation-based safety cases. Drawing on examples from existing AI systems, a
review of relevant research, and formal strategic analysis of a stylised
evaluation scenario, we present evidence for these claims and motivate several
research directions.

</details>


### [12] [A New Relaxation of Fairness in Two-Sided Matching Respecting Acquaintance Relationships](https://arxiv.org/abs/2508.15296)
*Ryota Takeshima,Kei Kimura,Ayumu Kuroki,Temma Wakasugi,Makoto Yokoo*

Main category: cs.GT

TL;DR: 该研究提出了一种新的局部嫉妒自由（local envy-freeness）公平性概念，通过限制图结构和学校偏好，分析在保持局部嫉妒自由的同时是否能实现帕累托效率匹配。


<details>
  <summary>Details</summary>
Motivation: 传统的双边匹配问题中，效率与公平性往往不可兼得，尤其是在学生与学校的匹配中。以往研究通常通过容忍学生的嫉妒来放松公平性约束。本研究则提出了一种新的方法，专注于解决学生可能更关注的嫉妒问题，即局部嫉妒。

Method: 研究假设学生对非熟人的嫉妒影响较小，从而将学生的关系表示为一个无向图，并定义局部嫉妒为对熟人（图中的邻居）的嫉妒。提出局部嫉妒自由的概念，并通过限制图结构和学校偏好，分析其与帕累托效率的兼容性。

Result: 研究表明，对于接近树结构的图和单峰偏好的图，可以设计出能够实现帕累托效率的同时保持局部嫉妒自由的机制。

Conclusion: 通过引入局部嫉妒自由的概念，本研究为双边匹配问题提供了一种新的平衡效率与公平性的方法，尤其适用于学生-学校匹配等实际场景。

Abstract: Two-sided matching, such as matching between students and schools, has been
applied to various aspects of real life and has been the subject of much
research, however, it has been plagued by the fact that efficiency and fairness
are incompatible. In particular, Pareto efficiency and justified-envy-freeness
are known to be incompatible even in the simplest one-to-one matching, i.e.,
the stable marriage problem. In previous research, the primary approach to
improving efficiency in matchings has been to tolerate students' envy, thereby
relaxing fairness constraints. In this study, we take a different approach to
relaxing fairness. Specifically, it focuses on addressing only the envy that
students may experience or prioritize more highly and seeks matchings without
such envy. More specifically, this study assumes that envy towards students who
are not acquaintances has less impact compared to envy towards students who are
acquaintances. Accordingly, we assume that the students know each other or not,
represented by an undirected graph, and define a local envy as a justified envy
toward an acquaintance or a neighbor in the graph. We then propose the property
that there is no local envy as a new relaxed concept of fairness, called local
envy-freeness. We analyze whether Pareto-efficient matching can be achieved
while maintaining local envy-freeness by meaningfully restricting the graph
structure and the school's preferences. To analyze in detail the fairness that
can achieve Pareto-efficient matching, we introduce a local version of the
relaxed fairness recently proposed by Cho et al. (AAMAS 2024), which
parameterizes the level of local envy-freeness by nonnegative integers. We then
clarify the level of local envy-freeness that can be achieved by
Pareto-efficient mechanisms for graphs that are ``close'' to trees and
single-peaked preferences on the graphs.

</details>


### [13] [ε-Stationary Nash Equilibria in Multi-player Stochastic Graph Games](https://arxiv.org/abs/2508.15356)
*Ali Asadi,Léonard Brice,Krishnendu Chatterjee,K. S. Thejaswini*

Main category: cs.GT

TL;DR: 本文提出了一种算法，用于在基于图的多人随机游戏中计算$ε$-Nash均衡，并通过FNP^NP时间的算法解决承诺问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过$ε$-Nash均衡来近似计算Nash均衡，特别是在受限的基于图的多人随机游戏环境中。

Method: 使用$ε$-Nash均衡近似Nash均衡的方法，并通过双指数概率和浮点表示编码策略，开发了一个FNP^NP时间的算法。

Result: 证明了在存在Nash均衡的情况下，可以找到一个$ε$-Nash均衡，并且该均衡在约束范围内满足$ε$的附加误差。进一步证明了决策问题是NP-hard的。

Conclusion: 研究结果表明，通过$ε$-Nash均衡可以有效地近似Nash均衡，但也揭示了策略中概率的双指数下界限制。

Abstract: A strategy profile in a multi-player game is a Nash equilibrium if no player
can unilaterally deviate to achieve a strictly better payoff. A profile is an
$\epsilon$-Nash equilibrium if no player can gain more than $\epsilon$ by
unilaterally deviating from their strategy. In this work, we use
$\epsilon$-Nash equilibria to approximate the computation of Nash equilibria.
Specifically, we focus on turn-based, multiplayer stochastic games played on
graphs, where players are restricted to stationary strategies -- strategies
that use randomness but not memory.
  The problem of deciding the constrained existence of stationary Nash
equilibria -- where each player's payoff must lie within a given interval -- is
known to be $\exists\mathbb{R}$-complete in such a setting (Hansen and
S{\o}lvsten, 2020). We extend this line of work to stationary $\epsilon$-Nash
equilibria and present an algorithm that solves the following promise problem:
given a game with a Nash equilibrium satisfying the constraints, compute an
$\epsilon$-Nash equilibrium that $\epsilon$-satisfies those same constraints --
satisfies the constraints up to an $\epsilon$ additive error. Our algorithm
runs in FNP^NP time.
  To achieve this, we first show that if a constrained Nash equilibrium exists,
then one exists where the non-zero probabilities are at least an inverse of a
double-exponential in the input. We further prove that such a strategy can be
encoded using floating-point representations, as in the work of Frederiksen and
Miltersen (2013), which finally gives us our FNP^NP algorithm.
  We further show that the decision version of the promise problem is NP-hard.
Finally, we show a partial tightness result by proving a lower bound for such
techniques: if a constrained Nash equilibrium exists, then there must be one
that where the probabilities in the strategies are double-exponentially small.

</details>


### [14] [Almost and Approximate EFX for Few Types of Agents](https://arxiv.org/abs/2508.15380)
*Vishwa Prakash HV,Ruta Mehta,Prajakta Nimbhorkar*

Main category: cs.GT

TL;DR: 本文研究了不可分割物品在具有k种不同加性估值代理中的公平分配问题，证明了在最多四种不同估值时，存在一种2/3-EFX分配；并进一步证明了在EFX与慈善的松弛条件下，存在一种(1-ε)-EFX分配，慈善物品数量为Õ(k/ε)^(1/2)。


<details>
  <summary>Details</summary>
Motivation: 研究公平分配问题是为了在多代理系统中实现近似无嫉妒分配（EFX），特别是在不同估值情况下，确保分配的公平性和可行性。

Method: 采用数学证明的方法，分别在最多四种不同估值和EFX与慈善松弛条件下，证明了存在2/3-EFX分配和(1-ε)-EFX分配。

Result: 证明了在最多四种不同估值时，存在2/3-EFX分配；在EFX与慈善条件下，存在(1-ε)-EFX分配且慈善物品数量为Õ(k/ε)^(1/2)。

Conclusion: 本文扩展了EFX分配的存在性范围，为解决多代理系统中的公平分配问题提供了新的理论支持。

Abstract: We study the problem of fair allocation of a set of indivisible goods among
$n$ agents with $k$ distinct additive valuations, with the goal of achieving
approximate envy-freeness up to any good ($\alpha-\mathrm{EFX}$).
  It is known that EFX allocations exist for $n$ agents when there are at most
three distinct valuations due to HV et al. Furthermore, Amanatidis et al.
showed that a $\frac{2}{3}-\mathrm{EFX}$ allocation is guaranteed to exist when
number of agents is at most seven. In this paper, we show that a
$\frac{2}{3}-\mathrm{EFX}$ allocation exists for any number of agents when
there are at most four distinct valuations.
  Secondly, we consider a relaxation called $\mathrm{EFX}$ with charity, where
some goods remain unallocated such that no agent envies the set of unallocated
goods. Akrami et al. showed that for $n$ agents and any $\varepsilon \in
\left(0, \frac{1}{2}\right]$, there exists a $(1-\varepsilon)-\mathrm{EFX}$
allocation with at most $\tilde{\mathcal{O}}((n/\varepsilon)^{\frac{1}{2}})$
goods to charity. In this paper, we show that a $(1-\varepsilon)-\mathrm{EFX}$
allocation with a $\tilde{\mathcal{O}}(k/\varepsilon)^{\frac{1}{2}}$ charity
exists for any number of agents when there are at most $k$ distinct valuations.

</details>
