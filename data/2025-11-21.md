<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 本文提出了一个统一的框架，用于在虚拟现实中实时实现与刚体、可变形物体和拉格朗日流体的双向触觉交互，通过整合光滑粒子流体动力学（SPH）和双向力耦合技术，提高了触觉反馈的稳定性和物理意义。


<details>
  <summary>Details</summary>
Motivation: 触觉反馈在虚拟环境中提升沉浸感的关键在于用户能够与模拟物体进行物理互动，但在多物理系统中支持精确的力反馈是一个挑战，尤其是在需要实时互动的情况下。

Method: 本文方法整合了光滑粒子流体动力学（SPH）、双向力耦合和反馈平滑技术，以实现稳定的触觉反馈，并提供符合流体-结构行为的触觉响应。

Result: 通过虚拟现实场景中的流体搅拌、软组织操作和刚体互动等交互式实验，展示了该框架的能力。

Conclusion: 本文提出的系统通过将流体、软体和刚体动力学统一到一个适用于沉浸式教育应用的平台中，推动了触觉支持的多物理模拟的发展。

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [2] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 本文提出了一种名为可控层分解（CLD）的方法，用于实现对栅格图像的细粒度和可控多层分离。该方法通过两个关键模块（LD-DiT和MLCA）提升了分层编辑的可控性和精度，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 设计师通常在合成最终栅格图像前独立生成和编辑每个RGBA层，但这一过程不可逆。现有方法在可控性和分割精度上存在局限，因此需要一种更高效的分层编辑解决方案。

Method: 提出了两个关键模块：LD-DiT用于将图像元素解耦到不同层并实现细粒度控制；MLCA通过将目标图像信息注入多层标记中，实现精确的条件生成。

Result: 实验结果表明，CLD在分解质量和可控性方面均优于现有方法。分离出的层可直接在设计工具（如PowerPoint）中操作，体现了其实际价值。

Conclusion: CLD在细粒度分层编辑和实际应用方面表现出色，为创造性工作流程提供了高效的工具。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: 本文探讨了表达问题的基本权衡，并提出了一个解决极性语言中隐式参数的算法类型系统和推断方法。


<details>
  <summary>Details</summary>
Motivation: 极性语言在处理两种类型的扩展性（操作扩展和构造函数扩展）时存在对称性，但目前缺乏隐式参数等现代依赖类型语言功能。本文旨在填补这一空白。

Method: 提出了一种算法类型系统和推断方法，支持隐式参数并尊重语言的核心对称性。提供了完整的类型系统算法描述和统一算法的全面描述。

Result: 实现了还原语义、转换检查和模式匹配的统一算法规则，并提供了一个未完成的实现。

Conclusion: 本文的统一算法和设计决策可为其他对称支持归纳和共归纳类型的依赖类型语言提供参考。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [4] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一种将编排编程引入Elixir的语言，旨在构建鲁棒的分布式应用，其独特之处在于能够容忍参与者失败并通过元编程实现紧密集成。


<details>
  <summary>Details</summary>
Motivation: 现有的编排语言在参与者失败时处理能力有限，Chorex的目标是通过恢复机制和紧密集成提升分布式应用的鲁棒性和开发效率。

Method: Chorex通过元编程实现编排功能，支持参与者失败时的状态恢复和网络配置更新，并静态检查编排要求与实现的匹配性。

Result: Chorex在多个示例中验证了其有效性，包括高阶书商和安全远程密码协议，并展示了检查点机制的开销。

Conclusion: Chorex的策略为其他语言支持可重启参与者提供了一种可行的思路，并通过紧密集成提升了开发体验。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [5] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本文提出了一种分解式虚拟机（BlueScript VM），通过将大部分组件卸载到主机上，利用主机丰富的内存和强大的处理能力，为资源有限的微控制器提供丰富的功能。


<details>
  <summary>Details</summary>
Motivation: 由于微控制器虚拟机的内存限制，现有的虚拟机往往缺乏交互响应性或高执行速度。本文旨在通过分解式虚拟机的设计，解决这些问题。

Method: 设计并实现了BlueScript VM，将大部分组件卸载到主机上，并使用称为“影子机器”的数据结构来减少主机与微控制器之间的通信开销。

Result: 实验证明，卸载组件不会严重影响预期收益，卸载的增量编译器比MicroPython和Espruino执行速度更快，同时保持了与MicroPython相当的交互性。

Conclusion: 研究表明，即使针对内存有限的微控制器，通过分解式虚拟机的设计，也能提供丰富的功能和高性能。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [6] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一种基于Rust的工作流引擎，通过引入命名维度和明确依赖关系的新形式，解决了不规则数据处理中的复杂性和依赖性问题。


<details>
  <summary>Details</summary>
Motivation: 现代数据处理工作流中常遇到不规则数据，现有引擎缺乏原生支持，导致用户需手动管理复杂的索引和依赖关系。Operon旨在解决这一问题。

Method: Operon提供了一种领域特定语言，用户可通过维度注解声明管道，并在运行时动态调度任务。系统还形式化了部分形状的数学基础，并证明其增量构造算法的确定性。

Result: 实证评估显示，Operon在减少基线开销14.94倍的同时，保持了近乎线性的端到端输出率，适用于机器学习中的大规模数据生成流水线。

Conclusion: Operon通过明确的依赖关系和动态调度机制，为不规则数据处理提供了高效且可靠的解决方案，尤其适合机器学习应用。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Prior-free Collusion-proof Dynamic Mechanisms](https://arxiv.org/abs/2511.15727)
*Endre Csóka*

Main category: cs.GT

TL;DR: 本文研究了动态随机多玩家问题的无先验机制,提出了TU-GUM和NTU-GUM的无先验版本,并证明其在特定情况下可实现近似帕累托效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决动态随机多玩家问题中的效率问题,需要设计不依赖于先验信息的机制。

Method: 定义了TU-GUM和NTU-GUM的无先验版本,并在重复单物品分配问题中验证其效果。

Result: 无先验NTU-GUM在特定情况下实现了对帕累托效率的1.283-近似。

Conclusion: 无先验机制在动态随机多玩家问题中具有潜力,能够有效实现近似效率。

Abstract: For a general class of dynamic stochastic multi-player problems, Csóka, Liu, Rodivilov, and Teytelboym (2024) proposed prior-dependent mechanisms. The Guaranteed Utility Mechanism with transfers (TU-GUM) implements efficiency in a Guaranteed Utility Equilibrium (GUE). Its transfer-free variant (NTU-GUM) implements approximate efficiency in ε-GUE. In this paper, we define prior-free versions of both TU-GUM and NTU-GUM. As a special case, we believe that the new prior-free NTU-GUM implements a 1.283-approximation to Pareto efficiency for the repeated single good allocation problem in Fikioris, Banerjee, and Tardos (2024).

</details>


### [8] [Polynomial-Time Algorithms for Computing the Nucleolus: An Assessment](https://arxiv.org/abs/2511.16517)
*Holger I. Meinhardt*

Main category: cs.GT

TL;DR: Maggiorano等人声称开发了一种基于简化博弈方法和子模函数最小化的强多项式时间组合算法，用于凸博弈的核仁，但该算法存在应用错误且忽略了其他解的性质。作者重新评估了其他方法，并证明在特定情况下可以高效计算核仁。


<details>
  <summary>Details</summary>
Motivation: Maggiorano等人的算法声称解决了凸博弈核仁的计算问题，但其基于错误的简化博弈性质应用。作者旨在揭示其错误并探索其他可行的方法。

Method: 作者重新评估了Faigle等人的椭球法和Meinhardt的基于Fenchel-Moreau共轭的凸分析方法，用于计算预核元素，并在单一预核情况下实现高效计算。

Result: 研究发现，Maggiorano等人的算法因选择性错误而失败。而在单一预核情况下，核仁与预核重合，可以通过O(n^3)复杂度的多项式时间算法计算。

Conclusion: Maggiorano等人的算法存在缺陷，但在特定条件下，其他方法仍能高效计算核仁。

Abstract: Recently, Maggiorano et al. (2025) claimed that they have developed a strongly polynomial-time combinatorial algorithm for the nucleolus in convex games that is based on the reduced game approach and submodular function minimization method. Thereby, avoiding the ellipsoid method with its negative side effects in numerical computation completely. However, we shall argue that this is a fallacy based on an incorrect application of the Davis/Maschler reduced game property (RGP). Ignoring the fact that despite the pre-nucleolus, other solutions like the core, pre-kernel, and semi-reactive pre-bargaining set possess this property as well. This causes a severe selection issue, leading to the failure to compute the nucleolus of convex games using the reduced games approach. In order to assess this finding in its context, the ellipsoid method of Faigle et al. (2001) and the Fenchel-Moreau conjugation-based approach from convex analysis of Meinhardt (2013) to compute a pre-kernel element were resumed. In the latter case, it was exploited that for TU games with a single-valued pre-kernel, both solution concepts coincide. Implying that one has computed the pre-nucleolus if one has found the sole pre-kernel element of the game. Though it is a specialized and highly optimized algorithm for the pre-kernel, it assures runtime complexity of O(n^3) for computing the pre-nucleolus whenever the pre-kernel is a single point, which indicates a polynomial-time algorithm for this class of games.

</details>
