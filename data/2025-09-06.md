<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 7]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [LuxDiT: Lighting Estimation with Video Diffusion Transformer](https://arxiv.org/abs/2509.03680)
*Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang*

Main category: cs.GR

TL;DR: 本文提出了LuxDiT，一种基于视频扩散变换器的数据驱动方法，用于从视觉输入生成HDR环境地图，并通过低秩适应微调策略提升输入与预测结果的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 从单张图像或视频估计场景光照是计算机视觉和图形学中的长期挑战，现有的学习型方法受限于真实HDR环境地图的稀缺性和多样性不足。

Method: LuxDiT是一种新颖的数据驱动方法，通过微调视频扩散变换器来生成条件于视觉输入的高动态范围（HDR）环境地图，并使用低秩适应微调策略优化语义对齐。

Result: 方法在合成的多样化光照数据集上训练，能够从间接视觉线索中推断光照，并有效泛化到真实场景，生成的光照预测具有真实的角度高频细节，在定量和定性评估中优于现有技术。

Conclusion: LuxDiT通过学习间接视觉线索和全局非局部上下文关系，为光照估计提供了一种高效的解决方案，显著提升了准确性和实用性。

Abstract: Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.

</details>


### [2] [Memory Optimization for Convex Hull Support Point Queries](https://arxiv.org/abs/2509.03753)
*Michael Greer*

Main category: cs.GR

TL;DR: 本文评估了几种改进凸包内存布局的方法，以加速支持点查询的计算时间，这种查询是常见碰撞算法的核心部分。


<details>
  <summary>Details</summary>
Motivation: 支持点查询是常见碰撞算法的基础操作，但其性能受凸包顶点数量的影响较大，因此需要优化内存布局以提升计算效率。

Method: 通过改进凸包的内存布局，优化支持点查询的计算效率。

Result: 研究结果表明，该方法在不同顶点数量的凸包上均实现了显著的加速效果。

Conclusion: 本文提出的内存布局改进方法显著提升了支持点查询的计算速度，特别是在顶点数量较多的情况下效果更为明显。

Abstract: This paper evaluates several improvements to the memory layout of convex
hulls to improve computation times for support point queries. The support point
query is a fundamental part of common collision algorithms, and the work
presented achieves a significant speedup depending on the number of vertices of
the convex hull.

</details>


### [3] [ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction](https://arxiv.org/abs/2509.03775)
*Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: ContraGS是一种通过压缩3D高斯泼溅（3DGS）表示来减少内存消耗和加速训练/渲染的方法，同时保持模型质量。


<details>
  <summary>Details</summary>
Motivation: 传统的3DGS技术需要大量3D高斯分布来实现高质量场景建模，但这会增加GPU内存消耗并降低训练/渲染效率。ContraGS旨在通过压缩3DGS表示解决这一问题。

Method: ContraGS利用码书紧凑存储高斯参数向量，并通过贝叶斯推断和非可微参数学习的MCMC采样方法，直接在压缩表示上进行训练。

Result: ContraGS显著减少了训练时的峰值内存（平均3.49倍）并加速了训练和渲染（分别平均1.36倍和1.88倍），同时保持了接近现有技术的模型质量。

Conclusion: ContraGS通过压缩3DGS表示成功解决了内存和效率问题，为高质量实时渲染提供了一种高效的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.

</details>


### [4] [TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media](https://arxiv.org/abs/2509.04047)
*Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T. M. Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 该论文提出了一种基于学习的前馈框架TensoIS，用于从稀疏多视角图像中估计异质散射参数，并创建了一个合成数据集HeteroSynth。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设介质均匀或通过复杂路径积分建模异质性，但缺乏明确建模真实世界异质散射参数的方法。论文尝试利用Perlin噪声分布填补这一空白。

Method: 论文提出TensoIS框架，使用可学习的低秩张量分量表示散射体积，并基于Fractal Perlin噪声创建合成数据集HeteroSynth。

Result: TensoIS在合成测试集、烟雾和云几何体以及真实样本上表现出色，验证了其在逆散射问题中的有效性。

Conclusion: 本研究探索了Perlin噪声分布在前馈方式下建模真实世界异质散射的潜力，填补了现有文献的空白。

Abstract: Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.

</details>


### [5] [SMooGPT: Stylized Motion Generation using Large Language Models](https://arxiv.org/abs/2509.04058)
*Lei Zhong,Yi Yang,Changjian Li*

Main category: cs.GR

TL;DR: 该论文提出了一种基于LLM的新方法SMooGPT，用于生成具有高度可解释性和控制性的风格化运动，解决了现有方法在风格迁移和条件生成中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有风格化动作生成方法存在低可解释性、控制性差和对新风格泛化能力有限的问题，论文旨在通过自然语言和LLM的能力改进这些问题。

Method: 论文提出了一种基于推理-组合-生成的新方法，利用身体部位文本空间作为中间表示，并开发了SMooGPT（一种微调的LLM）作为推理、组合和生成工具。

Result: 实验和用户感知研究表明，该方法具有高度的可解释性和控制性，能够有效解决运动内容与风格之间的冲突，并对新风格具有良好的泛化能力。

Conclusion: 基于LLM的SMooGPT方法在风格化动作生成中表现出色，尤其是在纯文本驱动的情况下，为未来研究提供了新的方向和可能性。

Abstract: Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.

</details>


### [6] [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](https://arxiv.org/abs/2509.04145)
*Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard*

Main category: cs.GR

TL;DR: 本文提出了一种结合个性化渲染和扩散生成模型的新方法，能够生成具有高真实感和姿态依赖变形能力的动态人类化身。


<details>
  <summary>Details</summary>
Motivation: 现有的人类化身生成方法要么局限于单一身份的渲染模型，要么生成质量较低且无法捕捉姿态依赖变形。本文旨在结合两者的优势，实现高质量和动态化的化身生成。

Method: 采用两阶段流程：首先优化一组个性化UNet网络以捕捉姿态依赖变形，然后训练一个超扩散模型来生成实时可控的动态化身网络权重。

Result: 实验表明，该方法在大规模、跨身份的多视角视频数据集上优于现有的人类化身生成方法。

Conclusion: 通过结合个性化渲染和扩散生成模型，本文成功实现了高真实感和姿态依赖变形的动态人类化身生成。

Abstract: Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.

</details>


### [7] [Massively-Parallel Implementation of Inextensible Elastic Rods Using Inter-block GPU Synchronization](https://arxiv.org/abs/2509.04277)
*Przemyslaw Korzeniowski,Niels Hald,Fernando Bello*

Main category: cs.GR

TL;DR: 本文提出了一种基于GPU的大规模并行实现方法，用于模拟Cosserat弹性杆模型，显著提高了计算速度，适用于实时模拟导管/导丝等柔性医疗器械。


<details>
  <summary>Details</summary>
Motivation: 为了高效模拟弹性杆（如导管、导丝等）的大范围变形，并实现实时交互式模拟，需要开发一种高性能的并行计算方法。

Method: 采用GPU并行计算模型（基于CUDA Scalable Programming Model），通过块间同步技术，实现了每个内核启动执行多个物理时间步长的高效计算。

Result: 在测试中，GPU实现的原始CoRdE模型速度提升了40倍，而不可伸缩的CoRdE变体平均提升了15.11倍，导管/导丝对的模拟性能提升了13.5倍。

Conclusion: 提出的并行计算方法显著提高了Cosserat弹性杆模型的模拟效率，能够支持实时高精度模拟（0.5-1kHz），适用于医疗器械的交互式应用。

Abstract: An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [8] [When Lifetimes Liberate: A Type System for Arenas with Higher-Order Reachability Tracking](https://arxiv.org/abs/2509.04253)
*Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 本研究结合区域系统、所有权类型和可达性类型的优势，提出了新的资源管理方案，支持灵活的资源共享和静态生命周期控制。


<details>
  <summary>Details</summary>
Motivation: 静态资源管理在高级函数式语言中一直具有挑战性，现有方法（如区域系统和所有权类型）在控制、表达性和灵活性之间存在矛盾。

Method: 提出了两种新的扩展：A<:通过二维存储模型实现粗粒度的可达性跟踪；{A}<:在此基础上提供静态生命周期控制，避免了流敏感推理的复杂性。

Result: 所提出的方案在Rocq中形式化并证明为类型安全的，同时保留了语言的参数化和高阶特性。

Conclusion: 该研究为高阶函数式语言中的静态资源管理提供了一种可行的统一方案，兼具灵活性和安全性。

Abstract: Static resource management in higher-order functional languages remains
elusive due to tensions between control, expressiveness, and flexibility.
Region-based systems [Grossman et al. 2002; Tofte et al. 2001] offer control
over lifetimes and expressive in-region sharing, but restrict resources to
lexical scopes. Rust, an instance of ownership types [Clarke et al. 2013],
offers non-lexical lifetimes and robust safety guarantees, yet its global
invariants make common sharing patterns hard to express. Reachability types
[Wei et al. 2024] enable reasoning about sharing and separation, but lack
practical tools for controlling resource lifetimes.
  In this work, we try to unify their strengths. Our solution enables grouping
resources as arenas for arbitrary sharing and static guarantees of lexically
scoped lifetimes. Crucially, arenas and lexical lifetimes are not the only
choice: users may also manage resources individually, with non-lexical
lifetimes. Regardless of mode, resources share the same type, preserving the
higher-order parametric nature of the language.
  Obtaining static safety guarantee in a higher-order language with flexible
sharing is nontrivial. To this end, we propose two new extensions atop
reachability types [Wei et al. 2024]. First, A<: features a novel
two-dimensional store model to enable coarse-grained reachability tracking for
arbitrarily shared resources within arenas. Building on this, {A}<: establishes
lexical lifetime control with static guarantees. As the first reachability
formalism presented for lifetime control, {A}<: avoids the complication of
flow-sensitive reasoning and retains expressive power and simplicity. Both
calculi are formalized and proven type safe in Rocq.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [9] [The evolution of trust as a cognitive shortcut in repeated interactions](https://arxiv.org/abs/2509.04143)
*Cedric Perret,The Anh Han,Elias Fernández Domingos,Theodor Cimpeanu,Simon T. Powers*

Main category: cs.GT

TL;DR: 该论文通过将信任形式化为重复博弈中的认知捷径，探讨了信任如何在不同社会困境中促进合作。研究发现，信任策略在许多情况下能胜过传统互惠策略，并提高整体合作水平。


<details>
  <summary>Details</summary>
Motivation: 现有博弈论模型往往未能区分合作行为与信任，导致难以测量信任及其在社会困境中的作用。本文旨在通过形式化信任来解决这一问题。

Method: 作者将信任定义为重复博弈中的认知捷径，即一旦观察到合作伙伴的合作行为达到阈值，便停止检查其行为。研究者分析了基于信任的策略在对称双人社会困境博弈中的演化。

Result: 研究发现，在检查合作行为成本高昂的情况下（如现实世界中的许多场景），信任策略能胜过如“以牙还牙”等传统互惠策略。此外，信任的存在提高了整体合作水平，即使在存在策略性信任滥用的情况下。

Conclusion: 研究结果表明，信任启发式能为个体带来适应性优势，并提供了信任如何在不同社会互动中促进合作的形式化理论。作者还讨论了这对人类与人工智能互动的影响。

Abstract: Trust is often thought to increase cooperation. However, game-theoretic
models often fail to distinguish between cooperative behaviour and trust. This
makes it difficult to measure trust and determine its effect in different
social dilemmas. We address this here by formalising trust as a cognitive
shortcut in repeated games. This functions by avoiding checking a partner's
actions once a threshold level of cooperativeness has been observed. We
consider trust-based strategies that implement this heuristic, and
systematically analyse their evolution across the space of two-player symmetric
social dilemma games. We find that where it is costly to check whether another
agent's actions were cooperative, as is the case in many real-world settings,
then trust-based strategies can outcompete standard reciprocal strategies such
as Tit-for-Tat in many social dilemmas. Moreover, the presence of trust
increases the overall level of cooperation in the population, especially in
cases where agents can make unintentional errors in their actions. This occurs
even in the presence of strategies designed to build and then exploit trust.
Overall, our results demonstrate the individual adaptive benefit to an agent of
using a trust heuristic, and provide a formal theory for how trust can promote
cooperation in different types of social interaction. We discuss the
implications of this for interactions between humans and artificial
intelligence agents.

</details>
