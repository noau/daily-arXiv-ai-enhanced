<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 5]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
*Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman*

Main category: cs.GR

TL;DR: 提出了一个完全零样本的动态概念个性化框架，通过结构化视频网格和轻量级Grid-LoRA适配器实现高质量视频编辑与合成，无需实例微调。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成方法通常需要对每个实例进行微调，限制了其扩展性。本文旨在通过零样本框架解决这一问题，实现对动态概念的个性化处理。

Method: 采用结构化2x2视频网格组织输入输出对，训练轻量级Grid-LoRA适配器进行编辑和合成。在推理阶段，通过Grid Fill模块补全部分观测布局，生成时间连贯且保留身份的输出。

Result: 实验表明，该方法在未经训练的动态概念和多样编辑场景中均能产生高质量且一致的结果。

Conclusion: 提出的零样本框架能够高效地实现动态概念个性化，适用于广泛的文本到视频生成任务，且无需测试时优化。

Abstract: Recent advances in text-to-video generation have enabled high-quality
synthesis from text and image prompts. While the personalization of dynamic
concepts, which capture subject-specific appearance and motion from a single
video, is now feasible, most existing methods require per-instance fine-tuning,
limiting scalability. We introduce a fully zero-shot framework for dynamic
concept personalization in text-to-video models. Our method leverages
structured 2x2 video grids that spatially organize input and output pairs,
enabling the training of lightweight Grid-LoRA adapters for editing and
composition within these grids. At inference, a dedicated Grid Fill module
completes partially observed layouts, producing temporally coherent and
identity preserving outputs. Once trained, the entire system operates in a
single forward pass, generalizing to previously unseen dynamic concepts without
any test-time optimization. Extensive experiments demonstrate high-quality and
consistent results across a wide range of subjects beyond trained concepts and
editing scenarios.

</details>


### [2] [DanceGraph: A Complementary Architecture for Synchronous Dancing Online](https://arxiv.org/abs/2507.18052)
*David Sinclair,Ademyemi Ademola,Babis Koniaris,Kenny Mitchell*

Main category: cs.GR

TL;DR: DanceGraph 是一种用于克服网络化身体姿势共享延迟的同步在线舞蹈架构。


<details>
  <summary>Details</summary>
Motivation: 解决网络化身体姿势共享的延迟问题，实现实时、高效的同步在线舞蹈体验。

Method: 开发了一种实时且带宽高效的架构，以减少延迟并缩短动作预测时间，同时提供交互式的参数化舞蹈动作风格化方法。

Result: 该架构有效减少了延迟，实现了与音乐节奏的同步，并通过在线舞蹈矫正提供了参数化的风格化舞蹈动作。

Conclusion: DanceGraph 通过高效架构和交互式方法，成功解决了同步在线舞蹈中的延迟问题，并提供了更丰富的舞蹈体验。

Abstract: DanceGraph is an architecture for synchronized online dancing overcoming the
latency of networked body pose sharing. We break down this challenge by
developing a real-time bandwidth-efficient architecture to minimize lag and
reduce the timeframe of required motion prediction for synchronization with the
music's rhythm. In addition, we show an interactive method for the
parameterized stylization of dance motions for rhythmic dance using online
dance correctives.

</details>


### [3] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
*SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park*

Main category: cs.GR

TL;DR: GeoAvatar是一种用于自适应几何高斯泼溅的框架，通过APS分割高斯区域，优化嘴部结构和变形策略，提升了3D头部化身的重建和动画质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡身份保留与新颖姿势和表情时效果不佳，尤其在面部区域的几何偏差处理上存在问题。GeoAvatar旨在解决这些问题。

Method: 提出了一种自适应几何高斯泼溅框架，包含APS分割高斯区域、嘴部结构优化和部分变形策略，并引入了正则化损失。

Result: 实验证明，GeoAvatar在重建和新颖动画场景中表现优于现有方法。

Conclusion: GeoAvatar通过自适应技术显著提升了3D头部化身的重建和动画质量，同时发布了高表现力的面部动作数据集DynamicFace。

Abstract: Despite recent progress in 3D head avatar generation, balancing identity
preservation, i.e., reconstruction, with novel poses and expressions, i.e.,
animation, remains a challenge. Existing methods struggle to adapt Gaussians to
varying geometrical deviations across facial regions, resulting in suboptimal
quality. To address this, we propose GeoAvatar, a framework for adaptive
geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation
Stage (APS), an unsupervised method that segments Gaussians into rigid and
flexible sets for adaptive offset regularization. Then, based on mouth anatomy
and dynamics, we introduce a novel mouth structure and the part-wise
deformation strategy to enhance the animation fidelity of the mouth. Finally,
we propose a regularization loss for precise rigging between Gaussians and 3DMM
faces. Moreover, we release DynamicFace, a video dataset with highly expressive
facial motions. Extensive experiments show the superiority of GeoAvatar
compared to state-of-the-art methods in reconstruction and novel animation
scenarios.

</details>


### [4] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
*Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng*

Main category: cs.GR

TL;DR: 论文提出了PS-GS方法，结合多视角光度立体（MVPS）和逆向渲染，通过2D高斯光斑建模和多层感知机优化，高效估计物体的几何、材质和光照，提升了3D重建的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的逆向渲染方法依赖固定环境光照，精确度有限。而MVPS虽然提供了更准确的重建，但其与逆向渲染的高效结合仍具挑战性。为此，论文提出PS-GS方法填补这一空白。

Method: 方法首先通过2D高斯光斑建模初始化几何；随后基于全渲染方程和光照计算多层感知机进行逆向渲染优化，并结合未标定光度立体法正则化法线贴图；同时提出2D高斯光线追踪进一步优化光照。

Result: 实验表明，PS-GS在合成和真实数据集上均优于现有方法，显著提升了重建精度和计算效率，并支持新视角合成、重光照及材质与形状编辑。

Conclusion: PS-GS通过多视角和多光源图像的联合优化，解决了逆向渲染的病态问题，为高效且精确的3D重建提供了新思路。

Abstract: Integrating inverse rendering with multi-view photometric stereo (MVPS)
yields more accurate 3D reconstructions than the inverse rendering approaches
that rely on fixed environment illumination. However, efficient inverse
rendering with MVPS remains challenging. To fill this gap, we introduce the
Gaussian Splatting for Multi-view Photometric Stereo (PS-GS), which efficiently
and jointly estimates the geometry, materials, and lighting of the object that
is illuminated by diverse directional lights (multi-light). Our method first
reconstructs a standard 2D Gaussian splatting model as the initial geometry.
Based on the initialization model, it then proceeds with the deferred inverse
rendering by the full rendering equation containing a lighting-computing
multi-layer perceptron. During the whole optimization, we regularize the
rendered normal maps by the uncalibrated photometric stereo estimated normals.
We also propose the 2D Gaussian ray-tracing for single directional light to
refine the incident lighting. The regularizations and the use of multi-view and
multi-light images mitigate the ill-posed problem of inverse rendering. After
optimization, the reconstructed object can be used for novel-view synthesis,
relighting, and material and shape editing. Experiments on both synthetic and
real datasets demonstrate that our method outperforms prior works in terms of
reconstruction accuracy and computational efficiency.

</details>


### [5] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
*Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage*

Main category: cs.GR

TL;DR: 该论文提出了一种通过混合知识蒸馏和伪标签技术训练小型学生模型的方法，用于实时、设备上的语音驱动3D面部动画，显著降低了模型的内存占用和计算需求。


<details>
  <summary>Details</summary>
Motivation: 当前语音驱动3D面部动画模型依赖于大型预训练语音编码器，导致模型过大且仅适用于离线推理。为了解决这一问题，论文探索了设备上的实时动画模型，尤其适用于游戏开发。

Method: 通过混合知识蒸馏和伪标签技术，使用高性能教师模型训练小型学生模型。学生模型仅包含卷积和全连接层，无需注意力机制或循环更新。

Result: 实验显示，该方法将内存占用降至3.4 MB，未来音频上下文需求降至81毫秒，同时保持了高质量的动画效果。

Conclusion: 该研究为设备上的实时推理铺平了道路，是实现真实、模型驱动的数字角色的重要一步。

Abstract: The training of high-quality, robust machine learning models for
speech-driven 3D facial animation requires a large, diverse dataset of
high-quality audio-animation pairs. To overcome the lack of such a dataset,
recent work has introduced large pre-trained speech encoders that are robust to
variations in the input audio and, therefore, enable the facial animation model
to generalize across speakers, audio quality, and languages. However, the
resulting facial animation models are prohibitively large and lend themselves
only to offline inference on a dedicated machine. In this work, we explore
on-device, real-time facial animation models in the context of game
development. We overcome the lack of large datasets by using hybrid knowledge
distillation with pseudo-labeling. Given a large audio dataset, we employ a
high-performing teacher model to train very small student models. In contrast
to the pre-trained speech encoders, our student models only consist of
convolutional and fully-connected layers, removing the need for attention
context or recurrent updates. In our experiments, we demonstrate that we can
reduce the memory footprint to up to 3.4 MB and required future audio context
to up to 81 ms while maintaining high-quality animations. This paves the way
for on-device inference, an important step towards realistic, model-driven
digital characters.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 该论文提出了一个统一的Howe方法，通过抽象高阶规范（AHOS）和纤维化建模行为一致性，证明了在这种一般性条件下，最大行为（双）一致性形成一个程序同余。


<details>
  <summary>Details</summary>
Motivation: 随着具有定量特征（如概率性）语言的兴起，需要扩展归纳方法以处理更精细的行为一致性，但现有方法需要针对每种语言和行为一致性进行复杂调整，因此需要统一的方法。

Method: 论文采用抽象的范畴化方法，通过AHOS建模高阶语言，并通过纤维化建模行为一致性，提供了一个通用的Howe方法框架。

Result: 在AHOS和纤维化的自然条件下，论文证明了最大行为（双）一致性形成一个程序同余，并应用于概率高阶语言的互模拟和行为伪度量。

Conclusion: 论文提出的范畴化框架为行为一致性提供了一个通用的理论支持，能够简化复杂语言的行为等价性证明。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [$k$-Approval Veto: A Spectrum of Voting Rules Balancing Metric Distortion and Minority Protection](https://arxiv.org/abs/2507.17981)
*Fatih Erdem Kizilkaya,David Kempe*

Main category: cs.GT

TL;DR: 该论文探讨了单赢家排名选举中多数原则与少数原则之间的权衡，引入ℓ-互少数准则度量少数保护，并分析k-批准否决投票规则在多种目标下的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于民主选举系统中如何平衡社会福利最大化（多数原则）与保护少数群体（少数原则）之间的矛盾。

Method: 论文通过引入ℓ-互少数准则度量少数保护，并使用k-批准否决投票规则分析其在功利主义、α-百分位和平均主义目标下的表现。

Result: 结果表明，k-批准否决投票规则可以提供任意级别的少数保护，但会降低社会福利。具体来说，功利主义目标的失真随k线性增加，α-百分位目标的失真在α ≥ k/(k+1)时为5，否则无界，而平均主义目标的失真始终为3。

Conclusion: 论文结论指出，k-批准否决投票规则为多数与少数原则之间的权衡提供了灵活选择，但其代价是社会福利的降低。

Abstract: In the context of single-winner ranked-choice elections between $m$
candidates, we explore the tradeoff between two competing goals in every
democratic system: the majority principle (maximizing the social welfare) and
the minority principle (safeguarding minority groups from overly bad
outcomes).To measure the social welfare, we use the well-established framework
of metric distortion subject to various objectives: utilitarian (i.e., total
cost), $\alpha$-percentile (e.g., median cost for $\alpha = 1/2$), and
egalitarian (i.e., max cost). To measure the protection of minorities, we
introduce the $\ell$-mutual minority criterion, which requires that if a
sufficiently large (parametrized by $\ell$) coalition $T$ of voters ranks all
candidates in $S$ lower than all other candidates, then none of the candidates
in $S$ should win. The highest $\ell$ for which the criterion is satisfied
provides a well-defined measure of mutual minority protection (ranging from 1
to $m$).
  Our main contribution is the analysis of a recently proposed class of voting
rules called $k$-Approval Veto, offering a comprehensive range of trade-offs
between the two principles. This class spans between Plurality Veto (for $k=1$)
- a simple voting rule achieving optimal metric distortion - and Vote By Veto
(for $k=m$) which picks a candidate from the proportional veto core. We show
that $k$-Approval Veto has minority protection at least $k$, and thus, it
accommodates any desired level of minority protection. However, this comes at
the price of lower social welfare. For the utilitarian objective, the metric
distortion increases linearly in $k$. For the $\alpha$-percentile objective,
the metric distortion is the optimal value of 5 for $\alpha \ge k/(k+1)$ and
unbounded for $\alpha < k/(k+1)$. For the egalitarian objective, the metric
distortion is the optimal value of 3 for all values of $k$.

</details>


### [8] [On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities](https://arxiv.org/abs/2507.18251)
*Jiarong Jin,Biaoshuai Tao*

Main category: cs.GT

TL;DR: 本文研究了分配不可分割物品给具有个性化双值效用的代理问题，给出了帕累托最优分配的完整刻画，并探讨了EFX分配的存在性与计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决在个性化双值效用下，不可分割物品的公平分配问题，尤其是帕累托最优分配和EFX（无嫉妒性）分配的存在性与计算复杂性。

Method: 方法包括对帕累托最优分配的完整刻画，以及在整数比率下多项式时间算法的提出。对一般情况（比率可为分数）证明了决策问题的coNP完全性。进一步证明了在个性化双值效用下，EFX分配的存在性及多项式时间可计算性。

Result: 结果表明，在整数比率下帕累托最优性可多项式时间判定，而在一般情况下为coNP完全。同时证明了EFX分配在此设置下的存在性及多项式时间可计算性。

Conclusion: 结论指出该研究填补了现有结果的空白，并提出了EFX与帕累托最优分配是否总存在（且可多项式时间计算）的开放问题。

Abstract: We study the fair division problem of allocating $m$ indivisible goods to $n$
agents with additive personalized bi-valued utilities. Specifically, each agent
$i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating
that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For
convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.
  We give a characterization to all the Pareto-optimal allocations. Our
characterization implies a polynomial-time algorithm to decide if a given
allocation is Pareto-optimal in the case each $r_i$ is an integer. For the
general case (where $r_i$ may be fractional), we show that this decision
problem is coNP-complete. Our result complements the existing results: this
decision problem is coNP-complete for tri-valued utilities (where each agent's
value for each good belongs to $\{a,b,c\}$ for some prescribed $a>b>c\geq0$),
and this decision problem belongs to P for bi-valued utilities (where $r_i$ in
our model is the same for each agent).
  We further show that an EFX allocation always exists and can be computed in
polynomial time under the personalized bi-valued utilities setting, which
extends the previous result on bi-valued utilities. We propose the open problem
of whether an EFX and Pareto-optimal allocation always exists (and can be
computed in polynomial time).

</details>
