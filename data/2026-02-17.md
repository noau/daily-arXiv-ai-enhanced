<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.GT](#cs.GT) [Total: 16]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Polar: An Algebraic Analyzer for (Probabilistic) Loops](https://arxiv.org/abs/2602.14573)
*Marcel Moosbrugger,Julian Müllner,Ezio Bartocci,Laura Kovács*

Main category: cs.PL

TL;DR: Polar框架通过代数推理全自动分析经典和概率循环，处理代数递推并计算变量高阶矩的精确闭式，推导不变量和参数敏感性。


<details>
  <summary>Details</summary>
Motivation: 为了解决循环分析中的计算复杂性，特别是涉及概率循环和高阶矩的情况，Polar框架旨在提供一个自动化工具。

Method: Polar通过将循环分析转化为线性递推求解，利用代数递推的闭式计算最强多项式不变量或推断参数敏感性。

Result: Polar能分析包含if语句、多项式算术和常见概率分布的概率循环，且在限定编程模型中具备完备性和正确性。

Conclusion: Polar框架在特定限制下实现了高效和精确的循环分析，但放宽限制会显著增加计算复杂度。

Abstract: We present the Polar framework for fully automating the analysis of classical and probabilistic loops using algebraic reasoning. The central theme in Polar comes with handling algebraic recurrences that precisely capture the loop semantics. To this end, our work implements a variety of techniques to compute exact closed-forms of recurrences over higher-order moments of variables, infer invariants, and derive loop sensitivities with respect to unknown parameters. Polar can analyze probabilistic loops containing if-statements, polynomial arithmetic, and common probability distributions. By translating loop analysis into linear recurrence solving, Polar uses the derived closed-forms of recurrences to compute the strongest polynomial invariant or to infer parameter sensitivity. Polar is both sound and complete within well-defined programming model restrictions. Lifting any of these restrictions results in significant hardness limits of computation. To overcome computational burdens for the sake of efficiency, Polar also provides incomplete but sound techniques to compute moments of combinations of variables.

</details>


### [2] [Optimal Program Synthesis via Abstract Interpretation](https://arxiv.org/abs/2602.14717)
*Stephen Mell,Steve Zdancewic,Osbert Bastani*

Main category: cs.PL

TL;DR: 本文提出了一种在特定领域语言（DSL）中合成最优程序的通用框架，通过A*搜索和基于抽象解释的启发式方法提高可扩展性，并在数据分类DSL中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 合成具有数值常数的程序以优化定量目标（如准确性）是一个挑战。本文旨在提供一种能够保证最优性的通用合成框架，并通过启发式方法提高其可扩展性。

Method: 提出了一种基于A*搜索和抽象解释启发式的通用框架。该方法通过枚举搜索图中的程序子集，利用抽象解释的上界估计来剪枝明显不优的子图。此外，还提出了构造单调语义抽象变换器的策略。

Result: 在两个现有的数据分类DSL中实现了该方法，实验表明其比现有最优合成算法更具可扩展性。

Conclusion: 本文提出的框架能够高效合成最优程序，并通过理论和实验证明了其在DSL中的优越性和可扩展性。

Abstract: We consider the problem of synthesizing programs with numerical constants that optimize a quantitative objective, such as accuracy, over a set of input-output examples. We propose a general framework for optimal synthesis of such programs in a given domain specific language (DSL), with provable optimality guarantees. Our framework enumerates programs in a general search graph, where nodes represent subsets of concrete programs. To improve scalability, it uses A* search in conjunction with a search heuristic based on abstract interpretation; intuitively, this heuristic establishes upper bounds on the value of subtrees in the search graph, enabling the synthesizer to identify and prune subtrees that are provably suboptimal. In addition, we propose a natural strategy for constructing abstract transformers for monotonic semantics, which is a common property for components in DSLs for data classification. Finally, we implement our approach in the context of two such existing DSLs, demonstrating that our algorithm is more scalable than existing optimal synthesizers.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [3] [The Complexity of Tournament Fixing: Subset FAS Number and Acyclic Neighborhoods](https://arxiv.org/abs/2602.13422)
*Yuxi Liu,Junqiang Peng,Mingyu Xiao*

Main category: cs.GT

TL;DR: 本文研究了锦标赛固定问题（TFP），探讨其在不同参数条件下的可解性，并证明了在子集FAS数为常数且邻域为无环时TFP仍为NP难问题。


<details>
  <summary>Details</summary>
Motivation: 探讨锦标赛固定问题（TFP）在子集FAS数参数下的复杂度，填补现有研究的空白，并尝试寻找可解条件。

Method: 通过理论分析，证明TFP在子集FAS数为常数且邻域为无环时仍为NP难问题，并在特定条件下给出了FPT解。

Result: 证明了TFP在子集FAS数为常数且邻域为无环时仍为NP难问题；同时在邻域均为无环时证明了其为FPT问题。

Conclusion: 本文解决了TFP在子集FAS数参数下的复杂度问题，并提供了解决TFP的新条件。

Abstract: The \textsc{Tournament Fixing Problem} (TFP) asks whether a knockout tournament can be scheduled to guarantee that a given player $v^*$ wins. Although TFP is NP-hard in general, it is known to be \emph{fixed-parameter tractable} (FPT) when parameterized by the feedback arc/vertex set number, or the in/out-degree of $v^*$ (AAAI 17; IJCAI 18; AAAI 23; AAAI 26). However, it remained open whether TFP is FPT with respect to the \emph{subset FAS number of $v^*$} -- the minimum number of arcs intersecting all cycles containing $v^*$ -- a parameter that is never larger than the aforementioned ones (AAAI 26). In this paper, we resolve this question negatively by proving that TFP stays NP-hard even when the subset FAS number of $v^*$ is constant $\geq 1$ and either the subgraph induced by the in-neighbors $D[N_{\mathrm{in}}(v^*)]$ or the out-neighbors $D[N_{\mathrm{out}}(v^*)]$ is acyclic. Conversely, when both $D[N_{\mathrm{in}}(v^*)]$ and $D[N_{\mathrm{out}}(v^*)]$ are acyclic, we show that TFP becomes FPT parameterized by the subset FAS number of $v^*$. Furthermore, we provide sufficient conditions under which $v^*$ can win even when this parameter is unbounded.

</details>


### [4] [Personalization Aids Pluralistic Alignment Under Competition](https://arxiv.org/abs/2602.13451)
*Natalie Collina,Surbhi Goel,Aaron Roth,Mirah Shi*

Main category: cs.GT

TL;DR: 研究发现，在AI提供商竞争的环境下，若满足"弱市场对齐"条件，个性化能实现多样用户的对齐结果；而匿名策略下则可能导致无信息行为。强对齐条件可确保用户最优效用。


<details>
  <summary>Details</summary>
Motivation: 探讨竞争的AI提供商能否为偏好多样的用户提供对齐结果，以及个性化模型在此过程中的作用。

Method: 采用多领导者（提供商）和跟随者（用户）的Stackelberg博弈模型，分析提供商和用户的策略互动。

Result: 个性化条件下，弱市场对齐可产生与完美对齐模型相当的结果；匿名策略下则可能出现无信息行为。强对齐条件能保证用户最优效用。

Conclusion: 个性化是实现多元对齐结果的有效手段，而强对齐条件在匿名策略下也能确保用户利益。

Abstract: Can competition among misaligned AI providers yield aligned outcomes for a diverse population of users, and what role does model personalization play? We study a setting where multiple competing AI providers interact with multiple users who must make downstream decisions but differ in preferences. Providers have their own objectives over users' actions and strategically deploy AI models to advance them. We model the interaction as a Stackelberg game with multiple leaders (providers) and followers (users): providers commit to conversational policies, and users choose which model to use, how to converse, and how to act. With user-specific personalization, we show that under a Weak Market Alignment condition, every equilibrium gives each user outcomes comparable to those from a perfectly aligned common model -- so personalization can induce pluralistically aligned outcomes, even when providers are self-interested. In contrast, when providers must deploy a single anonymous policy, there exist equilibria with uninformative behavior under the same condition. We then give a stronger alignment condition that guarantees each user their optimal utility in the anonymous setting.

</details>


### [5] [Revenue-Optimal Pricing for Budget-Constrained Buyers in Data Markets](https://arxiv.org/abs/2602.13897)
*Bhaskar Ray Chaudhury,Jugal Garg,Eklavya Sharma,Jiaxin Song*

Main category: cs.GT

TL;DR: 研究了数据市场中收入最优定价问题，买家有预算限制且理性。发现最优定价在单调且下半连续条件下具有分段线性凸形式，并可通过线性规划高效计算。线性定价虽简单但APX难，设计了在线和离线近似算法。


<details>
  <summary>Details</summary>
Motivation: 探讨数据市场中如何为多数据集设定最优定价函数以最大化总收入，同时考虑买家的预算约束和理性选择。

Method: 分析单调且下半连续的定价函数形式，发现最优定价为分段线性凸（PLC），可通过线性规划计算。进一步研究线性定价的复杂性。

Result: 最优定价呈分段线性凸形式，且当数据集远超买家时，多数定价函数为线性。线性定价虽APX难，但设计了近似算法。

Conclusion: 揭示了非线性定价的高效性与线性定价的复杂性，为探索更广义定价方案和更丰富效用模型奠定基础。

Abstract: We study revenue-optimal pricing in data markets with rational, budget-constrained buyers. Such a market offers multiple datasets for sale, and buyers aim to improve the accuracy of their prediction tasks by acquiring data bundles. For each dataset, the market sets a pricing function, which maps the number of records purchased from the dataset to a non-negative price. The market's objective is to set these pricing functions to maximize total revenue, considering that buyers with quasi-linear utilities choose their bundles optimally under budget constraints.
  We analyze optimal pricing when each dataset's pricing function is only required to be monotone and lower-continuous. Surprisingly, even with this generality, optimal pricing has a highly structured form: it is piecewise linear and convex (PLC) and can be computed efficiently via an LP. Moreover, the total number of kinks across all pricing functions is bounded by the number of buyers. Thus, when datasets far outnumber buyers, most pricing functions are effectively linear.
  This motivates studying linear pricing, where each record in a dataset is priced uniformly. Although competitive equilibrium gives revenue-optimal linear prices in rivalrous markets with quasi-linear buyers, we show that revenue maximization under linear pricing in data markets is APX-hard. Hence, a striking computational dichotomy emerges: fully general (nonlinear) pricing admits a polynomial-time algorithm, while the simpler linear scheme is APX-hard.
  Despite the hardness, we design a 2-approximation algorithm when datasets arrive online, and a $(1-1/e)^{-1}$-approximation algorithm for the offline setting. Our framework lays the groundwork for exploring more general pricing schemes, richer utility models, and a deeper understanding of how market structure -- rivalrous versus non-rivalrous -- shapes revenue-optimal pricing.

</details>


### [6] [Truthful Reporting of Competence with Minimal Verification](https://arxiv.org/abs/2602.14076)
*Reshef Meir,Jonathan Wagner,Omer Ben-Porat*

Main category: cs.GT

TL;DR: 研究了在学生可以自由作弊的家庭考试中，如何通过有限的抽查次数最小化报告的偏差，即学生能力与预期成绩的差异。


<details>
  <summary>Details</summary>
Motivation: 探讨在家庭考试中，学生可能自由作弊的情况下，如何设计机制以减少报告的偏差，并保证诚实报告是最优策略。

Method: 使用了真实性报告为主导策略的机制，并通过抽查验证学生表现。在完美验证条件下，提出了最佳权衡的参数化机制；在噪声验证条件下，利用适当的评分规则构建诚实机制。

Result: 完美验证条件下，提出了最优的权衡机制；噪声验证条件下，构建了良好的诚实机制，但权衡不一定是全局最优。

Conclusion: 即使在验证不完全的情况下，通过适当设计评分规则，可以有效减少报告的偏差并鼓励诚实行为。

Abstract: Suppose you run a home exam, where students should report their own scores but can cheat freely. You can, if needed, call a limited number of students to class and verify their actual performance against their reported score. We consider the class of mechanisms where truthful reporting is a dominant strategy, and truthful agents are never penalized -- even off-equilibrium.
  How many students do we need to verify, in expectation, if we want to minimize the bias, i.e., the difference between agents' competence and their expected grade? When perfect verification is available, we characterize the best possible tradeoff between these requirements and provide a simple parametrized mechanism that is optimal in the class for any distribution of agents' types. When verification is noisy, the task becomes much more challenging. We show how proper scoring rules can be leveraged in different ways to construct truthful mechanisms with a good (though not necessarily optimal) tradeoff.

</details>


### [7] [Evaluating the Performance of Approximation Mechanisms under Budget Constraints](https://arxiv.org/abs/2602.14120)
*Juan Carlos Carbajal,Ahuva Mualem*

Main category: cs.GT

TL;DR: 本文研究了在买家有私有预算的情况下，卖家如何最大化收入的单物品拍卖问题。分析了近似机制的性能与最优机制的对比，揭示了在不同条件下近似机制的收入损失及其局限性。


<details>
  <summary>Details</summary>
Motivation: 传统单物品垄断问题在买家有私有预算的情况下变得复杂，最优机制难以分析。因此，本文旨在评估近似机制的稳健性能，并揭示其在不同条件下的表现。

Method: 使用三种性能指标（GFOR、MVR和非单调性差距）分析近似机制的稳健性。研究了不同分布（有界和无界支持）下的机制表现，特别是估值与预算的相关性影响。

Result: 在有界支持分布下，简单的多对数菜单大小机制可以很好地近似最优收入；而在无界支持或单位正方形集中分布下，任何简单机制都无法保证正比例的最优收入。此外，估值与预算负相关时，某些放松机制可实现无界收入增长。

Conclusion: 研究表明，除了少数特定条件外，近似机制在私有预算存在时会带来较大的收入损失，凸显了机制设计在简单性和稳健性方面的根本限制。分析结果对环境细节极为敏感。

Abstract: We study revenue maximization in a buyer-seller setting where the seller has a single object and the buyer has both a private valuation and a private budget. The presence of private budgets complicates the classic single-product monopoly problem, making optimal mechanisms difficult to analyze. To overcome this, we evaluate the robust performance of approximation mechanisms relative to optimal mechanisms. We work with three measures of performance: the guaranteed fraction of optimal revenue (GFOR) for restricted classes of mechanisms, the maximal value of relaxation (MVR) for relaxed classes, and a revenue non-monotonicity gap for either relaxed or restricted classes. Our analysis reveals sharp contrasts. On the positive side, we show that for distributions with bounded support, simple mechanisms with poly-logarithmic menu size can approximate optimal revenue arbitrarily well, regardless of correlation between valuations and budgets. On the negative side, we establish strong impossibility results: for distributions with unbounded support, or even bounded distributions concentrated in the unit square, no simple mechanism - or indeed any mechanism with a finite or sublinear menu - can guarantee a positive fraction of the optimal revenue. We also demonstrate unbounded revenue gains from certain relaxations when valuations and budgets are negatively correlated, and highlight cases of revenue non-monotonicity. Taken together, our results underscore the fragility of approximation approaches in the presence of private budgets: except for a narrow set of conditions, approximation mechanisms incur large revenue losses, pointing to fundamental limits of simplicity and robustness in mechanism design. Our analysis highlights that approximation results are highly sensitive to details of the design environment.

</details>


### [8] [Pareto and Bowley Reinsurance Games in Peer-to-Peer Insurance](https://arxiv.org/abs/2602.14223)
*Tim J. Boonen,Kenneth Tsz Hin Ng,Tak Wa Ng,Thai Nguyen*

Main category: cs.GT

TL;DR: 提出了一种P2P保险方案，包含风险共享池和再保险公司，研究了计划管理者和再保险公司之间的策略互动，提出了两种博弈论合同设计。


<details>
  <summary>Details</summary>
Motivation: 探讨P2P保险中计划管理者与再保险公司之间的策略互动，以优化风险分配和再保险定价。

Method: 提出两种博弈论合同设计：Pareto设计和Bowley设计，分别通过合作和领导者-追随者框架推导最优合同。

Result: Pareto设计产生多个最优合同，Bowley设计产生唯一最优合同；再保险的存在提升了福利，尤其在Pareto设计中。

Conclusion: Bowley最优合同不具备Pareto最优性，且通常福利较低；再保险特别是Pareto设计对高风险成员更有利。

Abstract: We propose a peer-to-peer (P2P) insurance scheme comprising a risk-sharing pool and a reinsurer. A plan manager determines how risks are allocated among members and ceded to the reinsurer, while the reinsurer sets the reinsurance loading. Our work focuses on the strategic interaction between the plan manager and the reinsurer, and this focus leads to two game-theoretic contract designs: a Pareto design and a Bowley design, for which we derive closed-form optimal contracts. In the Pareto design, cooperation between the reinsurer and the plan manager leads to multiple Pareto-optimal contracts, which are further refined by introducing the notion of coalitional stability. In contrast, the Bowley design yields a unique optimal contract through a leader-follower framework, and we provide a rigorous verification of the individual rationality constraints via pointwise comparisons of payoff vectors. Comparing the two designs, we prove that the Bowley-optimal contract is never Pareto optimal and typically yields lower total welfare. In our numerical examples, the presence of reinsurance improves welfare, especially with Pareto designs and a less risk-averse reinsurer. We further analyze the impact of the single-loading restriction, which disproportionately favors members with riskier losses.

</details>


### [9] [Characterizing Robustness of Strategies to Novelty in Zero-Sum Open Worlds](https://arxiv.org/abs/2602.14278)
*Mayank Kejriwal,Shilpa Thomas,Hongyu Li*

Main category: cs.GT

TL;DR: 该研究探讨了在开放世界中，固定策略代理在面对游戏规则或得分机制变化时的鲁棒性，通过衡量个体鲁棒性和全局影响来评估性能变化。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解固定策略代理在游戏规则或得分机制变化时的表现，从而设计更鲁棒的自主系统对抗动态环境中的新颖条件。

Method: 研究通过在迭代囚徒困境和德州扑克中引入规则或得分机制的扰动，测量个体鲁棒性和全局影响来评估代理性能变化。

Result: 实验结果显示，某些新颖条件会导致严重的性能波动，揭示了代理在扰动下的系统性鲁棒模式。

Conclusion: 研究为设计更鲁棒的自主系统提供了量化基础，尤其是在对抗性和动态环境中应对新颖条件的挑战。

Abstract: In open-world environments, artificial agents must often contend with novel conditions that deviate from their training or design assumptions. This paper studies the robustness of fixed-strategy agents to such novelty within the setting of two-player zero-sum games. We present a general framework for characterizing the impact of environmental novelties, such as changes in payoff structure or action constraints, on agent performance in two distinct domains: Iterated Prisoner's Dilemma (IPD) and heads-up Texas Hold'em Poker. Novelty is operationalized as a perturbation of the game's rules or scoring mechanics, while agent behavior remains fixed. To measure the effects, we introduce two metrics: per-agent robustness, quantifying the relative performance shift of each strategy across novelties, and global impact, summarizing the population-wide disruption caused by a novelty. Our experiments, comprising 30 IPD agents across 20 payoff matrix novelties and 10 Poker agents across 5 rule-based novelties, reveal systematic patterns in robustness and highlight certain novelties that induce severe destabilization. The results offer insights into agent generalizability under perturbation and provide a quantitative basis for designing safer and more resilient autonomous systems in adversarial and dynamic environments.

</details>


### [10] [Offline Learning of Nash Stable Coalition Structures with Possibly Overlapping Coalitions](https://arxiv.org/abs/2602.14321)
*Saar Cohen*

Main category: cs.GT

TL;DR: 本文提出了一种新的联盟形成模型，允许重叠联盟和部分信息下的偏好学习，研究了数据集信息约束对学习效果的影响，并在不同效用反馈模型下设计高效算法以近似纳什稳定解。


<details>
  <summary>Details</summary>
Motivation: 现实中的联盟形成往往是重叠的，且代理的偏好信息不完全已知。现有模型假设联盟不相交且偏好完全已知，这限制了其实际应用。

Method: 提出了一种支持重叠联盟和部分信息的新模型，从固定离线数据集中学习代理偏好，研究了两种效用反馈模型（代理级和联盟级）的影响，并设计了两类高效学习算法。

Result: 在代理级反馈下，算法能在数据集信息充足且必要条件满足时高效收敛到近似纳什稳定解；在联盟级反馈下，需更严格假设才能达到类似效果。实验验证了算法在多种设置下的有效性。

Conclusion: 本文证明了在不同信息约束下学习代理偏好并达成纳什稳定解的可行性，为实际联盟形成问题提供了理论基础和算法支持。

Abstract: Coalition formation concerns strategic collaborations of selfish agents that form coalitions based on their preferences. It is often assumed that coalitions are disjoint and preferences are fully known, which may not hold in practice. In this paper, we thus present a new model of coalition formation with possibly overlapping coalitions under partial information, where selfish agents may be part of multiple coalitions simultaneously and their full preferences are initially unknown. Instead, information about past interactions and associated utility feedback is stored in a fixed offline dataset, and we aim to efficiently infer the agents' preferences from this dataset. We analyze the impact of diverse dataset information constraints by studying two types of utility feedback that can be stored in the dataset: agent- and coalition-level utility feedback. For both feedback models, we identify assumptions under which the dataset covers sufficient information for an offline learning algorithm to infer preferences and use them to recover a partition that is (approximately) Nash stable, in which no agent can improve her utility by unilaterally deviating. Our additional goal is devising algorithms with low sample complexity, requiring only a small dataset to obtain a desired approximation to Nash stability. Under agent-level feedback, we provide a sample-efficient algorithm proven to obtain an approximately Nash stable partition under a sufficient and necessary assumption on the information covered by the dataset. However, under coalition-level feedback, we show that only under a stricter assumption is sufficient for sample-efficient learning. Still, in multiple cases, our algorithms' sample complexity bounds have optimality guarantees up to logarithmic factors. Finally, extensive experiments show that our algorithm converges to a low approximation level to Nash stability across diverse settings.

</details>


### [11] [A Bayesian Framework for Human-AI Collaboration: Complementarity and Correlation Neglect](https://arxiv.org/abs/2602.14331)
*Saurabh Amin,Amine Bennouna,Daniel Huttenlocher,Dingwen Kong,Liang Lyu,Asuman Ozdaglar*

Main category: cs.GT

TL;DR: 论文提出了一个决策理论模型，研究人工智能辅助何时改善或损害人类决策，重点关注信息重叠和行为扭曲的影响。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能辅助对人类决策的实际影响，特别是在人类如何结合自身信息与AI建议的背景下，探讨其改善或损害决策的条件。

Method: 通过决策理论模型分析人类与AI的互动，量化信息重叠和AI建议对行为的影响，并以相关性忽略为例进行实证研究。

Result: 研究表明，AI辅助的效果取决于信息的边际价值和人类使用建议的行为扭曲；信息重叠与AI能力共同决定了互动模式（增强、损害、互补或自动化）。

Conclusion: AI辅助的效果不仅取决于其信息价值，还受人类行为因素的影响；信息重叠是理解人机互动的关键变量。

Abstract: We develop a decision-theoretic model of human-AI interaction to study when AI assistance improves or impairs human decision-making. A human decision-maker observes private information and receives a recommendation from an AI system, but may combine these signals imperfectly. We show that the effect of AI assistance decomposes into two main forces: the marginal informational value of the AI beyond what the human already knows, and a behavioral distortion arising from how the human uses the AI's recommendation. Central to our analysis is a micro-founded measure of informational overlap between human and AI knowledge. We study an empirically relevant form of imperfect decision-making -- correlation neglect -- whereby humans treat AI recommendations as independent of their own information despite shared evidence. Under this model, we characterize how overlap and AI capabilities shape the Human-AI interaction regime between augmentation, impairment, complementarity, and automation, and draw key insights.

</details>


### [12] [Truthful Reverse Auctions for Adaptive Selection via Contextual Multi-Armed Bandits](https://arxiv.org/abs/2602.14476)
*Pronoy Patra,Sankarshan Damle,Manisha Padala,Sujit Gujar*

Main category: cs.GT

TL;DR: 本文提出了一种基于反向拍卖设计和上下文在线学习的框架，用于在多LLM提供商环境中选择最优模型，平衡成本和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多LLM提供商环境中，用户需要在高成本高可靠性的模型和低成本低可靠性的模型之间做出顺序决策，现有机制未解决反向拍卖和上下文适应的问题。

Method: 通过设计基于重采样的方法，将真实的前向MAB机制推广到反向拍卖中，并提出上下文MAB算法，学习查询依赖的模型质量。

Result: 证明了任何具有该方法的单调分配规则都是真实的，并提出了一种具有次线性遗憾的上下文MAB算法。

Conclusion: 该框架结合了机制设计和自适应学习，实现了高效、真实且查询感知的LLM选择。

Abstract: We study the problem of selecting large language models (LLMs) for user queries in settings where multiple LLM providers submit the cost of solving a query. From the users' perspective, choosing an optimal model is a sequential, query-dependent decision problem: high-capacity models offer more reliable outputs but are costlier, while lightweight models are faster and cheaper. We formalize this interaction as a reverse auction design problem with contextual online learning, where the user adaptively discovers which model performs best while eliciting costs from competing LLM providers. Existing multi-armed bandit (MAB) mechanisms focus on forward auctions and social welfare, leaving open the challenges of reverse auctions, provider-optimal outcomes, and contextual adaptation. We address these gaps by designing a resampling-based procedure that generalizes truthful forward MAB mechanisms to reverse auctions and prove that any monotone allocation rule with this procedure is truthful. Using this, we propose a contextual MAB algorithm that learns query-dependent model quality with sublinear regret. Our framework unifies mechanism design and adaptive learning, enabling efficient, truthful, and query-aware LLM selection.

</details>


### [13] [Near-Optimal Best-of-Both-Worlds Fairness for Few Agents](https://arxiv.org/abs/2602.14668)
*Moshe Babaioff,Gefen Frosh*

Main category: cs.GT

TL;DR: 该论文研究了在加法估值下不可分割物品的公平分配问题，提出了首个适用于三个代理的Best-of-Both-Worlds（BoBW）算法，实现了近乎最优的公平性，并提供了高效的近似计算方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，不可分割物品的公平分配问题在多个代理情况下仍存在挑战，尤其是在兼顾事前公平和事后公平方面。论文旨在填补这一空白，提供适用于少数代理的高效算法。

Method: 论文设计了BoBW算法，确保了三个代理下的近乎最优公平性。此外，利用FPTAS方法计算BoBW分布，保证了所有基于嫉妒的公平性，并在近似条件下保留了基于价值的公平性。

Result: 结果表明，对于三个代理，存在一种事前比例分布，其每个分配都是EEFX，并保证每个代理人至少获得其MMS的9/10。此外，论文还提供了适用于两个代理的FPTAS算法。

Conclusion: 该论文提出的BoBW算法在少数代理情况下实现了近乎最优的公平分配，同时提供了高效的近似计算方法，扩展了现有研究的可能性。

Abstract: We consider the problem of fair allocation of indivisible goods among agents with additive valuations, aiming for Best-of-Both-Worlds (BoBW) fairness: a distribution over allocations that is ex-ante fair, and additionally, it is supported only on deterministic allocations that are ex-post fair. We focus on BoBW for few agents, and our main result is the design of the first BoBW algorithms achieving near-optimal fairness for three agents. For three agents, we prove the existence of an ex-ante proportional distribution whose every allocation is Epistemic EFX (EEFX) and guarantees each agent at least $\tfrac{9}{10}$ of her MMS. As MMS allocations do not exist for three additive agents, in every allocation at least one agent might not be getting her MMS. To compensate such an agent, we also guarantee that if an agent is not getting her MMS then she is EFX-satisfied - giving her the strongest achievable envy-based guarantee. Additionally, using an FPTAS for near-MMS partitions, we present an FPTAS to compute a BoBW distribution preserving all envy-based guarantees, and also preserving all value-based guarantees up to $(1-\varepsilon)$. We further show that exact ex-ante proportionality can be restored when dropping EEFX. To do so, we first design, for two agents and any $\varepsilon > 0$, a Fully Polynomial-Time Approximation Scheme (FPTAS) that outputs a distribution which is ex-ante envy-free (and thus proportional) and ex-post envy-free up to any good (EFX), while guaranteeing each agent at least a $(1-\varepsilon)$-fraction of her maximin share (MMS). We then leverage this two-agent FPTAS algorithm as a subroutine to obtain, for three agents, the FPTAS guaranteeing exact ex-ante proportionality. We note that our result for two agents essentially matches the strongest fairness and efficiency guarantees achievable in polynomial time, and thus might be of independent interest.

</details>


### [14] [Revenue Guarantees in Autobidding Platforms](https://arxiv.org/abs/2602.14815)
*Ioannis Caragiannis,Anders Bo Ipsen,Stratis Skoulakis*

Main category: cs.GT

TL;DR: 研究了在线广告自动竞价系统中的收入最大化问题，证明了首次价格均衡（FPPE）在预算约束买家市场中至少能提供最优收入的一半，并在在线和凹估值函数情况下扩展了分析。


<details>
  <summary>Details</summary>
Motivation: 受在线广告自动竞价系统的启发，研究预算约束买家市场中可分割商品的收入最大化问题，以计算最大化总收入的单价和分配方案。

Method: 提出并使用首次价格均衡（FPPE）方法，证明其能提供至少最优收入的一半，并在在线场景和凹估值函数情况下扩展了该方法。

Result: FPPE在预算约束买家市场中保证至少一半的最优收入，在线场景下提供1/4的近似率，并在凹估值函数情况下表现稳健。

Conclusion: FPPE是一种有效的收入最大化方法，适用于预算约束市场和复杂估值函数场景。

Abstract: Motivated by autobidding systems in online advertising, we study revenue maximization in markets with divisible goods and budget-constrained buyers with linear valuations. Our aim is to compute a single price for each good and an allocation that maximizes total revenue. We show that the First-Price Pacing Equilibrium (FPPE) guarantees at least half of the optimal revenue, even when compared to the maximal revenue of buyer-specific prices. This guarantee is particularly striking in light of our hardness result: we prove that revenue maximization under individual rationality and single-price-per-good constraints is APX-hard.
  We further extend our analysis in two directions: first, we introduce an online analogue of FPPE and show that it achieves a constant-factor revenue guarantee, specifically a $1/4$-approximation; second, we consider buyers with concave valuation functions, characterizing an FPPE-type outcome as the solution to an Eisenberg-Gale-style convex program and showing that the revenue approximation degrades gracefully with the degree of nonlinearity of the valuations.

</details>


### [15] [Fair Allocation with Initial Utilities](https://arxiv.org/abs/2602.14850)
*Niclas Boehmer,Luca Kreisel*

Main category: cs.GT

TL;DR: 该论文研究了在不可分割资源分配问题中如何考虑初始不平等以实现结果平等的公平性，并提出了一种新的公平概念和算法。


<details>
  <summary>Details</summary>
Motivation: 传统公平分配算法忽视了代理人的初始不平等，而公平性应理解为结果平等。本文旨在通过扩展经典模型，研究如何在分配资源时考虑初始效用，以实现更公平的结果。

Method: 本文扩展了经典模型，为每个代理人分配初始效用，并研究了基于结果平等原则的新公平概念的可行性和计算复杂性。提出了一种新的公平概念minimum-EF1-init，并设计了基于扩展轮询程序的多项式时间算法。

Result: 研究发现，满足EF1扩展概念的完全分配可能不存在且难以计算。提出的minimum-EF1-init概念总是可满足，并通过算法实现了多项式时间内的计算。

Conclusion: 通过考虑初始不平等，论文提出的新公平概念和算法为解决资源分配问题提供了更贴近现实的方法，进一步推动了公平性在算法设计中的应用。

Abstract: The problem of allocating indivisible resources to agents arises in a wide range of domains, including treatment distribution and social support programs. An important goal in algorithm design for this problem is fairness, where the focus in previous work has been on ensuring that the computed allocation provides equal treatment to everyone. However, this perspective disregards that agents may start from unequal initial positions, which is crucial to consider in settings where fairness is understood as equality of outcome. In such settings, the goal is to create an equal final outcome for everyone by leveling initial inequalities through the allocated resources. To close this gap, focusing on agents with additive utilities, we extend the classic model by assigning each agent an initial utility and study the existence and computational complexity of several new fairness notions following the principle of equality of outcome. Among others, we show that complete allocations satisfying a direct analog of envy-freeness up to one resource (EF1) may fail to exist and are computationally hard to find, forming a contrast to the classic setting without initial utilities. We propose a new, always satisfiable fairness notion, called minimum-EF1-init and design a polynomial-time algorithm based on an extended round-robin procedure to compute complete allocations satisfying this notion.

</details>


### [16] [Thermal Min-Max Games: Unifying Bounded Rationality and Typical-Case Equilibrium](https://arxiv.org/abs/2602.14858)
*Yuma Ichikawa*

Main category: cs.GT

TL;DR: 本文介绍了热最小最大博弈，通过为每个玩家分配温度来调节其理性水平，统一了有限理性和完全理性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于许多应用中博弈是从一个群体中抽取的，玩家表现出有限理性，而战略形式的极小极大博弈理论仅适用于完全理性的情况。

Method: 研究方法是通过热力学松弛引入热最小最大博弈，并开发嵌套复制框架来分析大策略极限下的典型行为。

Result: 研究结果表明，渐进预测能够准确地与中等规模有限博弈的均衡点吻合，预测了典型均衡值和混合策略统计数据。

Conclusion: 结论是热最小最大博弈理论为典型行为提供了可处理的预测，统一了有限理性和完全理性，适用于大策略极限下的博弈分析。

Abstract: Strategic-form min-max game theory examines the existence, multiplicity, selection of equilibria, and the worst-case computational complexity under perfect rationality. However, in many applications, games are drawn from an ensemble, and players exhibit bounded rationality. We introduce thermal min-max games, a thermodynamic relaxation that unifies bounded and perfect rationality by assigning each player a temperature to regulate their rationality level. To analyze typical behavior in the large-strategy limit, we develop a nested replica framework for this relaxation. This theory provides tractable predictions for typical equilibrium values and mixed-strategy statistics as functions of rationality strength, strategy-count aspect ratio, and payoff randomness. Numerical experiments demonstrate that these asymptotic predictions accurately align with the equilibrium of finite games of moderate size.

</details>


### [17] [The Distortion of Stable Matching](https://arxiv.org/abs/2602.14961)
*Aris Filos-Ratsikas,Georgios Kalantzis*

Main category: cs.GT

TL;DR: 本文研究了稳定匹配中的失真问题，探讨了如何在有限访问代理人的基数偏好情况下，设计算法以计算高质量的稳定匹配。研究发现确定性算法存在无限失真，而随机化算法或少量查询可以在某些情况下达到较低的失真。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解稳定匹配算法在有限信息情况下的表现，尤其是当代理人偏好信息不完全时，如何设计高效算法以实现高质量的匹配。

Method: 研究方法包括分析确定性算法的局限性，引入随机化算法（如随机化的延迟接受算法），以及探讨通过少量查询代理人基数偏好来提高匹配质量的方法。

Result: 结果显示，确定性算法在仅有序数信息时存在无限失真，而随机化算法可将失真降至2。此外，每代理人仅需1次查询即可达到相同失真，而改进失真需要更多查询。还展示了在特定分布偏好下的平均性能。

Conclusion: 结论表明，随机化或少量查询是解决稳定匹配失真问题的有效方法，且在特定条件下可实现更优的失真控制。研究结果为实际应用中的匹配算法设计提供了理论支持。

Abstract: We initiate the study of distortion in stable matching. Concretely, we aim to design algorithms that have limited access to the agents' cardinal preferences and compute stable matchings of high quality with respect to some aggregate objective, e.g., the social welfare. Our first result is a strong impossibility: the classic Deferred Acceptance (DA) algorithm of Gale and Shapley [1962], as well as any deterministic algorithm that relies solely on ordinal information about the agents' preferences, has unbounded distortion.
  To circumvent this impossibility, we consider algorithms that either (a) use randomization or (b) perform a small number of value queries to the agents' cardinal preferences. In the former case, we prove that a simple randomized version of the DA algorithm achieves a distortion of $2$, and that this is optimal among all randomized stable matching algorithms. For the latter case, we prove that the same bound of $2$ can be achieved with only $1$ query per agent, and improving upon this bound requires $Ω(\log n)$ queries per agent. We further show that this query bound is asymptotically optimal for any constant approximation: for any $\varepsilon >0$, there exists an algorithm which uses $O(\log n /\varepsilon^2)$ queries, and achieves a distortion of $1+\varepsilon$. Moreover, under natural structural restrictions on the instances of the problem, we provide improved upper bounds on the number of queries required for a $(1+\varepsilon)$-approximation.
  We complement our main findings above with theoretical and empirical results on the average-case performance of stable matching algorithms, when the preferences of the agents are drawn i.i.d. from a given distribution.

</details>


### [18] [Robust Value Maximization in Challenge the Champ Tournaments with Probabilistic Outcomes](https://arxiv.org/abs/2602.14966)
*Umang Bhaskar,Juhi Chaudhary,Sushmita Gupta,Pallavi Jain,Sanjay Seetharaman*

Main category: cs.GT

TL;DR: 研究了在挑战冠军赛（Challenge the Champ）中，当比赛结果具有概率性时如何最大化总价值。尽管在非自适应算法中难以近似最优鲁棒价值（VnaR），但自适应算法或限制概率性比赛时能获得良好近似。


<details>
  <summary>Details</summary>
Motivation: 比赛结果通常是概率性的而非确定性的，此前的研究多关注确定性结果下的价值最大化，本文旨在解决概率性结果下的鲁棒价值最大化问题。

Method: 研究了挑战冠军赛的种子排序问题，探讨了自适应与非自适应算法在概率性比赛结果下的表现，并引入了VnaR（鲁棒价值）概念。

Result: 在非自适应算法中，最优VnaR难以近似；而自适应算法或限制概率性比赛时能有效近似VnaR。

Conclusion: 概率性比赛结果的挑战冠军赛中，自适应算法具有显著优势，能更有效地实现鲁棒价值最大化。

Abstract: Challenge the Champ is a simple tournament format, where an ordering of the players -- called a seeding -- is decided. The first player in this order is the initial champ, and faces the next player. The outcome of each match decides the current champion, who faces the next player in the order. Each player also has a popularity, and the value of each match is the popularity of the winner. Value maximization in tournaments has been previously studied when each match has a deterministic outcome. However, match outcomes are often probabilistic, rather than deterministic. We study robust value maximization in Challenge the Champ tournaments, when the winner of a match may be probabilistic. That is, we seek to maximize the total value that is obtained, irrespective of the outcome of probabilistic matches. We show that even in simple binary settings, for non-adaptive algorithms, the optimal robust value -- which we term the \textsc{VnaR}, or the value not at risk -- is hard to approximate. However, if we allow adaptive algorithms that determine the order of challengers based on the outcomes of previous matches, or restrict the matches with probabilistic outcomes, we can obtain good approximations to the optimal \textsc{VnaR}.

</details>
