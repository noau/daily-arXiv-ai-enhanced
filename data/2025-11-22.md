<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 提出了一個統一的實時雙向觸覺反饋框架，適用於虛擬現實中的剛體、可變形物體和流體交互。


<details>
  <summary>Details</summary>
Motivation: 在虛擬環境中，精確的多物理系統力反饋對提升沉浸感至關重要，但目前面臨計算量大且實時交互困難的挑戰。

Method: 整合了平滑粒子流體動力學（SPH），採用雙向力耦合和反饋平滑技術，以保持穩定並產生物理意義明確的觸覺反應。

Result: 通過虛擬現實場景演示了流體攪拌、軟組織操作和剛體交互等應用，證明了框架的有效性。

Conclusion: 該框架將流體、軟體和剛體動力學統一於單一平台，推動了觸覺技術在多物理模擬中的教育應用發展。

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [2] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 本文提出了一种名为可控层分解（CLD）的新方法，用于实现光栅图像的细粒度和可控多层分离。CLD通过两个关键模块（LD-DiT和MLCA）显著提升了分割精度和可控性，并在实验和实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 设计者在实际工作流程中通常独立生成和编辑RGBA层，但合成后的图像无法进行层级编辑。现有方法在可控性和分割精度上存在局限，因此需要一种更高效的方法。

Method: CLD方法包含两个核心模块：LayerDecompose-DiT（LD-DiT）用于将图像元素解耦到不同层并提供细粒度控制；Multi-Layer Conditional Adapter（MLCA）通过多令牌信息注入实现精确条件生成。

Result: 实验结果表明，CLD在分解质量和可控性上均优于现有方法，且在常用设计工具（如PowerPoint）中可直接操作分离的图层，具有较高的实用价值。

Conclusion: CLD方法不仅解决了现有技术的局限性，还展示了在实际创作工作流程中的广泛适用性和实用价值。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [3] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: Polarity语言旨在解决表达性问题中的两种扩展性对称性问题，并为隐式参数提供一种算法类型系统和推断算法。


<details>
  <summary>Details</summary>
Motivation: 解决依赖类型语言中表达性问题，即在功能编程和面向对象编程中扩展类型的对称性问题。

Method: 提出了一个算法类型系统和推断算法，支持隐式参数，并提供了完整的类型系统描述和统一算法，涵盖任意归纳和共归纳类型。

Result: 提供了一个正在进行中的算法实现，包括归约语义、转换检查和模式匹配的统一算法。

Conclusion: 该论文的算法设计和统一算法描述可以作为其他支持归纳和共归纳类型对称性的依赖类型语言的蓝图。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [4] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一种将协同编程引入Elixir的语言，旨在构建健壮的分布式应用，支持容错并通过元编程实现紧密集成。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式应用中演员崩溃时的恢复问题，并验证通过元编程实现全功能协同语言的可行性。

Method: Chorex通过生成无状态函数集实现演员的可重启性，利用检查点恢复状态并更新网络配置，同时静态检测协同需求与实现的不匹配。

Result: Chorex在多个示例中展示了其功能，包括高阶书商和安全远程密码协议，并测量了检查点的开销。

Conclusion: Chorex的投影策略为其他语言支持可重启演员提供了可行的参考途径。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [5] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本文提出了一种分解式虚拟机（VM），将尽可能多的组件卸载到主机上，以利用主机的丰富内存和强大处理能力，为微控制器提供丰富的功能。


<details>
  <summary>Details</summary>
Motivation: 微控制器虚拟机（VM）由于内存有限，功能受限，且缺乏交互响应性或高执行速度。尽管已有研究尝试卸载某些VM组件，但可卸载的类型仍受限制。

Method: 设计了BlueScript VM作为分解式VM的实例，将大部分组件卸载到主机。为减少通信开销，主机上使用了影子机器数据结构来镜像微控制器的执行状态。

Result: 实验证实，卸载组件不会严重影响预期优势。增量编译器的执行速度优于MicroPython和Espruino，同时保持与MicroPython相当的交互性。动态编译器也提升了VM性能。

Conclusion: 研究表明，即使在内存有限的微控制器上，通过分解式VM也能提供丰富的功能，展示了其可行性。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [6] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一个基于Rust的工作流引擎，专门处理不规则数据，通过命名维度和依赖关系的新颖形式化方法，解决现有引擎在跟踪数据形状和依赖关系上的不足。


<details>
  <summary>Details</summary>
Motivation: 现代数据处理工作流经常遇到不规则数据，而现有引擎缺乏对这些数据的原生支持，用户需手动管理复杂的索引和依赖关系。

Method: Operon引入了一个领域特定语言，用户可通过维度注释声明管道，运行时系统动态调度任务，同时数学上证明了其增量构造算法的确定性和并行执行的合流性。

Result: 实证评估表明，Operon在减少基线开销14.94倍的同时，保持了接近线性的端到端输出率，尤其适用于机器学习中的大规模数据生成管道。

Conclusion: Operon通过显式建模部分已知状态和多队列架构，实现了高效并行和鲁棒性，适合处理不规则数据的大规模工作流。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [7] [Prior-free Collusion-proof Dynamic Mechanisms](https://arxiv.org/abs/2511.15727)
*Endre Csóka*

Main category: cs.GT

TL;DR: Csóka等人（2024）提出了依赖先验的机制，本文定义了这些机制的无先验版本，并展示了其在重复单物品分配问题中的高效性。


<details>
  <summary>Details</summary>
Motivation: 研究一类动态随机多参与者问题的机制设计，旨在实现高效性，尤其在无先验信息的情况下。

Method: 定义了TU-GUM和NTU-GUM的无先验版本，特别针对重复单物品分配问题。

Result: 新的无先验NTU-GUM在重复单物品分配问题中实现了1.283倍的帕累托效率近似。

Conclusion: 本文提出的无先验机制能够有效地解决动态随机问题，尤其在缺乏先验信息的情况下，展示了高效性。

Abstract: For a general class of dynamic stochastic multi-player problems, Csóka, Liu, Rodivilov, and Teytelboym (2024) proposed prior-dependent mechanisms. The Guaranteed Utility Mechanism with transfers (TU-GUM) implements efficiency in a Guaranteed Utility Equilibrium (GUE). Its transfer-free variant (NTU-GUM) implements approximate efficiency in ε-GUE. In this paper, we define prior-free versions of both TU-GUM and NTU-GUM. As a special case, we believe that the new prior-free NTU-GUM implements a 1.283-approximation to Pareto efficiency for the repeated single good allocation problem in Fikioris, Banerjee, and Tardos (2024).

</details>


### [8] [Polynomial-Time Algorithms for Computing the Nucleolus: An Assessment](https://arxiv.org/abs/2511.16517)
*Holger I. Meinhardt*

Main category: cs.GT

TL;DR: Maggiorano等人声称开发了一种基于子模函数最小化的强多项式时间组合算法用于凸博弈的核仁计算,但该作者认为其错误应用了Davis/Maschler简化博弈性质,导致选择问题。通过重新评估Faigle等人的椭球方法和Meinhardt的Fenchel-Moreau共轭方法,证明了在某些条件下可以高效计算预核仁。


<details>
  <summary>Details</summary>
Motivation: 揭露Maggiorano等人在凸博弈核仁计算中的方法错误,并通过其他成熟方法验证正确的计算途径。

Method: 重新评估Faigle等人的椭球方法和Meinhardt的Fenchel-Moreau共轭方法,利用预核与预核仁在单值条件下的等价性。

Result: 证明了在预核为单点时,可以以O(n^3)时间复杂度高效计算预核仁,表明该类博弈的多项式时间算法可行性。

Conclusion: Maggiorano等人的方法存在根本性错误,而通过其他方法在特定条件下可以实现高效核仁计算。

Abstract: Recently, Maggiorano et al. (2025) claimed that they have developed a strongly polynomial-time combinatorial algorithm for the nucleolus in convex games that is based on the reduced game approach and submodular function minimization method. Thereby, avoiding the ellipsoid method with its negative side effects in numerical computation completely. However, we shall argue that this is a fallacy based on an incorrect application of the Davis/Maschler reduced game property (RGP). Ignoring the fact that despite the pre-nucleolus, other solutions like the core, pre-kernel, and semi-reactive pre-bargaining set possess this property as well. This causes a severe selection issue, leading to the failure to compute the nucleolus of convex games using the reduced games approach. In order to assess this finding in its context, the ellipsoid method of Faigle et al. (2001) and the Fenchel-Moreau conjugation-based approach from convex analysis of Meinhardt (2013) to compute a pre-kernel element were resumed. In the latter case, it was exploited that for TU games with a single-valued pre-kernel, both solution concepts coincide. Implying that one has computed the pre-nucleolus if one has found the sole pre-kernel element of the game. Though it is a specialized and highly optimized algorithm for the pre-kernel, it assures runtime complexity of O(n^3) for computing the pre-nucleolus whenever the pre-kernel is a single point, which indicates a polynomial-time algorithm for this class of games.

</details>
