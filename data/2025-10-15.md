<div id=toc></div>

# Table of Contents

- [cs.GR](#cs.GR) [Total: 4]
- [cs.PL](#cs.PL) [Total: 5]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [1] [GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality](https://arxiv.org/abs/2510.11878)
*Anastasiya Pechko,Piotr Borycki,Joanna Waczyńska,Daniel Barczyk,Agata Szymańska,Sławomir Tadeja,Przemysław Spurek*

Main category: cs.GR

TL;DR: Gaussian Splatting for Virtual Environment Rendering and Scene Editing (GS)提出了一种新方法，通过直接集成物体网格与GS表示，解决了VR中3D内容交互的局限性问题。


<details>
  <summary>Details</summary>
Motivation: 随着对沉浸式3D内容需求的增长，现有VR交互方法存在工程密集和几何简化的问题，影响了视觉保真度和物理精度。

Method: GS方法直接集成物体网格与GS表示，实现更精确的表面近似和真实变形交互，同时支持物理引擎无关的设计。

Result: 通过18人参与的对比用户研究，验证了GS方法在物理感知拉伸等操作中显著优于现有技术，并在其他物理操作中表现一致可靠。

Conclusion: GS方法为交互式3D操作提供了一种高效、适应性强且直观的替代方案，具有广泛的应用潜力。

Abstract: As the demand for immersive 3D content grows, the need for intuitive and
efficient interaction methods becomes paramount. Current techniques for
physically manipulating 3D content within Virtual Reality (VR) often face
significant limitations, including reliance on engineering-intensive processes
and simplified geometric representations, such as tetrahedral cages, which can
compromise visual fidelity and physical accuracy. In this paper, we introduce
\our{} (\textbf{G}aussian \textbf{S}platting for \textbf{V}irtual
\textbf{E}nvironment \textbf{R}endering and \textbf{S}cene \textbf{E}diting), a
novel method designed to overcome these challenges by directly integrating an
object's mesh with a Gaussian Splatting (GS) representation. Our approach
enables more precise surface approximation, leading to highly realistic
deformations and interactions. By leveraging existing 3D mesh assets, \our{}
facilitates seamless content reuse and simplifies the development workflow.
Moreover, our system is designed to be physics-engine-agnostic, granting
developers robust deployment flexibility. This versatile architecture delivers
a highly realistic, adaptable, and intuitive approach to interactive 3D
manipulation. We rigorously validate our method against the current
state-of-the-art technique that couples VR with GS in a comparative user study
involving 18 participants. Specifically, we demonstrate that our approach is
statistically significantly better for physics-aware stretching manipulation
and is also more consistent in other physics-based manipulations like twisting
and shaking. Further evaluation across various interactions and scenes confirms
that our method consistently delivers high and reliable performance, showing
its potential as a plausible alternative to existing methods.

</details>


### [2] [Coordinate Condensation: Subspace-Accelerated Coordinate Descent for Physics-Based Simulation](https://arxiv.org/abs/2510.12053)
*Ty Trusty*

Main category: cs.GR

TL;DR: Coordinate Condensation是一种改进的坐标下降方法，通过结合Schur补子空间校正来加速物理仿真，避免了阻尼问题，并在适当情况下实现近牛顿收敛。


<details>
  <summary>Details</summary>
Motivation: 传统坐标下降方法在处理全局耦合问题时引入阻尼，可能降低收敛速度。本文旨在通过改进方法消除阻尼并提高效率。

Method: 利用Schur补子空间校正增强局部坐标更新，独立求解局部和子空间位移，避免阻尼问题。

Result: 实验表明，该方法在不同材料刚度和网格分辨率下均显著优于传统坐标下降和JGS2方法，收敛速度更快。

Conclusion: Coordinate Condensation在保持高效并行性的同时，实现了近牛顿收敛，并为未来求解器设计提供了指导。

Abstract: We introduce Coordinate Condensation, a variant of coordinate descent that
accelerates physics-based simulation by augmenting local coordinate updates
with a Schur-complement-based subspace correction. Recent work by Lan et al.
2025 (JGS2) uses perturbation subspaces to augment local solves to account for
global coupling, but their approach introduces damping that can degrade
convergence. We reuse this subspace but solve for local and subspace
displacements independently, eliminating this damping. For problems where the
subspace adequately captures global coupling, our method achieves near-Newton
convergence while retaining the efficiency and parallelism of coordinate
descent. Through experiments across varying material stiffnesses and mesh
resolutions, we show substantially faster convergence than both standard
coordinate descent and JGS2. We also characterize when subspace-based
coordinate methods succeed or fail, offering insights for future solver design.

</details>


### [3] [Can Representation Gaps Be the Key to Enhancing Robustness in Graph-Text Alignment?](https://arxiv.org/abs/2510.12087)
*Heng Zhang,Tianyi Zhang,Yuling Shi,Xiaodong Gu,Yaomin Shen,Zijian Zhang,Yilei Yuan,Hao Zhang,Jin Huang*

Main category: cs.GR

TL;DR: 论文提出了一个名为LLM4GTA的框架，通过保留表示间隙来解决文本属性图（TAGs）中图和文本表示之间的几何不兼容问题，从而提升迁移性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过对比学习最大化跨模态相似性，但过度对齐会导致表示空间的结构崩溃，损害拓扑推理和语义理解能力。

Method: LLM4GTA框架包括自适应间隙保留模块和模态内补偿机制，前者防止过度对齐，后者通过辅助分类器增强图空间的区分能力。

Result: 实验表明，LLM4GTA在零样本和少样本场景下显著优于现有方法。

Conclusion: 保留表示间隙是维护模态特定知识和提升迁移性能的关键，LLM4GTA有效地解决了现有方法的局限性。

Abstract: Representation learning on text-attributed graphs (TAGs) integrates
structural connectivity with rich textual semantics, enabling applications in
diverse domains. Current methods largely rely on contrastive learning to
maximize cross-modal similarity, assuming tighter coupling between graph and
text representations improves transfer performance. However, our empirical
analysis reveals that both natural gap expansion and forced gap reduction
result in performance degradation by disrupting pre-trained knowledge
structures and impairing generalization. This arises from the geometric
incompatibility between encoders, where graph encoders capture topological
patterns, while text encoders capture semantic structures. Over-alignment
compresses these distinct spaces into shared subspaces, causing structure
collapse that diminishes both topological reasoning and semantic understanding.
We propose \textbf{LLM4GTA}, a gap-aware alignment framework that preserves
representation gaps as geometric necessities for maintaining modality-specific
knowledge and improving transfer performance. LLM4GTA includes an adaptive gap
preservation module to prevent over-alignment by monitoring similarity
evolution and an intra-modal compensation mechanism that boosts discriminative
power using auxiliary classifiers in graph space. Extensive experiments show
significant improvements over existing methods in zero-shot and few-shot
scenarios.

</details>


### [4] [SDGraph: Multi-Level Sketch Representation Learning by Sparse-Dense Graph Architecture](https://arxiv.org/abs/2510.12192)
*Xi Cheng,Pingfa Feng,Zhichao Liao,Mingyu Fan,Long Zeng*

Main category: cs.GR

TL;DR: 该论文提出了一种多级别草图表示方案（Multi-Level Sketch Representation Scheme）和深度学习架构SDGraph，用于系统识别和利用草图中的有效信息，显著提升了草图分类、检索和生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的草图学习方法在识别和利用草图中的有效信息方面存在局限，缺乏对有效信息的系统性研究，这限制了现有方法的性能。

Method: 首先提出了多级别草图表示方案，将草图信息分为草图级、笔画级和点级三个层次；随后设计了深度学习架构SDGraph，包含稀疏图和稠密图两个互补模块，分别用于不同层次的表示学习，并通过信息融合模块增强特征提取。

Result: SDGraph在草图分类和检索任务中分别实现了1.15%和1.70%的准确率提升，在矢量草图生成质量上提升了36.58%。

Conclusion: 多级别草图表示方案和SDGraph架构有效提升了草图相关任务的性能，验证了系统性识别和利用草图信息的潜力。

Abstract: Freehand sketches exhibit unique sparsity and abstraction, necessitating
learning pipelines distinct from those designed for images. For sketch learning
methods, the central objective is to fully exploit the effective information
embedded in sketches. However, there is limited research on what constitutes
effective sketch information, which in turn constrains the performance of
existing approaches. To tackle this issue, we first proposed the Multi-Level
Sketch Representation Scheme to systematically identify the effective
information. The scheme organizes sketch representation into three levels:
sketch-level, stroke-level, and point-level. This design is based on the
granularity of analytical elements, from coarse (sketch-level) to fine
(point-level), thereby ensuring more comprehensive coverage of the sketch
information. For each level, we conducted theoretical analyses and experimental
evaluations to identify and validate the effective information. Building on the
above studies, we developed SDGraph, a deep learning architecture designed to
exploit the identified effective information across the three levels. SDGraph
comprises two complementary modules: a Sparse Graph that treats strokes as
nodes for sketch-level and stroke-level representation learning, and a Dense
Graph that treats points as nodes for sketch-level and point-level
representation learning. Both modules employ graph convolution along with
down-sampling and up-sampling operations, enabling them to function as both
encoder and decoder. Besides that, an information fusion module bridges the two
graphs to further enhance feature extraction. SDGraph supports a wide range of
sketch-related downstream tasks, achieving accuracy improvements of 1.15\% and
1.70\% over the state-of-the-art in classification and retrieval, respectively,
and 36.58\% improvement in vector sketch generation quality.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [5] [Verifying Correctness of Shared Channels in a Cooperatively Scheduled Process-Oriented Language](https://arxiv.org/abs/2510.11751)
*Jan Pedersen,Kevin Chalmers*

Main category: cs.PL

TL;DR: 该论文研究了协作调度运行时中共享通信通道的行为，使用FDR工具进行规范检查和建模，验证了正确行为实现的可行性，但指出其依赖于资源的充足性。


<details>
  <summary>Details</summary>
Motivation: 研究共享通信通道在协作调度运行时中的行为，以确保并发组件在现实条件下能按规范运行。

Method: 使用FDR工具进行规范检查和建模，开发共享通道的行为规范和其在ProcessJ语言中的实现模型。

Result: 结果表明，虽然可以正确实现共享通道的行为，但其结果依赖于执行所有相关进程的充足资源。

Conclusion: 建模并发组件的运行时环境是确保其在现实中按规范运行的必要条件。

Abstract: Correct concurrent behaviour is important in understanding how components
will act within certain conditions. In this work. we analyse the behaviour of
shared communicating channels within a coorporatively scheduled runtime. We use
the refinement checking and modelling tool FDR to develop both specifications
of how such shared channels should behave and models of the implementations of
these channels in the cooperatively scheduled language ProcessJ. Our results
demonstrate that although we can certainly implement the correct behaviour of
such channels, the outcome is dependant on having adequate resources available
to execute all processes involved. We conclude that modelling the runtime
environment of concurrent components is necessary to ensure components behave
as specified in the real world.

</details>


### [6] [AwareCompiler: Agentic Context-Aware Compiler Optimization via a Synergistic Knowledge-Data Driven Framework](https://arxiv.org/abs/2510.11759)
*Hongyu Lin,Haolin Pan,Haoran Luo,Yuchen Li,Kaichun Yao,Libo Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.PL

TL;DR: 本文提出了一个名为AwareCompiler的框架，通过结合结构化知识整合、知识驱动的自适应优化过程生成和数据驱动的混合训练流程，解决了LLM代理在编译器优化中的语义不对齐、交互效率低和奖励稀疏等问题。


<details>
  <summary>Details</summary>
Motivation: 编译器优化对提升程序性能至关重要，但现有基于LLM的代理在自动化编译器优化中面临语义不对齐、交互效率低和奖励稀疏的挑战。

Method: AwareCompiler框架通过结构化知识整合和数据集构建、知识驱动的自适应优化过程生成以及数据驱动的混合训练流程，解决了上述挑战。

Result: 在标准基准测试中，AwareCompiler在性能和效率上均显著优于现有基线，验证了其知识数据驱动方法的有效性。

Conclusion: AwareCompiler通过创新的知识数据驱动方法，成功提升了编译器优化的自动化水平和性能，为相关领域提供了新的解决方案。

Abstract: Compiler optimization is crucial for enhancing program performance by
transforming the sequence of optimization passes while maintaining correctness.
Despite the promising potential of large language models (LLMs)-based agent for
software optimization, automating compiler optimization remains challenging due
to: (1) semantic misalignment between abstract program representations and
concrete optimization passes, (2) inefficient interaction mechanisms between
agents and compiler environments, and (3) reward sparsity from the extensive
decision-making process within large optimization spaces. This paper introduces
\textbf{AwareCompiler}, an agentic framework for compiler optimization that
addresses these challenges through three key innovations: structured knowledge
integration and dataset construction, knowledge-driven adaptive pass
generation, and data-driven hybrid training pipeline. Experimental results on
standard benchmarks demonstrate that AwareCompiler significantly outperforms
existing baselines in both performance and efficiency, highlighting the
effectiveness of our synergistic knowledge-data-driven approach. Our code is
publicly available at https://github.com/LHY-24/AwareCompiler.

</details>


### [7] [Functional Reasoning for Distributed Systems with Failures](https://arxiv.org/abs/2510.12131)
*Haobin Ni,Robbert van Renesse,Greg Morrisett*

Main category: cs.PL

TL;DR: 本文通过设计双语言Sync和Async，将分布式系统的非正式推理与标准形式方法联系起来，提出了一种组合式形式推理方法，适用于包括拜占庭故障在内的分布式系统。


<details>
  <summary>Details</summary>
Motivation: 分布式系统理论中的非正式推理虽然直观，但其正确性和形式证明的对应性存疑。本文旨在通过语言设计和元分析，将这种推理方式正式化并与标准形式方法连接。

Method: 设计了双语言Sync和Async，Sync以同步数据并行程序描述分布式系统，适合Hoare风格的形式推理；Async以交互式单子程序集合描述系统，具有标准基于跟踪的操作语义。Sync编译为Async并可提取为可执行代码。

Result: 证明了在Sync程序的指称语义中验证的安全属性在其编译的Async程序的操作语义中得以保留。并在Rocq中实现了双语言，验证了BOSCO和SeqPaxos两种容错共识协议的安全属性。

Conclusion: 本文通过双语言设计，提供了一个组合式形式推理框架，成功将分布式系统的非正式推理与形式证明联系起来。

Abstract: Distributed system theory literature often argues for correctness using an
informal, Hoare-like style of reasoning. While these arguments are intuitive,
they have not all been foolproof, and whether they directly correspond to
formal proofs is in question. We formally ground this kind of reasoning and
connect it to standard formal approaches through language design and
meta-analysis, which leads to a functional style of compositional formal
reasoning for a class of distributed systems, including cases involving
Byzantine faults. The core of our approach is twin languages: Sync and Async,
which formalize the insight from distributed system theory that an asynchronous
system can be reduced to a synchronous system for more straightforward
reasoning under certain conditions. Sync describes a distributed system as a
single, synchronous, data-parallel program. It restricts programs syntactically
and has a functional denotational semantics suitable for Hoare-style formal
reasoning. Async models a distributed system as a collection of interacting
monadic programs, one for each non-faulty node in the system. It has a standard
trace-based operational semantics, modeling asynchrony with interleaving. Sync
compiles to Async and can then be extracted to yield executable code. We prove
that any safety property proven for a Sync program in its denotational
semantics is preserved in the operational semantics of its compiled Async
programs. We implement the twin languages in Rocq and verify the safety
properties of two fault-tolerant consensus protocols: BOSCO and SeqPaxos.

</details>


### [8] [Operational methods in semantics](https://arxiv.org/abs/2510.12295)
*Roberto M. Amadio*

Main category: cs.PL

TL;DR: 这篇论文概述了编程语言的操作语义学的基本思想和方法，强调了其在实际应用中的有效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是通过抽象描述程序的执行步骤，建立一个可扩展的框架，以支持语义等价性、规范语言和静态分析的研究和应用。

Method: 采用操作语义学的方法，从程序的抽象计算步骤出发，逐步构建语义等价性、规范语言和静态分析的理论体系。

Result: 操作语义学方法在数学复杂度适中、适应多种编程特性的情况下表现优异，适用于便携式语言实现、程序属性规范和测试，以及编译器或静态分析器正确性证明等任务。

Conclusion: 操作语义学是一种有效且灵活的框架，适用于编程语言的语义学研究及其实际应用，具有广泛的应用前景。

Abstract: The focus of these lecture notes is on abstract models and basic ideas and
results that relate to the operational semantics of programming languages
largely conceived. The approach is to start with an abstract description of the
computation steps of programs and then to build on top semantic equivalences,
specification languages, and static analyses. While other approaches to the
semantics of programming languages are possible, it appears that the
operational one is particularly effective in that it requires a moderate level
of mathematical sophistication and scales reasonably well to a large variety of
programming features. In practice, operational semantics is a suitable
framework to build portable language implementations and to specify and test
program properties. It is also used routinely to tackle more ambitious tasks
such as proving the correctness of a compiler or a static analyzer.

</details>


### [9] [GUPPY: Pythonic Quantum-Classical Programming](https://arxiv.org/abs/2510.12582)
*Mark Koch,Alan Lawrence,Kartik Singhal,Seyon Sivarajah,Ross Duncan*

Main category: cs.PL

TL;DR: Guppy是一个嵌入Python的领域特定语言，旨在让用户以Python语法编写具有复杂控制流的混合量子程序，并在实际量子硬件上运行。


<details>
  <summary>Details</summary>
Motivation: 当前的量子编程工具通常缺乏高级控制和灵活性，难以支持复杂的控制流。Guppy旨在通过Pythonic语法提供更直观的编程体验，并将程序运行在实际量子硬件上。

Method: Guppy是一种嵌入Python的领域特定语言，允许用户编写高级混合量子程序，并支持复杂的控制流。

Result: Guppy提供了Pythonic的编程语法，使得编写和控制量子程序更加直观和灵活。

Conclusion: Guppy为量子编程提供了一种更高级和灵活的工具，有望在实际量子硬件上运行复杂程序。

Abstract: We present ongoing work on Guppy, a domain-specific language embedded in
Python that allows users to write high-level hybrid quantum programs with
complex control flow in Pythonic syntax, aiming to run them on actual quantum
hardware.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [10] [Rationally Analyzing Shelby: Proving Incentive Compatibility in a Decentralized Storage Network](https://arxiv.org/abs/2510.11866)
*Michael Crystal,Guy Goren,Scott Duke Kominers*

Main category: cs.GT

TL;DR: 本文分析了Shelby存储网络协议的激励属性，首次提供了其激励特性的正式证明，并探讨了其对联盟行为的抵抗能力。


<details>
  <summary>Details</summary>
Motivation: 尽管区块链上的去中心化存储是Web3生态的核心组成部分，但大多数存储协议的激励属性缺乏正式分析。这种分析空白可能导致系统虽然能够分发存储，但无法真正实现去中心化。

Method: 通过博弈论模型分析了Shelby协议的激励属性，研究了其结合链下审计与偶尔链上验证的设计，并对联盟行为进行了探讨。

Result: 研究表明，单独的链下审计会导致普遍的逃避行为，而Shelby的结合设计在自然参数设置下实现了激励兼容性。此外，提出了一个简单的修改以增强协议的抵抗联盟能力。

Conclusion: Shelby协议的激励设计在理论上是可行的，通过适当的修改可以进一步增强其抵抗恶意联盟的能力，从而为去中心化存储提供了一个更有前途的解决方案。

Abstract: Decentralized storage is one of the most natural applications built on
blockchains and a central component of the Web3 ecosystem. Yet despite a decade
of active development -- from IPFS and Filecoin to more recent entrants -- most
of these storage protocols have received limited formal analysis of their
incentive properties. Claims of incentive compatibility are sometimes made, but
rarely proven. This gap matters: without well-designed incentives, a system may
distribute storage but fail to truly decentralize it.
  We analyze Shelby -- a storage network protocol recently proposed by Aptos
Labs and Jump Crypto -- and provide the first formal proof of its incentive
properties. Our game-theoretic model shows that while off-chain audits alone
collapse to universal shirking, Shelby's combination of peer audits with
occasional on-chain verification yields incentive compatibility under natural
parameter settings. We also examine coalition behavior and outline a simple
modification that strengthens the protocol's collusion-resilience.

</details>


### [11] [Fair Division of Indivisible Items](https://arxiv.org/abs/2510.12158)
*Kevin Hsu*

Main category: cs.GT

TL;DR: 研究了不可分割物品的公平分配问题，包括一般模型和图模型中的MMS、EF1和EFX公平标准。提出了混合物品存在MMS分配的充分条件，分析了EFX取向的多项式时间算法和NP完全性，并解决了图模型中EF1和EFX取向的问题。


<details>
  <summary>Details</summary>
Motivation: 探讨不可分割物品在不同公平标准下的分配问题，尤其是在混合物品（物品和杂务）中MMS分配的存在性，以及图模型中EFX和EF1取向的计算复杂度。

Method: 采用一般模型和图模型分析方法，研究了MMS、EF1和EFX公平标准在不同条件下的分配可能性，并通过多项式时间算法和NP完全性证明了部分问题的计算复杂度。

Result: 证明了混合物品在特定条件下存在MMS分配；EFX取向在图模型中是NP完全问题，但在特定多图中可多项式时间内解决；EF1和EFX取向在图模型中可多项式时间内解决，而在多图中则为NP难问题。

Conclusion: 研究揭示了混合物品分配的复杂性，并为图模型中公平分配问题的算法设计和计算复杂度提供了新见解，突出了物品和杂务分配的根本差异。

Abstract: We study the fair division of indivisible items. In the general model, the
goal is to allocate $m$ indivisible items to $n$ agents while satisfying
fairness criteria such as MMS, EF1, and EFX. We also study a
recently-introduced graphical model that represents the fair division problem
as a multigraph, in which vertices correspond to agents and edges to items. The
graphical model stipulates that an item can have non-zero marginal utility to
an agent only if its corresponding edge is incident to the agent's
corresponding vertex. We study orientations (allocations that allocate each
edge to an endpoint) in this model, as they are particularly desirable.
  Our first contribution concerns MMS allocations of mixed manna (i.e. a
mixture of goods and chores) in the general model. It is known that MMS
allocations of goods exist when $m \leq n+5$. We generalize this and show that
when $m \leq n+5$, MMS allocations of mixed manna exist as long as $n \leq 3$,
there is an agent whose MMS threshold is non-negative, or every item is a
chore. Remarkably, our result leaves only the case where every agent has a
negative MMS threshold unanswered.
  Our second contribution concerns EFX orientations of multigraphs of goods. We
show that deciding whether EFX orientations exist for multigraphs is
NP-complete, even for symmetric bi-valued multigraphs. Complementarily, we show
symmetric bi-valued multigraphs that do not contain non-trivial odd multitrees
have EFX orientations that can be found in polynomial time.
  Our third contribution concerns EF1 and EFX orientations of graphs and
multigraphs of chores. We obtain polynomial-time algorithms for deciding
whether such graphs have EF1 and EFX orientations, resolving a previous
conjecture and showing a fundamental difference between goods and chores
division. In addition, we show that the analogous problems for multigraphs are
NP-hard.

</details>


### [12] [Single-Deviation Stability in Additively Separable Hedonic Games with Constrained Coalition Sizes](https://arxiv.org/abs/2510.12641)
*Martin Bullinger,Adam Dunajski,Edith Elkind,Matan Gilboa*

Main category: cs.GT

TL;DR: 研究了具有固定大小限制的可加分解合作博弈中的稳定性，分析了四种经典稳定性概念及其变体，并针对存在性问题给出了完整的结果和计算复杂度分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨在联盟大小受限的可加分解合作博弈中，不同类型的稳定性概念如何影响稳定结果的存在性及其计算复杂度。

Method: 方法包括分析四种经典稳定性概念（纳什稳定性、个体稳定性、契约纳什稳定性和契约个体稳定性），并考虑两种变体：一种是离开联盟后必须仍满足大小限制，另一种则无此限制。

Result: 结果为每种稳定性概念及其变体提供了关于存在性的完整刻画，并在仅有上限限制时，完全描述了计算复杂度。此外，还给出了契约个体稳定性和契约纳什稳定性的多项式时间算法。

Conclusion: 结论是不同稳定性概念在联盟大小受限的可加分解合作博弈中具有不同的存在性和计算复杂度特性，特别是一些特定的限制条件下可以获得高效算法。

Abstract: We study stability in additively separable hedonic games when coalition sizes
have to respect fixed size bounds. We consider four classic notions of
stability based on single-agent deviations, namely, Nash stability, individual
stability, contractual Nash stability, and contractual individual stability.
For each stability notion, we consider two variants: in one, the coalition left
behind by a deviator must still be of a valid size, and in the other there is
no such constraint. We provide a full picture of the existence of stable
outcomes with respect to given size parameters. Additionally, when there are
only upper bounds, we fully characterize the computational complexity of the
associated existence problem. In particular, we obtain polynomial-time
algorithms for contractual individual stability and contractual Nash stability,
where the latter requires an upper bound of 2. We obtain further results for
Nash stability and contractual individual stability, when the lower bound is at
least 2.

</details>
